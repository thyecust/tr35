<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>title</th>
      <th>subtitle</th>
      <th>age</th>
      <th>affiliation</th>
      <th>from</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Hongjie Liu</td>
      <td></td>
      <td></td>
      <td>Reexen Technology</td>
      <td>computing-internet-2022</td>
      <td><p>We live in a world of devices that are rarely or never turned off<em>—</em>hearing aids, various types of sensors, augmented-reality devices, smartphones. But batteries don’t stay charged forever, so it’s critical to minimize devices’ power consumption. Hongjie Liu, 34, has created novel ultra-low-power chip designs that can extend battery life more than 10 times by more efficiently processing analog signals and digital data. “My innovation is analog preprocessing combined with mixed-signal computing, a novel processing architecture that mimics some of the principles of the human brain,” she says. </p></td>
    </tr>
    <tr>
      <td>Stefanie Mueller</td>
      <td></td>
      <td></td>
      <td>MIT</td>
      <td>computing-internet-2022</td>
      <td><p>It’s easy to change the appearance of a digital photo by applying a digital filter. Now imagine the same principle applied to physical objects<em>—</em>clothing that could change its appearance daily or even hourly. Stefanie Mueller, 34, is developing a way to reprogram the appearance of objects using photochromic dyes with fine control over each color channel. “Developing this method required me to leverage knowledge from optics, materials science, hardware engineering, and computational optimization algorithms,” she says. Mueller thinks her innovation could be useful in product design. Instead of just buying a shirt, she says, you might buy a subscription that gives that shirt a new look every day.</p></td>
    </tr>
    <tr>
      <td>Uzoma Orchingwa</td>
      <td></td>
      <td></td>
      <td>Ameelio</td>
      <td>computing-internet-2022</td>
      <td><p>People coming out of prison often struggle to put their lives back together, but research has shown that family contact and access to education can dramatically improve their prospects. Uzoma Orchingwa, 31, CEO and cofounder of Ameelio, wants to offer those benefits to prisoners via a free communication and education platform. A big part of the problem, in Orchingwa’s view, is the $3 billion prison telecommunication industry, dominated by just two companies. “Families spend up to $500 a month to stay connected with incarcerated loved ones,” he says. His goal is to disrupt that industry and, in the process, help prisoners to earn degrees and jobs, thus reducing recidivism and incarceration.</p></td>
    </tr>
    <tr>
      <td>Sara Wahedi</td>
      <td></td>
      <td></td>
      <td>Ehtesab</td>
      <td>computing-internet-2022</td>
      <td><p>Sara Wahedi, 27, came up with the idea for Ehtesab following a suicide explosion that occurred near her home in Kabul, Afghanistan. As she searched for information after the tragedy, she wondered why a city like Kabul did not have a verified, monitored platform for emergency information<em>—</em>a situation that has become worse under the Taliban regime. Wahedi’s app, called Ehtesab, provides real-time alerts to Kabul residents on everything from electricity outages to explosions and gunfire. The app maps these incidents and updates them; alerts are sent straight to a user’s phone after they have been robustly verified.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Xu Zhang</td>
      <td></td>
      <td></td>
      <td>Carnegie Mellon University</td>
      <td>computing-internet-2022</td>
      <td><p>Moore’s Law, which has powered the drive toward ever-smaller, more powerful computers, has led to the likes of AI, cloud computing, and autonomous driving. But the law is reaching its limits because the billions of devices squeezed onto a silicon chip can only get so small before the laws of physics intervene. Xu Zhang, 34, has approached the problem by developing a kind of two-dimensional semiconductor that’s just atoms thick. “By transforming semiconductors from 3D to 2D, it is possible to truly push computing technologies to the ultimate atomic limit and enable a future of ubiquitous computing and ambient intelligence,” Zhang says.</p></td>
    </tr>
    <tr>
      <td>Setor Zilevu</td>
      <td></td>
      <td></td>
      <td>Meta and Virginia Tech</td>
      <td>computing-internet-2022</td>
      <td><p>Setor Zilevu, 27, is working at the intersection of human-computer interaction and machine learning to create semi-automated, in-home therapy for stroke patients. After his father suffered a stroke, Zilevu wanted to understand how to integrate those two fields in a way that would enable patients at home to get the same type of therapy, including high-quality feedback, that they might get in a hospital. The semi-­automated human-computer interaction, which Zilevu calls the “tacit computable empower” method, can be applied to other domains both within and outside health care, he says.</p></td>
    </tr>
    <tr>
      <td>Maayan Ziv</td>
      <td></td>
      <td></td>
      <td>AccessNow</td>
      <td>computing-internet-2022</td>
      <td><p>In 2015, Maayan Ziv, now 31, created a mobile app called AccessNow in response to her frustration trying to navigate inaccessible places in her wheelchair. Users can search for, review, and discover locations that meet their needs according to over 25 criteria, including step-free entrances and accessible parking and bathrooms. In 2021, AccessNow filed a patent application regarding its development of technology to detect accessibility features based on patterns “observed” in the built environment and collect and share that information. Using deep learning, AccessNow is training a data model that’s designed to deliver increasingly accurate, personalized accessibility information autonomously.</p></td>
    </tr>
    <tr>
      <td>Shelley Ackerman</td>
      <td>She co-invented a novel immunotherapy for difficult-to-treat cancers.</td>
      <td>29</td>
      <td>Bolt Biotherapeutics</td>
      <td>inventors-2021</td>
      <td><p>Using the body’s own immune system to fight cancer has shown promise against several types of tumors, but it’s not always effective. “There’s a whole subset of patients that it really doesn’t work well in,” says Shelley Ackerman.</p>  <p>Tumors have to be “hot,” or inflamed, for <a href="https://www.cancer.net/navigating-cancer-care/how-cancer-treated/immunotherapy-and-vaccines/understanding-immunotherapy">immunotherapy drugs</a> to work well. Hot tumors are characterized by the presence of a type of immune cell called T cells. Immunotherapy drugs give those T cells a boost, making them better cancer fighters. But many tumors are “cold” and thus evade the immune system. Without any T cells to work with, immunotherapy drugs fail against these tumors.&nbsp;</p>  <p>As a graduate student at Stanford, Ackerman worked with <a href="https://profiles.stanford.edu/edgar-engleman">Edgar Engleman</a>, a professor of medicine and pathology, to develop a therapy aimed at turning cold tumors into hot ones. The approach uses a tumor-targeting antibody chemically attached to an immune-stimulating small-molecule drug that prompts the immune system to recognize and attack the tumor, transforming it into a hot one invaded by tumor-killing T cells. Engleman founded a biotech company, <a href="https://www.boltbio.com/">Bolt Biotherapeutics</a>, in 2015 to commercialize the approach; Ackerman joined Bolt in 2018.&nbsp;</p>  <p>As a child, Ackerman lost her uncle and a close friend to metastatic cancer within a year, and that experience made her want to keep working on the therapy in hopes that it would one day be used to treat patients.&nbsp;</p>  <p>Last year, Bolt began testing its approach in patients with breast, gastric, and other tumors that express a protein known as <a href="https://www.breastcancer.org/symptoms/diagnosis/her2#:~:text=HER2%20(human%20epidermal%20growth%20factor,a%20role%20in%20the%20cancer.">HER2</a>. The company, which has raised $438 million in funding, is also developing drugs for colorectal, lung, and pancreatic cancers.</p></td>
    </tr>
    <tr>
      <td>Ryan Babbush</td>
      <td>Efficient quantum simulation algorithms might help find novel, powerful materials.</td>
      <td>32</td>
      <td>Google</td>
      <td>inventors-2021</td>
      <td><p>Molecules are complicated. Forget the grade-school picture of electrons orbiting a nucleus like planets around the sun. Electrons can be shared among many atomic nuclei. They interact with one another in ways described by the equations of quantum mechanics. It’s these complex interactions, which grow exponentially with the number of electrons, that largely govern chemical reactions and the properties of molecules.</p>  <p>Simulating these electrons with perfect precision might take a conventional computer millions of years. But algorithms running on quantum computers might be able to perform precise computations in days or even hours. This would provide clues on how to precisely design molecules with desired properties and tailor their reactions with amazing control.&nbsp;</p>  <p>Sufficiently <a href="https://arxiv.org/abs/1506.01029">precise quantum simulation</a> might allow chemists to create new compounds like better high-temperature superconductors, catalysts that could take nitrogen or carbon dioxide out of the air, new drugs, more efficient solar cells, strong lightweight materials for airplanes, and so forth. It would be a way to quickly figure out how a new substance would behave without actually having to synthesize it. It might herald a new age of materials science.</p>  <p>Between 2014 and 2020, Ryan Babbush published <a href="https://research.google/people/RyanBabbush/">dozens of papers</a>—together with collaborators at Google and elsewhere—that outlined dramatically more efficient quantum simulation algorithms. The upshot is that some quantum simulation calculations could, in principle, be done in hours, on a sufficiently powerful quantum computer.</p>  <p>Take the case of nitrogenase, an enzyme that some bacteria use to remove nitrogen from the air and create ammonia, a compound of nitrogen and hydrogen. This process, known as nitrogen fixation, is essential for agriculture, which is why nitrogen-based fertilizers are a linchpin of the world’s food system. Nitrogenase is a big molecule that includes a catalytic site known as <a href="https://www.nature.com/articles/ncomms10902">FeMoco</a>.</p>  <p>Currently, an energy-intensive technique known as the Haber-Bosch process produces most fertilizers, accounting for about 2% of humanity’s total energy usage. “If we could figure out how that enzyme [nitrogenase] is doing this, then we might be able to design an industrially viable alternative for producing fertilizer, which could scale and save a huge amount of energy,” Babbush says.&nbsp;</p>  <p>He and his collaborators have found a potential way to use a quantum computer to analyze FeMoco and shed light on the mechanism by which it first breaks the bonds between nitrogen atoms that are bound together in nitrogen gas and then succeeds in combining the nitrogen with hydrogen. (Babbush acknowledges that competing approaches using clever approximations to simulate molecules on classical computers might get there first.)</p>  <p>Another line of research that Babbush has advanced aims to figure out how quantum computers can calculate the behavior of electrons in metals and crystals. Potential applications could include finding better superconductors or making more efficient solar cells. In these materials, the repeating pattern of the atoms creates very complicated behavior among the interdependent electrons. And Babbush is figuring out how quantum computers can be used to make sense of these interactions.</p>  <p>If quantum computers succeed in remaking our material world, Babbush’s work will be one reason why. </p></td>
    </tr>
    <tr>
      <td>Amay Bandodkar</td>
      <td>His lightweight sensors could make wearable tech more useful and practical.</td>
      <td>33</td>
      <td>North Carolina State University</td>
      <td>inventors-2021</td>
      <td><p><a href="https://www.businessinsider.com/wearable-technology-healthcare-medical-devices">Wearable technology</a> can provide real-time information about a person’s health and fitness, but creating sensors that can collect data without a cumbersome and impractical system of staying powered has proved difficult. <a href="https://ece.ncsu.edu/people/ajbandod/">Amay Bandodkar</a> thinks he’s hit on a new way of creating “self-powered” biochemical sensors through unconventional technologies, making wearable tech lighter and less cumbersome. It’s about four times smaller and 20 times lighter than similar devices produced two years ago, he says.</p>  <p>The key to shrinking the sensor was overhauling how it’s powered. “All the groups that were working on this were using these really bulky batteries, and the sensor was around 3% of the total size and weight,” he says. So he built a sensor that doesn’t require a battery: it harnesses the catalytic properties of enzymes to generate signals without the need for power sources. While this concept can be used to develop self-powered sensors for some chemicals, for other kinds of sensors that still need a power source, Bandodkar has developed a <a href="https://bioelectronics.northwestern.edu/documents/nelectrsweatbatt.pdf">lightweight battery that runs on sweat</a>. It’s made of a magnesium anode and a cathode made of silver and silver chloride, separated by a dry cellulose membrane. When a person wearing it starts to perspire, the cellulose membrane absorbs the sweat and acts as an electrolyte, effectively turning the battery on and powering the sensor.</p>  <p>Bandodkar has successfully tested out a heart-rate sensor running on his battery, opening the gateway for heart-monitoring wearables. </p></td>
    </tr>
    <tr>
      <td>Jonathan Gootenberg</td>
      <td>Expanding the capabilities of gene editing.</td>
      <td>30</td>
      <td>MIT</td>
      <td>inventors-2021</td>
      <td><p>The gene-editing tool CRISPR uses a <a href="https://www.technologyreview.com/2017/10/25/148146/crispr-20-is-here-and-its-way-more-precise/">protein called Cas9</a> to snip out a targeted part of the genome. It does amazing work but has downsides. It can cause unintended edits to other places in the genome, and if you want to make only a temporary tweak, Cas9 can’t do it.&nbsp;</p>  <p>Jonathan Gootenberg is creating other editing tools to get around these shortcomings and add to the capabilities of CRISPR. ­Gootenberg has used <a href="https://www.cell.com/pb-assets/products/research-arc/infographics/CrisprVizInfo_vol1a.pdf">Cas12</a><em>—</em>a more compact protein than Cas9<em>—</em>to edit many genes at a time. This capability could be used to edit a patient’s immune cells so that they fight cancer.&nbsp;</p>  <p>Then there’s <a href="https://www.nature.com/articles/nature24049">Cas13</a>. ­Gootenberg and his colleague <a href="https://www.technologyreview.com/innovator/omar-abudayyeh/">Omar ­Abudayyeh</a> (a 2020 Innovator Under 35) demonstrated that the protein could target RNA instead of DNA<em>—</em>an intriguing finding. Many viruses have RNA as their genetic material, and bacteria have both DNA and RNA, so the researchers reasoned that you could use Cas13 to find genetic material from pathogens in human cells. That led to repurposing the gene-editing tool as a paper-based diagnostic test, and in 2019 ­Gootenberg and Abudayyeh cofounded <a href="https://sherlock.bio/">Sherlock Biosciences</a> to commercialize the technology.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Nicholas Harris</td>
      <td>Shining light through optical chips might be the fastest way for neural networks to make decisions.</td>
      <td>33</td>
      <td>Lightmatter</td>
      <td>inventors-2021</td>
      <td><p>For decades physicists and engineers have dreamed of making optical chips that use photons, not electrons, to do computing. Such circuits could be lightning fast and energy efficient. But making them work has been difficult.</p>  <p>In 2017, Nicholas Harris, together with <a href="http://ADD LINK">Yichen Shen</a> and other colleagues at MIT, published a <a href="https://www.nature.com/articles/nphoton.2017.93">widely cited paper</a> describing a design that allowed them to calculate the outputs of neural networks that had been conventionally trained.</p>  <p>The paper describes a circuit of 56 programmable interferometers—devices that carefully break apart and recombine light waves.&nbsp;The circuits they created solved a simplified problem of recognizing vowels correctly—distinguishing about three quarters of the 180 cases they tried. This wasn’t as good as a conventional computer, which got over 90% of them right. Shortly thereafter, Shen and Harris launched competing startups.</p>  <p>Once a given neural network has been trained and implemented on an optical chip, performing inferences— figuring out which vowel corresponds to which sound, or how an autonomous car should react if a pedestrian steps into the street—can be almost as simple as shining light through it. This has the advantage of being both fast and energy efficient.</p>  <p>In March 2021, <a href="https://lightmatter.co/">Lightmatter</a> announced it would soon start selling a <a href="https://lightmatter.co/products/envise/">“machine-learning accelerator” chip</a>. “It’s just a completely different kind of computer,” says Harris. “Right now we’re at about a factor of 20 times more efficient than the most advanced node in digital computers.” Lightmatter closed a second round of funding in May, bringing its total investment to $113 million.</p></td>
    </tr>
    <tr>
      <td>Yichen Shen</td>
      <td>Optical chips that can make calculations for neural networks are poised to become big business.</td>
      <td>32</td>
      <td>Lightelligence</td>
      <td>inventors-2021</td>
      <td><p>There are two basic types of computations involving neural networks. First, the networks must be trained, which usually involves showing them lots of data, causing them to adjust the strength of the connections between their numerous “neurons.” Next, those existing connections are used to make decisions. It’s the difference between learning to drive and driving.</p>  <p>The difference is crucial. If a neural network takes weeks to learn how to recognize images, that’s not necessarily a problem. But if it is driving an autonomous car, it needs to be able to make life-or-death inferences in fractions of a second.</p>  <p>That’s where <a href="https://uncw.edu/phy/documents/raphael_06.pdf">optical computers</a> come in. Despite decades of research, they’ve never worked that well. It’s harder to manipulate photons than electrons. But for certain types of computations—like those commonly needed when using an existing neural network to make inferences—photons are just the thing.</p>  <p>In 2017, Yichen Shen and <a href="http://ADD LINK">Nicholas Harris</a> published a widely cited paper on the use of optical circuits for machine-learning tasks including speech and image recognition. Their design, one review article notes, “represents a truly parallel implementation of one of the most crucial building blocks of neural networks using light, and modern foundries could easily mass-fabricate this type of photonic system.” This means that optical computers on a chip could become a huge business, with one in every device that uses a neural network to make decisions.</p>  <p>Shen and Harris now run competing startups. Shen’s firm, <a href="https://www.lightelligence.ai/">Lightelligence</a>, released a <a href="https://venturebeat.com/2019/04/15/lightelligence-releases-prototype-of-its-optical-ai-accelerator-chip/">prototype optical AI chip</a> in 2019, and Shen says they have secured over $100 million in funding.</p></td>
    </tr>
    <tr>
      <td>Virginia Smith</td>
      <td>Her AI techniques are efficient and accurate while preserving fairness and privacy.</td>
      <td>31</td>
      <td>Carnegie Mellon University</td>
      <td>inventors-2021</td>
      <td><p>When <a href="https://www.cs.cmu.edu/~smithv/">Virginia Smith</a> began her PhD in artificial intelligence, she had a question: How do you train a neural network on data that is stored across multiple machines?&nbsp;</p>  <p>Her attempts to answer it have made her a leader in the field of <a href="https://medium.com/@ODSC/what-is-federated-learning-99c7fc9bc4f5">federated learning</a>, which seeks to handle data spread across hundreds, or even millions, of remote sources.&nbsp;</p>  <p>Google researchers first introduced federated learning in 2017 to use with the company’s mobile devices. The method they devised involved training millions of neural networks locally before sending them to a company server to be merged together in a master model. It allowed the master model to train on data from every device without making it necessary to centralize that data. This not only reduced latency in the mobile experience but could also improve each user’s data privacy.</p>  <p>But combining millions of AI models also risks creating a central model that performs well on average but poorly for outliers—for example, voice recognition software that fails when the speaker has an unfamiliar accent.</p>  <p>So Smith proposed a new technique for more <a href="https://arxiv.org/abs/2012.04221">“personalized” federated learning</a>. Rather than merge a million localized models into one, it merges the most similar localized models into a few—the more heterogeneous the data, the greater the number of final models. Each model still learns from many devices but is also tailored to specific subsets of the user population.</p>  <p>Smith also works to overcome other challenges in federated learning, such as accounting for different power and memory constraints on different devices. To encourage more research, she co-created an open-source tool that lets researchers test their federated techniques on more realistic data sets and in more realistic environments. </p></td>
    </tr>
    <tr>
      <td>Xiao Sun</td>
      <td>He designs imprecise—but energy-efficient—AI hardware and software.</td>
      <td>34</td>
      <td>IBM</td>
      <td>inventors-2021</td>
      <td><p>Artificial-intelligence systems often require a vast amount of computation. That’s why in recent years, AI hardware researchers have been striving to achieve lower precision, which is good enough to produce a correct answer but avoids the use of calculations that require keeping track of lots of digits.</p>  <p>Deep learning relies on networks that might have dozens of layers, and millions, or even billions, of parameters that must be adjusted to the correct values, a process called training the network. This often takes days or weeks of computations using hundreds of specialized chips.</p>  <p><a href="https://scholar.google.com/citations?user=TNXVwh8AAAAJ&amp;hl=en">Xiao Sun</a> is part of a <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-xsun">research group at IBM</a> that has been finding ways to perform those computations using three-digit, or even just two-digit, numbers (in contrast, a modern laptop or cell phone uses 20 digits to make calculations, while most dedicated machine-learning chips use five).&nbsp;</p>  <p>The real trick is in finding techniques that allow for small numbers to be used throughout the computation. You might still have to do many trillions of computations, but each one will be far simpler. This saves both time and energy—using two-digit numbers is more than 20 times more energy efficient than doing the same calculations using numbers in the billions, according to a paper by Sun and colleagues at IBM.</p>  <p>In February, IBM announced a <a href="https://www.ibm.com/blogs/research/2021/02/ai-chip-precision-scaling/">new chip</a>, based in part on Sun’s work, that trains neural networks using computations involving mostly three-digit numbers. The company hopes to use it not only to train large neural networks in cloud computing centers but also in mobile phones that could train on local data.</p></td>
    </tr>
    <tr>
      <td>Jie Xu</td>
      <td>She makes durable, easy-to-manufacture polymer semiconductors for skin-like electronics.</td>
      <td>33</td>
      <td>Argonne National Laboratory</td>
      <td>inventors-2021</td>
      <td><p><a href="https://www.anl.gov/profile/jie-xu">Jie Xu</a> has made printable, stretchable electronics viable for mass production. Her <a href="https://www.nature.com/articles/nature25494?WT.feed_name=subjects_electronic-devices">multiple breakthroughs</a> could be used in future wearable technology, advanced robotics, and human-computer interfaces with sensors connected to the skin.</p>  <p>The key for Xu was inventing polymer circuits that kept working despite being flexed, stretched, and repeatedly moved. That had been a challenge for researchers until 2016, when Xu engineered a two-polymer coating applied to a rubbery surface that could be stretched to twice its size and still conduct electricity.&nbsp;</p>  <p>In 2019, she refined the technology so that her stretchable semiconductors could be mass-produced using roll-to-roll manufacturing, a common industrial fabrication process used to print anything from textiles to plastics on large rollers. It was the first time anyone had achieved such a feat at scale.&nbsp;</p>  <p>In the short term, Xu’s materials and manufacturing inventions can make flexible displays and skin-worn medical sensors much more practical and easy to make. Samsung Electronics has already patented two methods Xu helped define during collaboration with the company. Xu’s materials could also aid in the design of prosthetics with functional skin-like outer coverings.&nbsp;</p>  <p>Wary of adding yet more plastics into the world, Xu is searching for versions of the polymer semiconducting materials that are recyclable or biodegradable. “I think that kind of idea should be integrated from the very beginning of any commercial material,” she says. </p></td>
    </tr>
    <tr>
      <td>Jacob Becraft</td>
      <td>He runs a company that’s figuring out the next steps for messenger RNA.</td>
      <td>30</td>
      <td>Strand Therapeutics</td>
      <td>entrepreneurs-2021</td>
      <td><p>Safe and effective covid-19 vaccines have finally provided an exit to the pandemic. The most innovative of these vaccines use <a href="https://www.technologyreview.com/2021/02/05/1017366/messenger-rna-vaccines-covid-hiv/">messenger RNA</a>—strings of nucleic acids—to instruct cells to make a protein found in the virus, causing the body to produce antibodies against it. Now scientists are eyeing all sorts of other potential uses for this underlying technology.</p>  <p>“With covid-19, we have gone from mRNA being potentially useful to saying we know it works in humans,” says Jacob Becraft. He runs a startup called <a href="https://www.strandtx.com/">Strand Therapeutics</a>, which is working on the next step for mRNA—ways to “program” the molecules to do additional useful tricks, like turn on only in specific cell types, at specific times, or automatically copy themselves so as to strengthen their effects.&nbsp;</p>  <p>Though mRNA’s effects are temporary (because it’s an unstable molecule), using it is in many ways simpler, safer, and faster than trying to change the genome of a cell. One idea the company is pursuing is to use injections of mRNA to instruct the body’s immune cells to attack cancers of the skin and breast.&nbsp;</p>  <p>Becraft grew up in a small farming community in central Illinois, famous as home to a federal lab that discovered how to mass-produce penicillin during World War II. In high school, he says, he didn’t have patience for pictures of cells, with their labeled parts.&nbsp;</p>  <p>“It wasn’t until college that I got exposed to biology as a machine, not just a list of things to memorize,” he says. “But when someone tells me how a system works, I get it. I can imagine it.” </p></td>
    </tr>
    <tr>
      <td>Janice Chen</td>
      <td>She’s using CRISPR to make new diagnostic tests.</td>
      <td>30</td>
      <td>Mammoth Biosciences</td>
      <td>entrepreneurs-2021</td>
      <td><p>Janice Chen was jumping into an Uber, cramming in equipment the size of a microwave. At the time a PhD student at the University of California, Berkeley, Chen had been invited to a lab to look for the human papillomavirus in hospital medical samples using a new technique she had created.</p>  <p>Soon enough, bingo. Her test, which uses the gene-editing tool CRISPR, was able to spot the virus nearly every time, offering a new way to test for germs. She and several other students, along with <a href="https://www.technologyreview.com/2020/10/07/1009601/nobel-prize-chemistry-crispr-gene-editing-doudna-charpentier/">Jennifer Doudna</a>, the co-discoverer of CRISPR, cofounded a company with plans to develop a new generation of testing instruments. They called it <a href="https://mammoth.bio/">Mammoth Biosciences</a>.</p>  <p>The diagnostics business isn’t easy to break into: a few companies with well-established technologies dominate. Chen is now in charge of a team of 40 as the chief technology officer of Mammoth. She says she leans on her experience playing chess competitively as a teenager, when she learned how to build a position move by move, make meaningful sacrifices, and get inside competitors’ minds.&nbsp;</p>  <p>Chen grew up in Salt Lake City. Her parents were immigrants from China. Her brother is a world champion and Olympic medalist in figure skating. When she was growing up, she says, her parents urged her and her siblings to “find your passion and do your best to move it forward in a significant way.”</p>  <p>Chen crammed for years studying chess moves but ended up finding her real interest while moonlighting at her father’s biotech supply company. That’s where she first copied genes and engineered a bacterium.&nbsp;</p>  <p>Then, at Johns Hopkins University, she had a chance to help out on a large ongoing project to assemble the entire genome of a yeast cell from DNA parts. As an undergraduate, she did menial lab tasks. Still, here was life being engineered from the ground up. And she was part of it.</p>  <p>For her PhD, Chen landed a spot in <a href="https://doudnalab.org/">Doudna’s Berkeley lab</a>, where CRISPR editing had been co-developed in 2012.&nbsp;</p>  <p>Chen joined a fast-paced hunt to discover and understand even more types of DNA editors and harness them for new uses. She demonstrated a way that a particular gene-editing enzyme could be used as a diagnostic test. Her test could find a specific sequence of viral DNA in a sample, cut it, and unleash a fluorescent signal that would report the result.&nbsp;</p>  <p>That looked useful enough for infectious-disease testing to try to commercialize it, which is what led her to cofound Mammoth in 2017.&nbsp;</p>  <p>Then came covid-19. When the rollout of the standard tests stumbled in the spring of 2020, the US Food and Drug Administration gave Mammoth and dozens of other smaller companies an emergency green light to sell their tests for the virus. It was a crisis, and that meant the purse strings were loosened too. Mammoth has won $30 million in government funding since the pandemic began.&nbsp;</p>  <p>As of May 2021, Mammoth was preparing to commercialize the company’s first product, kits that public health labs can use to run 1,500 simultaneous covid-19 tests with less human intervention than existing ones require. </p></td>
    </tr>
    <tr>
      <td>Tammy Hsu</td>
      <td>Her new dye can make one of the world’s most common types of clothing more environmentally friendly.</td>
      <td>30</td>
      <td>Huue</td>
      <td>entrepreneurs-2021</td>
      <td><p>Many consumers don’t realize that indigo, the signature color of denim, requires synthetic chemicals like formaldehyde and cyanide, which can be harmful to workers and can sometimes contaminate local water sources. Given that jeans are one of the most ubiquitous clothing items in the world, this is a huge environmental problem.</p>  <p><a href="https://scholar.google.com/citations?user=9xumpSMAAAAJ&amp;hl=en">Tammy Hsu</a>, the chief scientific officer of <a href="https://www.huue.bio/">Huue</a>, worked with colleagues to study how color is made in nature and program microbes to enzymatically produce the shade they wanted. The result is a sustainable solution that doesn’t rely on harmful processes or chemicals. Now the challenge is to make the natural dye as cheap to use as the synthetics the industry relies upon. “The chemical industry has had 100 years to hone their process and make it cost efficient,” Hsu says. “We were founded two years ago. We’re trying to catch up with that. That’s one of our biggest goals, to drive down the price of our process.”</p>  <p>Huue is on track to release its indigo dye next year. Next up for Hsu is figuring out how to coax microbes to produce a range of different dyes. “We’re trying to provide the fashion industry with an alternative way,” she says.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Sara Spangelo</td>
      <td>Her tiny satellites could bring connectivity to the remotest places on Earth.</td>
      <td>34</td>
      <td>Swarm Technologies</td>
      <td>entrepreneurs-2021</td>
      <td><p>Sara Spangelo didn’t quite make it as an astronaut. But four years after an unsuccessful tryout with Canada’s space agency, she’s achieved her own space milestone: unveiling the world’s lowest-cost always-available satellite communications network.</p>  <p>Spangelo, who holds a PhD in aerospace engineering from the University of Michigan, is CEO of <a href="https://swarm.space/">Swarm Technologies</a>, which seeks to provide affordable data services for devices anywhere on Earth. Today, nearly 90% of the planet’s surface, including oceans, deserts, and polar regions, lacks internet access. Connecting via satellite has long been cost-prohibitive, because satellite networks typically cost billions of dollars to deploy and maintain.</p>  <p>The key to lowering costs was to bring down size: Swarm’s satellites, roughly the size of a slice of French toast, are the smallest two-way communication devices in orbit today. Because they’re so compact, they can hitch rides on commercial rockets for bargain prices: total launch costs for Swarm’s full constellation of 150 satellites, which the company will finish placing in low Earth orbit by the end of 2021, will run less than $3 million.&nbsp;</p>  <p>Swarm’s data connection, which uses the VHF radio spectrum, won’t enable seafarers to stream Netflix: its current transfer rate of 1 kilobit per second is similar to 1990s dial-up. Swarm’s niche, rather, is giving customers the ability to transmit small yet highly useful packets of information from the world’s most far-flung places. This enables them to remotely monitor water supplies, detect leaks in pipelines, measure soil contents, track wildlife, or guarantee the temperature of vaccines in cold-chain transport. </p></td>
    </tr>
    <tr>
      <td>Emma Beede</td>
      <td>Her work helps ensure that fancy AI tools perform in the real world.</td>
      <td>30</td>
      <td>Google</td>
      <td>visionaries-2021</td>
      <td><p>Emma Beede has an unorthodox claim to technological fame: a study she ran showed that one of her employer’s new technologies needed critical improvements before it could be deployed in the real world. </p>  <p>Beede’s study tested a <a href="https://www.blog.google/technology/health/new-milestones-helping-prevent-eye-disease-verily/">deep-learning algorithm created by Google Health</a> to screen eye images for diabetic retinopathy, a condition caused by high blood sugar that damages the retina and makes it difficult to sense light. Beede found that the algorithm, which had performed with over 90% accuracy in the lab, <a href="https://research.google/pubs/pub48768/">presented problems in real-world tests</a> across 11 clinics in Thailand. She found that this was because the algorithm was trained on high-quality eye scans, and when the quality of images taken in the clinic suffered because of factors like poor lighting, the scans were rendered useless. More than 20% of retinal scans were rejected, leaving frustrated patients and their health-care providers looking for more conventional alternatives.</p>  <p>Beede thinks such unsatisfying results are a critical example of the need to ensure that AI-powered tools for humans are put through rigorous and meticulous testing before being deployed. “Humans in the real world are complicated, and we should account for that,” she says. “We need to be doing our due diligence to study those downstream effects so that we can mitigate any risk for harm.”</p></td>
    </tr>
    <tr>
      <td>Sara Berger</td>
      <td>Employing machine learning to make pain management more accessible.</td>
      <td>33</td>
      <td>IBM Research</td>
      <td>visionaries-2021</td>
      <td><p>Developing smart technology to help patients assess and manage pain is a deeply personal pursuit for <a href="https://researcher.watson.ibm.com/researcher/view.php?person=ibm-Sara.E.Berger">Sara Berger</a>, who spent years watching her parents cope with chronic painand struggle to navigate the medical system. “A lot of the suffering from having chronic pain is about no longer having control over your body and your body’s sensations,” says Berger. “Being able to use digital technologies provides a sense of control and creates more informed conversations with physicians.”</p>  <p>A neuroscientist at <a href="https://www.research.ibm.com/labs/watson/">IBM’s T.J. Watson Research Center</a>, Berger employs machine learning to quantify long-term pain and help predict ways to relieve it. With wearables and environmental sensors, she can capture metrics including heart rate, sleep patterns, and even the acoustic properties of a patient’s speech, all of which provide data about the person’s pain experience. Those metrics can then be analyzed using machine learning, taking into consideration other factors such as the emotional toll that often results from chronic discomfort, decreased mobility, or lost time with loved ones. What results is a far more holistic and informed assessment and treatment plan than those informed by traditional pain scales, which are prone to bias and oversimplification. “Pain isn’t linear,” says Berger. “Our assessment of it shouldn’t be either.”</p>  <p>Many people with chronic conditions, especially women and people of color, feel marginalized by the health care system and experience bias when they seek treatment for pain. “I’m on a mission to transform pain management into an accessible, personalized, and trusted experience for individuals across different socioeconomic backgrounds,” says Berger.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Priya Donti</td>
      <td>Finding climate-change solutions via computer science and public policy.</td>
      <td>28</td>
      <td>Carnegie Mellon University</td>
      <td>visionaries-2021</td>
      <td><p><a href="https://priyadonti.com/">Priya Donti</a> knows that a problem as complex and pervasive as climate change won’t be solved by one discipline alone. That’s why she cofounded <a href="https://www.climatechange.ai/">Climate Change AI</a>, an interdisciplinary organization that brings together academics and industry experts to demonstrate how machine learning can help.&nbsp;</p>  <p>Donti’s work combines computer science, engineering, and public policy, and her research focuses on how electric grids can more reliably integrate renewable energy.&nbsp;</p>  <p>In 2019, Donti was also a lead author on an influential paper titled <a href="https://arxiv.org/abs/1906.05433">“Tackling Climate Change with Machine Learning.”</a></p>  <p>“The tremendous response we received from that paper demonstrated just how many people felt a moral obligation to work on climate change but who also felt like they lacked the necessary community to do that work,” says Donti.&nbsp;</p>  <p>Donti, a second-generation Indian American says she’s well aware of the immense burden already felt by some of the planet’s most vulnerable people and recognizes that climate change will only exacerbate those burdens. “We know that the world’s most disadvantaged populations are going to be disproportionately affected by climate change,” says Donti. “Climate Change AI wants to help mitigate that.”&nbsp;</p></td>
    </tr>
    <tr>
      <td>Leah Ellis</td>
      <td>A new, climate-friendly way to make cement.</td>
      <td>31</td>
      <td>MIT, Sublime Systems</td>
      <td>visionaries-2021</td>
      <td><p>Making cement is one of the single largest drivers of climate change, <a href="https://www.bbc.com/news/science-environment-46455844">accounting for almost a tenth of global carbon dioxide emissions</a>. Ground-up limestone is typically cooked together with sand, clay, and other materials in kilns that are heated to around 1,500 ˚C (2,700 ˚F).&nbsp;</p>  <p>The limestone releases carbon dioxide as it breaks down, as do the fossil fuels that are burned to achieve those temperatures. For every resulting pound of cement, roughly a pound of carbon dioxide escapes into the atmosphere.</p>  <p>Leah Ellis came up with a better way. <a href="https://www.activate.org/sublime-systems">Sublime Systems</a>, a startup she cofounded in March 2020, dissolves pulverized limestone in water and then applies an electric current to trigger a series of chemical reactions.&nbsp;</p>  <p>The general idea of using electricity rather than heat to break down limestone has been around for a while, though earlier attempts worked at higher temperatures. Sublime’s apparatus operates at room temperature. Lots of carbon dioxide is still released from the limestone, but it’s much easier to capture and reuse<em>—</em>the gas comes out of one end of the device, mixed with oxygen, while hydrogen gas is released from the other end.</p>  <p>This electrochemical reaction produces pure lime, a white powder made of calcium, oxygen, and hydrogen. It can then be cleanly cooked in a kiln with silicon and oxygen to make cement. Ellis and her colleagues are still considering a variety of potential business models. Because they can rely on increasingly cheap electricity from solar or wind farms, Ellis says, they’ll be able to match the prices of standard cement. </p></td>
    </tr>
    <tr>
      <td>Kayla Lee</td>
      <td>She's working to build a more diverse future for quantum computing.</td>
      <td>30</td>
      <td>IBM</td>
      <td>visionaries-2021</td>
      <td><p>In 2018 <a href="https://newsroom.ibm.com/Harvard-Heritage-HBCUs-How-Dr-Kayla-Lee-is-Driving-Inclusive-Innovation">Kayla Lee</a> joined the enterprise consulting group at IBM, where part of her job is to persuade clients they should be interested in quantum computing. For each client, she says, she needs to figure out the same thing: “How do you make this new technology that is a little bit complicated, and sounds kind of like a science project, relevant to them?”</p>  <p>There are parallels between that work and her other project: leading the launch of the <a href="https://newsroom.ibm.com/2020-09-17-IBM-Establishes-First-Quantum-Education-and-Research-Initiative-for-Historically-Black-Colleges-and-Universities">IBM-HBCU Quantum Center</a>, a partnership between the company and 23 historically black colleges or universities, which aims to make quantum computing more accessible to Black students and faculty. Lee wants to give Black STEM students and scholars the foundation to excel in this emerging field.</p>  <p>Through the partnership, HBCUs have access to IBM’s cloud-based quantum computing service, which undergraduates, graduates, and faculty can use for research. The partnership not only supports Black faculty working on quantum projects but provides funding to “seed these research projects,” says Lee. In one example, IBM recently partnered with the International Society for Optics and Photonics to create a <a href="https://spie.org/about-spie/community-support/ibm-spie-hbcu-faculty-accelerator-award-in-quantum-optics-and-photonics?SSO=1">faculty award in quantum optics and photonics</a> specifically for IBM-HBCU Quantum Center members.  </p>  <p>Lee sees the project as a way to support Black students in an area where they’re grossly underrepresented. In 2017, Black students were awarded just 3% of all bachelor’s degrees in physics in the United States, and only 2% of physics PhDs. What’s more, according to the National Science Foundation, a third of all Black students who have earned doctoral degrees got their <a href="https://www.nsf.gov/news/special_reports/announcements/081920.jsp">bachelor’s degrees at HBCUs</a>, but to date few HBCUs have offered opportunities for students to study or conduct research in quantum information.&nbsp;</p>  <p>Lee aims to change that. She wants the Quantum Center to create “clear opportunities for engagement” and simply show students “what quantum scientists look like.” This is especially important, she says, because quantum computing is such a young field. “We really are at the start of a new model of computation, in the same way that we were at the start of a new model ... back in the ’60s,” she says. “So the questions we’re asking today are: What do the qubit implementations look like? How do we make less noisy qubits? What does <em>that</em> architecture look like?”</p>  <p>But for Lee there’s a further question about quantum computers: “I’m more focused on who gets to use them.”&nbsp;</p>  <p>The question of who gets the opportunities to work on this cutting-edge technology will shape the way the field develops. She points to artificial intelligence, which is already known to be afflicted by problems with racial bias. She says this problem could be exponentially worse in quantum computing, both because of the complexity and inscrutability of the machines and because “there are even fewer representative people” in the field. </p></td>
    </tr>
    <tr>
      <td>Dorsa Sadigh</td>
      <td>She uses simulated environments to teach robots to be better collaborators with people.</td>
      <td>30</td>
      <td>Stanford University</td>
      <td>visionaries-2021</td>
      <td><p>By developing new ways for computers to anticipate people’s actions, <a href="https://dorsa.fyi/">Dorsa Sadigh</a> wants to help pave the way for a future in which human and robots do things like share the roads.</p>  <p>In one widely cited <a href="https://iliad.stanford.edu/pdfs/publications/sadigh2016planning.pdf">paper</a> from 2016, she and her colleagues considered the idealized case of two cars, one driven by a person and another by a computer program. She first had real people drive a car in a video-game-like simulation with several autonomous counterparts that followed preplanned routes. On the basis of people’s behavior in the simulation, she developed a model for how humans drive, which the robot driver then used to devise new strategies for interacting with them. Without ever being explicitly told to do so, it did things like slowly backing up at an intersection, encouraging the “human” to go first. It also developed an attitude, learning how to cut human drivers off or force them to change lanes by swerving toward them.</p>  <p>More recently Sadigh and Dylan Losey, at the time her postdoctoral student, taught <a href="http://www.roboticsproceedings.org/rss16/p011.pdf">robots in a simulated setting how to trick humans</a> in a game that involves negotiating who will do more work in carrying plates to a table. “This robot is capable of bringing two plates, but misleads the human to believe that it can only carry one in order to reduce its overall effort,” they wrote in a paper on the work. Teaching robots to be lazy might not sound particularly worthwhile. But Sadigh and Losey are thinking of future applications in which robots might be called upon to help stroke patients in their recovery, for example. Robots, they say, “need to make intelligent decisions that motivate user participation.”</p></td>
    </tr>
    <tr>
      <td>Kaitlyn Sadtler</td>
      <td>Her test was among the first to determine how many people had been infected with covid-19.</td>
      <td>31</td>
      <td>National Institutes of Health</td>
      <td>visionaries-2021</td>
      <td><p>In early 2020, <a href="https://www.nibib.nih.gov/about-nibib/staff/kaitlyn-sadtler">Kaitlyn Sadtler</a> envisioned a long, slow season getting her lab up and running. Then covid-19 happened. Within weeks, she and her team were among the first to develop an <a href="https://pubmed.ncbi.nlm.nih.gov/32511472/">effective antibody assay</a> capable of determining how many people had been infected with covid-19, whether they’d shown any symptoms or not.</p>  <p>Antibodies tag viruses for destruction and help the body mount an immune response. Those antibodies can linger for months. Existing tests didn’t pinpoint the unique antibodies for the covid-19 virus, leading to false positives among people who had previously been exposed to other coronaviruses. Sadtler and her team at NIH made a highly sensitive antibody test, which uses six different assays to more accurately identify the presence of covid-19 antibodies. Early results published in January confirmed that about <a href="https://pubmed.ncbi.nlm.nih.gov/33532807/">16.8 million Americans had been infected with covid-19</a> but hadn’t been diagnosed. (Sadtler will update those findings this fall and estimates that as many as one-third of all Americans have been infected with the virus.)&nbsp;</p>  <p>The blood test is sensitive enough to determine whether an individual has antibodies from the virus itself or in response to a vaccine, and it can distinguish between variants of the virus as well. It’s simple and cheap to use, making it practical in both rich and poor countries. “This is a global pandemic,” says Sadtler, “which means we need to think globally.” </p></td>
    </tr>
    <tr>
      <td>Varun Sivaram</td>
      <td>Designing new public policies to promote energy innovation.</td>
      <td>32</td>
      <td>Biden-Harris administration</td>
      <td>visionaries-2021</td>
      <td><p><a href="https://www.varunsivaram.com/">Varun Sivaram</a> earned his doctorate researching novel solar materials, but when he graduated in 2013, it wasn’t clear where he could apply those skills in the private sector.</p>  <p>Very few startups working on advanced approaches had survived the clean-tech bust of the early 2010s. Commodity silicon solar panels, mostly made in China, dominated the business.&nbsp;</p>  <p>That experience prompted him to begin exploring what changes to the innovation system would be required in order to develop better and cheaper clean energy technologies. In studies and books, Sivaram <a href="https://www.varunsivaram.com/books">argued</a> that governments must provide far more funding and <a href="https://www.energypolicy.columbia.edu/research/commentary/bring-emissions-slashing-technologies-market-united-states-needs-targeted-demand-pull-innovation">early policy support</a> for crucial technologies. He also concluded that solar power would still require <a href="https://www.nature.com/articles/nenergy201636.epdf?shared_access_token=dRmrdYeaQdfT2Al2osmRZtRgN0jAjWel9jnR3ZoTv0NXc2hjZ25Lm7Rw67TPp-P0TM8jucoY28MEzkKIYyStSEPGBN_OJSagplbfw4XpbAKcnLrOfI_eXdcZI_yNww5R1BzzdvKJukroU2pYuA5DcyxiURCXxWSr_vva9PjN1MVGoILbzLbr1LV-PYKMFEx0CgLDkgIJTDg8sQKGK0KPEQ1crO2Z9mCxntZWBGCYhhU%3D">significant advances</a> to generate an ever larger share of electricity.</p>  <p>He worked on these issues directly as chief technology officer at ReNew Power, a large Indian renewable energy company. Now he’s joined the Biden administration, where he advises John Kerry, the US climate czar, and serves as his senior director for clean energy, innovation, and competitiveness. Sivaram traveled to India with Kerry, who negotiated <a href="https://www.state.gov/u-s-india-joint-statement-on-launching-the-u-s-india-climate-and-clean-energy-agenda-2030-partnership/">a partnership</a> to help that nation achieve its 2030 climate goals. Those include reaching 450 gigawatts of renewable capacity.</p>  <p>Sivaram believes that innovation is the most powerful lever the US has to help the rest of the world raise its climate ambitions. Driving down the cost of carbon-free technologies makes it cheaper, easier, and more politically palatable to accelerate the shift to emissions-free energy. Sivaram adds that this is particularly crucial for poorer nations, which often can’t afford to sacrifice economic growth. Without such advances, emissions in emerging economies will soar in coming decades, he warns. &nbsp;</p></td>
    </tr>
    <tr>
      <td>Aäron van den Oord</td>
      <td>His AI system creates artificial voices that sound remarkably human.</td>
      <td>33</td>
      <td>DeepMind</td>
      <td>visionaries-2021</td>
      <td><p>In 2016, <a href="https://scholar.google.com/citations?user=TqUN-LwAAAAJ&amp;hl=en">Aäron van den Oord</a> had just won an award for his research in image generation when he was struck by an idea. If his technique could learn to predict a two-dimensional sequence of pixels, could it also learn to predict a waveform and thus generate realistic voices? The idea was intriguing but seemed like a long shot. His manager at <a href="https://deepmind.com/">DeepMind</a>, an AI research subsidiary of Google, gave him two weeks to try it out, saying that if it didn’t work, he should move on to something else.</p>  <p>The results beat everyone’s expectations. Within two weeks, van den Oord had a prototype. Within three months, it was generating more realistic voices than any existing systems. Within another year, Google had begun using <a href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio">WaveNet</a>, as the system came to be called, to generate voices for Google Assistant.</p>  <p>WaveNet now powers 51 voices as well as Google’s newest voice assistant, which calls salons and restaurants on behalf of users to book appointments or reserve tables. The results are startlingly realistic. When Google CEO Sundar Pichai first demoed <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex</a> in 2018, with all its human-like “umms” and “ahs,” it set a new bar for what can be possible when people communicate with machines.</p>  <p>While voice assistants need to do more than just generate a synthetic voice<em>—</em>they also need to be able to recognize when someone is talking and understand what’s being said, each of which is a challenge unto itself<em>—</em>researchers have long sought to create the right artificial voice for achieving natural and engaging conversations. “There’s a lot of meaning in a voice,” says van den Oord.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Aadeel Akhtar</td>
      <td>His bionic hands combine sensitivity with affordability.</td>
      <td>34</td>
      <td>Psyonic</td>
      <td>humanitarians-2021</td>
      <td><p><a href="https://www.aadeelakhtar.com/">Aadeel Akhtar</a> has developed algorithms that make upper-limb prosthetics much more functional to use. Some send electrical currents to stimulate the nerves so that users can “feel” what their prosthetics are touching; others record the electrical currents caused by muscle contractions, making it possible to control movement. Akhtar has been doing this work for over 10 years, first as a doctoral researcher at the University of Illinois at Urbana-­Champaign and then, starting in 2015, as the founder of the robotic-­limb startup <a href="https://www.psyonic.io/">Psyonic</a>.</p>  <p>Akhtar holds four patents on advances in prosthetics that have all gone into Psyonic’s first product, the <a href="https://www.psyonic.io/ability-hand">Ability Hand</a>. The Ability Hand was designed to be controlled by both muscle sensors and Bluetooth (yes, there’s an app!) and provide tactile sensory data to its user, all while withstanding the normal stresses of everyday life (like getting knocked against a table) without cracking.&nbsp;</p>  <p>Akhtar’s team of 20 designed with affordability in mind, he says, and built a hand inexpensive enough to be covered by Medicare. This means far more people in the US will be able to afford it. Previously, Akhtar explains, the only insurance that covered bionic hands was associated with veterans’ benefits and worker’s compensation claims, which he estimates cover only about 10% of the need in the United States. Participation from Medicare would make bionic hands available to 75% of individuals in the US who need them. “If Medicare covers it, then other insurers usually follow suit,” Akhtar says. </p></td>
    </tr>
    <tr>
      <td>Sriram Chandrasekaran</td>
      <td>His AI systems identify better treatments for tuberculosis.</td>
      <td>34</td>
      <td>University of Michigan</td>
      <td>humanitarians-2021</td>
      <td><p>Before covid-19, <a href="https://www.who.int/news-room/fact-sheets/detail/tuberculosis">tuberculosis</a> was the most dangerous infection in the world, killing more than 1.5 million people annually. The problem prompted <a href="https://medicine.umich.edu/dept/dcmb/sriram-chandrasekaran-phd">Sriram Chandrasekaran</a> to build AI tools to identify potent drug combinations to treat it. His goal is to boost the effectiveness of existing antibiotics to combat drug resistance among TB patients.&nbsp;</p>  <p>Drug-resistant infections occur when people don’t finish their course of treatment or are treated incorrectly. They can also occur when people come in contact with a patient infected with drug-resistant bacteria. While a typical TB treatment regimen lasts six to nine months, a drug-resistant case takes 18 to 24 months to treat. Chandrasekaran wants to drastically reduce this timeline. Curing patients faster could also save thousands of dollars in treatment costs.&nbsp;</p>  <p>Chandrasekaran’s systems predict the effectiveness of various drug combinations for TB. “We’ve found some really surprising ones,” he says, including an antipsychotic drug that would enhance the potency of existing antibiotics. ­He and his team confirmed the results against the TB bacterium in the lab.</p>  <p>Many drugs work in the lab but aren’t effective in the body, and Chandrasekaran wanted to make sure his algorithms take this into account. One system he built simulates characteristics of the infection site<em>—</em>for example, how much oxygen it gets or whether amino acids are present, which can affect a drug’s effectiveness. <a href="https://systemsbiologylab.org/">Chandrasekaran’s lab</a> is now identifying promising drug combinations for use in clinical trials of treatment against drug-resistant TB. </p></td>
    </tr>
    <tr>
      <td>Emma Pierson</td>
      <td>She employs AI to get to the roots of health disparities across race, gender, and class.</td>
      <td>30</td>
      <td>Cornell University</td>
      <td>humanitarians-2021</td>
      <td><p>Cornell University computer scientist <a href="https://cs.stanford.edu/~emmap1/">Emma Pierson</a> uses AI and emerging data science models to reveal how health disparities arise between sexes, races, socioeconomic groups, and other demographic categories. “These are fancy ways of saying I use math to find patterns in large data sets, and the specific types of patterns I’m looking for are attempting to answer sort of old questions in health and social sciences,” she says.&nbsp;</p>  <p>The “old questions” she’s investigating range widely in their specifics, but she focuses on uncovering how systemic inequalities in public health come to be, and pointing at ways to dismantle them. For example, by analyzing mobile-phone data, she recently showed that particular <a href="https://www.nature.com/articles/s41586-020-2923-3">“superspreader” locations</a> were primarily responsible for transmitting covid-19 across populations, and that low-income and minority communities suffered greater risk of exposure.&nbsp;</p>  <p>Beyond the pandemic, Pierson’s research team recently examined nearly a decade’s worth of data to show the extent of racial disparities in traffic stops made by police across the US. She analyzed <a href="https://www.nature.com/articles/s41562-020-01046-9">menstrual health data</a> from millions of women in 109 countries to demonstrate how effects on mood and behavior are experienced universally, seeking to destigmatize discussions around women’s health. And she used <a href="https://www.nature.com/articles/s41591-020-01192-7">deep learning to study data on knee pain</a>, revealing that the problem was often poorly measured and even exacerbated in patients from racially underserved groups and lower economic backgrounds.</p>  <p>Pierson has made it her mission to see this work break out of the confines of academia. She’s a fairly regular contributor to the New York Times and the Atlantic, offering up a layperson’s account of her work to a large audience. And she engages directly with organizations that can pressure policymakers. Her work on <a href="https://drive.google.com/file/d/1B58Os2Hb2v__YQ8whdWRULY9mgxxsHoO/view">racial disparities in traffic stops</a> ultimately led the Los Angeles Police Department to announce that it would reduce the number of random stops it conducted, and state departments of health leaned on her covid-19 findings to determine how to safely reopen businesses.</p>  <p>A self-professed math nerd, Pierson simultaneously earned a bachelor’s degree in physics and a master’s in computer science at Stanford before moving to Oxford as a Rhodes scholar, where she earned a master’s in statistics, afterward earning a doctorate in computer science at Stanford.</p>  <p>“I wanted to work on problems that were very concretely tied to people’s lives,” she says. “I think this sense was particularly driven by my own family’s medical history.” In December 2011, Pierson learned she was carrying a genetic mutation that increases her risk of breast and ovarian cancer, and it drove her to focus on work that could make an impact in health care and medicine.</p>  <p>Industries like health care deal with insanely large data sets that can really be understood only with the kinds of analytical techniques Pierson has mastered. The data might be the genomes of thousands of people, containing millions upon millions of data points, or medical images from many different patients, representing terabytes of information. AI tools can sort through this data and look for patterns that no human could readily identify. “Computational methods are not optional here,” Pierson says. “They’re the only solution.” &nbsp;</p></td>
    </tr>
    <tr>
      <td>Shriya Srinivasan</td>
      <td>Her surgical techniques provide a sense of touch to people with prosthetic limbs.</td>
      <td>27</td>
      <td>MIT</td>
      <td>humanitarians-2021</td>
      <td><p>As a child, <a href="https://www.media.mit.edu/people/shriyas/overview/">Shriya Srinivasan</a>, now a postdoctoral researcher in biomedical engineering at MIT, witnessed the challenges of living with prosthetic limbs. A friend had been born with missing limbs and used prosthetics; like amputees, whose nerves have been severed, her brain lacked the important neural signals that enable most people to feel objects, maintain balance, and sense their body’s position in space. Srinivasan has invented two new types of <a href="https://www.sciencemag.org/news/2017/05/new-surgical-procedure-could-lead-lifelike-prosthetic-limbs">surgical techniques</a> that could soon help people using prosthetic limbs regain their sense of touch.</p>  <p>Her first innovation, which she developed as an MIT doctoral student, involves grafting small segments of muscle onto the residual limb; the goal is to enhance the mind’s awareness of limb position and movement. Patients who underwent a version of this procedure in clinical trials have exhibited far greater control over their prostheses—and less pain—than those with traditional amputations. Her second procedure has shown early promise in re-creating touch. It works by fitting a person’s residual limb with flaps of skin from the fingertips or feet, encased by a muscle graft and electrode. A prosthetic arm or hand is then equipped with sensors and a wireless transmitter; when it touches an object, it conveys that sensation to the natural sensors on the grafted skin—which relay it on to the brain. Both techniques can be performed either as part of an amputation procedure or in patients with previous amputations.&nbsp;</p>  <p>Ultimately, Srinivasan hopes her work will help make using a prosthetic limb far more like the real thing—while initiating a broader shift in our approach to amputation from a form of salvage to a method of restoring mobility. </p></td>
    </tr>
    <tr>
      <td>George Boateng</td>
      <td>He built a smartphone-based platform to teach young people to code— and tackle Africa’s IT skills gap in the process.</td>
      <td>28</td>
      <td>SuaCode.ai</td>
      <td>pioneers-2021</td>
      <td><p>George Boateng’s venture, <a href="https://suacode.ai/">SuaCode.ai</a>, emerged largely by accident. In 2013, as an undergraduate at Dartmouth College, he’d teamed up with a group of friends to launch a summer innovation boot camp for high school students in their native Ghana. When the donated laptops they’d gotten for the course broke down a few years later, they were in a fix: only a quarter of the students had laptops of their own, and buying more would overwhelm their budget. All the students, however, had smartphones<em>—</em>so Boateng and his colleagues redesigned the coding module to fit a five-inch screen.</p>  <p>The experience went so well that it hatched a spinoff: in 2018, Boateng and cofounder Victor Kumbol ran their first pilot of SuaCode, an eight-week <a href="https://nsesafoundation.org/suacode/">smartphone-­based course</a>. The course, which teaches Processing, a Java-based language, now has more than 600 graduates from two dozen countries. Boateng, currently a doctoral candidate in applied machine learning at ETH Zurich, also engineered an English- and French-speaking AI-­powered teaching assistant named Kwame<em>—</em>a nod to Ghana’s first president, Kwame Nkrumah. “His pan-­Africanist vision resonates with our goal of empowering youth across the continent,” Boateng says.</p>  <p>Boateng’s hope is that the automated nature of the course will help it reach far more students<em>—</em>providing early exposure to coding that will serve as a bedrock for further education and ultimately help them land well-­paying jobs in tech.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Anna Goldie</td>
      <td>She uses AI to design microchips much more quickly than humans can.</td>
      <td>34</td>
      <td>Google Brain / Stanford University</td>
      <td>pioneers-2021</td>
      <td><p><a href="https://www.annagoldie.com/">Anna Goldie</a> designs <a href="https://www.nature.com/articles/s41586-021-03544-w">computer chips using reinforcement learning</a>, an AI technique that works by repeatedly generating solutions from an artificial neural network. The system then provides feedback to the network, “reinforcing” pathways that lead to successful outcomes and weakening pathways that don’t.&nbsp;</p>  <p>Building on this branch of machine learning, which also underlies the most successful methods for teaching computers to play games like chess or Go, has allowed Goldie and her team to speed up the process of chip design.</p>  <p>Modern chips are composed of millions or even billions of components. Some perform computations; others store data in short-term memory. Figuring out the best way to place all the components in a chip’s layout can take engineers weeks or even months—they must try to minimize power consumption and area but also maximize performance, all while making sure that traffic between components doesn’t get too congested.&nbsp;</p>  <p>Goldie’s AI can, in under six hours, come up with solutions that match—or even outperform—the ones that people were able to develop.</p>  <p>In early 2021, Goldie collaborated with Google engineers to produce physical versions of her layouts for Google’s latest artificial-intelligence chip. By using AI to design better hardware faster, she hopes to pave the way for AI advances that further improve and accelerate hardware design, creating a symbiotic loop between hardware and artificial intelligence.</p>  <p>“It generates these very strange, alien-looking layouts,” she says. “The chip designers were like: What if it goes wrong?” It didn’t.</p></td>
    </tr>
    <tr>
      <td>Adnan Mehonic</td>
      <td>Memristors can be a new and more efficient building block of modern computers.</td>
      <td>34</td>
      <td>University College London and Intrinsic</td>
      <td>pioneers-2021</td>
      <td><p><a href="https://www.americanscientist.org/article/the-memristor">Memristors</a> are a novel type of electric circuit element that were first theorized to exist in 1971. In 2008, researchers at Hewlett-Packard identified them for the first time, in nano­devices made from titanium dioxide, but the technology has not replaced flash memory as initially predicted.&nbsp;</p>  <p>Resistors are elements of a circuit that control the flow of electric current. A memristor, as its name suggests, is like an adjustable resistor with memory. Turn the power off, and a memristor “remembers” the most recent resistance it had. That holds the promise of faster, more efficient chips that integrate memory with logic.</p>  <p><a href="https://www.ucl.ac.uk/electronic-electrical-engineering/people/dr-adnan-mehonic">Adnan Mehonic</a> is developing memristors out of silicon oxide, the material most commonly used in computer chips. His most straightforward goal is to make dense, low-power, high-speed memory. More ambitiously, he is using the physics of memristors to implement in-memory computing and brain-like functionalities for future neuromorphic systems.&nbsp;</p>  <p>Among other applications, memristors could greatly improve the energy efficiency of AI systems, proponents say. “Crossbar arrays” of memristors, says Mehonic, could perform deep-learning tasks using one-500th as much energy as current hardware. A startup he cofounded concluded a $1.9 million financing round in March.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Marc Miskin</td>
      <td>He figured out how to give motion to microscopic robots.</td>
      <td>34</td>
      <td>University of Pennsylvania</td>
      <td>pioneers-2021</td>
      <td><p><a href="https://www.seas.upenn.edu/~mmiskin/">Marc Miskin</a> has given life to a technology that’s eluded the world’s top nanoscientists for decades: robots too small to see. Miskin’s tiny bots piggyback on more than 50 years of electronics innovation, making it possible to build silicon chips smaller than the width of a human hair. The challenge was getting these circuits, which function as the robots’ brains, to move: previous approaches to connecting them to a pair of microscopic legs required too much voltage to work at such a tiny scale.</p>  <p>His technique fabricates legs from sheets of platinum a dozen or so atoms thick, capped on one side with an even smaller layer of titanium. When activated with a current—generated by solar cells attached to the robot brain—the platinum bends, causing the bot to march forward. Miskin’s initial prototype, which he developed as a postdoctoral researcher at Cornell University, requires only one-fifth of a volt to move and measures just 40 by 40 microns—smaller than many single-celled microorganisms. It’s recognized by <a href="https://www.guinnessworldrecords.com/world-records/634629-smallest-walking-robot">Guinness World Records</a> as the smallest ever walking robot, and a million of them at a time can be fabricated on a single 10-centimeter wafer.</p>  <p>For now, Miskin’s robot does little more than prance under a microscope, but his lab at the University of Pennsylvania, where he’s a professor of electrical and systems engineering, is fabricating limbs for a “smart bot” with programmable memory, developed with researchers at the University of Michigan. In the longer term, Miskin envisions tiny bots being used to engineer new materials, rid crops of pests, or even act as microscopic surgeons, programmed to eliminate cancer cells one by one. </p></td>
    </tr>
    <tr>
      <td>Nako Nakatsuka</td>
      <td>Her miniature biosensors could give scientists better insight into depression and dementia.</td>
      <td>31</td>
      <td>ETHZurich</td>
      <td>pioneers-2021</td>
      <td><p><a href="https://lbb.ethz.ch/the-group/principal-investigator/nakatsuka-nako.html">Nako Nakatsuka</a> is building tiny sensors that can detect chemical changes in the brain and other parts of the body more precisely than ever before. Scientists can use such information to help them understand and treat conditions like depression and dementia. Compared with earlier sensors, Nakatsuka’s are better at differentiating between structurally similar chemicals, like neurotransmitters and their precursors and metabolites.&nbsp;</p>  <p>For now, her sensors are used to take measurements on samples in the lab, but the technology is being refined to work directly in the body and on a wider range of chemicals.&nbsp;</p>  <p>Nakatsuka built her sensors using molecules called aptamers, which can be designed to have strong affinity for specific targets. She first used an aptamer constructed from DNA that changes its shape in the presence of serotonin, a neurotransmitter that plays an important role in bodily functions like sleep and appetite, and in conditions like depression and obsessive-compulsive disorder.&nbsp;</p>  <p>Later she developed a way to attach the aptamer to the opening of a tiny pipette, just 10 nanometers in diameter, hooked up to an electrical circuit. As the aptamer changes its shape in the presence of serotonin, it alters the electrical current. The sensor can measure samples in brain fluid or tissue, or potentially directly next to individual neurons in a lab dish or in the brain.&nbsp;</p>  <p>&nbsp;“This might help us to better understand Parkinson’s and other diseases,” Nakatsuka says. Her sensors could be used to monitor how neurons in or from a patient with such a disease function in real time. And since aptamers can be used in all sorts of tests, Nakatsuka’s technology could lead to faster, cheaper, and more accurate detection for all kinds of medical conditions and infections.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Moses Namara</td>
      <td>Working to break down the barriers keeping young Black people from careers in AI.</td>
      <td>29</td>
      <td>Clemson University</td>
      <td>pioneers-2021</td>
      <td><p><a href="http://mosesn.people.clemson.edu/">Moses Namara</a> knew two fundamental truths: first, that misuses of AI disproportionately harm Black communities around the world, and second, that Black people are underrepresented in university AI programs. Just <a href="https://cra.org/wp-content/uploads/2020/05/2019-Taulbee-Survey.pdf">1.8% of students</a> enrolled in computer science PhD programs in the United States were Black in the 2018-2019 school year, and the numbers were only marginally better for master’s students.&nbsp;</p>  <p>Namara knew something else, too: that the barriers to entry are often rooted in resources, and that some of those resources were things a mentorship network could provide. “One is just information,” he says. For example: applicants need to know which research opportunities to pursue as undergrads, which university programs and professors best suit their interests, and what resources might be out there to help with the expensive process of actually applying. “If you don’t know where to look for the information, then that’s the number one step that you’re going to fail,” he says.</p>  <p>So in 2018 Namara co-­created the <a href="https://www.radicalai.org/black-in-ai-academic-program">Black in Artificial Intelligence graduate application mentoring program</a> to help students applying to graduate school. The program, run through the resource group Black in AI, has mentored 400 applicants, 200 of whom have been accepted to competitive AI programs. It provides an array of resources: mentorship from current PhD students and professors, CV evaluations, and advice on where to apply. Namara now sees the mentorship system evolving to the next logical step: helping Black PhD and master’s students find that first job.</p></td>
    </tr>
    <tr>
      <td>David Rolnick</td>
      <td>He's employing artificial intelligence in the fight against climate change.</td>
      <td>30</td>
      <td>McGill University</td>
      <td>pioneers-2021</td>
      <td><p>In 2019, as a postdoctoral researcher at the University of Pennsylvania, <a href="https://davidrolnick.com/">David Rolnick</a> was lead author of an influential <a href="https://arxiv.org/abs/1906.05433">report</a> that described various ways machine learning could reduce greenhouse-gas emissions and help society adapt to climate change, from predicting energy needs to managing forests to modeling planet-scale weather systems. His coauthors included DeepMind cofounder <a href="https://cbmm.mit.edu/about/people/hassabis">Demis Hassabis</a> and Turing Award winner <a href="https://yoshuabengio.org/">Yoshua Bengio</a>. That year, Rolnick was a lead organizer for the first workshops on climate change at three leading AI conferences, and lead organizer of an event on AI at the United Nations Climate Change Conference.&nbsp;</p>  <p>“David Rolnick has been hugely influential in convening AI practitioners to work on climate&nbsp;change,” says <a href="https://www.andrewng.org/">Andrew Ng</a>, a cofounder of Google Brain and former chief scientist at Baidu. “By helping shape a vision&nbsp;of how AI could help climate change and tirelessly organizing a community&nbsp;around&nbsp;it, he has catalyzed a significant amount of activity on this important topic.”</p>  <p>Rolnick now leads a group at McGill University that uses different AI techniques to attack problems related to climate.</p>  <p>For example, data relevant to climate change—records of infrastructure spending or greenhouse-gas emissions or simply weather patterns—varies enormously between countries. And yet climate needs to be understood at a global level.</p>  <p>“In the Global South there can be less information on infrastructure,” says Rolnick. “So policymakers may have less to go on when it comes to making decisions about energy requirements or managing coastal flood risk.” Countries also have different regulations about what does and does not get recorded. Germany gathers information on where its solar panels are, for example, but the US does not, so researchers are using machine learning to identify solar panels in the US from satellite imagery. Machine learning can also be used to forecast energy demand more accurately than is possible with existing techniques, Rolnick says. This allows energy providers to manage their electricity grids more efficiently.&nbsp;</p>  <p>Rolnick and his colleagues are trying to come up with new machine-learning techniques that could be applied to the study of climate change as well.</p>  <p>For instance, they are building algorithms for transfer learning, which involves training an AI on one set of examples and then transferring what it’s learned to new situations. They are also researching meta-learning, a set of techniques that make AI better at learning from small or incomplete data sets. Rolnick thinks these methods are especially useful for modeling biodiversity because sources of real-world data are so patchy.&nbsp;</p>  <p>Rolnick is also involved in projects that combine machine learning with climate models to simulate complex physical and atmospheric processes like cloud formation. The precise means by which clouds form, and how much they reflect or absorb sunlight, is one of the largest sources of uncertainty in existing climate models—partly because simulating clouds in climate models is computationally intensive. Using machine learning to find patterns in when and where clouds form and how reflective they tend to be—without trying to understand the underlying atmospheric chemistry—allows scientists to run models more quickly.&nbsp;</p>  <p>Rolnick and his collaborators are convinced AI will be a crucial tool in fighting climate change. All the same, there are growing concerns that <a href="https://www.technologyreview.com/2021/02/24/1017797/gpt3-best-worst-ai-openai-natural-language/">machine learning itself is part of the problem</a>. He acknowledges that training today’s largest AI models consumes large amounts of energy, but he points out that this contributes a tiny fraction of global emissions—and that the real climate risks from AI arguably have more to do with its uses in areas such as oil and gas exploration. “I’m much more worried about negative applications of machine learning than I am about its energy use,” he says.</p></td>
    </tr>
    <tr>
      <td>Max Shulaker</td>
      <td>His work with carbon nanotubes could lead to the next generation of computers.</td>
      <td>33</td>
      <td>MIT</td>
      <td>pioneers-2021</td>
      <td><p><a href="https://scholar.google.com/citations?user=ac1SojMAAAAJ&amp;hl=en">Max Shulaker</a> has built the world’s first functional <a href="https://news.mit.edu/2019/carbon-nanotubes-microprocessor-0828">computer using carbon nanotubes</a>, and he has also designed systems that combine computing, memory, and sensing directly on top of one another on a single chip. Together, these new technologies could increase energy efficiency in computers up to 1,000-fold and make possible a whole world of new devices like low-cost medical sensors.&nbsp;</p>  <p>Carbon nanotubes are “basically a straw that is one carbon atom thin,” says Shulaker. For 20 years, researchers have talked about using them to replace traditional silicon chips. But turning carbon-nanotube transistors and wires into actual devices has proved difficult, and Shulaker has solved several problems to make them work. He developed a way to remove poorly formed carbon nanotubes during production, devised new processes to create wafers of nanotube-based transistors using regular industrial fabrication plants, and invented a new design ensuring that chips built with a certain number of defective tubes are guaranteed to work.&nbsp; &nbsp;</p>  <p>These breakthroughs represent a significant step toward next-generation computer systems far more energy efficient than anything built to date.&nbsp;</p>  <p>Shulaker’s drive led him to work on another feat: monolithic, three-dimensional nanosystems. These fuse microprocessor, memory, and additional functional layers directly on top of one another using carbon nanotubes. Traditional designs have the microchip and memory on separate chips connected by wires. But moving massive quantities of data between those chips leads to slowdowns and wasted energy—a problem known in the industry as “the memory wall.” Shulaker’s 3D nanosystems solve it. </p></td>
    </tr>
    <tr>
      <td>Jinxing Zheng</td>
      <td>He created new physics models for controlling fusion reactions and hot plasma.</td>
      <td>34</td>
      <td>Institute of Plasma Physics, Chinese Academy of Sciences</td>
      <td>pioneers-2021</td>
      <td><p><a href="https://www.researchgate.net/profile/Jinxing-Zheng-2">Jinxing Zheng</a> has devised better ways to model the use of powerful magnets for controlling plasma at extreme temperatures, a major advance for fusion-based energy. Zheng’s work is helping China leapfrog the rest of the world and design the largest fusion reactor to date, called the <a href="https://www.asiafinancial.com/china-fires-up-nuclear-fusion-reactor">China Fusion Engineering Test Reactor</a>. CFETR is expected to finish construction and go online before 2035, though it may take five to 10 years to reach full power.&nbsp;</p>  <p>Fusion reactors, based on the energy released when atoms are combined, have great potential for creating clean energy and are inherently safer than existing nuclear power based on fission reactions. But no one has built a practical one, in part because it’s so challenging to contain the necessary plasma, which can reach temperatures of hundreds of millions of degrees Celsius.&nbsp;</p>  <p>Zheng’s innovation amounts to having discovered new theoretical models for understanding how multiple large superconducting magnets can rapidly change their magnetic fields to keep plasma in one place while fusion reactions occur. In 2018, with the help of Zheng’s models, a fusion reactor in Hefei, China, called the <a href="https://www.sciencedirect.com/science/article/pii/B9780081003152000131">Experimental Advanced Superconducting Tokamak</a>—nicknamed “the artificial sun”—controlled plasma at a record temperature of 50 million˚C for 102 seconds.</p>  <p>China’s future CFETR is intended to operate at over 1 gigawatt of power sometime in the 2030s. That’s double the power of <a href="https://www.iter.org/">ITER</a>, a fusion reactor currently being completed in the south of France with cooperation from countries around the world.</p></td>
    </tr>
    <tr>
      <td>Omar Abudayyeh</td>
      <td>He’s working to use CRISPR as a covid-19 test that you could take at home.</td>
      <td>30</td>
      <td>MIT</td>
      <td>inventors-2020</td>
      <td><p>CRISPR has been called the discovery of the century for its potential to change biomedical research and treatment of genetic diseases. But it was Omar Abudayyeh who helped turn the gene-editing tool into a diagnostic test, one that might help slow down the covid-19 pandemic.&nbsp;</p>  <p>Seizing on the precise gene-finding mechanism, in 2016 Abudayyeh, along with Jonathan Gootenberg and other colleagues at MIT, forged CRISPR into a tool to spot cancer mutations, bacteria, and mosquito-borne viruses like Zika. Soon, there was a spinout startup company called Sherlock Biosciences, $49 million in funding, and newspaper stories about CRISPR’s “new capabilities.”&nbsp;</p>  <p>Then came covid-19. Genetic tests to spot the pathogen were in desperately short supply in the US, with the workhorse technology, PCR, floundering. By early May, three months into the outbreak, around 2% of Americans had been tested for covid-19. Some economists say the country needs to test that many people <em>every day</em> to reopen with confidence.&nbsp;</p>  <p>That’s why, since January, Abudayyeh and his colleagues have been trying to forge CRISPR into an at-home test for the virus. The basic chemistry is simple enough, they think, to create an easy-to-use test that you could give yourself before heading to work, or maybe take at an airport gate before catching a flight.&nbsp;</p>  <p>If they succeed, virus testing could happen anywhere, anytime, and the gene-editing revolution would reach directly into people’s homes and lives for the first time.&nbsp;</p>  <h3 class="wp-block-heading">Here’s how it works&nbsp;</h3>  <p>The CRISPR revolution began with discoveries, in the early 2000s, that bacteria had evolved a way to chop up marauding phage viruses. CRISPR, whose name is an acronym for this natural biological invention, can spot unique sequences of DNA letters and cleave them with a cutting enzyme, Cas9. The tool, it turned out, was easy to use and worked in many species. Biotech startups began racing to treat genetic disease in humans. Gene-edited human twins were even born in China.&nbsp;</p>  <p>During what he calls the “Cas9 craze,” Abudayyeh was drafted into a less visible avenue of research: the effort to discover and characterize novel CRISPR enzymes.&nbsp;</p>  <p>Soon the list was growing, and Abudayyeh and colleagues were demonstrating what the new editors could do. There would be Cpf1, also known as Cas12a, and then Cas12b. But one called Cas13, discovered literally under our noses (it’s part of a human oral bacterium called <em>Leptotrichia shahii</em>), was special. Instead of cutting DNA, the enzyme could instead target RNA, the genetic messenger molecule inside of cells, which is also the primary genetic material of many viruses, including the coronavirus.&nbsp;</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>“I think our goal right now is to have it ready for the fall. For when the second wave comes.”</p></blockquote></figure>  <p>It was a totally new way to edit. What hadn’t changed was Abudayyeh’s close and ongoing collaboration with fellow gene editor Jonathan Gootenberg. The pair first met as MIT undergrads and then worked together in the busy lab of CRISPR pioneer Feng Zhang&nbsp; (who made our list of 35 innovators in 2013) at the Broad Institute. They’ve written 28 papers together, and in 2017 they were hired to establish a joint lab at the MIT McGovern Institute, which they christened the “AbuGoot Lab.”</p>  <p>“We joke that it’s a scientific bromance that just keeps on going,” says Abudayyeh, who reckons he’s the more practical of the two, while Gootenberg is more mathematical. “Our brains haven’t quite merged, but it’s close.”&nbsp;</p>  <p>And they needed two heads to understand the new RNA editor, Cas13. The enzyme turned out to have a bizarre “collateral effect.” Not only did it cut specific RNA strands, but once it got going, it would furiously chop up and degrade any RNA in its path. “The mechanism was insane and very confusing at first,” says Abudayyeh. “We think it’s part of a cell-suicide mechanism”—a natural self-destruct device in bacteria attacked by a virus. “When it activates, it shuts down everything in the cell.”&nbsp;</p>  <p>The indiscriminate cutting, though, meant Cas13 wasn’t a great editor on its own. “It was kind of disappointing, but we came from an engineering background, so we asked what it is good for,” says Abudayyeh. Maybe they could blow up RNA in a cancer cell, bringing it to a halt?&nbsp;</p>  <p>The idea that the collateral damage could turn CRISPR into a lab diagnostic was first floated by scientists from the rival laboratory of Jennifer Doudna at the University of California, Berkeley. There a team proposed that indiscriminate cutting could serve as a detection mechanism. In short, if the enzyme found a match in a test tube—a piece of RNA belonging to a virus, say—the collateral cutting could be used to sever special RNA that, when broken, would set off a visible fluorescent signal.</p>  <p>Great idea, but on its own, Cas13 wasn’t sensitive enough to create a test. So Abudayyeh and Gootenberg got help from MIT professor Jim Collins, who showed them how to add a preamplification step, or a way to copy and multiply the RNA before testing for a match. By 2017, the group was showing off a complete CRISPR diagnostic system called Sherlock that could locate unique mutations that cause cancer or flag the presence of bacteria, or even the Zika virus. And it was highly accurate. Imagine being able to pick out one person’s face from the population of 100 million Earths. That’s the equivalent of what Sherlock could do in sorting through RNA.&nbsp;</p>  <p>Sherlock soon had competition from the Berkeley team, which started its own CRISPR diagnostics company, Mammoth Biosciences. One result: a tangle of competing diagnostic patents that is reminiscent of the bruising, costly fight between the two institutions over the original CRISPR inventions. Abudayyeh shrugs: “It’s more exciting when you have more than one group working on it. And it’s better for CRISPR diagnostics that it’s not just one company trying to peddle a technology.”&nbsp;</p>  <p>He’s right: reaching the market is the hard part. That’s because diagnostic testing is a business of giant companies, big machines, and centralized labs. It can take a hundred million dollars to develop a test that sells for $45. “Not for the faint of heart” is how venture capitalist Bruce Booth once described the business. By late 2019, Sherlock, a company Abudayyeh cofounded, was still edging the CRISPR-based tests toward the market.&nbsp;</p>  <p>But then the pandemic exploded out of China and changed everything. When the shortage of tests in the US became clear, the Food and Drug Administration started giving emergency approvals to makers of dozens of tests, allowing them into the market immediately. In May, Sherlock Biosciences won US authorization to perform a version of the CRISPR test that had to be done in a lab, although at press time no one had yet used it on a patient.&nbsp;</p>  <h3 class="wp-block-heading">A home test</h3>  <p>Still, it wasn’t easy enough for someone without training to use. Back on MIT’s campus, Abudayyeh, Gootenberg, and Zhang set out to simplify the technology. They reasoned that if they could eliminate some of the fluid mixing steps, the test could be used in workplaces, in pharmacies, or even at home. It didn’t need repeated heating and cooling, as PCR does. And the readout was easy to understand: just colored bars on a paper strip, like a pregnancy test. “Our vision is really testing that can be done at home,” says Abudayyeh. “So how can we push this so it’s fewer steps, simple, and cheap?”&nbsp;</p>  <p>Right now, so-called point-of-care diagnostic tests do exist, but they need to be run on machines that cost thousands of dollars. One device, ID NOW, which is sold by Abbott, returns coronavirus results in 15 minutes and is used by the White House to screen visitors meeting with President Donald Trump. But the machine that processes the test costs thousands to buy. Abudayyeh says CRISPR home tests might cost $6 each and only use simple equipment.</p>  <p>By May, the researchers had created a simplified version and launched a website to share the new chemistry, which they showed could spot the coronavirus in swabs from patients. They are working with a design firm to create a prototype of a plastic cartridge to hold and mix the test ingredients. So has Abudayyeh tested himself? He hasn’t. “It’s tempting to spit in the tube,” he says. “But it’s also a scary thing to do.”</p>  <p>Pretty soon, though, people around the world may be having such “Do I or don’t I have it?” moments regularly, or at least that’s the hope.&nbsp;</p>  <p>The work is “not final,” Abudayyeh&nbsp; says. “Final is a simple device you can spit in. But this is the version of the chemistry that would work for the home. I think our goal right now is to have it ready for the fall. For when the second wave comes.”</p>  <p><em>Photo by David Vintiner</em></p></td>
    </tr>
    <tr>
      <td>Christina Boville</td>
      <td>She modifies enzymes to enable production of new compounds for industry.</td>
      <td>32</td>
      <td>Aralez Bio</td>
      <td>inventors-2020</td>
      <td><p>Christina Boville helped design a process that improves on biology’s way of controlling chemical reactions. She starts with natural enzymes—proteins that enable chemical reactions in living cells—and engineers them to produce useful chemicals that don’t exist in nature. The approach can reduce manufacturing times for compounds used in the pharmaceutical industry from months to days, shrink waste by up to 99%, and cut energy consumption in half.</p>  <p>In 2019, Boville cofounded Aralez Bio with David Romney and Frances Arnold, who won a Nobel Prize in 2018 for a new way of creating enzymes called directed evolution. Boville’s process creates chemicals known as non-canonical amino acids (ncAAs), which are used in making 12% of the 200 best-selling medicines, including those for migraines and diabetes, and are also used in agriculture. “Nature was built using 20 amino acids, and now our enzymes can make hundreds more,” she says. Drug ingredients “normally take five to 10 steps to make,” she adds, “but we can do it in a single step.”</p>  <p>Aralez Bio was recently approached by a pharmaceutical company to produce ncAAs that had taken the company nine months to make with conventional methods. Boville’s enzymes now makes the same compound overnight.</p></td>
    </tr>
    <tr>
      <td>Manuel Le Gallo</td>
      <td>He uses novel computer designs to make AI less power hungry.</td>
      <td>34</td>
      <td>IBM Research</td>
      <td>inventors-2020</td>
      <td><p>Training a typical natural-language processor requires so much computing power that it emits as much carbon as the life span of five American cars. Training an image recognition model releases as much energy as a typical home puts out in two weeks—and it’s something that leading tech companies do multiple times a day.&nbsp;</p>  <p>Much of the energy use in modern computing comes from the fact that data needs to be constantly transferred back and forth between memory and the processor. Manuel Le Gallo is working with a research team at IBM that’s building technology to enable new kinds of computing architecture that aims to be faster and more energy efficient but still highly precise.&nbsp;</p>  <p>Le Gallo’s team developed a system that uses memory itself to process data, and his team’s early work has shown they can achieve both precision and huge energy savings. The team recently completed a process using just 1% as much energy as when the same process was performed with conventional methods.</p>  <p>As companies from the financial sector to life sciences constantly train their AI models to improve them, their energy needs will balloon. “What will change is we will be able to change models faster and more energy efficiently, which will definitely reduce the carbon footprint and energy spent training those models,” Le Gallo says.</p>  <p><em>Photo by Samuel Trümpy</em></p></td>
    </tr>
    <tr>
      <td>Nadya Peek</td>
      <td>She builds novel modular machines that can do just about anything you can imagine.</td>
      <td>34</td>
      <td>University of Washington</td>
      <td>inventors-2020</td>
      <td><p>Nadya Peek began tinkering with machines out of stubbornness.&nbsp;</p>  <p>As an undergraduate, when she collaborated with artists on their installations, she often ran into limitations with the tools and equipment they were using. Rather than accept her fate, she hacked the machines until they finally did what she wanted. It got her thinking: why couldn’t machines be more flexible? What if instead of changing your idea to fit the tools, you could change the tools to fit your idea? Thus began her quest to create application-specific machines that could help anyone do almost anything.</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>Her goal is to give anyone with an idea the means to efficiently translate it into physical reality.</p></blockquote></figure>  <p>Peek is now an assistant professor at the University of Washington, where she dedicates herself to this vision. She designs modular components<em>—</em>motors, mechanical arms, and material cutters<em>—</em>that can be assembled every which way and programmed with a little bit of code to carry out tasks from the frivolous to the scientific. When she teaches people to use her components, she delights in their creativity: they’ve made T-shirt-­designing machines and cocktail-mixing machines, 3D printers, and chemistry pipetting machines. The machines are often no larger than a desktop and can be broken down and reassembled for new tasks once they’ve outlived their original use.&nbsp;</p>  <p>Peek tries to make her tools as low-cost and accessible as possible: some use only cardboard for their frames, and the designs are available to download. Her machines have been used by students, hackers, and even architects.</p>  <p>Peek’s goal is to give anyone with an idea the means to translate it into physical reality. She notes that computers were originally designed to carry out specific tasks, but evolved to be more general-purpose. She thinks machines that automate physical tasks should be no different. “I ultimately really would like to see automation as ... just another thing that you can use for creative problem solving,” she says.&nbsp;</p>  <p><em>Photo by Dakota Lenox</em></p></td>
    </tr>
    <tr>
      <td>Leila Pirhaji</td>
      <td>She developed an AI-based system that can identify more small molecules in a patient’s body, faster than ever before.</td>
      <td>34</td>
      <td>ReviveMed</td>
      <td>inventors-2020</td>
      <td><p>Leila Pirhaji built an AI-based tool for measuring tiny molecules in the body called metabolites, and her work could help us better detect and treat diseases. “There are 100,000 metabolites in the body,” she says. “They are involved in our metabolism and are downstream from DNA, so they show the effects of both our genes and lifestyle.” Such metabolites include everything from blood sugars and cholesterol to obscure molecules that appear in significant numbers only when someone is sick.</p>  <p>The problem is that measuring and identifying metabolites is expensive and time consuming, and fewer than 5% of metabolites in a patient can be identified using common technologies.</p>  <p>So Pirhaji developed a platform that uses machine learning to do it much more quickly. First she built a huge database of all known information about existing metabolites and how they interact with various proteins and other molecules. Then her team collected tissue and blood samples from patients with known diseases, and measured the metabolites.</p>  <p>Her platform was able to analyze the data, understand the complex connections between diseases and metabolites, and use this information to discover new drugs. When she tested it in a mouse with Huntington’s disease during her PhD at MIT, her team learned new mechanisms for the disease and found new potential ways of treating it.&nbsp;</p>  <p>As CEO of ReviveMed, Pirhaji is focusing on liver, immune, inflammatory, and other diseases. Using her platform, the startup partners with major pharmaceutical companies to match existing medicines to new treatments and find&nbsp; new targets for future drugs</p></td>
    </tr>
    <tr>
      <td>Randall Jeffrey Platt</td>
      <td>His recording tool provides a video of genes turning on or off.</td>
      <td>32</td>
      <td>ETH Zurich</td>
      <td>inventors-2020</td>
      <td><p>Randall Platt has created a way to record molecular events in a cell across time—a technology that has the potential to transform our understanding of a number of important biological processes.</p>  <p>Currently, for instance, one of the best tools available to understand the molecular processes that occur during embryonic development or immune responses to cancer is RNA-seq, a technique that allows biologists to develop a snapshot of how genes are being expressed—which ones are being turned on or off—at a single moment in time.&nbsp; But while RNA-seq provides a snapshot, Platt’s tool could potentially be used to record the equivalent of a brief video, capturing gene expression over time and thus providing a much richer picture of, say, an embryo’s development.&nbsp;</p>  <p>“At the core of all of biology and biomedicine is looking at transitions in systems—whether it be a stem cell that develops into a neuron or a healthy neuron that develops into a degenerative neuron,” he says. “How people approach this problem today is they perform time-point experiments and then kind of guess what’s happening in between. I was going after a technology that would fill that gap—what was happening to the cells throughout this transition.”&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>  <p>Platt has big ambitions for his tool. He invented it to deal with a problem that repeatedly frustrated him when he was a graduate student at MIT. A group identified a gene that, when mutated and missing, appeared to play a role in autism—though precisely when the gene affected the brain’s development remained a mystery.&nbsp;&nbsp;</p>  <p>“If you want to identify a meaningful defect in a neuron you need to know exactly when, where, and how to look,” he says. “This was the biological problem that motivated me to create the recording tool.”</p></td>
    </tr>
    <tr>
      <td>Rebecca Saive</td>
      <td>She found a way to make solar panels cheaper and more efficient.</td>
      <td>33</td>
      <td>University of Twente and ETC Solar</td>
      <td>inventors-2020</td>
      <td><p>The silver lines that crisscross the face of solar panels are essentially metal wires. They’re necessary to channel the electric current flowing out of the cells, but they reflect about 5% of the sunlight that reaches them, creating the single biggest drain on their efficiency.</p>  <p>Rebecca Saive, an assistant professor in applied physics at the University of Twente in the Netherlands, has invented a novel type of “front contact” that addresses this problem, reducing the wasted sunlight and improving the performance of solar photovoltaics.</p>  <p>Her transparent contacts are made from silver nanoparticles 3D-printed onto the silicon layer of a solar cell, using a technique she developed that produces an extremely thin and precise triangular shape. The steeply angled sidewalls reflect arriving light toward the absorbing body of the cell like a mirror, boosting electricity output by at least 5% and lowering costs roughly the same amount.</p>  <p>ETC Solar—a startup Saive cofounded&nbsp; with headquarters in Pasadena, California, and Rotterdam—produces a printing tool that enables manufacturers to integrate the technology into otherwise standard photovoltaics. It’s already selling the product, though the company hasn’t announced customers yet.&nbsp;</p>  <p>Meanwhile, ETC and Saive’s academic team at the University of Twente are using the front contacts and other advances to develop even more efficient solar cells that she says could eventually lead to solar plants that produce lower-cost electricity, and even to solar-powered cars.</p></td>
    </tr>
    <tr>
      <td>Venkat Viswanathan</td>
      <td>His work on a new type of battery could make EVs much cheaper.</td>
      <td>34</td>
      <td>Carnegie Mellon University</td>
      <td>inventors-2020</td>
      <td><p>Venkat Viswanathan, an associate professor at Carnegie Mellon, has made major strides in developing anodes made out of pure lithium, promising a new class of batteries that pack more energy and deliver more power for a given amount of weight. That could enable cheaper electric vehicles and low-emissions aircraft.&nbsp;</p>  <p>Researchers have long recognized that lithium-metal anodes could boost the performance of batteries over ones made of graphite. But they’re prone to developing needle-like “dendrites” as lithium ions build up. This can shorten the battery’s life and even spark fires. Viswanathan’s solution was developing a hybrid polymer-ceramic separator between the electrodes. It applies enough pressure to prevent the dendrites from forming but still allows ions to flow through the battery, which produces the electric current.</p>  <p>Viswanathan and colleagues secured more than $4 million from the Energy Department’s moonshot ARPA-E program, and partnered with battery maker 24M Technologies to produce and test commercial-size lithium-metal cells.</p>  <p>Viswanathan has also worked with Aurora Flight Sciences and Airbus A<sup>3</sup> on battery designs for vertical takeoff and landing aircraft, which can function as air taxis or ambulances that zip across metropolitan areas. </p></td>
    </tr>
    <tr>
      <td>Anastasia Volkova</td>
      <td>Her platform uses remote sensing and other techniques to monitor crop health—helping farmers focus their efforts where they’re most needed.</td>
      <td>28</td>
      <td>Flurosat</td>
      <td>inventors-2020</td>
      <td><p>If there’s one thing that frustrates Anastasia Volkova, it’s inefficiency. So when she realized she could combine remote sensing data with scientific modeling to improve crop yields, reduce the use of agricultural chemicals, and make better use of water, she knew she’d found her life’s work. It didn’t matter that she was still pursuing her doctorate in aerospace at Sydney University or that she would need to single-handedly raise more than $5 million in startup money: Volkova, the daughter of a self-taught botanist and the goddaughter of a successful farmer, wanted to fix what she thought was wrong with large-scale farming.</p>  <p>Her resulting venture, Flurosat, uses imaging sensors on satellites, planes, and drones to detect when crops are in trouble long before their distress is discernible to the naked eye. Like humans, plants spike a fever when they’re sick. They also heat up in response to pests or because they’re not getting the nutrition or water they need. Flurosat uses multispectral and thermal cameras to record these changes and AI to calibrate crop models. Comparing a real crop with its digital twin then enables Volkova and her team to make real-time recommendations to agronomists and farm managers about what their yields need to thrive.&nbsp;</p>  <p>This kind of monitoring and support could reduce the overuse of nitrogen, pesticides, and herbicides and optimize irrigation.</p></td>
    </tr>
    <tr>
      <td>Sihong Wang</td>
      <td>His stretchable microchips promise to make all sorts of new devices possible.</td>
      <td>33</td>
      <td>University of Chicago</td>
      <td>inventors-2020</td>
      <td><p>Microchips are usually etched into a substrate of brittle silicon crystals. That means if you try to bend or stretch them, their molecular structures break and performance drops dramatically. Circuits that aren’t as fragile have been around for a while, but they’ve always had to trade off performance or ease of manufacturing to achieve flexibility. Sihong Wang, however, has developed new manufacturing techniques to build circuits that can stretch and bend while performing just as well as an inorganic semiconductor circuit.&nbsp;</p>  <p>Building on his previous work with Zhenan Bao at Stanford, one of the field’s pioneers, Wang has created a set of new processes that dramatically move things forward. Using a physical effect known as nanoconfinement to build layered polymer circuits at the smallest possible scale, he can now reliably build high-performance circuits that can be stretched to twice their original length without losing any performance.</p>  <p>These rubbery polymers, he says, open up whole new classes of devices—malleable enough to be molded to your shape, applied as a skin patch, or even inserted inside the body, while able to do everything just as well as a more traditional machine. But that means a set of new problems to solve. How do you power them? He’s already got ways to harness energy from the human body—using another invention called a “nanogenerator”—rather than requiring external batteries. Can these then be placed inside the body without triggering an immune response? That’s next.</p></td>
    </tr>
    <tr>
      <td>Jiwei Li</td>
      <td>In the last few months, Google and Facebook have both released new chatbots. Jiwei Li’s techniques are at the heart of both.</td>
      <td>31</td>
      <td>Shannon.ai & Zhejiang University</td>
      <td>entrepreneurs-2020</td>
      <td><p>Jiwei Li applies deep reinforcement learning—a relatively new technique in which neural networks learn by trial and error—to natural-language processing (NLP), the field of computer science in which programs are made to manipulate human languages.&nbsp;</p>  <p>By using deep reinforcement learning to identify syntactic structures within large pieces of text, Li made machines better at extracting semantic information from them. Syntax refers to the grammatical relationship between words, while semantics refers to their meaning.</p>  <p>In written language, words with a close semantic relationship are not always close together on the page. A verb and its object can be separated by a string of adjectives or a subordinate clause, for example. Previous attempts at getting machines to parse natural language often overplayed the importance of proximity, leading to obvious mistakes. Li’s machine-learning algorithms find the grammatical structure of a sentence to get a much more reliable sense of the meaning. They have become a cornerstone of many NLP systems.&nbsp;</p>  <p>Li grew up in China and studied biology at Peking University before moving to the US, where he began a PhD in biophysics at Cornell. But he soon switched fields, turning to NLP first at Carnegie Mellon and then at Stanford, where he became the first student ever to obtain a computer science PhD in less than three years.&nbsp;</p>  <p>Li has also explored other ways to teach artificial intelligence how to spot patterns in linguistic data. In 2014 he and his colleagues correlated Twitter posts with US meteorological data to see how weather affected users’ mood. First he labeled 600 tweets by hand as happy, angry, sad, and so on. He used this labeled data to train a neural network to assess the mood of a tweet and cross-referenced that mood against geolocation data for about 2% of all the tweets published in 2010 and 2011.</p>  <p>His results were not surprising. Moods worsened when it rained; people expressed anger when it was hot. But for Li it was a lesson in how hidden information could be extracted from large amounts of text.&nbsp;</p>  <p>After finishing his studies in 2017, he moved back to Beijing and founded an NLP startup called Shannon.ai, which now has dozens of employees and $20 million in funding from venture capitalists. Li’s company is building on the pattern-matching work demonstrated in the Twitter weather study to develop machine-learning algorithms that extract economic forecasts from texts including business reports and social-media posts.</p>  <p>Li has also applied deep reinforcement learning to the challenge of generating natural language. For him it is the obvious next step. Once you have learned to read, you can learn to write, he says.&nbsp;</p>  <p>Even the best chatbots still make obviously stupid mistakes, spewing out non sequiturs or displaying a lack of basic common knowledge about the world. The longer a conversation, the harder it is for an AI to keep track of what’s been said. Li’s techniques give AI a good grasp of linguistic structure. In a conversation, keeping track of subjects and objects is easier if the syntax of utterances is explicit. For example, given the question “Shall we get started?” a bot might answer “Of course!”—but that response could follow any question. Li’s technique can instead give responses more like “Yes. We’ve got a lot of work to do here,” referencing the content of the original query.&nbsp;</p>  <p><em>Photo by David Vintiner</em></p></td>
    </tr>
    <tr>
      <td>Atima Lui</td>
      <td>She’s using technology to correct the cosmetics industry’s bias toward light skin.</td>
      <td>30</td>
      <td>Nudemeter</td>
      <td>entrepreneurs-2020</td>
      <td><p>Atima Lui grew up in Kansas as the descendant of American slaves and the daughter of a Sudanese refugee, and she remembers trying on makeup with a friend for the first time as a child. Her friend had lighter skin. “As soon as she put it on my face,” Lui says, “there was nothing we could do to make it look good.” She’d discovered the cosmetic industry’s long-running assumption that “nude” means white or light.</p>  <p>Lui is now deploying an AI-based app called Nudemeter to try to fix that problem. Through photos and a short quiz, it determines a user’s skin color, accounts for how the skin is illuminated, predicts changes in skin tone through the year, and helps consumers of any complexion choose makeup colors that work with their skin.&nbsp;</p>  <p>Lui has managed to build a business around Nudemeter, but her goals go beyond the technology itself. Growing up, she says, she was shaped and hurt by society’s assumptions about “who gets to be an entrepreneur, or who gets to be a technologist.” That’s something else she’s trying to fix.</p>  <p><em>Photo by Ashley Soong</em></p></td>
    </tr>
    <tr>
      <td>Tony Pan</td>
      <td>His company revamps an old device to allow you to generate electricity in your own home.</td>
      <td>34</td>
      <td>Modern Electron</td>
      <td>entrepreneurs-2020</td>
      <td><p>Modern Electron has applied a modern twist to an old technology. By using computer simulations and novel materials, the Seattle startup has made a new type of thermionic converter, a heat engine first developed in the 1950s, that’s more efficient than the old model at turning heat into electricity.</p>  <p>Cofounder and CEO Tony Pan believes his company can use the technology to convert home boilers and furnaces, which generally use natural gas or oil to heat water and homes, into mini residential power plants that produce electricity on site. He says this would be a far cheaper and more efficient way of generating residential power than a central power plant, particularly when coupled with home solar panels and batteries.</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>If adopted widely, Pan’s product could reduce our reliance on electricity from centralized coal or natural-gas plants.</p></blockquote></figure>  <p>A thermionic converter consists of a pair of metal plates, separated by a vacuum. Heat—from, say, the flame of a furnace—agitates and excites the electrons on one plate to the point that they leap across the gap to the cool one, generating an electric current. In one application, Modern Electron has rolled the metal plates into a tube that resembles a light-saber handle and fits over a gas burner.&nbsp;</p>  <p>Homeowners could rely on rooftop solar panels much of the time, turning to Modern Electron’s system during the night, on cloudy days, or in the winter months. If adopted widely, the product could reduce our reliance on electricity from centralized coal or natural-gas plants, which waste vast amounts of energy between burning fuels and delivering power over hundreds of miles of transmission lines. That, in turn, could reduce greenhouse-gas emissions from the power sector, Pan says.</p>  <p>The company’s technology also works with other fuels. So if residential heating systems eventually shift toward low- or zero-emissions sources like hydrogen, a change some companies and regions are exploring, the thermionic converter could make a bigger dent in pollution.</p>  <p>Pan believes his device could have an even bigger impact in developing countries. Enabling communities to set up their own mini power plants would allow them to skip the massive investments of money and time required to build centralized generation and distribution systems. That could bring electrification faster to rural areas</p></td>
    </tr>
    <tr>
      <td>Leilani Battle</td>
      <td>Her program sifts through data faster so scientists can focus more on science.</td>
      <td>31</td>
      <td>University of Maryland</td>
      <td>visionaries-2020</td>
      <td><p>When Leilani Battle was working on her PhD, she helped develop ForeCache, a tool designed to help researchers browse large arrays of data—for instance, scanning high-resolution satellite images to look for areas covered with snow. The goal is to reduce latency, so that a user can pan and zoom across the data set without perceptible delay. A common way to do this is to predict which parts of the data a user is likely to need and then “prefetch” them. But how to predict what to prefetch? That depends on understanding the user’s behavior.</p>  <p>Battle and her colleagues developed a more efficient prediction system. It attempts to discern first which “analysis phase” a user is in, and then what tiles of data might be wanted next. They dubbed the three phrases “foraging,” “sensemaking,” and “navigation.” They suppose that users in the “foraging” phase are browsing at a coarse level, in order to come up with new ideas. “Sensemaking” is a closer examination meant to test those ideas, and “navigation” is a transition between the two.</p>  <p>This system allowed them, they said, to predict which tiles users wanted about 25% better than existing prefetching systems they benchmarked against, almost halving the latency.</p>  <p>Battle has devoted her career to designing systems and interfaces that help researchers sifting through data do their work better and faster. She hopes to make exploration tools more interactive and visual so they’ll be less daunting. Perhaps this will allow scientists to spot data quirks that would otherwise go unnoticed.</p></td>
    </tr>
    <tr>
      <td>Morgan Beller</td>
      <td>She was a key player behind the idea of a Facebook cryptocurrency.</td>
      <td>27</td>
      <td>Novi</td>
      <td>visionaries-2020</td>
      <td><p>In the summer of 2017, Morgan Beller approached her supervisor on Facebook’s corporate development team with a proposal: what if she began spending the bulk of her job researching how the social-media giant could enter the digital currency market?&nbsp;</p>  <p>Beller was so new at Facebook that she was still completing her orientation, but she’d cut her teeth at a venture capital firm, where she’d worked on early cryptocurrency investments. She could see that a seismic shift in the global financial community was coming.&nbsp;</p>  <p>When she realized that no one at Facebook was working&nbsp;on blockchain, she volunteered and quickly became the company’s digital currency evangelist, shepherding the development of both its open-source blockchain infrastructure, Libra, and its currency application and digital wallet, Novi. Today she serves as head of strategy for the latter, where she works with a team of digital currency developers.</p>  <p>Facebook and its founder, Mark Zuckerberg, endured sharp criticism after announcing the plans for Libra. Beller wasn’t surprised. “We’re trying to change the system, and there are a lot of people who are incentivized for the global financial system not to change,” she says.&nbsp;</p>  <p>Libra hasn’t even rolled out yet, but it’s already prompted several countries, including China, to accelerate the development of their own national digital currencies. The Libra Association recently announced plans to scale back Libra and first issue a coin backed by a local currency, but even with these modifications, Libra has already been disruptive.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Eimear Dolan</td>
      <td>Medical implants are often thwarted as the body grows tissue to defend itself. She may have found a drug-free fix for the problem.</td>
      <td>32</td>
      <td>National University of Ireland Galway</td>
      <td>visionaries-2020</td>
      <td><p>When Eimear Dolan first worked to develop implantable medical devices to treat type 1 diabetes, she and her colleagues had to overcome a common roadblock. Their problem was one that’s long dogged makers of devices like pacemakers, insulin delivery systems, and breast implants: when the body senses an implanted foreign object, it constructs a protective wall of fibrous tissue. This reaction, known as the foreign body response, is one of the main reasons medical implants fail.</p>  <p>Today, as a biomedical engineer at the National University of Ireland Galway, Dolan thinks she’s found a way to counteract the foreign body response. Her weapon is a small robotic device known as a dynamic soft reservoir. Developed through a collaboration between Dolan’s lab at NUI Galway and researchers at MIT, the device is made of a soft material that can be made to oscillate, creating enough fluid flow to alter the environment around the implant and keep protective tissue from forming. </p>  <p>Past researchers have sought to use drugs or modify the surface chemistry of an implant. Dolan’s innovation, which she and her colleagues have successfully tested in rats, marks the first time anyone has tackled the problem mechanically. “The beauty about it is it’s a drug-free approach,” Dolan says.</p>  <p>Her team is redesigning the dynamic soft reservoir as part of an effort to construct a “bioartificial pancreas,” an implantable reservoir of cells that produce insulin for people with type 1 diabetes. Early attempts at such devices have been particularly liable to be rejected by the body and fail. Dolan believes her team can change that—and ultimately improve the success of other implantable devices.</p>  <p><em>Photo by Lillie Paquette</em></p></td>
    </tr>
    <tr>
      <td>Rose Faghih</td>
      <td>Her sensor-laden wristwatch would monitor your brain states.</td>
      <td>34</td>
      <td>University of Houston and MIT</td>
      <td>visionaries-2020</td>
      <td><p>If Rose Faghih’s project pans out, a seemingly simple smart watch could determine what’s happening deep inside your brain.</p>  <p>Faghih has developed an algorithm to analyze otherwise imperceptible<br>changes in sweat activity—a key indicator of stress and stimulation. Using two small electrodes attached to the back of a smart watch, she can monitor changes in skin conductance caused by sweat. Signal-processing algorithms then allow Faghih to correlate those changes with specific events, such as a PTSD-related flashback or even just wandering attention, in order to pinpoint the person’s brain state.</p>  <p>Typically, this kind of real-time data is available only by way of expensive scalp-based electrode systems like EEG or functional MRI. Faghih’s “Mindwatch” would in theory be cheap and portable enough to let people monitor their brain states anywhere.</p>  <p>Faghih hopes it will help people manage their own changing moods and mental states: a wearable with her technology could suggest that an agitated driver try some deep breathing or prompt a lonely shut-in to turn on mood-enhancing music. For people with mental illness or chronic conditions like diabetes, it could potentially even trigger an automated deep-brain stimulation device or an insulin pump.</p>  <p><em>Photo by Jeff Lautenberger,&nbsp;Cullen College of Engineering, University of Houston</em></p></td>
    </tr>
    <tr>
      <td>Bo Li</td>
      <td>By devising new ways to fool AI, she is making it safer.</td>
      <td>32</td>
      <td>University of Illinois at Urbana-Champaign</td>
      <td>visionaries-2020</td>
      <td><p>A few years ago, Bo Li and her colleagues placed small black-and-white stickers on a stop sign in a graffiti-like pattern that looked random to human eyes and did not obscure the sign’s clear lettering. Yet the arrangement was deliberately designed so that if an autonomous vehicle approached, the neural networks powering its vision system would misread the stop sign as one posting a speed limit of 45 mph.</p>  <p>Such “adversarial attacks”<em>—</em>manipulation of input data that looks innocuous to a person but fools neural networks<em>—</em>had been tried before, but earlier exampleshad been mostly digital. For instance, a few pixels might be altered in an image, a change invisible to the naked eye. Li was one of the first to show that such attacks were possible in the physical world. They can be harder for an AI to detect because the methods developed to spot manipulated digital images don’t work on physical objects.</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>Her goal is to use her knowledge about potential attacks to make AI more robust.</p></blockquote></figure>  <p>Li also devised subtle changes in the features of physical objects, like shape and texture, that again are imperceptible to humans but can make the objects invisible to image recognition algorithms. Her goal is to use this knowledge about potential attacks to make AI more robust. She pits AI systems against each other, using one neural network to identify and exploit vulnerabilities in another. This process can expose flaws in the training or structure of the target network. Li then develops strategies to patch these flaws and defend against future attacks. &nbsp;</p>  <p>Adversarial attacks can fool other types of neural networks too, not just image recognition algorithms. Imperceptible tweaks to audio can make a voice assistant misinterpret what it hears, for example. Some of Li’s techniques are already being used in commercial applications. IBM uses them to protect its Watson AI, and Amazon to protect Alexa. And a handful of autonomous-­vehicle companies apply them to improve the robustness of their machine-learning models.</p></td>
    </tr>
    <tr>
      <td>Zlatko Minev</td>
      <td>His discovery could reduce errors in quantum computing.</td>
      <td>30</td>
      <td>IBM Quantum Research, TJ Watson</td>
      <td>visionaries-2020</td>
      <td><p>Zlatko Minev overturned a mainstay of quantum physics that had troubled Niels Bohr and Albert Einstein alike. For most of the 20th century, it was assumed that atoms change from one energy level to another in abrupt, unpredictable, discrete quantum jumps. Minev proved otherwise.</p>  <p>“Quantum physics is not quite as unpredictable and discrete as we previously thought,” he says.&nbsp;</p>  <p>His experiment showed that when an atom is bombarded with energy in the form of light, it moves from one energy level to the next in a continuous, smooth way, not an instantaneous jump. What’s more, Minev was able to detect the change in an atom’s energy level quickly enough to control it so he could stop the jump midflight and reverse it before it was completed.&nbsp;</p>  <p>“In the short term,” he says, “with the monitoring that I developed for this project, we can actually have a window of predictability.”&nbsp;</p>  <p>Minev’s work could have major implications for quantum computing. Such systems are riddled with errors that occur when subatomic particles jump between energy levels, like the atoms in Minev’s experiment. The ability to detect and reverse such jumps before they finish should dramatically boost the power of quantum computers, allowing them to better crack encryption, model chemical reactions, and forecast weather.&nbsp;</p>  <p><em>Photo by Robert Jones</em></p></td>
    </tr>
    <tr>
      <td>Miguel Modestino</td>
      <td>He is reducing the chemical industry’s carbon footprint by using AI to optimize reactions with electricity instead of heat.</td>
      <td>34</td>
      <td>NYU</td>
      <td>visionaries-2020</td>
      <td><p>Miguel Modestino has cleared a major hurdle in electrifying the chemical industry, which produces compounds used in everything from plastics to fertilizer. His AI-based system teaches itself how to optimize the reactions for making various chemicals by zapping them with pulses of electricity instead of the conventional approach of heating them, which typically involves burning fossil fuels. And since electricity can come from renewable sources like wind or solar, electrifying chemical plants could greatly reduce emissions.&nbsp;</p>  <p>In an early lab project, Modestino’s team achieved more than a 30% boost in the production rate of adiponitrile<em> (</em>which is used in making nylon, among numerous other industrial processes)<em>—</em>a greater improvement than any other method has shown in the last 50 years.</p>  <p>The key was using complex pulses of electrical current at constantly varying rates to optimize yields. Figuring out what patterns of pulses to use required machine learning. Modestino ran a few experiments making adiponitrile under different electrical conditions and then let his AI analyze the data to figure out how to make the compound with less energy, better yields, and less waste.&nbsp;</p>  <p>Modestino and two former students recently founded Sunthetics to apply the AI system to other chemical processes, like those involved in generating hydrogen fuel and making polymers. The company is also working to scale up the adiponitrile process for a full pilot reactor and to extend the approach to other processes.</p>  <p><em>Photo by Eduardo Whaite</em></p></td>
    </tr>
    <tr>
      <td>Inioluwa Deborah Raji</td>
      <td>Her research on racial bias in data used to train facial recognition systems is forcing companies to change their ways.</td>
      <td>24</td>
      <td>AI Now Institute</td>
      <td>visionaries-2020</td>
      <td><p>The spark that sent Inioluwa Deborah Raji down a path of artificial-intelligence research came from a firsthand realization that she remembers as “horrible.”</p>  <p>Raji was interning at the machine--learning startup Clarifai after her third year of college, working on a computer vision model that would help clients flag inappropriate images as “not safe for work.” The trouble was, it flagged photos of people of color at a much higher rate than those of white people. The imbalance, she discovered, was a consequence of the training data: the model was learning to recognize NSFW imagery from porn and safe imagery from stock photos—but porn, it turns out, is much more diverse. That diversity was causing the model to automatically associate dark skin with salacious content.</p>  <p>Though Raji told Clarifai about the problem, the company continued using the model. “It was very difficult at that time to really get people to do anything about it,” she recalls. “The sentiment was ‘It’s so hard to get any data. How can we think about diversity in data?’”</p>  <p>The incident pushed Raji to investigate further, looking at mainstream data sets for training computer vision. Again and again, she found jarring demographic imbalances. Many data sets of faces lacked dark-skinned ones, for example, leading to face recognition systems that couldn’t accurately differentiate between such faces. Police departments and law enforcement agencies were then using these same systems in the belief that they could help identify suspects. &nbsp; &nbsp; &nbsp;</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>“There are a lot of machine-learning models currently being deployed ... and there was no sense of accountability”</p></blockquote></figure>  <p>“That was the first thing that really shocked me about the industry. There are a lot of machine-learning models currently being deployed and affecting millions and millions of people,” she says, “and there was no sense of accountability.”</p>  <p>Born in Port Harcourt, Nigeria, Raji moved to Mississauga, Ontario, when she was four years old. She remembers very little of the country she left other than the reason for leaving: her family wanted to escape its instability and give her and her siblings a better life. The transition proved tough. For the first two years, Raji’s father continued to work in Nigeria, flying back and forth between two continents. Raji attended seven different schools during their first five years in Canada.</p>  <p>Eventually, the family moved to Ottawa and things began to stabilize. By the time she applied to college, she was sure she was most interested in pre-med studies. “I think if you’re a girl and you’re good at science, people tell you to be a doctor,” she says. She was accepted into McGill University as a neuroscience major. Then, on a whim,&nbsp; and with her father’s encouragement, she visited the University of Toronto and met a professor who persuaded her to study engineering. “He was like, ‘If you want to use physics and you want to use math to build things that actually create impact, you get to do that in this program,’” she remembers. “I just fell for that pitch and overnight changed my mind.”</p>  <p>It was at university that Raji took her first coding class and quickly got sucked into the world of hackathons. She loved how quickly she could turn her ideas into software that could help solve problems or change systems. By her third year, she was itching to join a software startup and experience this in the real world. And so she found herself, a few months into her internship at Clarifai, searching for a way to fix the problem she had discovered. Having tried and failed to get support internally, she reached out to the only other researcher she knew of who was working on fighting bias in computer vision.</p>  <p>In 2016, MIT researcher Joy Buolamwini (one of MIT Technology Review’s 35 Innovators Under 35 in 2018) gave a TEDx talk about how commercial face recognition systems failed to detect her face unless she donned a white mask. To Raji, Buolamwini was the perfect role model: a black female researcher like herself who had successfully articulated the same problem she had identified. She pulled together all her code and the results of her analyses and sent Buolamwini an unsolicited email. The two quickly struck up a collaboration.</p>  <p>At the time, Buolamwini was already working on a project for her master’s thesis, called Gender Shades. The idea was simple yet radical: to create a data set that could be used to evaluate commercial face recognition systems for gender and racial bias. It wasn’t that companies selling these systems didn’t have internal auditing processes, but the testing data they used was as demographically imbalanced as the training data the systems learned from. As a result, the systems could perform with over 95% accuracy during the audit but have only 60% accuracy for minority groups once deployed in the real world. By contrast, Buolamwini’s data set would have images of faces with an even distribution of skin color and gender, making it a more comprehensive way to evaluate how well a system recognizes people from different demographic groups.&nbsp;</p>  <p>Raji joined in the technical work, helping to prepare the data for Buolamwini's audits. The results were shocking: among the companies tested—Microsoft, IBM, and Megvii (the company best known for making the software Face++)—the worst identified the gender of dark-skinned women 34.4% less accurately than that of light-skinned men. The other two didn’t do much better. The findings made a headline in the New York Times and forced the companies to do something about the bias in their systems.</p>  <p>Gender Shades showed Raji how auditing could be a powerful tool for getting companies to change. So in the summer of 2018, she left Clarifai to pursue a new project with Buolamwini at the MIT Media Lab, which would make its own headlines in January 2019. This time Raji led the research. Through interviews at the three companies they’d audited, she saw how Gender Shades had led them to change the ways they trained their systems in order to account for a greater diversity of faces. She also reran the audits and tested two more companies: Amazon and Kairos. She found that whereas the latter two had egregious variations in accuracy between demographic groups, the original three had dramatically improved.</p>  <p>The findings made a foundational contribution to AI research. Later that year, the US National Institute of Standards and Technology also updated its annual audit of face recognition algorithms to include a test for racial bias.</p>  <p>Raji has since worked on several other projects that have helped set standards for algorithmic accountability. After her time at the Media Lab, she joined Google as a research mentee to help the company make its AI development process more transparent. Whereas traditional software engineers have well-established practices for documenting the decisions they make while building a product, machine-learning engineers at the time did not. This made it easier for them to introduce errors or bias along the way, and harder to check such mistakes retroactively.</p>  <p>Along with a team led by senior research scientist Margaret Mitchell, Raji developed a documentation framework for machine-learning teams to use, drawing upon her experience at Clarifai to make sure it would be easy to adhere to. Google rolled out the framework in 2019 and built it into Google Cloud for its clients to use. A number of other companies, including OpenAI and natural-language processing firm Hugging Face, have since adopted similar practices.</p>  <p>Raji also co-led her own project at Google to introduce internal auditing practices as a complement to the external auditing work she did at the Media Lab. The idea: to create checks at each stage of an AI product’s development so problems can be caught and dealt with before it is put out into the world. The framework also included advice on how to get the support of senior management, so a product would indeed be held back from launching if it didn’t pass the audits.</p>  <p>With all her projects, Raji is driven by the desire to make AI ethics easier to practice—“to take the kind of high-level ethical ideals that we like to talk about as a community and try to translate that into concrete actions, resources, and frameworks,” she says.</p>  <p>It hasn’t always been easy. At Google, she saw how much time and effort it took to change the way things were done. She worries that the financial cost of eliminating a problem like AI bias deters companies from doing it. It’s one reason she has moved back out of industry to continue her work at the nonprofit research institute AI Now. External auditing, she believes, can still hold companies accountable in ways that internal auditing can’t.</p>  <p>But Raji remains hopeful. She sees that AI researchers are more eager than ever before to be more ethical and more responsible in their work. “This is such impactful technology,” she says. “I just really want us to be more thoughtful as a field as to how we build these things, because it does matter and it does affect people.”&nbsp;</p>  <p><em>Photo by David Vintiner</em></p>  <p><em>Update Sept 23, 2020: Some details of Raji's involvement with Gender Shades have been clarified</em>.</p></td>
    </tr>
    <tr>
      <td>Adriana Schulz</td>
      <td>Her tools let anyone design products without having to understand materials science or engineering.</td>
      <td>34</td>
      <td>University of Washington</td>
      <td>visionaries-2020</td>
      <td><p>Adriana Schulz’s computer-based design tools let average users and engineers alike use graphical drag-and-drop interfaces to create functional, complex objects as diverse as robots and birdhouses without having to understand their underlying mechanics, geometries, or materials.</p>  <p>“What excites me is that we’re about to enter the next phase in manufacturing—a new manufacturing revolution,” says Schulz.&nbsp;</p>  <p>One of her creations is Interactive Robogami, a tool she built to let anyone design rudimentary robots. A user designs the shape and trajectory of a ground-based robot on the screen. Schulz’s system automatically translates the raw design into a schematic that can be built from standard or 3D-printed parts.</p>  <p>Another of the tools she and her collaborators built lets users design drones to meet their chosen requirements for payload, battery life, and cost. The algorithms in her system incorporate materials science and control systems, and they automatically output a fabrication plan and control software.&nbsp;</p>  <p>Schulz is now helping start the University of Washington Center for Digital Fabrication, which she will co-direct. She will work with local technology and manufacturing companies to move her tools out of the lab.</p>  <p><em>Photo by David Curtis</em></p></td>
    </tr>
    <tr>
      <td>Dongjin Seo</td>
      <td>He is designing computer chips to seamlessly connect human brains and machines.</td>
      <td>31</td>
      <td>Neuralink</td>
      <td>visionaries-2020</td>
      <td><p>Six years ago Dongjin “DJ” Seo said he'd always wanted to be “a scientist with strong intuitions about how to improve the world through engineering.” At the time, he was working in a crowded corner of a lab at the University of California, Berkeley, on a concept called neural dust—ultra-small electronic sensors that could be sprinkled in an animal’s brain and controlled with acoustic waves. </p>  <p>The goal of that project was new types of brain-machine interfaces that could read the firing of neurons inside the cortex and even send information back in. That kind of technology might open up ways to read and write information from and to the brain.&nbsp;</p>  <p>Then, in 2016, Elon Musk tapped him to join a new company, Neuralink, which was ready to spend millions on engineering a seamless interface between human brains and computers. “The vision that Elon outlined—well, it was hard to say no,” Seo says. “It was everything I had imagined.” </p>  <p>Instead of neural dust, the startup is betting on a robot that plunges ultra-thin electrodes into animal brains. Seo is head of a team of about a dozen people designing low-power wireless computers that fit into a small burr hole that’s cut into the skull. He says his primary contribution is designing the necessary circuit boards and chips. “We need these chips to collect a signal that may look like noise, process it, and do all that without cooking your brain.” &nbsp;</p>  <p>After tests on animals, the company hopes to try the brain connection on someone with paralysis or a serious illness. Eventually, “augmentation” of healthy people “is an obvious result,” Seo says: “It’s being able to enhance our ability to interact with the world.”&nbsp;</p></td>
    </tr>
    <tr>
      <td>Mohamed Dhaouafi</td>
      <td>His company’s artificial limbs are not only high-functioning but cheap enough for people in low-income countries.</td>
      <td>28</td>
      <td>Cure Bionics</td>
      <td>humanitarians-2020</td>
      <td><p>Four years ago, during a university challenge, Mohamed Dhaouafi found out that one of his teammates’ cousins had been born without upper limbs and couldn’t afford prosthetics. An engineering student at the time, he’d been searching for a project that would have a social impact—and as he started to research limb loss around the world, he found a massive unmet need. The World Health Organization estimates that there are 30 million people with amputated limbs in poor countries, and only 5% of them have access to prosthetics. Fitting children with high-quality devices is particularly expensive because they’re constantly growing. But without prosthetics, stigma and mobility problems keep large numbers of them from attending school, setting many up for lifelong unemployment. “We’re not just talking about limb differences,” Dhaouafi says. “We’re talking about poverty, access to education, access to health care.”&nbsp;</p>  <p>Today, Dhaouafi has a product he believes will help make advanced artificial limbs more accessible. His Tunisia-based startup, Cure Bionics, is in the process of finalizing an adjustable multi-grip bionic arm that will sell for about $2,000—a fraction of the cost of similar devices. His team plans to keep costs down by 3D-printing key components and engineering much of the circuitry in-house.&nbsp;</p>  <p>But this doesn’t mean they’re skimping on quality: like bionic arms developed elsewhere, Cure’s prototype is equipped with sensors that allow users to operate the hand by flexing or relaxing the muscles in their residual limb. The company is also developing algorithms to help the arm recognize the body’s electrical signals more accurately, which will minimize reliance on an orthopedist for adjustments. At a later stage, Cure plans to introduce a virtual--reality headset that will gamify the physical therapy process for children. “Instead of a doctor asking you to imagine picking up an apple, you’ll be using your hand to jump between buildings like Spider-Man,” Dhaouafi says.</p>  <p>Dhaouafi and his colleagues are closing in on their initial product launch: they’ve already tested their arm with five Tunisian youths and will soon initiate trials at three government hospitals. Ultimately Dhaouafi hopes to offer a range of high-quality, affordable prosthetics for young people across Africa, the Middle East, and beyond.&nbsp;</p>  <p><em>Photo by the Obama Foundation</em></p></td>
    </tr>
    <tr>
      <td>Alex Le Roux</td>
      <td>A massive 3D-printing project in Mexico could point the way to the future of affordable housing.</td>
      <td>27</td>
      <td>Icon</td>
      <td>humanitarians-2020</td>
      <td><p>Alex Le Roux thinks 3D printing can open new possibilities for architectural design and cut the cost of building housing around the world.</p>  <p>As cofounder of Icon, a startup based in Austin, Texas, Le Roux is the mastermind behind the Vulcan, an industrial--scale 3D printer that can construct the wall system of an entire house in just 24 hours of print time. According to the United Nations, some 1.6 billion people lack adequate shelter, and a third of the world’s urban population lives in informal settlements or slums. Part of the reason, Le Roux says, is that traditional building methods lead to wasted materials and excess labor costs, driving up housing prices beyond the reach of many poor families.</p>  <p>The Vulcan is designed to change that by introducing automation to the process. The 12-foot-tall robotic device works by extruding inch-thick layers of a special concrete mix fed in from a separate machine, much like a giant tube of toothpaste. Icon programs its home designs ahead of time to make the operator’s job as simple as possible. “Once these two machines are set up on a job site, you download an app and you’re off to the races,” Le Roux says.</p>  <p>In March 2018, Icon built the US’s first officially permitted 3D-printed house. It has now built 16 houses in Austin and in Mexico, where it’s constructing the world’s first 3D-printed community, designed to accommodate 50 low-income families. Icon’s ultimate goal, Le Roux says, is to reduce the cost of homebuilding by 50%.&nbsp;</p>  <p><em>Photo by Natalie Cass, Score Headshots</em></p></td>
    </tr>
    <tr>
      <td>Katharina Volz</td>
      <td>A loved one’s diagnosis led her to employ machine learning in the search for a Parkinson’s cure.</td>
      <td>33</td>
      <td>OccamzRazor</td>
      <td>humanitarians-2020</td>
      <td><p>In 2016, Katharina Volz received news that someone close to her had Parkinson’s. At the time Volz had just finished her PhD at Stanford and was locked into a well-earned career in academic research, working on stem cells. But the news changed all that.&nbsp;</p>  <p>“I just knew I could actually make a difference,” she says. “Sometimes you feel helpless. But actually I felt deeply responsible for finding a way to get curative treatments for this disease, because I knew I could do something about it.” Volz now leads a company, OccamzRazor, that has successfully married machine learning with biomedical research and is pushing the search for a Parkinson’s cure.&nbsp;</p>  <p>Volz noticed a problem when it comes to researching Parkinson’s, and it’s one that arguably plagues science at large. Experts studying the disease were specializing in particular aspects of it and generally didn’t know much about and couldn’t engage with other aspects. These academic silos made it hard for new insights to be properly shared and explored, impeding our continued understanding of how Parkinson’s progresses.&nbsp;</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>“I felt deeply responsible for finding a way to get curative treatments for this disease, because I knew I could do something about it.”</p></blockquote></figure>  <p>“Even if you’re the smartest researcher in the world, you can’t put all of this information together and make the connections you need to truly understand how the disease operates,” says Volz. “As humans, our ability to draw these numerous connections is limited.”</p>  <p>That’s where machine learning comes in. Volz realized AI could do a better job than a human at reading all the different papers and data sets published on a topic and identifying insights that could lead to breakthroughs. Though machine learning isn’t her specialty, she brought together a team of AI researchers, along with experts from other fields like computational biology, drug development, and neuroscience. She raised money from various investors, including Jeff Dean (the head of AI at Google) and the Michael J. Fox Foundation. Thus, in 2016, OccamzRazor was born.&nbsp;</p>  <p>The company is tackling the problem in two major steps. First, it has developed programs that read and understand published materials on Parkinson’s. Next, it is using AI to integrate genomics, proteomics, and clinical data sets. The goal is to predict new pathways and genes important to Parkinson’s that can then be tested in the laboratory.&nbsp;</p>  <p>The result is what OccamzRazor calls the “Parkinsome”—a knowledge map of Parkinson’s that reveals how the disease is caused and progresses, points to signs and symptoms that can help make an early diagnosis, and identifies potential therapeutic targets. After OccamzRazor validates its findings, it partners with biotech and pharma companies to develop drugs.&nbsp;</p>  <p>The goal is to take this approach beyond just Parkinson’s. Volz and her team have plans to scale up the platform to build comprehensive knowledge maps for other complex diseases related to the aging of the brain.&nbsp; “Diseases inform each other,” says Volz. “Studying Parkinson’s is one of the best ways to study brain aging in general.”&nbsp;</p>  <p><em>Photo by David Vintiner</em></p></td>
    </tr>
    <tr>
      <td>David Warsinger</td>
      <td>His system could alleviate the drawbacks of existing desalination plants.</td>
      <td>32</td>
      <td>Purdue University</td>
      <td>humanitarians-2020</td>
      <td><p>David Warsinger thinks he’s found an innovation that could help combat one of the 21st century’s great environmental challenges: water shortages around the globe.</p>  <p>His fix is an improved form of reverse osmosis<em>—</em>the most common method of desalination. Today, an estimated 5% of the world’s population relies on desalinated water, drawn from the ocean or brackish inland sources, to meet at least some daily needs. This figure will continue to rise as aquifers are further squeezed by pollution, overuse, and shifting rainfall patterns linked to climate change. According to the United Nations, some 3.6 billion people live in areas that experience water scarcity at least one month of the year<em>—</em>and that number is likely to exceed five billion by 2050. “Globally, we are truly tapping out our water resources,” Warsinger says.</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>“Globally, we are truly tapping out our water resources.”</p></blockquote></figure>  <p>Yet desalination today has major limitations. Traditional reverse osmosis, in which pressurized water is forced through a salt-removing membrane, uses a lot of energy and is costly. It also leaves behind a large part of the water as brine<em>—</em>an especially big problem for inland plants, where source water is scarcer.</p>  <p>Warsinger’s system, which he developed with Emily Tow while they were both at MIT, is known as batch reverse osmosis, and it is designed to make the process more efficient. The technique allows desalination to occur in batches, with salinity and pressure varying over time. Whereas traditional reverse osmosis systems apply constant pressure, the batch system is engineered to apply less pressure to water that’s less salty, saving a considerable amount of energy. It also increases the rate of fresh water extraction by minimizing the build-up of salt on the membranes.</p>  <p>Warsinger’s lab at Purdue, where he’s now a professor of mechanical engineering, has since worked to refine the batch design. His team has developed a trailer-sized prototype it hopes to use for pilot plants in Peru and Kenya.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Ghena Alhanaee</td>
      <td>Heavy dependence on infrastructure like oil rigs, nuclear reactors, and desalination plants can be catastrophic in a crisis. Her data-driven framework could help nations prepare.</td>
      <td>30</td>
      <td>University of Southern California</td>
      <td>pioneers-2020</td>
      <td><p>Early on in her days as a doctoral student at the University of Southern California, Ghena Alhanaee stumbled upon a disturbing set of facts. The countries of the Persian Gulf, including her native United Arab Emirates, were far more vulnerable to disaster than she’d realized. Not only was the Gulf itself one of the world’s largest oil and gas production zones, with more than 800 offshore platforms and thousands of tankers passing through its shallow waters every year, but the UAE was also building the Arab Peninsula’s first nuclear power plant. Meanwhile, several Gulf countries relied almost exclusively on desalinated Gulf water for drinking, with emergency supplies for just two or three days. “If something were to happen, and desalination plants weren’t able to operate, right now there really is no backup plan,” Alhanaee says.</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p> <span style="font-size: 1.5rem; background-color: initial;">“If something were to happen, and desalination plants weren’t able to operate... there really is no backup plan.”</span></p></blockquote></figure>  <p>Ever since, she has devoted her energy to tackling the Gulf’s disaster preparedness gap. She’s developing a data-driven framework to help the region better mitigate the risks of an oil spill or nuclear accident. Since the Gulf’s nuclear industry is nascent, and its oil and gas sector keeps its data private, she’s relying on information from the US: her statistical model draws on data from more than 4,000 reported safety incidents in the US nuclear and offshore oil industries over the past decade. The trick, she says, is to better understand which combinations of small incidents, under which scenarios, are most likely to snowball into something major.</p>  <p>Alhanaee’s framework seeks to do just that. She plans to apply her findings to a particularly vulnerable spot in the Gulf<em>—</em>in the vicinity of the Barakah nuclear power plant, which is nearing completion, and large-scale oil and desalination installations. Ultimately, she hopes her research will help the region’s governments develop more robust, and better coordinated, disaster mitigation strategies.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Avinash Manjula Basavanna</td>
      <td>His biodegradable plastic protects against extreme chemicals, but heals itself using water.</td>
      <td>33</td>
      <td>Wyss Institute, Harvard University</td>
      <td>pioneers-2020</td>
      <td><p>Of the estimated <a href="https://advances.sciencemag.org/content/3/7/e1700782.full">9.1 billion tons of plastic ever produced</a>, only <a href="https://www.statslife.org.uk/news/4026-statistics-of-the-year-2018-winners-announced">9% has been recycled</a>. Almost 80% ends up as waste that adds to growing landfills or pollutes the natural environment, where it takes a thousand years to degrade. Such materials can also end up in the human body as microplastics, slowly accumulating with devastating effects on health. One key to solving these problems could be bioplastics—plastic alternatives produced through bioengineered organisms. These can degrade naturally and much more quickly.</p>  <p>The idea of bioplastics isn’t exactly new, but it’s been difficult to make them in the sorts of quantities and with the properties that would be useful for industry. Avinash Manjula Basavanna, a postdoc at the Wyss Institute for Biologically Inspired Engineering at Harvard University, thinks he can do better. He and his colleagues have developed a new type of plastic based on living materials that he calls AquaPlastic and which can be produced at a commercial scale, exhibits the tough qualities of many petroleum-based plastics, and can degrade in water in as little as two months.&nbsp;</p>  <p>The material itself is resistant to strong acids and bases. It can be applied as a coating using nothing but water, which makes the plastic turn adhesive—the first plastic of its kind to boast this feature. If it gets scratched, the coating can also be “healed” using water. And most important, “it’s flushable,” says Manjula Basavanna. “You don’t have to worry about it adding to our plastic and microplastic problem.” He and his partners are now in the beginning stages of forming a startup around AquaPlastic. If manufactured at scale, the cheap, biodegradable material could compete with conventional plastic coatings.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Lili Cai</td>
      <td>She created energy-efficient textiles to break our air-conditioning habit.</td>
      <td>33</td>
      <td>University of Illinois at Urbana-Champaign</td>
      <td>pioneers-2020</td>
      <td><p>Lili Cai has created nanomaterial--based textiles the thickness of a normal T-shirt that can keep you warm or cool you off.&nbsp;</p>  <p>Cai’s work takes advantage of the fact that human skin strongly emits infrared radiation in a specific range of wavelengths. By manipulating the ways in which her fabrics block or transmit radiation in this band, she has produced multiple textiles that can have different effects on temperature.</p>  <p>To heat the body, Cai created a metallized polyethylene textile that can minimize heat radiation loss but is still breathable. Compared with normal textiles, it keeps people about 7 °C warmer. Under direct sunlight, her cooling fabric, a novel nanocomposite material, can cool the body by more than 10 °C.&nbsp;</p>  <p>Cai believes it’s extremely important to figure out how to make such textiles look as much as possible like normal clothing. Previous radiative cooling materials could only be produced in white, but in 2019 Cai figured out how to fabricate her textiles in different colors. Her goal is to eventually produce one single adaptive textile that keeps you warm if it’s cold out, but cools you off in the heat.</p>  <p>As climate change introduces shifts in weather and temperature patterns globally, people will use even more energy to regulate building temperatures. If she can figure out how to cheaply make her textiles at scale, they will provide an alternative that could help cut those heating and cooling bills.</p></td>
    </tr>
    <tr>
      <td>Gregory Ekchian</td>
      <td>He invented a way to make radiation therapy for cancer safer and more effective.</td>
      <td>32</td>
      <td>MIT</td>
      <td>pioneers-2020</td>
      <td><p>The amount of radiation it takes to kill a tumor depends on the level of oxygen in the tumor cells. This can vary greatly, but oncologists don’t currently adjust radiation doses to account for it. Gregory Ekchian, cofounder of Stratagen Bio, has developed a sensor for reading tumor oxygen levels to personalize cancer treatment.&nbsp;</p>  <p>Ekchian recognized a glaring need for a new sensing tool after discussions with clinicians at Brigham and Women’s Hospital in Boston. He developed a prototype for a cancer treatment technique called high-dose-rate brachytherapy.&nbsp;In this form of treatment, doctors puncture the tumor with a series of hollow catheter tubes and then drop radioactive seeds through the tubes to suffuse the tumor with radiation, removing them once the desired dose has been delivered.</p>  <p>For his prototype, Ekchian added a strip of a recently invented oxygen-sensitive polymer to the tips of a modified version of the catheters. During routine MRI scans, protons in the polymer are excited; these protons return to equilibrium far faster in catheters surrounded by high levels of oxygen than low levels. The speed at which they return to equilibrium can therefore be used to map out how oxygen levels vary in different parts of the tumor, allowing oncologists to pinpoint where radiation doses should go and tailor their length and intensity to be most effective. &nbsp;</p>  <p>“If we weren’t worried about healthy tissue, we would just boost the dose to the entire tumor,” he says, but excess radiation can harm the patient. That means “it’s really important to figure out where those high doses need to go.” &nbsp;</p>  <p>Ekchian is preparing to publish the results of a clinical trial involving seven patients with cervical cancer, the first in humans. He ultimately hopes to employ his oxygen-sensing applications for a wide range of clinical needs.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Jennifer Glick</td>
      <td>If quantum computers work, what can we use them for? She’s working to figure that out.</td>
      <td>30</td>
      <td>IBM QUANTUM</td>
      <td>pioneers-2020</td>
      <td><p>The world’s biggest machine, the Large Hadron Collider, was built to help answer some of the most important questions in physics. To do that, the scientists behind the particle collider have to be able to process and understand the massive amounts of data from the machine. They want to be able to tell whether certain particles are produced in high--energy collisions taking place at nearly the speed of light.&nbsp;</p>  <p>The LHC can produce over a petabyte of data per second from one billion particle collisions, requiring about one million processor cores spread out around the world to analyze and understand what would otherwise be chaos. What does all that data mean?</p>  <p>This is one of the most staggering problems facing Jennifer Glick, an IBM researcher whose work is to find big problems that can benefit from quantum computing and then either try to solve them with existing quantum algorithms or create new ones for the purpose.&nbsp;</p>  <p>Quantum computing promises enormous advances in processing power over classical computing for certain problems that are intractably large or time-consuming for classical computers—the kind of problems Glick looks for. A quantum computer’s strength can be credited to the superposition and entanglement of quantum bits, or qubits, which offer an exponentially large computational space. For example, 50 perfect qubits can represent over a quadrillion states to explore.</p>  <p>Still, it’s a technology in its very early days. In two years at IBM, Glick has helped lead an effort to create partnerships that bring quantum technology into the real world. She spends a lot of her time hunting for problems and then developing and demonstrating ways in which a quantum computer could solve them faster than a classical one.</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p><span style="font-size: 1.5rem; background-color: initial;">She’s helped lead an effort to bring quantum technology into the real world.</span></p></blockquote></figure>  <p>“What we’re looking at for the Large Hadron Collider is to use a quantum algorithm to predict whether or not a certain particle was produced,” she says. “Was that the particle I think was produced or not?”</p>  <p>In 2019, Glick and her colleagues tackled another big but more workaday problem with the banking giant Barclays. The challenge was managing the quadrillions of dollars processed each year in securities transaction settlements. These occur, for instance, when a financial institution buys shares, bonds, or derivatives. Clearinghouses must run complex optimization algorithms on the transactions to settle as many of them as possible within technical and legal constraints.&nbsp;</p>  <p>The results of the team’s research indicate&nbsp; that quantum technology could make this process more efficient, speeding up the time between trade and settlement. “When someone gives you an industry or business problem, there’s a lot of complications to start out with. It’s a very complex, gnarly problem,” Glick says. “Part of it is breaking it down into simpler pieces to be able to identify where the bottlenecks are with respect to classical computing methods that are being used today. And can any of those bottlenecks be removed by an quantum approach?"</p>  <p><em>Photo by David Vintiner</em></p></td>
    </tr>
    <tr>
      <td>Andrej Karpathy</td>
      <td>He’s employing neural networks to allow automated cars to “see.”</td>
      <td>33</td>
      <td>Tesla</td>
      <td>pioneers-2020</td>
      <td><p>Getting computers to see—to actually see—has been an ambition of countless computer scientists for decades. Few have come closer than Andrej Karpathy, whose approach to deep neural networks allows machines to make sense of what is happening in images.</p>  <p>As a graduate student at Stanford, Karpathy extended techniques for building what are known as convolutional neural networks (CNNs)—systems that broadly mimic the neuron structure in the visual cortex. (In 2015 he also designed and was the primary instructor for the first deep-learning class at Stanford.)</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p><span style="font-size: 1.5rem; background-color: initial;">Using Karpathy’s advances, Tesla is taking a different path from most other automakers.</span></p></blockquote></figure>  <p>By combining CNNs with other deep-learning approaches, he created a system that was not just better at recognizing individual items in images (say, a dog or a person), but capable of seeing an entire scene full of objects—multiple dogs and people interacting with each other—and effectively building a story of what was happening in it and what might happen next.&nbsp;</p>  <p>In 2017, Karpathy joined Tesla, where he oversees neural networks for the cars’ Autopilot feature. That includes collision detection, self-driving capabilities, and summoning (having a car drive autonomously from where it is parked).&nbsp;</p>  <p>Using Karpathy’s advances, Tesla is taking a different path from most other automakers. Typically, self-­driving vehicles scan their surroundings with expensive laser range finders, build a virtual map, and then use AI to make decisions about what to do. Tesla’s approach uses traditional cameras. Not only can Karpathy’s method let the car spot objects in the road as a human driver would, but it can take in the entire scene (cars, people, intersections, stop signs, and more) and—if it works as intended—instantly infer what’s taking place. Doing so requires nearly 50 neural networks to constantly process data coming in as the more than a million cars in the fleet look and learn.</p></td>
    </tr>
    <tr>
      <td>Siddharth Krishnan</td>
      <td>A tiny, powerful sensor for making disease diagnosis cheaper, faster, and easier.</td>
      <td>29</td>
      <td>MIT</td>
      <td>pioneers-2020</td>
      <td><p>Siddharth Krishnan, a materials scientist at MIT, developed a tiny sensor that could save people from a devastating and often deadly brain condition.&nbsp;</p>  <p>Between one and two in every 1,000 babies born in the United States have hydrocephalus, a condition in which cerebrospinal fluid builds up in the brain. It can also occur later in life, including after traumatic brain injury. Over a million people in the United States have hydrocephalus, and nearly all of them have a shunt installed that drains fluid from their brain into their chest or abdomen. The condition can be fatal if untreated, but if it’s dealt with promptly a full recovery is often possible.</p>  <p>If shunts fail, because they get clogged, then fluid will again build up in the brain. This happens to about half of shunts within six years, so it’s a major problem.&nbsp;</p>  <p>Earlier techniques for detecting shunt failure all had various shortcomings. Repeated CT scans, MRIs, or x-rays subject patients to dangerous doses of radiation, cost a lot, and—because they measure the performance of shunts only indirectly—are not all that reliable. Sometimes, invasive brain surgery is done just to verify that a shunt is working. And because checks were being performed only a few times a year, patients and their families had to live with constant uncertainty, wondering if their shunts were working properly.&nbsp;</p>  <figure class="wp-block-pullquote alignleft"><blockquote><p>His noninvasive sensor can radically improve the treatment for hydrocephalus, which can be fatal if left untreated.</p></blockquote></figure>  <p>In any case, because the flow of fluid from the brain is naturally intermittent, spot checks don’t necessarily catch problems.</p>  <p>Krishnan’s sensor offers a noninvasive way to monitor the flow in shunts: it can be placed over the skin on the neck, near the valve. It measures the temperature at several distinct spots, inferring from the temperature distribution at those spots whether or not liquid is flowing. Unlike an earlier generation of noninvasive sensors, which made fewer temperature measurements and required the use of an ice pack, his device can continuously measure the flow, reporting results via Bluetooth.&nbsp;</p>  <p>So far, field trials on seven patients reported in a paper earlier this year in the journal NPJ Digital Medicine show that his sensor gives “robust, high-quality data” for hours at a time.</p>  <p>Krishnan hopes that his sensor will have applications beyond hydrocephalus, possibly monitoring other diseases like diabetes, where tiny changes beneath the skin can have huge effects.</p></td>
    </tr>
    <tr>
      <td>Andreas Puschnik</td>
      <td>Seeking a universal treatment for viral diseases, he might leave us much better prepared for the next pandemic.</td>
      <td>31</td>
      <td>Chan Zuckerberg Biohub</td>
      <td>pioneers-2020</td>
      <td><p>Zika, Ebola, SARS, dengue fever, and covid-19. These diseases have fearsome personalities, yet the viruses that cause them are not really alive. To reproduce, viruses need to hijack a cell and use its components to produce more viruses.&nbsp;</p>  <p>To Andreas Puschnik, understanding which of our biomolecules viruses depend on could lead to new types of broad-acting antiviral drugs. “The idea is that viruses depend on specific cellular pathways which could themselves become drug targets,” says Puschnik.</p>  <p>Usually, the German-born researcher says, drug makers look to take out pathogens with chemicals designed to bind to and disable the molecular components of the virus itself. This “one drug, one bug” solution can work powerfully (think HIV drugs). The problem is that each drug has to be specially designed.&nbsp;</p>  <p>An alternative, called host-directed therapeutics, is in its early days. But Puschnik has helped speed it up using the gene-editing tool CRISPR. In a mass screening approach, he uses CRISPR to pepper millions of human cells growing in flasks with a hundred thousand different genetic mutations. If any of those cells survive infection with, say, yellow fever, it means he’s inactivated a molecular pathway the germ needs to reproduce.</p>  <p>Puschnik has already helped find an enzyme that mosquito-borne flaviviruses like dengue, Zika, and West Nile need to reproduce, as well as a drug to block it. Since all flaviviruses work similarly, he hopes the drug could be a “universal treatment” for them.</p>  <p>During California’s 2020 lockdown, the biologist remained at work at the Chan Zuckerberg Biohub, a new institute that picked him as its first scientific fellow. “It is still busy days for virologists,” says Puschnik, who now plans to turn his attention to the coronavirus that causes covid-19. Perhaps, he thinks, a drug that changes cells so they are less hospitable to coronaviruses could be ready for the next pandemic: “You might be able to treat viruses you don’t even know about yet.”</p>  <p><em>Photo by David Vintiner</em></p></td>
    </tr>
    <tr>
      <td>Silvia Caballero</td>
      <td>Training helpful bacteria to fight the world’s most dangerous pathogens</td>
      <td>34</td>
      <td>Vedanta Biosciences</td>
      <td>inventors-2019</td>
      <td><p class="p1">In 20 years, antibiotic drug resistance is projected to kill more people than cancer. That’s why Silvia Caballero feels such urgency to develop new approaches to controlling bacterial infections.</p><p class="p2">She was among the first to discover that certain organisms among the trillions that inhabit the human gut can help the body fight back when antibiotic-resistant bacteria begin to take hold.</p><p class="p2">While working in a lab at Memorial Sloan-Kettering Cancer Center in New York, Caballero developed lab mice that mimic intestinal colonization by vancomycin--resistant enterococcus and carbapenem-resistant enterobacteriaceae, also known as superbugs. She used these models together with bioinformatic tools to identify species of microbes that could clear the mouse gut of multi-drug- resistant bacteria, in this way destroying the main reservoir for infection.</p><p class="p2">Now working for Vedanta Biosciences in Cambridge, Massachusetts, Caballero is trying to do the same for people, identifying bacteria that can effectively control three potentially lethal bacterial strains often found in hospitals and nursing homes.</p><p class="p2">She played a key role in the creation of the world’s largest library of human gut bacteria and led a campaign to test thousands of species for their ability to kill those three menacing organisms. Her work led to the identification of a bacterial cocktail derived from human gut flora that can control all three types of bacteria. Vedanta’s goal is to begin clinical studies with this drug candidate in 2021.</p></td>
    </tr>
    <tr>
      <td>Dawei Di</td>
      <td>His LED materials are cheaper and easier on the environment than ones now in use</td>
      <td>34</td>
      <td>Zhejiang University &amp; University of Cambridge</td>
      <td>inventors-2019</td>
      <td><p class="p1"><span class="s1">Light-emitting diodes (LEDs) are used in a plethora of products ranging from smartphone and TV screens to traffic lights, but they’re expensive to make. In addition, the sweet spot between the highly efficient conversion of electricity to light and the ability to shine brightly has been difficult to reach. </span></p><p class="p2"><span class="s1">Dawei Di co-invented new LED materials and devices that can generate light from electricity at maximum efficiency even when they need to reach high brightness. What’s more, they can be manufactured using cheaper, simpler, and less energy-intensive processes.</span></p><p class="p2"><span class="s1">Typical LED production lines require high-temperature processes or depositing light-emitting materials on a solid surface in a vacuum, and thus they use lots of energy. Di’s materials are cheaper because they can be made from widely available substances, and they don’t need to be deposited at high temperature or in a vacuum. Instead, they’re dissolved in a liquid and then coated onto a solid surface. </span></p><p class="p2"><span class="s1">A number of companies are already testing production lines with Di’s methods. Although these lines won’t be replacing standard production facilities immediately, he believes they will become increasingly common.<span class="Apple-converted-space">&nbsp; </span>“The industry is heading that way,” says Di, who’s both a faculty member at Zhejiang University and a visiting researcher at the University of Cambridge. </span></p></td>
    </tr>
    <tr>
      <td>Olga Dudchenko</td>
      <td>She created a better way to sequence a genome</td>
      <td>34</td>
      <td>Baylor College of Medicine &amp; Rice University</td>
      <td>inventors-2019</td>
      <td><p class="p1">Modern gene sequencing machines are very fast, reading through the DNA of a peanut, eggplant, or armadillo in two days. But what they spit out are billions of disorganized fragments of DNA code. Olga Dudchenko has helped to make the next step—pasting those bits together in the right order, to reveal the actual genome—faster and cheaper.</p><p class="p2"><span class="s1">Dudchenko uses Hi-C, a technique originally developed to study how chromosomes fold, to show which bits of DNA lie physically close to one another. Coupled with Dudchenko’s methods and algorithms, this makes assembling genomes easy.</span></p><p class="p2"><span class="s1">In late 2018, Dudchenko and her colleagues shared the first results of DNA Zoo, including end-to-end chromosome sequences for more than 50 species, including the cheetah, red panda, and Brazilian porcupine. In a world of mounting extinction, these species’ DNA code may one day be all that’s left of them.</span></p><p class="p2">The job ahead is to characterize the genome of every species on earth. The DNA Zoo (where Dudchenko is referred to as “chief zookeeper”) releases new data every week. “The ability to [make] decisions in an informed fashion can mean the difference between survival and extinction of the species,” she says.</p></td>
    </tr>
    <tr>
      <td>Abhinav Kandala</td>
      <td>Paving the way for quantum-computer-powered drug and material development</td>
      <td>32</td>
      <td>IBM Research</td>
      <td>inventors-2019</td>
      <td><p class="p1"><span class="s1">More accurate computer models of molecules could help predict useful properties for everything from new drugs to better batteries. But simulating the behavior of the atoms and electrons they consist of means calculating huge numbers of possibilities, so even powerful computers use approximations.</span></p><p class="p2">Abhinav Kandala is solving this problem by using quantum computers to simulate molecules. In 2017 he simulated three-atom beryllium hydride, the largest molecule modeled on a quantum computer to date. This was a crucial step that laid the groundwork for precise simulations of larger molecules, which could lead to the discovery of new medicines and materials.</p><p class="p2"><span class="s1">Quantum computers are made of qubits—the physical elements that encode information the way bits do in a conventional computer. Because qubits are governed by quantum mechanics, they could model other particles subject to its rules, like atoms and electrons, more easily than conventional computers. Kandala, who works for IBM Research in New York, says this makes simulating molecules one of the technology’s “killer applications.”</span></p><p class="p2"><span class="s1">Since 2017 he’s made an even more fundamental contribution. Because quantum states are fragile, quantum computers are error-prone, and compensating for this requires large numbers of qubits. But today’s devices consist of only tens of qubits—not enough to create a fault-tolerant quantum computer. Kandala has demonstrated a way to harness errors to boost accuracy without increasing the number of qubits. His experiments allow him to identify trends that could be used to extrapolate what should be observed in the absence of errors, an advance that could speed practical applications of near-term quantum computers.</span></p></td>
    </tr>
    <tr>
      <td>Marc Lajoie</td>
      <td>Programming white blood cells to fight cancer</td>
      <td>33</td>
      <td>Lyell Immunopharma</td>
      <td>inventors-2019</td>
      <td><p class="p1"><span class="s1">One of the most promising cancer therapies to emerge in recent years is CAR T-cell therapy. This genetically alters a patient’s white blood cells, or T cells, to target a specific protein, or antigen, found on the surface of cancer cells before releasing chemicals to kill them. The problem is that cancer cells often share antigens with cells of other types, so the therapy is currently limited to cancers of certain blood cells with unique antigens.</span></p><p class="p2"><span class="s1">Marc Lajoie has invented a way to reprogram T cells so they can target combinations of antigens rather than just single ones, which should allow them to tackle a much wider range of cancers. “It’s the equivalent of putting a microchip into a cell,” he says. “We can install these new programs and co-opt the cell to make the decisions that we want them to make.”</span></p><p class="p2"><span class="s1">Lajoie and colleagues at the University of Washington developed switches made from proteins, which he then used as the basis of a series of logic gates capable of carrying out the same “and,” ”or,” and “not” operations that computer chips do. </span></p><p class="p2"><span class="s1">Such gates can be tuned to react to different antigens, which allows T cells to target unique combinations of antigens, avoid antigens found on healthy cells, or target cancers that develop resistance due to antigen loss.</span></p><p class="p2"><span class="s1">Lajoie has cofounded a startup called Lyell Immunopharma and works at the company’s Seattle office to develop more effective CAR T-cell therapies using his protein logic. But he says the same technology could help treat all kinds of diseases by rewiring how cells respond to their environment.</span></p></td>
    </tr>
    <tr>
      <td>Ritu Raman</td>
      <td>She’s developed inchworm-size robots made partly of biological tissue and muscle</td>
      <td>27</td>
      <td>MIT</td>
      <td>inventors-2019</td>
      <td><p class="p1"><span class="s1">Ritu Raman’s robots are made out of both polymers and muscle tissue, and are capable of sensing their environment and recognizing<span class="Apple-converted-space">&nbsp; </span>temperature, pH, and mechanical pressure. </span></p><p class="p2">“I’m a mechanical engineer by training, and I’m honestly a little bored building with the materials we’ve been building with for the past thousand years. So I’m making robots and machines that use biological materials to move and walk around and sense their environment, and do more interesting things—like get stronger when they need to and heal when they get damaged.”</p><p class="p2"><span class="s1">Raman has built 3D printers capable of patterning living cells and proteins, injecting those into a mold where the cells self-­assemble into dense muscle tissue. The tissue is then transferred to a robotic skeleton. The robots, powered by living skeletal muscle, move in response to light or electricity. </span></p><p class="p2"><span class="s1">Right now, they look a bit like inchworms, but that’s just the proof of concept. “Can we make new ‘biohybrid’ implants for drug delivery that adapt to your body better than purely synthetic implants could?” Raman says. “Can we release robots into a polluted water supply and have them walk toward a toxin and exude a chemical to neutralize that?”</span></p></td>
    </tr>
    <tr>
      <td>Isaac Sesi</td>
      <td>He created an affordable fix for one of the most vexing problems for farmers in sub-Saharan Africa</td>
      <td>26</td>
      <td>Sesi Technologies</td>
      <td>inventors-2019</td>
      <td><p class="p1"><span class="s1">Isaac Sesi built a gadget he believes can tackle one of the biggest risks faced by farmers across Africa: the contamination of grains following harvest.</span></p><p class="p2"><span class="s1">Sesi’s product, GrainMate, allows famers and grain purchasers to affordably measure moisture levels of maize, rice, wheat, millet, sorghum, and other staples. It’s designed for a simple yet persistent problem: according to the UN Food and Agriculture Organization, more than 20% of sub--Saharan Africa’s cereal output is lost or wasted, often because grains aren’t dried sufficiently before they’re stored. Grain stored while moist can develop aflatoxins—contaminants produced by fungi that are harmful to humans and animals. </span></p><p class="p2"><span class="s1">In Sesi’s native Ghana, individual farmers often sell their harvests to aggregators or animal feed producers; if one farmer’s crops are too moist they risk spoiling the entire batch. Although imported moisture detection devices are available, few farmers in Ghana can afford the nearly $400 price tag. “That might be half of what a farmer is making from his entire field” per harvest, Sesi says.</span></p><p class="p2"><span class="s1">Sesi, who grew up without electricity or running water and often went to school hungry, spent much of his childhood tinkering with electronic devices. He learned by dissecting broken radios and other abandoned gadgets with the help of a book from his school library. He long sought a way to apply that passion to a field that could have a social impact—and in 2017, as a recent electrical engineering graduate, he got his chance. A United States Agency for International Development project operating in partnership with his school, the Kwame Nkrumah University of Science and Technology, had recently designed a grain-moisture meter for the local market. But it wanted to bring the cost down and find a way to produce the device in Ghana.</span></p><p class="p2"><span class="s1">Sesi was their man: with the help of a small team, he streamlined the original device, redesigned its circuit board, built an accompanying mobile app, and found five Ghanaian subcontractors to make components that had previously been sourced from China. Sesi’s device sells for $80—less than one-fourth as much as existing alternatives. Sesi and his team are now developing a more efficient version of the meter and a second product to help farmers identify ideal soil inputs. They’re also raising funds to expand to the bigger markets in Kenya and Nigeria. Ultimately, Sesi believes he can help farmers across the continent cut wastage, minimize economic losses, and improve the safety of their products.</span></p></td>
    </tr>
    <tr>
      <td>Brandon Sorbom</td>
      <td>His high-temperature superconductors could make fusion reactors much cheaper to build</td>
      <td>32</td>
      <td>Commonwealth Fusion Systems</td>
      <td>inventors-2019</td>
      <td><p class="p1"><span class="s1">Brandon Sorbom has solved a fundamental problem that has made fusion reactors too expensive to build. By developing an electromagnetic system using high-temperature superconductors to insulate part of the fusion process, Sorbom’s breakthrough could make fusion reactor designs dramatically cheaper to build.</span></p><p class="p2"><span class="s1">A fusion reactor that can deliver energy to the grid is more than a decade away at best. But developing such a reactor is a worthy goal because fusion has the potential to offer almost limitless zero-carbon energy, with low radioactive waste and safety risks.</span></p><p class="p2"><span class="s1">One puzzle has stumped scientists for decades: how to maintain the 100 million-degree temperatures needed for fusion and do it cheaply enough to profitably produce energy. Powerful magnets can do the job by insulating the fuel at a reactor’s core. But until recently, not even the world’s best electromagnets were good enough. </span></p><p class="p2"><span class="s1">So Sorbom and his team designed a better magnet from a superconductor called yttrium barium copper oxide. First as a student at MIT, and now as the chief scientist at startup Commonwealth Fusion Systems, Sorbom used this magnet as part of a fusion reactor design almost 100 times smaller than was previously thought possible.<span class="Apple-converted-space">&nbsp; </span>The reactor is so small, in fact, that Commonwealth Fusion is on track to build its first functional concept within the next decade.</span></p></td>
    </tr>
    <tr>
      <td>Archana Venkataraman</td>
      <td>We still don’t know much about neurological disorders. She’s using AI to change that.</td>
      <td>33</td>
      <td>John Hopkins University</td>
      <td>inventors-2019</td>
      <td><p class="p1"><span class="s1">Archana Venkataraman is using artificial intelligence to better map the human brain—and to develop entirely new ways to diagnose and treat neurological disorders. </span></p><p class="p2"><span class="s1">Despite decades of research, we have only a basic understanding of disorders such as epilepsy, autism, Alzheimer’s, and schizophrenia, and thus a limited ability to treat them. Most therapies are administered on a trial and error basis, guided by a physician’s instinct. Many of them regularly fail.</span></p><p class="p2"><span class="s1">Informed by data from existing imaging technologies—including the electroencephalogram, or EEG, and functional magnetic resonance imaging, or fMRI— Venkataraman develops mathematical models designed to unlock the “black box” of the brain’s function and provide the building blocks for treatments that are less invasive and far more precise. Her most groundbreaking work targets epilepsy, which affects more than 50 million people globally. Roughly 30% of epilepsy patients do not respond to medication and thus require surgery—which can only work after the seizure onset zone has been successfully isolated to a specific region of the brain. </span></p><p class="p2"><span class="s1">Data-driven models that pinpoint seizure onset, Venkataraman believes, can limit invasive monitoring and improve surgical outcomes. She has developed a seizure-detection algorithm, which is being evaluated on clinical data from Johns Hopkins. This algorithm uses EEG data and employs methods of deep learning to track the time and location of seizure onset in patients’<span class="Apple-converted-space">&nbsp;</span>brains.</span></p></td>
    </tr>
    <tr>
      <td>Anurag Bajpayee</td>
      <td>His approaches can treat dirty wastewater and can make desalination more efficient.</td>
      <td>34</td>
      <td>Gradiant</td>
      <td>entrepreneurs-2019</td>
      <td><p class="p1">Anurag Bajpayee built a one-stop shop for cleaning up the world’s most contaminated water. And after just six years, his Boston-based company, Gradiant, has more than 200 employees and operates more than 20 treatment plants around the world.</p><p class="p2"><span class="s1">Bajpayee started Gradiant with lab-mate Prakash Govindan, who like him was working on desalination techniques. The oil and gas industry was at the peak of the shale boom thanks to advances in fracking, where rock formations are fractured using pressurized fluids to extract oil and gas trapped inside. They quickly found customers keen to use Govindan’s technology to extract water from fluids contaminated during the process, which reduces water requirements and minimizes how much toxic brine needs to be stored in deep disposal wells.</span></p><p class="p2">Since then they’ve developed an extensive patent portfolio, says Bajpayee, and commercialized two more treatment technologies<em>—</em>one that efficiently pulls specific contaminants out of industrial wastewater so it can be reused, and another that disinfects water without the use of chemicals like bleach. This year Gradiant will launch its first commercial system based on a new technology that can be installed in seawater desalination plants to increase recovery of fresh water by up to 85%.</p><p class="p2">As a PhD student at MIT he invented a membrane-free desalination technique that Scientific American recognized as one of its annual Top 10 World-Changing Ideas. But Bajpayee realized that it was a long way from commercial viability and any business built around this one idea was likely to fail. Instead he decided to develop and collect lots of different technologies, so his company could tackle any water contamination problem it encountered.&nbsp;</p></td>
    </tr>
    <tr>
      <td>Jason Buenrostro</td>
      <td>A tinkerer figures out how to tell which genes are active inside a cell</td>
      <td>31</td>
      <td>Harvard University</td>
      <td>entrepreneurs-2019</td>
      <td><p class="p1"><span class="s1">After Jason Buenrostro graduated from Santa Clara University with a degree in biology and engineering, he went to work in a lab at Stanford, overseeing an $800,000 gene sequencing machine. </span></p>  <p class="p2"><span class="s1">He wanted to understand the effects of the genetic mutations his machine detected. But many of the mutated genes he found were considered junk because they didn’t direct the production of proteins. So in his graduate research at Stanford, he pivoted to developing methods for measuring these underexplored regions. </span></p>  <p class="p2"><span class="s1">DNA is essentially identical from cell to cell, but a kidney cell differs from a brain cell in the activity of those genes. Regions of DNA need to be tightly wound to fit inside the nucleus, and only open DNA regions can be active. </span></p>  <p class="p2"><span class="s1">Buenrostro and his colleagues developed a tool called ATAC-seq to measure these open regions of the genome, many of which don’t make proteins but regulate genetic activity. “I didn’t realize how useful [a tool] it would be for people. It kind of exploded,” says Buenrostro, noting that ATAC-seq now has its own Wikipedia page.</span></p>  <p class="p2">More recently, Buenrostro has further developed the technology to identify open DNA at the level of a single cell. With this tool, researchers can determine which genes are active in single cells, studying how these cells sometimes develop into cells of new types, and how some functions go awry in disease.</p>  <p class="p2"><span class="s1">Buenrostro wants to use these methods to learn new basic information about the differences between healthy and diseased cells and to use this information to engineer new behaviors into cells as they develop and mature.</span></p>  <p class="p2"><span class="s1">Buenrostro, who now oversees a lab of 10, says, “I want to understand cell fate decisions to ultimately be able to engineer cells to do whatever I would like them to”—for instance, fighting cancer.</span></p></td>
    </tr>
    <tr>
      <td>Vivian Chu</td>
      <td>Her robots do some of the grunt work so hospital staffers can spend more time with the patients</td>
      <td>32</td>
      <td>Diligent Robotics</td>
      <td>entrepreneurs-2019</td>
      <td><p class="p1"><span class="s1">Vivian Chu developed the AI software for a hospital robot called Moxi, which has already been tested in four Texas hospitals. During those trials, Moxi worked 22/7—with two hours off a day for charging—picking up supplies such as syringes with its gripper hand and then dexterously moving its arm to drop them into the tray in its base. After that, it would roll down the hallway, taking care not to bump into people, and drop the supplies off in drawers outside patients’ rooms. Moxi can also complete other repetitive tasks such as delivering lab samples and removing soiled linen bags, easing the workload of hospital staff and freeing up more time for them to spend with patients. </span></p><p class="p2"><span class="s1">Chu’s graduate thesis focused on robots that can combine different kinds of sensory information from their surroundings—visual, auditory, kinetic—to guide their actions when they encounter a new situation. For example, one of her robots automatically adjusts the force it applies when pulling on a drawer handle if it learns that the drawer is already half open. Chu hopes to add similar functionality to future versions of Moxi. “It gives you that richness and robustness to be able to learn about the world,” says Chu, the chief technology officer of Diligent Robotics, which she cofounded in 2017. </span></p><p class="p2">Growing up in a three-generation household in the heart of Silicon Valley, she experienced firsthand how her family struggled to take care of her grandparents as they aged, and that’s where Chu wants to use her robotics expertise in the future to make a positive impact. She hopes to give elderly people staying in nursing homes “the tools to be able to age with dignity, age with grace, [and] be more independent for longer.”</p></td>
    </tr>
    <tr>
      <td>Tim Ellis</td>
      <td>Developed a massive 3D metal printer—for building an entire rocket</td>
      <td>29</td>
      <td>Relativity Space</td>
      <td>entrepreneurs-2019</td>
      <td><p class="p1"><span class="s1">Tim Ellis uses 3D metal printing, machine learning, and automated manufacturing to build rockets and satellites. Relativity Space uses this approach to build rockets with just a thousand moving parts (see <a href="https://www.technologyreview.com/s/613743/relativity-space-3d-printed-rocket/" target="_blank" rel="noopener noreferrer">our profile of the company</a>). A typical rocket, in comparison, has 100,000 moving parts—which not only makes the rocket more expensive but also gives it that many more ways to fail.</span></p><p class="p2"><span class="s1">Step one for Ellis was building a massive 3D metal printer that stands about 20 feet (6 meters) tall and can print 95% of the parts for a rocket that’s up to 10 feet in diameter and 100 feet tall. Step two was writing the code to automate much of the process and using machine learning to optimize which parts to print, and how to do it.</span></p><p class="p2"><span class="s1">Relativity Space says it will soon be able to print and iterate a design in as little as 60 days, compared with the industry standard of 18 months—dramatically bringing down costs. This earned the company its first contract, with Telesat, a major Canadian satellite operator, to build rockets to launch some of the company’s satellites starting in 2021. </span></p><p class="p2"><span class="s1"> “We founded Relativity with the long-term vision of 3D-printing the first rocket made on Mars,” says Ellis. “Over time we’ll actually shrink the factory to the point where then we could launch it to another planet.”</span></p></td>
    </tr>
    <tr>
      <td>Kathy Hannun</td>
      <td>Working to make geothermal energy practical</td>
      <td>32</td>
      <td>Dandelion Energy</td>
      <td>entrepreneurs-2019</td>
      <td><p class="p1"><span class="s1">Kathy Hannun brought something to geothermal heating and cooling technology that it hasn’t had before: affordability. </span></p><p class="p2"><span class="s2">In the past, using heat from the earth has been something of a luxury good—systems were expensive and had to be custom-built for the house they were heating, with prices to build and install them in New York reaching well above $60,000. </span></p><p class="p2"><span class="s1">“The earth is a relatively constant temperature of 50 °F year-round once you get down about six feet and below, lasting hundreds of feet down,” she says. Using ground loops filled with water mixed with a propylene glycol solution, it’s possible to exchange heat very efficiently between the earth and the home that’s being heated or cooled. “Horizontal geothermal systems put the loops in about 10 feet below ground,” she explains. “This requires a lot of surface and rips up a large section of ground.” Getting ground loops installed in the yard has in the past been quite an ordeal, requiring massive drilling equipment and significant surface damage. Instead, using technological innovations pioneered by the oil and gas industry, Hannun’s Dandelion Energy has created a drilling system that limits the amount of land needed and the surface damage done to achieve the same result.</span></p><p class="p2"><span class="s1">Dandelion can install a system for a total cost of less than $30,000. </span></p><p class="p2"><span class="s1">Hannun came to geothermal while working as a product manager for Google X. Her goal: take geothermal “down the path that solar has been down over the past two decades, and bring it from a very niche technology to one that replaces furnaces and boilers.”</span></p></td>
    </tr>
    <tr>
      <td>Qichao Hu</td>
      <td>On the cusp of the next big battery breakthrough</td>
      <td>33</td>
      <td>SolidEnergy Systems</td>
      <td>entrepreneurs-2019</td>
      <td><p class="p1"><span class="s1">Qichao Hu believes he’s on the cusp of one of the most highly anticipated developments in industry: the next battery revolution.</span></p><p class="p2">As founder and CEO of SolidEnergy Systems, a startup based in Woburn, Massachusetts, he’s come as close as anyone to commercializing rechargeable batteries made of lithium metal. These promise twice the energy density of lithium-ion batteries, the current industry standard for nearly all electronics and electric vehicles.</p><p class="p2"><span class="s1">Since the development of the lead-acid battery in 1870, there have been only five major breakthroughs in battery technology—with energy density doubling roughly every 30 years. If the pattern holds, the next breakthrough is almost due: lithium-ion batteries, whose anodes are usually made of graphite or silicon, were first commercialized in 1991 by Sony. </span></p><p class="p2">The boost in energy density offered by lithium metal batteries could effectively double the range of an electric vehicle. The problem is that lithium metal is highly reactive. When charging, early prototypes of lithium metal batteries would form needle--like structures known as dendrites, which could short the cells and cause them to catch fire or explode.</p><p class="p2"><span class="s2">Hu, who was born in China and moved to New York at 12, developed a liquid electrolyte, consisting of a high--concentration solvent in salt, which reduced the formation of dendrites. Building on this solution, SolidEnergy Systems developed a pilot line of lithium metal batteries in 2016 that are now being tested in drones. Later in 2019, it will open the world’s largest manufacturing facility for lithium metal batteries in Shanghai, where Hu hopes to scale up production to tens of thousands of cells per month.</span></p></td>
    </tr>
    <tr>
      <td>Riana Lynn</td>
      <td>Using AI to make packaged foods better</td>
      <td>33</td>
      <td>Journey Foods</td>
      <td>entrepreneurs-2019</td>
      <td><p class="p1"><span class="s1">Biologist turned serial entrepreneur Riana Lynn sees AI as a tool that could make packaged food that not only tastes good but is also affordable, nutrient-dense, and plant-based. After visiting farms and food companies around the world, she realized that the best way to achieve her goal was to make research and development in the food industry more efficient.</span></p><p class="p2"><span class="s1">Lynn’s Chicago-based company, Journey Foods, employs an “in-house automated scientist,” JourneyAI. Built around algorithms that Lynn helped to create and a database of nutrient and market data, Journey starts with a nutrition goal—“What if we make a product that’s high in vitamin C and protein at lower cost?”—and then devises a recipe that meets that goal. </span></p><p class="p2"><span class="s1">The company started with fruit snacks. These snacks, called Journey Bites, are made entirely of fruit puree, natural sources of flavor such as cayenne pepper and chia seeds, and “nutrient boosters” that have been devised from the company’s testing of fruit cultures, different types of seaweed, and other sources. </span></p><p class="p2"><span class="s1">Lynn says the company is now “opening our platform for more products. We’ve been asked to build out data sets for pasta, cookies, plant-based proteins, and more. We’ll be working on beverages by the fall.”</span></p></td>
    </tr>
    <tr>
      <td>Raluca Ada Popa</td>
      <td>Her computer security method could protect data, even when attackers break in</td>
      <td>32</td>
      <td>University of California, Berkeley</td>
      <td>visionaries-2019</td>
      <td><p class="p1">Raluca Ada Popa found a fix for one of cybersecurity’s most fundamental challenges: securing computer systems without relying on firewalls to keep hackers out.</p><p class="p2"><span class="s1">Popa’s breakthrough work started with practical database management systems that could work on encrypted data. Though encrypting data had worked for simple messaging applications like WhatsApp, it was too sluggish for systems that needed to also run calculations on the data, like databases and web applications. But Popa found a way to make computation on encrypted data practical. Today, her encryption systems work with a range of applications and provide a level of protection that firewalls cannot: even if attackers break in, they have no way to decipher the data. </span></p><p class="p2">Popa says her techniques allow systems to operate as if they’ve been blindfolded. They’re able to compute on data without actually seeing it—which is opening the cybersecurity field to a host of new applications. A more recent innovation of hers, Helen, can be used by hospitals to share and aggregate patient records without compromising confidentiality. Another of her systems, Opaque, secures hardware systems against potentially compromised software and is now used by such companies as IBM<span class="s1">. </span></p></td>
    </tr>
    <tr>
      <td>Noam Brown</td>
      <td>He’s making artificial intelligence better by having it play poker</td>
      <td>31</td>
      <td>Facebook</td>
      <td>visionaries-2019</td>
      <td><p class="p1"><span class="s1">Noam Brown was never very good at poker. But an artificially intelligent program he created became the first to beat the world’s top players in no-limit Texas Hold’em, the game’s most popular variant.</span></p><p class="p2"><span class="s1">In recent years, machines have defeated humans in checkers, chess, and Go—known as “perfect information” games, where both players know the exact state of play at any given point. Imperfect information games like poker, where hidden cards introduce strategies like bluffing, add another level of complexity. </span></p><p class="p2"><span class="s1">“When you introduce hidden information, all these past techniques just fall apart,” Brown says.</span></p><p class="p2"><span class="s2">Most strategic interactions in the real world, after all, involve some form of hidden information. In the long run, Brown envisions his research leading to automated solutions to situations that are similar to hidden-information games—from managing traffic, to predicting the performance of markets, to conducting national security negotiations.</span></p><p class="p2"><span class="s1">Brown’s creation, known as Libratus, is essentially three AI systems in one. The first developed a strategy for poker by playing against itself over trillions of hands during several months of training. Another refined that strategy in real time during games with humans, and a third reviewed the hands played at the end of each day of competition to identify weaknesses, like predictable betting patterns, that opponents might exploit. </span></p><p class="p2"><span class="s1">In January 2017, Libratus defeated four of the world’s top players head-to-head over 120,000 hands in 20 days at a Pittsburgh casino. Because the bot didn’t learn to play by mimicking humans, it used tactics that human players typically don’t employ. Some of those strategies, like dramatically upping the ante of small pots, have begun to change how the pros play poker. </span></p></td>
    </tr>
    <tr>
      <td>Camille Francois</td>
      <td>She uses data science to detect disinformation and organized harassment campaigns</td>
      <td>30</td>
      <td>Graphika</td>
      <td>visionaries-2019</td>
      <td><p class="p1"><span class="s1">Researchers have been refining methods to detect fake accounts on social media for many years. But methods created to sniff out individual bots can fail to detect more sophisticated forms of manipulation—such as state-sponsored disinformation or harassment campaigns spanning thousands of accounts over many years. </span></p><p class="p2"><span class="s1">Camille François, the chief innovation officer at Graphika, says the public needs better data and models to address online manipulation without inadvertently silencing genuine voices. </span></p><p class="p2"><span class="s1">François and her team use machine learning to map out online communities and the ways information flows through networks. They apply data science and investigative methods to these maps to find the telltale signatures of coordinated disinformation campaigns. Last year, François and colleagues at Oxford used this approach to help the US Senate Select Committee on Intelligence better understand Russian activities during and after the 2016 presidential election.</span></p><p class="p2"><span class="s1">François says that some of her biggest breakthroughs have come from interviewing troll farm defectors and victims to understand the inner workings of troll farms. “This work is two parts technology, one part sociology,” she says. “The techniques are always evolving, and we have to stay one step ahead."</span></p></td>
    </tr>
    <tr>
      <td>Guosong Hong</td>
      <td>His probes could revolutionize brain treatments</td>
      <td>33</td>
      <td>Stanford University</td>
      <td>visionaries-2019</td>
      <td><p class="p1"><span class="s1">Guosong Hong invented a tool for probing the brain and retina down to the resolution of individual neurons. It’s essentially a mesh-like electrode that’s small and flexible enough to be coiled into a needle and injected into the precise region researchers want to study. Brain electrodes are already being used to treat a number of conditions such as Parkinson’s disease, but these are large, rigid objects that need to be implanted by means of extensive surgery. A few weeks after these electrodes are implanted, scar tissue begins to build up, rendering them less effective over time.</span></p><p class="p2"><span class="s1">The electrode Hong invented can seamlessly integrate with neural tissues without eliciting attacks from the immune system. This allows researchers to safely and reliably record live animals’ neuronal activities for nearly a year. </span></p><p class="p2"><span class="s1">This tool could be applied in many areas. It could help scientists understand complex neurological processes such as the aging of the brain. It could be used to treat neurological diseases such as Alzheimer’s and epilepsy. It could help restore function in paralyzed people’s limbs. It also holds the potential for treating eye diseases such as glaucoma, if injected into the eye. </span></p><p class="p2"><span class="s1">Hong envisions building interfaces between the brain and computers using this mesh, or even enabling direct brain-to-brain communication. He believes the mesh is one step further toward a world where “everyone can freely share his or her thoughts without barrier.”</span></p></td>
    </tr>
    <tr>
      <td>Patrick Hsu</td>
      <td>Making CRISPR more flexible to treat brain disease</td>
      <td>27</td>
      <td>Salk Institute for Biological Studies</td>
      <td>visionaries-2019</td>
      <td><p class="p1">The gene-editing technology CRISPR has revolutionized our ability to alter DNA. Patrick Hsu is expanding its reach to RNA—the molecule responsible for translating DNA’s blueprints into proteins—and using it to tackle brain disease.</p><p class="p2">As a child, Hsu, who leads a lab at the Salk Institute for Biological Studies in California, watched the onset of dementia in his grandfather. “He would get into my bed in the middle of the night, disoriented, not knowing where he was,” he says. “It really made me think, how can I help?”</p><p class="p2">As a graduate student at Harvard University, he worked with CRISPR inventor Feng Zhang, building some of the technology’s foundational components. But he came to realize that manipulating RNA might be a more flexible technique than making permanent, and sometimes unintended, changes to the genetic code.</p><p class="p2">So after starting his own lab at Salk, Hsu developed a computer program to trawl publicly available genome data for novel proteins. He discovered a family of highly efficient and selective CRISPR enzymes targeting RNA.</p><p class="p2">Hsu is provided a tantalizing glimpse into how his technology could one day treat brain disease. He has shown that when it is applied to human neuron cells grown in the lab, it can correct RNA processing errors responsible for fronto-temporal dementia, a neurodegenerative disorder similar to Alzheimer’s that leads to a gradual decline in cognitive function<span class="s1">. </span></p></td>
    </tr>
    <tr>
      <td>Azalia Mirhoseini</td>
      <td>She taught an AI to design AI chips</td>
      <td>32</td>
      <td>Google Brain</td>
      <td>visionaries-2019</td>
      <td><p class="p1"><span class="s1">Azalia Mirhoseini, a research scientist at Google Brain, is using artificial intelligence itself<span class="Apple-converted-space">&nbsp; </span>to make better chips for artificial intelligence.</span></p><p class="p2"><span class="s1">Many microchips that are used for AI weren’t specifically built for it. Most are repurposed from hardware used in video and gaming. As a result, these older, human-engineered designs leave much to be desired in terms of energy efficiency, cost, and functionality.&nbsp;</span></p><p class="p2">Mirhoseini’s system—which trained itself using trial and error, based on the AI concept of reinforcement learning—can produce chip designs in just a few hours. (The world’s top experts need several weeks.) Her AI-designed methods allow for chips that are as good as or better than those designed by human engineers: they’re faster and more energy efficient, and their total internal wire length, and therefore cost, is much lower.</p><p class="p2">Reinforcement learning is one of AI’s most promising frameworks. Software that uses it essentially teaches itself how to accomplish a task, rather than being programmed, step by step, by<span class="Apple-converted-space">&nbsp; </span>a human. Now, Mirhoseini says, “it’s time to use machine learning and AI to develop better computers and close the loop.”</p></td>
    </tr>
    <tr>
      <td>Kimberly Stachenfeld</td>
      <td>She used reinforcement learning to better understand problem solving in both the human brain and AI systems</td>
      <td>28</td>
      <td>DeepMind</td>
      <td>visionaries-2019</td>
      <td><p class="p1"><span class="s1">Kimberly Stachenfeld, a researcher at DeepMind, helped to develop a theory of the human brain region called the hippocampus, which is responsible for spatial memory and navigation. Now she’s taking her groundbreaking neuroscience work and using it to better understand artificial intelligence. </span></p><p class="p2">Earlier theories of the hippocampus focused on its key role in representing the past and one’s current situation, in particular one’s location in space. But Stachenfeld wanted to explain how it may also link the present to the future, by representing the current situation in terms of what it predicts about upcoming events. Using insights from an area of AI called reinforcement learning, which is based on trial and error, Stachenfeld proposed that the hippocampus uses a similar mechanism to make associations between a person’s present state (like being in one’s garage) and a desirable future state (like getting to work on time).</p><p class="p2">Stachenfeld and her team’s theory better explains how the hippocampus might play a role as a prediction system to help the brain quickly evaluate choices, like getting into a car and heading to work versus staying at home and watching TV on a weekday morning.</p><p class="p2">Now Stachenfeld is taking what she knows about the brain and aims to use it to improve AI. For instance, AI systems can efficiently learn how to achieve simple tasks—like locating the sugar in your cabinet.</p><p class="p2"><span class="s2">But such systems are no match for the human brain, which can learn many things at once by grouping tasks together, and remembers incidental details while learning a task, which might be useful to recall while learning some other, related task. For example, we learn stirring and mixing are fundamentally similar concepts, and we can reuse similar behaviors to perform them.</span></p><p class="p2">If Stachenfeld can figure out how the brain does this, she believes she can will help train AI systems orders of magnitudes faster without the need for as much data.</p></td>
    </tr>
    <tr>
      <td>Liang Xu</td>
      <td>Using AI to make cities more responsive to their residents</td>
      <td>31</td>
      <td>Ping An Technology</td>
      <td>visionaries-2019</td>
      <td><p class="p1"><span class="s1">Liang Xu and his team have developed an AI platform that is transforming how cities across China improve public health, reduce crime, and increase efficiency in public management. Xu’s team works closely with municipal agencies in China, which provide access to troves of data such as tens of millions of health records and customs border-crossing records. After crunching all these data, stripped of identifying details, and going through other forms of training, the platform, called PADIA, is then integrated into these agencies’<span class="Apple-converted-space">&nbsp; </span>computer systems. </span></p><p class="p2"><span class="s1">In the cities of Chong­qing and Shenzhen, this platform is helping public health authorities predict flu outbreaks with an accuracy of over 90%. A local government agency in Shenzhen has also used the software to reduce the time it takes to process documents by 95%. In several provinces, it has detected health care fraud to the tune of nearly 1 billion yuan ($150 million).</span></p><p class="p2"><span class="s1">Government use of AI is stirring up debates in many countries. Xu is aware of pitfalls such as privacy breaches and job losses. But he’s also optimistic about AI’s potential to bring modern education and health care to areas that have traditionally been left out. He points out that teachers in rural areas could find answers to questions using AI’s vast knowledge base, and community health centers that lack trained staff members to interpret medical scans could use AI algorithms to help diagnose serious illnesses.</span></p></td>
    </tr>
    <tr>
      <td>Himabindu Lakkaraju</td>
      <td>Her AI program aims to weed out bias in decision making</td>
      <td>29</td>
      <td>Harvard University</td>
      <td>humanitarians-2019</td>
      <td><p class="p1">Himabindu Lakkaraju designed an artificial intelligence program that serve as a bias check for decision makers like judges and doctors.</p><p class="p2">Machine learning and AI are increasingly used in law enforcement to make decisions about which defendants get bail, in health care to determine medical treatments, and at financial institutions to determine who gets loans. But making decisions by automation can have pitfalls—software can miss the nuance that a human may catch when looking at a criminal, medical, or credit record. But humans can also miss nuances and have their own biases—especially when they’re pressed for time and have to make life-altering decisions.</p><p class="p2">Lakkaraju’s system doesn’t rely solely on human choices or on machine learning but uses a combination of the two. Most of her work deals with data sets in which she could see the expected outcomes from both AI and the human decision makers, and spot where bias might occur.</p><p class="p2">Her work is now being used by schools in Montgomery County, Maryland, to help them identify at-risk students and predict the likelihood that a child might need extra tutoring or mentoring.</p><p class="p2">“School districts are often limited in their resources—so knowing this likelihood will help the school districts assign those students to interventions who are most likely to benefit from them,” Lakkaraju says.</p></td>
    </tr>
    <tr>
      <td>Ida Pavlichenko</td>
      <td>Her invention could make ear infections easier to treat, especially in children</td>
      <td>32</td>
      <td>Harvard’s Wyss Institute</td>
      <td>humanitarians-2019</td>
      <td><p class="p1"><span class="s1">Ida Pavlichenko has engineered a major improvement to the ear tubes that doctors use to combat the ear infections that many young children endure.</span></p><p class="p2"><span class="s1"> The tubes in use today attract biofilms, leading to more infections. Pavlichenko has developed a smaller, infection-resistant tube that has proved safe in animal tests. Her tube is selective in what fluids it allows through—so medication can be delivered, but water from showering and swimming won’t get in. </span></p><p class="p2"><span class="s1">Pavlichenko hopes that improved tubes will also lead to new approaches for treating hearing loss, which now affects 450 million people around the world. The number is expected to double over the next three decades, as the population ages and music blasted through headphones take its toll. </span></p><p class="p2"><span class="s1">Pavlichenko was pregnant when she decided to pursue middle ear infections in her research. But solving the problem has taken on new urgency now that she has a child and knows what it’s like to see the child suffer. </span></p><p class="p2"><span class="s1">“The sooner you bring kids to daycare, the sooner you experience the terror of colds and endless antibiotic treatment,” says Pavlichenko, a fellow at Harvard’s Wyss Institute and cofounder of a startup called PionEar. She notes that some children have to have the current tubes implanted several times to end the cycle of painful infections, antibiotics, and speech delays.</span></p><p class="p2"><span class="s1">Not only can the tubes themselves get infected but they can fall out or get stuck when they need to come out. Implanting them requires general anesthesia, sometimes more than once.</span></p><p class="p2"><span class="s1"> In adults, ear problems can be even more challenging, because tubes may fail to stay in place long enough and medication is tricky to deliver deep inside an adult ear. Pavlichenko’s tubes address all these problems and are more effective, better fitting, and less likely to lead to damage, she says.</span></p></td>
    </tr>
    <tr>
      <td>John Porter</td>
      <td>His innovations could make all kinds of products more accessible to people with disabilities</td>
      <td>33</td>
      <td>University of Washington</td>
      <td>humanitarians-2019</td>
      <td><p class="p1"><span class="s1">John Porter is working to make sure people with disabilities can play video games. For anyone without disabilities, Porter says, the question of whether a game might be a good fit for them is largely a matter of taste—but for people with impairments, they have to figure out if they’ll be able to engage at all. </span></p><p class="p2">For Porter, who has spinal muscular atrophy, these barriers aren’t just theoretical. “Right now, people don’t have that information,” he says. “All they can do is drop sixty bucks to buy a new release and then hope they’ll be able to play it.”</p><p class="p2">Porter, who works at Microsoft as a user experience designer, wants the games industry to take accessibility into account from the very beginning. That means creating a system by which accessibility—for people with motor, sensory, or cognitive disabilities—is assessed. Porter is devising a robust set of objective yes-or-no questions about motor interaction—does a game require rapid button presses, or sustained button holds? Does it require combinations of three or more buttons simultaneously?</p><p class="p2">Porter hopes his system will get developers to think more about their games’ design at the earliest stages. “When people do this long enough, it’s going to change the way they visualize their process from day one,” Porter says. Though he’s passionate about gaming, he sees his work as having broader implications.<span class="Apple-converted-space">&nbsp; </span>“We can begin to ask, ‘How can this information help our devices and digital environments be more responsive and adaptive to our needs and abilities?’“ he says. “That is the logical next frontier of adaptive technologies.”</p></td>
    </tr>
    <tr>
      <td>Rediet Abebe</td>
      <td>She uses algorithms and AI to fight socioeconomic inequality</td>
      <td>28</td>
      <td>Cornell University</td>
      <td>pioneers-2019</td>
      <td><p class="p1"><span class="s1">Rediet Abebe uses algorithms and AI to improve access to opportunity for historically marginalized communities. When Abebe moved from her native Ethiopia to the United States to attend Harvard College, she was struck by how vital resources often fail to reach the most vulnerable people, even in the world’s wealthiest nation. She now uses computational techniques to mitigate socioeconomic inequalities.&nbsp;</span></p><p class="p2"><span class="s2">While she was an intern at Microsoft, Abebe formulated an AI project that analyzes search queries to shed light on the unmet health information needs of people in Africa. Her study revealed such information as which demographic groups are likely to show interest in natural cures for HIV and which countries’ residents are especially concerned about HIV/AIDS stigma and discrimination. This work is the first to use large web-based data to study health across all 54 African nations. </span></p><p class="p2">In an effort to inform health programming, Abebe is now taking these findings to health experts in ministries of health across the continent. She’s also working with the National Institutes of Health’s Advisory Committee to help reduce health disparities in the US.</p><p class="p2">To encourage growth in this area, she cofounded Mechanism Design for Social Good, a multi-institutional research initiative that uses algorithms to tackle problems ranging from allocating low-income housing to improving health outcomes.</p></td>
    </tr>
    <tr>
      <td>Cesar de la Fuente</td>
      <td>Digitizing evolution to make better antibiotics</td>
      <td>33</td>
      <td>University of Pennsylvania</td>
      <td>pioneers-2019</td>
      <td><p class="p1"><span class="s1">Bacteria evolve faster than scientists can make new antibiotics to fight them. That’s why César de la Fuente has developed algorithms that follow Darwin’s laws of evolution to create optimized artificial antibiotics. An expert in engineering bits of protein called peptides to solve medical problems, he has also developed a method of turning toxic proteins, like one found in wasp venom, into antimicrobials. And he has mined huge existing databases of proteins in the human body to discover molecules that can kill harmful microbes. </span></p><p class="p2"><span class="s1">“I wake up every day thinking about all the people that are dying in this country and around the world as a result of treatable infections, and try to come up with solutions,” says de la Fuente, who has always been fascinated by microbes’<span class="Apple-converted-space">&nbsp; </span>knack for survival. </span></p><p class="p2"><span class="s1">In addition to developing computer-made antibiotics, de la Fuente, an assistant professor at the University of Pennsylvania, hopes next to use the same engineering approach to find proteins implicated in psychiatric disorders like depression and anxiety and to modify them to affect brain function and behavior.</span></p></td>
    </tr>
    <tr>
      <td>Nicole Gaudelli</td>
      <td>She found a better way to correct single-gene mutations</td>
      <td>34</td>
      <td>Beam Therapeutics</td>
      <td>pioneers-2019</td>
      <td><p class="p1"><span class="s1">Nicole Gaudelli invented a way to potentially correct almost half of all genetic diseases caused by single-gene mutations. </span></p><p class="p2"><span class="s1">Gene-editing tools such as CRISPR can fix some of the single-letter genetic “spelling” mistakes that can drive inherited diseases. But they don’t correct for having the nucleic acid adenine, or A, appear in a DNA strand where there should have been a guanine, or G. This misplaced A is involved in sickle cell disease, cystic fibrosis, Parkinson’s, Alzheimer’s, and many types of cancer.</span></p><p class="p2"><span class="s1">So Gaudelli set out to make a new enzyme that can cleanly convert A-T base pairs into G-C base pairs with few undesired effects. </span></p><p class="p2"><span class="s1">“It was a little bit of magic,” says Gaudelli, about getting her enzyme to work. She’s now a senior scientist at Beam Therapeutics, a biotech company based in Cambridge, Massachusetts, working to commercialize her approach.</span></p></td>
    </tr>
    <tr>
      <td>Grace Gu</td>
      <td>She’s using AI to help dream up a new generation of lighter, stronger materials</td>
      <td>30</td>
      <td>University of California, Berkeley</td>
      <td>pioneers-2019</td>
      <td><p class="p1"><span class="s1">Grace Gu is using artificial intelligence to find ways to make better materials. Gu envisions materials that can be used for lighter and stronger body armors, 3D-printed and customizable medical implants, and tunable solar cell materials that push the boundaries of the renewable energy technology. </span></p><p class="p2"><span class="s1">Gu’s work is inspired by natural materials such as seashells and bamboo, in which the structure of the base constituents results in strength and other desirable properties. Her team at UC Berkeley uses machine learning algorithms to discover new composite </span><span class="s2">structures based on nature’s examples. This approach allows her to design materials that are superstrong and yet lightweight. These designs are then 3D-printed and tested to validate the algorithm, to make sure that the hypothetical materials work in the real world. </span></p><p class="p2"><span class="s1">Thus far, Gu’s research has led to material designs with dramatically enhanced mechanical properties. And as the team continues its research, Gu hopes that bigger breakthroughs are<span class="Apple-converted-space">&nbsp; </span>around the corner.</span></p></td>
    </tr>
    <tr>
      <td>Song Han</td>
      <td>Making the software that lets powerful AI programs run more smoothly</td>
      <td>30</td>
      <td>MIT</td>
      <td>pioneers-2019</td>
      <td><p class="p1">AlphaGo, the artificial intelligence that beat the best human player at Go in 2016, needed nearly 2,000 central processing units and 300 graphics processing units to function. As a consequence, its electricity bills were $3,000 per game. Song Han has designed software and hardware that enable powerful AI programs like AlphaGo to be deployed in low-power mobile devices.</p><p class="p2">The “deep compression” technique Han invented make it possible to run in real time on a smartphone AI algorithms that can recognize objects, generate imagery, and understand human language. Facebook, among other companies, uses Han’s software design to reduce the amount of computation an AI algorithm that can recognize objects needs. This allows people to use their smartphone camera to pinpoint objects in the real world and then add digital visual effects.</p><p class="p2"><span class="s1">In 2016, based on his innovations, Han cofounded an AI chip company called DeePhi Tech, which Xilinx, an American semiconductor company, acquired last year.</span></p><p class="p2">In his new role as an assistant professor at MIT, Han is automating the design of AI algorithms. The goal is to “let any non-expert push a button and design compact neural networks,” he says, referring to the computing systems loosely modeled after the human brain that are central to how AI works.</p><p class="p2">Software developers without AI expertise, he says, would be able to use such neural networks to classify objects, improve the resolution of images, and analyze videos more ­efficiently.</p></td>
    </tr>
    <tr>
      <td>Jinxing Li</td>
      <td>His tiny robots can be programmed to treat infection</td>
      <td>32</td>
      <td>Stanford University</td>
      <td>pioneers-2019</td>
      <td><p class="p1">Jinxing Li pioneered the use of tiny robots—just a few micrometers across—to treat disease in a living animal.</p><p class="p2">Li designed rocket-like micromotors that run on gut fluids in a living animal and biodegrade after completing their mission.</p><p class="p2">The bots are made from polymer-coated balls of magnesium, which react with stomach acid to create hydrogen bubbles that propel them through the gut. Li and collaborators loaded one of the polymer layers with anti­biotics, and the bots were administered to mice with stomach infections. On entering the stomach, they fired into the lining and stuck to the stomach wall before gradually dissolving to release their cargo over a long period to treat the infection.</p><p class="p2">Li recently showed that magnetically powered nanomotors cloaked in membranes from platelet cells could navigate efficiently through blood to remove toxins and pathogens without being cleared by the immune system or getting covered in sticky biomolecules, as foreign particles normally do.</p><p class="p2">The next step is to create “cyborg cells,” says Li, by taking the body’s immune cells, which hunt and destroy bacteria or cancer cells, and merging them with nanobots to navigate toward the disease site.</p></td>
    </tr>
    <tr>
      <td>Mariana Popescu</td>
      <td>She developed a construction process that turns knitted textiles into concrete buildings—saving money, carbon, and time</td>
      <td>32</td>
      <td>ETHZ</td>
      <td>pioneers-2019</td>
      <td><p class="p1">Mariana Popescu has developed a process and accompanying computational tools capable of turning knitted textiles into complex molds for concrete buildings. Her innovation makes it possible to build complex custom-made designs faster, with less waste and reduced carbon emissions.</p><p class="p2">“If you really want to make good structures that use less material, you end up having complicated geometries that are very often doubly curved or have other features that are difficult to mold,” says Popescu. Traditional construction that uses wood or foam supported by heavy scaffolding to create forms for pouring concrete takes months and limits what shapes are ­possible. <span class="s1">All you have to do is look at a sweater, she says, to see that textile materials are perfect for making a wide array of holes, channels, and other complicated 3D shapes that are sought after in contemporary buildings. </span></p><p class="p2"><span class="s1">So Popescu developed algorithms that automatically translate an architectural design into a textile-based mold that can be knitted by industrial machines in mere hours. The resulting mold is lightweight and flexible. Popescu, with the rest of her team, developed a system that uses steel cables to hold the mold in place while concrete is poured over it. </span></p><p class="p2"><span class="s1">Popescu’s innovation is an efficient and ecologically conscious way of building complex structures with a minimal ecological footprint, in record time, and at low cost. It also has the potential to speed up construction of low-cost, sturdy, lightweight structures in settings like refugee camps, war zones, and sites of natural disasters.</span></p></td>
    </tr>
    <tr>
      <td>Wojciech Zaremba</td>
      <td>He taught a robot hand how to figure out things on its own</td>
      <td>30</td>
      <td>OpenAI</td>
      <td>pioneers-2019</td>
      <td><p class="p1">Wojciech Zaremba led a team that used machine learning to train a robot hand to teach itself to pick up a toy block in different environments. The robot was tasked with figuring out on its own how to accomplish the complex task of grasping a block and twisting it around with its robotic fingers in response to commands.</p><p class="p2">Zaremba powered the robot through a neural network, a computer program that mimics the type of networks our brains use.</p><p class="p2"><span class="s1">Although reinforcement learning has been used before in robotics, it hasn’t worked on anything as complicated as a robotic hand, because the numerous tasks involved would require the equivalent of hundreds of years of experience. And robotic AIs trained in virtual worlds have typically failed to transfer successfully to reality, owing to the gap between simulated and real-world physics.</span></p><p class="p2"><span class="s1">Zaremba, a cofounder of the AI research group OpenAI, hypothesized that varying the conditions in a virtual environment coiuld prepare a neural network for the messiness of reality. </span></p><p class="p2"><span class="s1">He randomized 254 physical parameters—things like the mass of the block and the friction of fingertips—and found that the hand, after training, could manipulate the block the first time it was set loose in the real world</span><span class="s2">. </span></p></td>
    </tr>
    <tr>
      <td>James Dahlman</td>
      <td>His method makes it possible to test 300 drugs at once.</td>
      <td>31</td>
      <td>Georgia Tech</td>
      <td>inventors-2018</td>
      <td><p>For decades, the pharmaceuti<span class="s1">cal industry’s approach to finding new cancer therapies has been to put tumor cells in a dish and test drug-delivering nanoparticles (particles between one and 100 nanometers in size), one by one by one, to find one that’s effective. Then researchers have to hope that those particles go where they’re needed when introduced into a living subject whose body might attack them or break them down. </span></p>  <p><span class="s1">“The problem is that, forever, people have been testing drug delivery vehicles the wrong way,” says James Dahlman, who runs a lab at Georgia Tech.</span></p>  <p><span class="s1">Dahlman has invented a radically different process that involves encoding each nanoparticle with a DNA sequence that he calls a bar code. Three hundred of those nanoparticles can be injected into a laboratory mouse, and when researchers remove the tumor, they can use gene-sequencing technology to determine how each of the bar codes did, all at once. The difference in volume is staggering. Dahlman says he tested about 30 particles during his entire PhD; in 2018 alone, his lab will hit 3,000. He hopes this technology could mean that a drug designed to treat a tumor in the lung, for example, could go straight to the problem area—rather than making the patient’s hair fall </span><span class="s2">out.</span></p>  <p><em>—Dan Solomon</em></p></td>
    </tr>
    <tr>
      <td>Shreya Dave</td>
      <td>Her filtration system could eliminate much of the energy used in industrial separation processes.</td>
      <td>30</td>
      <td>Via Separations</td>
      <td>inventors-2018</td>
      <td><p><span class="s1">Shreya Dave thought her PhD research had no practical applications. It involved molecular filtration membranes made of graphene oxide—which is cheaper and less prone to degrading than the polymers and ceramics used today—but her method was too expensive for the water industry.</span></p>  <p>Then an article in <em>Nature</em> convinced her that the technique could save massive amounts of energy in the industrial processes used to separate chemicals for food, beverages, drugs, and fuel. These processes, it turns out, account for 12 percent of all US energy consumption.</p>  <p>Dave is now the CEO of Via Separations. The technology she and her team designed is meant to replace the current system for separating chemical compounds, which basically amounts to boiling. Dave believes that widespread adoption of Via’s filtration material could eliminate anywhere from 50 to 90 percent of the energy used in such industrial processes.</p>  <p>Her company is currently focusing on the food and beverage industry, but Dave thinks if she can prove that the technology is scalable and cost-effective in one industry, that will be the key to succeeding in others.</p>  <p><em>—Dan Solomon</em></p></td>
    </tr>
    <tr>
      <td>Shinjini Kundu</td>
      <td>Medical images are so detailed it can be hard to decipher them. Her program can spot what people can’t.</td>
      <td>27</td>
      <td>Carnegie Mellon University</td>
      <td>inventors-2018</td>
      <td><p>Medical images are massively important in diagnosing disease, but as they get more detailed it becomes harder and harder for a human being to interpret them. Shinjini Kundu created an artificial-­intelligence system that can analyze them to find patterns undetectable to the naked eye. Her innovation could have a fundamental impact on the way we detect and treat diseases.</p>  <p>“If there are hidden changes and there is a way to detect these invisible patterns, then maybe we have a chance to diagnose diseases early, before symptoms develop,” she says.</p>  <p>There are already AI algorithms that teach themselves to spot patterns, but they’re not able to explain their reasoning. In medical diagnosis, this can be a limitation: without some knowledge of how and why a disease is developing, it’s impossible to address.</p>  <p><span class="s1">Kundu’s system allows humans to look through the eyes of the computer to discover otherwise imperceptible patterns that reveal the early disease process. She also trained the AI to pull out the disease markers from the images so that they can be seen on their own. That could help humans recognize them months or years before the onset of illness—so rather than just humans teaching AI, AI can teach us.</span></p>  <p><span class="s1"><em>—Erika Beras</em></span></p></td>
    </tr>
    <tr>
      <td>Barbarita Lara</td>
      <td>An earthquake led her to invent a blend of analog and digital technologies for use when networks are down.</td>
      <td>32</td>
      <td>Emercom</td>
      <td>inventors-2018</td>
      <td><p>When an 8.8 magnitude earthquake hit her native Chile in 2010, Barbarita Lara started tinkering. An engineering student at the time, she was struck by the challenges of communication in the quake’s aftermath: everyone she knew had become dependent on the internet and cell phones, but most networks were down. Along the Chilean coast, 156 people were killed in a tsunami triggered by the quake—in part because they didn’t receive a warning in time.</p>  <p><span class="s1">Eight years later, Lara has a product she thinks can help save lives in the next disaster. Her platform, known by its Spanish acronym SiE, allows smartphone users to receive messages from authorities via encrypted high-frequency audio: a blend of analog and digital technologies designed for use when internet and phone networks aren’t working. The SiE platform, which makes use of existing radio infrastructure, also enables smartphones to message each other using mesh, a radio-enabled wireless ad hoc network. Lara’s invention was inspired by Morse code, which her father, a cryptologist in the Chilean navy, introduced to her when she was a child. “Sometimes the best solution is very simple,” she says. </span></p>  <p>Emercom, the startup she founded to develop and market the platform, is now in discussions with Chilean disaster management authorities about the prospect of using SiE for future alerts. It’s also in talks with a leading telecom about pre-installing SiE on new cell phones.</p>  <p><em>—Jonathan W. Rosen</em></p></td>
    </tr>
    <tr>
      <td>Will McLean</td>
      <td>Hearing loss in humans has always been irreversible. His innovation may change that.</td>
      <td>31</td>
      <td>Frequency Therapeutics</td>
      <td>inventors-2018</td>
      <td><p>Will McLean believes he’s found a fix for a medical conundrum that many thought could never be solved: hearing loss in humans.</p>  <p>McLean’s research focuses on the cochlea, the spiral-shaped cavity within the inner ear that’s responsible for hearing. At birth, the average human cochlea contains 15,000 hair cells, which detect sound waves and transfer them to the brain. Over time, many of these cells are killed by exposure to loud noise and toxic medications. In mammals, unlike birds, reptiles, and amphibians, they don’t naturally grow back. “The inner ear is one of the least regenerative parts of the body,” McLean says. “That’s why hearing loss is permanent.”</p>  <p>McLean, who holds a PhD from MIT in health science and technology, has spent the last decade trying to change that. His early work showed that the inner ear contains distinct progenitor cells—similar to stem cells but more specific in their capabilities—and that some have the potential to become hair cells, though they cannot divide or differentiate on their own to repair damaged tissue. To resolve this, he and colleagues used insights from regenerative tissues, such as those in the intestine. They exposed damaged cochleas from mice to a combination of drugs that can trigger regeneration in these other organs. Surprisingly, their technique not only caused the progenitor cells to proliferate but also induced them to generate new hair cells—the key to restoring hearing.</p>  <p>On the strength of this discovery, McLean and colleagues established Frequency Therapeutics, a startup working to commercialize what he describes as an entirely new mode of medicine. Frequency’s technique, known as progenitor cell activation, uses a combination of compounds that essentially unlock the body’s ability to heal itself. To date, Frequency has filed 19 patent applications and developed an injectable in-ear therapeutic to combat hearing loss. The treatment has successfully passed human safety trials.</p>  <p><em>—Jonathan W. Rosen</em></p></td>
    </tr>
    <tr>
      <td>Manan Suri</td>
      <td>His computer chips mimic the workings of the human brain.</td>
      <td>31</td>
      <td>Indian Institute of Technology, Delhi</td>
      <td>inventors-2018</td>
      <td><p>Manan Suri has built key elements of computer chips that mimic the learning ability and energy efficiency of the brain. And he did it by harnessing a quirk of next-generation memory technology.</p>  <p>That technology is known as emerging non-volatile memory (eNVM). Because of peculiarities in their nanoscale physics, eNVM devices often behave in random ways, which in computers is usually a flaw. But Suri realized that this irregularity could help researchers build so-called neuromorphic chips, which emulate the neurons and synapses in our brains.</p>  <p>While transistors store information as <em>1</em>s and <em>0</em>s, the biological synapses that store information in the brain can take multiple states. That means building computers that behave like the brain traditionally required complicated artificial synapses that can also take multiple states.</p>  <p>Suri recognized that he could harness the inherent variability of eNVMs to build large-scale neuromorphic sys­tems capable of doing supervised and unsupervised learning. He’s exploited that irregular behavior for cybersecurity and advanced sensing applications. Earlier this year he founded a startup, Cyran AI Solutions, to build neuromorphic and cybersecurity hardware based on his eNVM research.</p>  <p><em>—Edd Gent</em></p></td>
    </tr>
    <tr>
      <td>Sheng Xu</td>
      <td>Making off-the-shelf electronics stretchable.</td>
      <td>34</td>
      <td>University of California, San Diego</td>
      <td>inventors-2018</td>
      <td><p>Stretchy electronics that can conform to the body no longer have to compromise between electrical and mechanical performance, thanks to some smart engineering by Sheng Xu.</p>  <p><span class="s1">Marrying rigid electronic components with elastic materials is tricky. The mismatch in their mechanical properties generates huge strains, causing them to separate when deformed. That’s why most previous research in flexible electronics focused on building new components that are soft and flexible. But Xu didn’t see the sense in discarding decades of progress in the electronics industry. “Why not use something that already matured decades ago?” he says. His strategy made it possible to integrate off-the-shelf components into elastic materials to create highly stretchable electronics as capable as their rigid counterparts.</span></p>  <p><span class="s1">Xu opted to bond only tiny sections of the components to the elastic material and then support them in a fluid-filled capsule. These are joined together with wires configured into long wavy lines that unravel in an ordered way when stretched. He’s used the approach to build a lithium-ion battery that stretches by up to 300 percent and a hospital-quality health monitor that conforms to the body as it moves. The latter has been developed into a wearable physiological sensor called BioStamp by a startup called MC10. </span></p>  <p><span class="s1"><em>—Edd Gent</em></span></p></td>
    </tr>
    <tr>
      <td>Huanping Zhou</td>
      <td>Her innovations could make better, cheaper alternatives to silicon solar cells.</td>
      <td>34</td>
      <td>Peking University</td>
      <td>inventors-2018</td>
      <td><p>the solar energy industry has lacked a low-cost, high-performance alternative to silicon for a long time. In recent years, a family of hybrid materials called perovskites has gained attention because they can achieve high power output more cheaply than silicon. But making them work in practice has proved difficult. Early prototypes of perovskite-based solar cells weren’t as efficient as conventional silicon cells at converting the energy in sunlight into electricity.</p>  <p><span class="s1">Huanping Zhou developed a series of chemical processes that made perovskite-based solar cells more efficient and cheaper to produce. If they can be mass-produced, her innovation will make solar power much cheaper.</span></p>  <p><span class="s1">Growing up in the countryside of China, Zhou did not have electricity at home. She and her siblings did their homework by the light of a kerosene lamp. Her childhood experience motivated her to devote herself to solar technology.</span></p>  <p><span class="s2">The cell Zhou developed converts more than 20 percent of the energy in sunlight, about the same rate as existing silicon panels. Although some other perovskite cells are more efficient, Zhou’s invention is important because it makes the manufacturing process easier and cheaper. The cells can be produced at temperatures below 302 °F<span class="Apple-converted-space">&nbsp; </span>(150 °C) by spraying or printing a perovskite-based liquid solution onto a substrate such as glass. The process for some other types of perovskite cells requires temperatures around 932 °F.</span></p>  <p><span class="s1">Perovskite-based solar cells tend to degrade faster than silicon cells, so Zhou is also working on improving their durability. </span></p>  <p><span class="s1"><em>—Yiting Sun</em></span></p></td>
    </tr>
    <tr>
      <td>Natalya Bailey</td>
      <td>A system to propel tiny satellites using electrical energy.</td>
      <td>31</td>
      <td>Accion Systems</td>
      <td>entrepreneurs-2018</td>
      <td><p>Natalya Bailey helped develop a way to propel satellites as small as a shoebox or as big as a refrigerator using engines about the size of a dime. It’s based on so-called electrospray propulsion—the idea of using electrical energy to drive small rockets.</p>  <p>Electrospray technology has been in the works for many years. Researchers started studying it in the 1950s, but the work was abandoned because it required very high voltages and because the physics involved was not well understood. Bailey was able to use the technology’s advantages—it’s energy-efficient and doesn’t require toxic propellants or pressurized tanks—to create tiny engines that can be used independently or in tandem with other engines, depending on the size of the satellite.</p>  <p>Bailey founded Accion Systems, just outside Boston, to commercialize the technology. She says the rocket-science field can feel like an old boys’ club but she’s made it work. “Being one of very few women in this field makes me stand out more,” she says. “And I think it probably led to some opportunities that I maybe wouldn’t have had otherwise.”</p>  <p><em>—Erika Beras</em></p></td>
    </tr>
    <tr>
      <td>Jonas Cleveland</td>
      <td>Helping create the shopping robots of the near future.</td>
      <td>31</td>
      <td>COSY Robotics</td>
      <td>entrepreneurs-2018</td>
      <td><p><span class="s1">Jonas Cleveland thinks shopping robots will not only be picking goods off the shelves at massive warehouses but roaming the aisles at local businesses, grabbing products for online orders in stores that are also full of human shoppers. </span></p>  <p><span class="s1">Cleveland’s company, COSY (for Cognitive Operational Systems), is creating the sensor perception system for those robots. Cameras, AI, and mapping technology help make them smart enough to do their job without interfering with the people around them. So if you’re shopping in a pharmacy or home improvement store, Cleveland’s robots won’t bump into you, and if you’ve ordered online for delivery, the robot that prepares your order will know a six-pack of Diet Coke from a six-pack of Coke Zero. </span></p>  <p><span class="s1"><em>—Dan Solomon</em></span></p></td>
    </tr>
    <tr>
      <td>Elizabeth Nyeko</td>
      <td>Her energy solution for rural communities in Africa could make grids more efficient everywhere.</td>
      <td>34</td>
      <td>Modularity Grid</td>
      <td>entrepreneurs-2018</td>
      <td><p>Elizabeth Nyeko thinks she’s found a solution to one of rural Africa’s key development challenges: how to electrify communities in a way that’s affordable—and efficient.</p>  <p><span class="s1">As CEO of Modularity Grid, a London-based startup, Nyeko builds technologies that improve the performance of mini-grids, small-scale electricity generation and distribution systems that power homes and businesses in areas where extending national grids is too expensive. Yet mini-grids also have limitations. As Nyeko learned at Mandulis Energy, a company she cofounded that built a biomass-fired mini-grid in northern Uganda, the electricity demand of individual customers is very hard to track, which typically leads to overproduction of power, inefficient use of fuels, and inflated electricity prices.</span></p>  <p><span class="s1">At Modularity Grid, Nyeko designed an intelligent cloud-based platform that enables mini-grid operators to better track and predict individual consumption; it then redirects excess electricity to specific users in need of constant power, called “anchor loads.” At the Mandulis site in Uganda, where Nyeko is piloting her Modularity Grid solution, the anchor loads include the village rice mill—which also provides the rice husks used to fuel the mini-grid itself. “If we can deliver just the amount of electricity to people that they need, and redirect the rest to something that creates value for a rural community, we can make mini-grids viable in a low-income setting,” Nyeko says. </span></p>  <p>Nyeko, who was born in northern Uganda but fled from civil war there as a child, is now marketing her solution to other mini-grid providers and is set to begin work with Total and Vinci Energies on further power projects&nbsp;across Africa. Eventually, she believes, her solution can also help make national grids more efficient—in Africa and beyond.</p>  <p><em>—Jonathan W. Rosen</em></p></td>
    </tr>
    <tr>
      <td>Yin Qi</td>
      <td>His face-recognition platform transformed the way business is done in China.</td>
      <td>30</td>
      <td>Megvii</td>
      <td>entrepreneurs-2018</td>
      <td><p>Seven years ago, Yin Qi founded a company called Megvii with two college friends in Beijing. Now people from over 220 countries and regions use Megvii’s face-recognition platform, Face++. The company has more than 1,500 employees.</p>  <p>Face++ has transformed businesses in China, both online and offline. Subways and train stations use face recognition to expedite the screening process; banking apps use it to confirm the identities of their users.</p>  <p>Being in China has given Megvii an edge. While the use of face recognition in the West has mostly been confined to consumer-oriented applications such as unlocking smartphones, in China the same technology enjoyed strong backing from the government and big companies right away. This gives Megvii ample opportunities to commercialize its algorithms for industries as diverse as public security, real estate, finance, and retail.</p>  <p>Yin admits privacy is an issue. He says his products process sensitive raw data on local devices instead of uploading them to the cloud. He’d also like to see an industrywide standard on user privacy. “When there is a good system to manage and run these technologies, the benefits they will bring will outweigh the drawbacks,” he says.</p>  <p><em>—Yiting Sun</em></p></td>
    </tr>
    <tr>
      <td>Ashutosh Saxena</td>
      <td>When his smart speakers didn’t work as well as hoped, he built a better system.</td>
      <td>34</td>
      <td>Brain of Things</td>
      <td>entrepreneurs-2018</td>
      <td><p><span class="s1">Ashutosh Saxena is the CEO and cofounder of Brain of Things, which devel­oped an AI system called Caspar that turns a home into a sort of robot that we can talk to and interact with. By later this summer, Caspar will have been installed in about 500 apartments in California and Tokyo. </span></p>  <p><span class="s1">Each of these apartments is outfitted with around 100 devices including motion and humidity sensors, microphones, cameras, thermostats, and automated appliances. All of these feed data about residents’ behavior to Caspar, which uses a number of algorithms to analyze the data so that it gradually learns and adapts to people’s habits and preferences.</span></p>  <p><span class="s1">If you tend to ask a lot of questions about the packages you are expecting, Caspar will learn to send you alerts when they arrive. It will also learn to tailor its music playlist to what you are doing at the moment.</span></p>  <p><span class="s1">When asked whether it’s safe to entrust so many intimate details of our lives to a computer, Saxena says the sensitive raw data generated is stored within the home and not uploaded to the cloud. </span></p>  <p><span class="s1">The idea of creating Caspar came about in 2015, when Saxena and his roommate took home a couple of smart speakers. These devices, such as the Amazon Echo, can play music, order things online, switch the lights on and off, and do many other things around the house. But the roommates struggled to make the gadgets work the way they wanted them to. The virtual helpers sometimes turned off the wrong light, and when their masters’ schedules changed, they couldn’t adjust their control of other devices accordingly. </span></p>  <p><span class="s1">So Saxena, a robotics researcher, decided to build a better system.</span></p>  <p><span class="s1">“You no longer need to worry about packages not arriving at your home,” ­Saxena says. “Caspar notifies you of such things, orders dishwasher soap, or controls your home environment according to your preferences.” </span></p>  <p><span class="s1"><em>—Yiting Sun</em></span></p></td>
    </tr>
    <tr>
      <td>William Woodford</td>
      <td>Finding the materials for the next generation of grid-scale batteries.</td>
      <td>32</td>
      <td>Form Energy</td>
      <td>entrepreneurs-2018</td>
      <td><p>For renewables to work, they need batteries—otherwise, the lights go out when the sun goes down or the wind isn’t blowing. Companies like Tesla and Hyundai are addressing the problem by developing football-field-size lithium-ion batteries in Australia and South Korea.</p>  <p>These massive batteries, however, are expensive.</p>  <p>“There’s a cost floor to lithium-ion, which is dictated by the components that are used,” says William Woodford, the chief technology officer of Form Energy. “No matter how cheaply you put it together, you still have a certain set of active ingredients, and those have costs.” So while Elon Musk can build bigger, cheaper batteries, there’s a limit to how cheap they’ll ever get. Lithium carbonate, for example, can cost as much as $20,000 a ton.</p>  <p>To address this problem, Woodford has identified metal-sulfur chemistries that could beat lithium-ion technologies for long-term storage and cost. As a bonus, sulfur is cheap and abundant: it often goes unused as a waste product of oil and gas production.</p>  <p><em>—Dan Solomon</em></p></td>
    </tr>
    <tr>
      <td>Ji Xu</td>
      <td>He helped build a payment system that lets anyone with an internet connection use financial services.</td>
      <td>33</td>
      <td>Alipay</td>
      <td>entrepreneurs-2018</td>
      <td><p><span class="s1">Ji Xu&nbsp;played a key role in building the world’s largest payment platform, which can support more than a billion transactions a day. It’s a boon to commerce, but more important, it enables anyone—especially people without access to traditional banks—to use financial services over the internet.</span></p>  <p><span class="s1">Originally developed to make payments on Alibaba’s online shopping sites easier and more reliable, Alipay has become a ubiquitous electronic payment app in Chinese e-commerce and brick-and-mortar stores alike. It has 520 million users, who see cash as a thing of the past: whether grocery shopping, paying utility bills, or buying movie tickets, they simply pull out a smartphone and use Alipay to scan a payment code.</span></p>  <p><span class="s1">As its business grew, Alipay was confronted with two challenges. First of all, it needed to increase the number of transactions it could handle. In addition, it needed to manage a growing variety of funding options. People had started linking all sorts of funds—credit cards, debit cards, electronic cash gifts, and investment portfolios—with Alipay to pay for things, and sometimes one purchase was made using multiple types of funds.</span></p>  <p><span class="s1">As the chief architect of Alipay’s core payment platform, Xu led a team that increased the system’s capacity from 10 million to 100 million transactions a day, and eventually to one billion. The new system can use servers located anywhere without causing delays during peak hours, which is crucial because the servers consume so much power that no single location can support enough of them to meet the system’s requirements.</span></p>  <p><span class="s1">The increase in Alipay’s transaction capacity also made it possible to offer online financial services to anyone, regardless of income level. One popular feature of the app lets users invest their leftover cash from online spending in a fund and earn interest at higher rates than they could at a bank. </span></p>  <p><span class="s1">Growing up near Hangzhou, where the Alipay team is based, Xu was not interested in taking exams. He spent about two years in a computer science program in college before leaving to look for a job, and he joined Alipay at 23. “I wanted to learn technologies,” he recalls. While on the job, he caught up on programming knowledge through online courses. </span></p>  <p><span class="s1"><em>—Yiting Sun</em></span></p></td>
    </tr>
    <tr>
      <td>Alice Zhang</td>
      <td>Using machine learning to identify new treatments for Parkinson’s and Alzheimer’s.</td>
      <td>29</td>
      <td>Verge Genomics</td>
      <td>entrepreneurs-2018</td>
      <td><p>Traditional approaches to drug devel<span class="s1">opment for diseases like Alzheimer’s, Parkinson’s, and amyotrophic lateral sclerosis (ALS) haven’t offered patients much. Alice Zhang is trying something new. Her company, Verge Genomics, uses artificial intelligence to identify promising compounds, refining the algorithms with high-quality data from patients and lab tests. She hopes this will be a more effective way to find treatments for intractable neurodegenerative diseases.</span></p>  <p>Zhang’s unorthodox method was inspired when she heard a researcher give a talk detailing how hundreds of genes interact in cancer and wondered whether this “network” approach could apply to neurodegenerative diseases. “Computational biology has provided so much insight about cancer,” she says. “The brain is about 10 years behind.”</p>  <p><span class="s1">Verge is developing machine--learning models that identify key genes within a disease network and predict which compounds might interfere with their activity. It tests these compounds in animal models and nerves grown from patient-derived stem cells. The company then feeds the results back into the machine-learning model to refine it further. Zhang says seven of Verge’s candidate compounds for ALS have slowed cell death in patient neurons </span>in vitro.</p>  <p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Shehar Bano</td>
      <td>She made state censorship beatable by revealing the technology it relies on.</td>
      <td>31</td>
      <td>University College London</td>
      <td>visionaries-2018</td>
      <td><p><span class="s1">Shehar Bano made it possible to </span><span class="s2">fight state censorship of the internet—by pioneering the first systematic study of how it happens.</span></p>  <p><span class="s2">It all started when Bano’s homeland of Pakistan blocked YouTube in 2012. “Previously, people were under the delusion that this was magic,” she says of the inner workings of such restrictions. But she wanted to understand—and defeat—them.</span></p>  <p><span class="s2">So Bano probed three years of ISP data from Pakistan, and she experimented with ways to circumvent China’s Great Firewall. What she found was a variety of relatively basic technical restrictions, such as censors looking for any request to load a specific website and then sending signals to both the website’s servers and the surfer’s browser to end the request. Understanding this let her devise ways around the restriction without resorting to encryption, like sending an initial, fake request that the censor would see but ignore because of a misspelling—allowing the real request to slip through in the meantime.</span></p>  <p><span class="s2">Bano not only analyzed online censorship; she also looked into how users of anonymization and security software like Tor and ad blockers are treated differently from unprotected surfers, whether that means a worse user experience or an outright ban. </span></p>  <p><span class="s2">Bano has joined a wave of computer scientists working to protect the freedom of online communication. As a postdoc at University College London, she’s increasingly working with blockchain-based systems, like the smart-contract platform Chainspace, to improve online security and transparency by allowing transactions that are difficult for outside parties to monitor. </span></p>  <p><span class="s2"><em>—Russ Juskalian</em></span></p></td>
    </tr>
    <tr>
      <td>Niki Bayat</td>
      <td>She invented materials that can heal eyes by sealing up traumatic injuries.</td>
      <td>32</td>
      <td>Aesculatech</td>
      <td>visionaries-2018</td>
      <td><p>Growing up in Iran, Niki Bayat always wanted to use her aptitude in engineering to help people suffering from disease—especially after her father developed glaucoma and was unable to have eye surgery because of other health issues. She placed eighth in Iran’s countrywide university entrance exams and majored in chemical engineering at the country’s top university. For grad school, she set her sights on the University of Southern California and joined a collaboration between the labs of renowned chemist Mark Thompson and Mark Humayun, who developed the first artificial retina. “I convinced them that I could bridge the gap between polymer chemistry and biomedical engineering,” she says.</p>  <p><span class="s1">She did just that, using her chemical engineering expertise to develop materials that can help repair traumatic eye injuries and deliver ocular therapies. Bayat has created squishy, biocompatible polymers called hydrogels that become extremely sticky at body temperature, adhering as strongly as superglue. In cases of eye injury, they can be injected in the field, quickly sealing the wound to prevent blindness. Then, back at a hospital, a surgeon can flush the sealant with cold saline, remove it, and suture the wound. Bayat has also designed versions of these materials that can release glaucoma medication or antibiotics in a controlled manner.</span></p>  <p><span class="s1">In 2016, while still working on her PhD, Bayat started AesculaTech to commercialize these drug-delivering materials, which can be inserted into the tear ducts and release medication over periods of months—potentially preventing the need for patients to apply eye drops multiple times a day. AesculaTech plans to first seek approval for polymer devices to treat dry eye before trying to introduce drug-releasing versions. Her ultimate goal, she says, is to come up with a new and better treatment for glaucoma. </span></p>  <p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Marzyeh Ghassemi</td>
      <td>Using AI to make sense of messy hospital data.</td>
      <td>33</td>
      <td>University of Toronto</td>
      <td>visionaries-2018</td>
      <td><p><span class="s1">After collaborating with doctors in the intensive care unit at Beth Israel Deaconess Medical Center during her PhD studies, Marzyeh Ghassemi realized that one of their biggest challenges was information overload. So she designed a suite of machine-learning methods to turn messy clinical data into useful predictions about how patients will fare during a hospital stay.</span></p>  <p><span class="s1">It wasn’t easy. Areas where machine learning excels typically have huge, carefully labeled data sets. Medical data, on the other hand, comes in a bewildering variety of formats at erratic frequencies, ranging from daily written doctors’ notes to hourly blood tests to continuous heart-monitor data.</span></p>  <p><span class="s1">And while vision and language tasks are innately easy for humans to grasp, even highly trained medical specialists can disagree on diagnoses or treatment decisions. Despite these challenges, Ghassemi developed machine-learning algorithms that take diverse clinical data and accurately predict things like how long patients will stay in the hospital, how likely they are to die while there, and whether they’ll need interventions such as blood transfusions or ventilators.</span></p>  <p><span class="s1">This fall Ghassemi joins the University of Toronto and the Vector Institute, where she’s hoping to test her algorithms at local hospitals. </span></p>  <p><span class="s1"><em>—Edd Gent</em></span></p></td>
    </tr>
    <tr>
      <td>Archana Kamal</td>
      <td>She solved a big problem in quantum computing by shrinking the components.</td>
      <td>34</td>
      <td>University of Massachusetts, Lowell</td>
      <td>visionaries-2018</td>
      <td><p>As quantum computing starts to move from the lab to the factory, companies from Google to Intel are struggling to solve a tricky problem: how to faithfully steer the quantum information such systems spit out to traditional computers. Doing so is important since quantum systems, which are expected to have a profound impact on cryptography and other fields, will probably be useful only if regular computers can read their calculations.</p>  <p>Archana Kamal, an assistant professor at UMass Lowell, solved the problem. Kamal demonstrated that quantum information could be steered and amplified for transmission before leaving the device where it was processed. Previously, the transmission required large magnets and complicated devices too big to fit on a single chip, leading to data latency and loss, a major impediment in scaling up current qubit systems.</p>  <p>Kamal’s innovation was to slightly alter the path of the transmission of light signals carrying information so as to shrink the components from the size of a quarter to a few micrometers. “That’s a huge difference,” she says. “Our schemes enable the bulk of quantum signal processing to be done on-chip while preserving the high fidelity of the signals.”<span class="Apple-converted-space">&nbsp; &nbsp;</span></p>  <p><em>—Russ Juskalian</em></p></td>
    </tr>
    <tr>
      <td>Brenden Lake</td>
      <td>Getting machines to learn in the fast and flexible ways that humans can.</td>
      <td>31</td>
      <td>New York University</td>
      <td>visionaries-2018</td>
      <td><p>Brenden Lake created an AI program that can learn novel handwritten characters as well as a human can after seeing just a single example. That might seem mundane in a world where AI controls self-driving cars and beats the world’s best Go players. But today’s state-of-the-art deep-learning approaches train on thousands of examples and aren’t great at transferring their learning to new problems. A human who’s shown an unfamiliar object once, on the other hand, will be able to recognize a new example, draw it, and understand its various parts.</p>  <p>So Lake took inspiration from cognitive psychology. Instead of feeding his program thousands of examples of letters, he taught it how handwriting works. He showed his model motion-capture recordings of humans drawing letters from 30 alphabets so it could learn what pen movements are used to make strokes, how many strokes characters typically have, and how strokes are connected. When shown a character from an unfamiliar alphabet, the model can recognize and reproduce that character just as well as a person.</p>  <p>He’s applied the same approach to get machines to recognize and reproduce spoken words after hearing one example, and also to mimic how people creatively ask questions when solving a problem.</p>  <p>Getting machines to learn the way humans do could prove crucial for AI applications where training on big data isn’t feasible. “If we want to have smart robots in the home, we can’t pre-train or pre-program the robot to know everything out of the box,” Lake says. “Children pick up new concepts every day, and a truly intelligent machine must do the same.”</p>  <p><em>—Edd Gent</em></p></td>
    </tr>
    <tr>
      <td>Adam Marblestone</td>
      <td>He wrote the book on how to record every neuron in the brain.</td>
      <td>31</td>
      <td>Kernel</td>
      <td>visionaries-2018</td>
      <td><p>Adam Marblestone wants to make the brain machine-readable. So he worked out the physical limits of what’s possible in recording brain activity and is now using that knowledge to set technology strategy at Kernel, a startup with $100 million in funding that’s building neural interfaces for humans.</p>  <p>As a PhD student, Marblestone was a lead author of a paper now considered a foundational strategic document for researchers building technology to read brain activity. Using the mouse brain as a model, he identified the engineering problems we’ll have to solve to simultaneously measure the activity of every neuron in the brain.</p>  <p>“It’s all about how do we, in the approaches that we take to studying the brain, somehow try to match the complexity of the brain itself?” he says.</p>  <p>As chief strategy officer at Kernel, he’s marshalling a network of leading researchers to identify the most promising approaches for making neural interfaces that can help us understand and treat neurological diseases. One day they could even make it possible to merge our brains with machines.</p>  <p><em>—Edd Gent</em></p></td>
    </tr>
    <tr>
      <td>Prineha Narang</td>
      <td>Her research on materials at the smallest scale could lead to a new generation of technologies.</td>
      <td>28</td>
      <td>Harvard University</td>
      <td>visionaries-2018</td>
      <td><p><span class="s1">Prineha Narang seeks to build technologies by starting small: with the atom.</span></p>  <p><span class="s2">As an assistant professor of computational materials science at Harvard, Narang studies the optical, thermal, and electronic behavior of materials at the nanoscale. Her research in how materials interact with light and other forms of electro-magnetic radiation could drive innovations in electronics, energy, and space technologies.</span></p>  <p><span class="s1">Narang’s work builds on decades of advances in nanoscience that have brought the field closer to a long-held goal: the ability to engineer materials atom by atom. </span></p>  <p><span class="s1">Yet since its emergence in the 1980s, the discipline has focused mainly on nanostructures at or near equilibrium—their lowest state of energy. At the temperatures they encounter in nature, however, most materials are away from equilibrium, in so-called excited states, which remain poorly understood at the quantum level. “There’s so much more we can do with excited states that has just not been tried yet,” Narang says.</span></p>  <p><span class="s1">By studying these excited states, Narang is developing approaches that could lead to vastly improved materials. Applications could include improved reflectors and lenses for telescopes, lighter cell phones with better cameras, or synthetic fuels designed at the atomic level. </span></p>  <p><span class="s1"><em>—Jonathan W. Rosen</em></span></p></td>
    </tr>
    <tr>
      <td>Menno Veldhorst</td>
      <td>He figured out how to make workable quantum circuits on silicon—a feat previously considered impossible.</td>
      <td>33</td>
      <td>Delft University</td>
      <td>visionaries-2018</td>
      <td><p>Menno Veldhorst has invented a faster path to real-world quantum circuits by making it possible for them to be printed on silicon—the way computer chips have been made for decades.</p>  <p>Quantum computers would allow powerful calculations that no traditional computer is capable of, but before Veldhorst’s innovation, it was considered impossible to make semiconductor-based quantum circuits on silicon that would be stable enough for useful computation. These machines—which are governed by the strange physics of subatomic particles—have instead been built with esoteric materials, including superconductors, that are easier to control in their fragile quantum states. The trade-offs: working with such technology is expensive, and producing such circuitry at scale would require entirely new industrial processes.</p>  <p>Veldhorst, a researcher at Delft University in the Netherlands, has found a way forward with the most replicated manmade structure on the planet—the transistor. He was able to demonstrate calculations on the basic units of quantum information, known as qubits, in silicon semiconductors.</p>  <p>Now, thanks to Veldhorst’s breakthrough, Intel is printing hundreds of thousands of such simple systems on the same type of 300-millimeter wafers the company uses to make its conventional chips. This means collaborators at Intel can increasingly spend their time on the microelectronics and algorithms necessary for complete quantum computers rather than working through the basic physics.</p>  <p>What’s most exciting to Veldhorst is that—just as with the transistor and the computer itself—a flood of quantum computers will need to be built just to figure out what they are capable of. His research has allowed just that.</p>  <p><em>—Russ Juskalian</em></p></td>
    </tr>
    <tr>
      <td>Hera Hussain</td>
      <td>Her tech nonprofit makes it easy for women to build a domestic-abuse case without a lawyer.</td>
      <td>28</td>
      <td>Chayn</td>
      <td>humanitarians-2018</td>
      <td><p><span class="s1">Hera Hussain is empowering women around the world via a simple combination of social and technological innovation: enlisting volunteers to crowdsource multilingual online guides covering topics like how to build a domestic-abuse case without a lawyer, or how to identify psychological manipulation.</span></p>  <p><span class="s1">It all started after Hussain tried to help two friends escape abusive marriages. “You would think in the UK it would be easy to find information about how to get a divorce, how to apply for asylum, what are the laws to apply for child custody,” she says. “But it was frighteningly difficult to get that information.”</span></p>  <p><span class="s1">In 2013 Hussain founded the open-source, nonprofit organization Chayn in her spare time—to make the missing information easy to find and understand. Today, 70 percent of Chayn’s 400 volunteers are survivors of violence and oppression themselves. Their guides are built largely from crowdsourced research and firsthand experience of the overlapping psychological, cultural, and legal complexities involved in oppression against women. </span></p>  <p><span class="s1">Hussain says she’s lost count of the times she’s been lectured—mostly by men—that Chayn’s guides shouldn’t be written by people without legal or academic backgrounds. “You get talked down to a lot,” she says. She likes to counter their arguments with the example of a woman from India who for years was trying to figure out how to leave her abusive marriage. All the resources the woman found online were written by Indian lawyers, almost all men, lamenting that women took advantage of divorce laws rather than be dutiful wives. </span></p>  <p><span class="s1">Hussain continues to push Chayn to harness appropriate technologies to deepen its reach. A new chatbot, for instance, guides visitors to the most relevant information in as few clicks as possible. </span></p>  <p><span class="s1"><em>—Russ Juskalian</em></span></p></td>
    </tr>
    <tr>
      <td>Mustafa Suleyman</td>
      <td>Working to alleviate human suffering through AI.</td>
      <td>33</td>
      <td>DeepMind</td>
      <td>humanitarians-2018</td>
      <td><p><span class="s1">Mustafa Suleyman cofounded the AI company DeepMind out of a desire to have as broad an impact on society as possible. AI, he decided, was the fastest way to do it. </span></p>  <p><span class="s1">Now Suleyman has launched DeepMind Health to build AI that can better diagnose disease, including systems that detect early-stage eye disease and help analyze mammograms. He’s also focusing on how such technology is used by medical clinicians. “The tech community is only just finally catching up in thinking about the ethical impact of these systems,” says Suleyman. For instance, will time-pressed clinicians simply defer to the AI’s top suggestions without critical evaluation? How will such systems be audited? And how can new medical findings take into account implicit biases in old data used to train the AI? “I think this is going to be the year when Silicon Valley and the technology companies come to really accept the incredible social responsibility that such great power carries,” he says.</span></p>  <p><span class="s1">Last year, Suleyman launched the DeepMind Ethics &amp; Society unit to design systems that anticipate and direct algorithms’ decision-making processes and their impact on society. </span></p>  <p><span class="s1">“The big pivot that technology companies are going to make,” he says, “is to ask the question: How do we shape these algorithms so they represent the moral choices that we collectively elect to make?” </span></p>  <p><span class="s1"><em>—Russ Juskalian</em></span></p></td>
    </tr>
    <tr>
      <td>Minmin Yen</td>
      <td>Cholera kills, and vaccines don’t always work. She created a better solution.</td>
      <td>29</td>
      <td>PhagePro</td>
      <td>humanitarians-2018</td>
      <td><p>Cholera affects millions of people annually in the world’s poorest communities. It’s often treated with antibiotics, but they’re not ideal because they harm the bacteria in the gut, and antibiotic resistance is on the rise.</p>  <p>Minmin Yen developed a better solution: bacteriophages, or viruses that specifically target bacteria. What’s significant about Yen’s intervention is that it works immediately to kill the bacteria and prevent the disease from developing. Existing vaccines, in contrast, can take weeks to work.</p>  <p><span class="s1">Yen, who earned a PhD in molecular microbiology at Tufts University, says bacteriophages have been mostly unexplored because antibiotics are so prevalent, but she thinks it’s time for them to play a larger role now that resistant bacteria are so common. She has started a company, PhagePro, to bring her intervention to market. </span></p>  <p><span class="s1"><em>—Erika Beras</em></span></p></td>
    </tr>
    <tr>
      <td>Joy Buolamwini</td>
      <td>When AI misclassified her face, she started a movement for accountability.</td>
      <td>28</td>
      <td>MIT Media Lab and Algorithmic Justice League</td>
      <td>pioneers-2018</td>
      <td><p><span class="s1">As a college student, Joy Buol</span><span class="s2">amwini discovered that some facial-analysis systems couldn’t detect her dark-skinned face until she donned a white mask. “I was literally not seen by technology,” she says.</span></p>  <p><span class="s2">That sparked the research for her MIT graduate thesis. When she found that existing data sets for facial--analysis systems contained predominantly pale-skinned and male faces, Buolamwini created a gender-balanced set of over a thousand politicians from Africa and Europe. When she used it to test AI systems from IBM, Microsoft, and Face++, she found that their accuracy varied greatly with gender and skin color. When determining gender, the error rates of these systems were less than 1 percent for lighter-skinned males. But for darker-skinned female faces, the error rates were as high as 35 percent.</span></p>  <p>In some cases, as when Facebook mislabels someone in a photo, such mistakes are merely an annoyance. But with a growing number of fields coming to rely on AI—law enforcement is using it for predictive policing, and judges are using it to determine whether prisoners are likely to reoffend—the opportunities for injustice are frightening. “We have to continue to check our systems, because they can fail in unexpected ways,” Buolamwini says.&nbsp;</p>  <p>A former Rhodes scholar and Fulbright fellow, she founded the Algorithmic Justice League to confront bias in algorithms. Beyond merely bringing these biases to light, she hopes to develop practices to prevent them from arising in the first place—like making sure facial-recognition systems undergo accuracy tests.</p>  <p><em>—Erika Beras</em></p></td>
    </tr>
    <tr>
      <td>Alessandro Chiesa</td>
      <td>A cryptocurrency that’s as private as cash.</td>
      <td>30</td>
      <td>University of California, Berkeley</td>
      <td>pioneers-2018</td>
      <td><p>For all the promise of blockchain, there’s a problem that comes with treating all transactions as public information: some of that stuff is just nobody’s business. But with Zcash, a cryptocurrency cofounded by Alessandro Chiesa, transactions can be not only secure but as anonymous as handing someone a $20 bill from your wallet.</p>  <p><span class="s1">That’s because Zcash employs a cryptographic protocol called a succinct zero-knowledge proof (see “10 Breakthrough Technologies 2018: Perfect Online Privacy”)—that is, an efficient way to convince both parties to a transaction that something is true without divulging any other information. </span></p>  <p>Zcash has huge implications for transactions that might otherwise reveal a buyer’s or seller’s location, medical information, or other private data. It allows people to do transactions online without risking their privacy or exposing themselves to identity theft. Zcash, which Chiesa launched four years ago, now has a market cap of over a billion dollars.</p>  <p><em>—Dan Solomon</em></p></td>
    </tr>
    <tr>
      <td>Chelsea Finn</td>
      <td>Her robots act like toddlers—watching adults, copying them in order to learn.</td>
      <td>25</td>
      <td>Berkeley Artificial Intelligence Lab</td>
      <td>pioneers-2018</td>
      <td><p>Chelsea Finn is developing robots that can learn just by observing and exploring their environment. Her algorithms require much less data than is usually needed to train an AI—so little that robots running her software can learn how to manipulate an object just by watching one video of a human doing it.</p>  <p>Finn’s robots act like toddlers, watching adults do something and copying them. A wooden shape-sorting toy in her lab shows evidence of the process: marks from where a robot repeatedly bashed a red cube before learning to place it inside the square hole.</p>  <p>Her ultimate goal is to create robots that can be sent off into the world and acquire a general set of skills—not because they’ve been programmed for those tasks but because they’ve been taught to learn by observing. This might mean factory robots that wouldn’t have to be trained by teams of engineers, or AI systems that recognize objects without being trained on labeled images.</p>  <p>Finn thinks a good intermediate goal for her robots is to teach them how to set the table. The first step is to make robots that can learn how to arrange multiple objects. “In many ways, the capabilities of robotic systems are still in their infancy,” she says. “The goal is to have them gain common sense.”<span class="Apple-converted-space">&nbsp; </span></p>  <p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Alexandre Rebert</td>
      <td>He asked, what if a computer could fix itself?</td>
      <td>28</td>
      <td>ForAllSecure</td>
      <td>pioneers-2018</td>
      <td><p><span class="s1">When a computer system gets hacked, people typically fix the problem after the fact. Alexandre Rebert created a machine that can fix itself as the attack is happening.</span></p>  <p><span class="s1">Rebert recognized that computers may lack creativity, but they’re good at doing things quickly and on a massive scale. His system, called Mayhem, can analyze thousands of programs simultaneously, doing in a few hours what might take a human expert years to accomplish. </span></p>  <p><span class="s1">Mayhem, an autonomous system, does this by combining two techniques. The first is called coverage-based fuzzing—a standard in automated security testing, in which data is thrown at a program to see if an input triggers new behavior. It’s essentially scanning and searching in a fast way. The second, symbolic execution, analyzes the program in a slower, more nuanced way. The approaches complement each other, making the combination better than other techniques. </span></p>  <p><span class="s1">Rebert led the team creating Mayhem while working with ForAllSecure, the Pittsburgh-based cybersecurity company he cofounded. The company’s work and mission stem from his research at Carnegie Mellon. He thinks his invention could be especially useful for vulnerable systems like power grids, hospitals, and banks.</span></p>  <p><span class="s1">“There is an increasing amount of software in our lives,” says Rebert. “And depending only on human expertise is insufficient and dangerous.”</span></p>  <p><span class="s1"><em>—Erika Beras</em></span></p></td>
    </tr>
    <tr>
      <td>Nabiha Saklayen</td>
      <td>She developed a way to edit genes with cheap lasers.</td>
      <td>28</td>
      <td>Cellino Biotech</td>
      <td>pioneers-2018</td>
      <td><p>Gene editing is invaluable in correcting mutations like the one that causes sickle-cell anemia. But biologists need better ways to get DNA and other ingredients into cells. Typically, the gene-editing recipe is introduced by viruses, which can have dangerous side effects, or during electroporation, a technique that uses strong electrical pulses and kills many of the cells in the process.</p>  <p>Lasers offer a gentler alternative, but those methods have had their own drawbacks. The lasers used have typically been very powerful and expensive, and capable of injecting only one cell at a time—too slow for clinical applications.</p>  <p>Nabiha Saklayen’s innovation was to design nanostructured add-ons to the laser system that deliver pulses of laser light to large numbers of cells at once, making it possible to dose them with gene editors at clinically useful speeds. Her process doesn’t require an expensive laser, though it took her a while to convince other researchers and her advisor that relatively cheap ones were powerful enough. “It doesn’t matter to the cell,” she says.</p>  <p><span class="s1">Saklayen has now founded a company, Cellino Biotech, to commercialize her idea and use gene-editing tools to engineer cells.</span></p>  <p>Trained as a physicist, she is unusually comfortable with moving between scientific fields, including laser physics, nanomaterials, and synthetic biology. She credits her upbringing in Saudi Arabia, Bangladesh, Germany, and Sri Lanka with her adaptability. “I’m comfortable in new places, and at the interface of <br> different fields,” she says.</p>  <p>—<em>Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Julian Schrittwieser</td>
      <td>AlphaGo beat the world’s best Go player. He helped engineer the program that whipped AlphaGo.</td>
      <td>25</td>
      <td>DeepMind</td>
      <td>pioneers-2018</td>
      <td><p>A few years ago, when Julian Schrittwieser joined the Google-owned artificial-intelligence firm DeepMind, the board game Go was often called the Holy Grail of machine learning. The two-player game, which originated in ancient China, was so unconstrained by rules and so driven by intuition that many thought it would take a decade for AI to best the world’s top players. But in March 2016, a program developed by ­Schritt­wieser and his ­DeepMind colleagues defeated South Korea’s Lee Sedol, the world Go champion, in a best-of-five series that drew more than 100 million viewers. Go enthusiasts called it the match of the century.</p>  <p>Schrittwieser and his teammates followed this up with an even more impressive accomplishment. In October 2017, their new program, AlphaGo Zero, defeated the earlier program, AlphaGo, 100 games to zero. Unlike AlphaGo, which learned the game by studying the play of humans, AlphaGo Zero learned by playing against itself—a feat with major implications for artificial intelligence. “With AlphaGo Zero, we see that even in areas where we don’t have human knowledge, we can bootstrap that knowledge and have a system that learns on its own,” Schrittwieser says.</p>  <p><span class="s1">Schrittwieser, an Austrian native, is the lead software engineer on the AlphaGo Zero project. He is also a driving force behind a third DeepMind initiative, Alpha­Zero—a more generalized algorithm that has already mastered Go, chess, and the Japanese board game Shogi. The push toward generalization, ­Schrittwieser says, is key to DeepMind’s quest to build intelligent machines that are independent of human intuition—thereby devising better solutions to problems where the approach might otherwise be inhibited by human biases. Ultimately, he believes, this could lead to entirely new, AI-driven innovations in fields from pharmaceuticals to materials science. </span></p>  <p><span class="s1"><em>—Jonathan W. Rosen</em></span></p></td>
    </tr>
    <tr>
      <td>John Schulman</td>
      <td>Training AI to be smarter and better, one game of Sonic the Hedgehog at a time.</td>
      <td>30</td>
      <td>OpenAI</td>
      <td>pioneers-2018</td>
      <td><p>John Schulman, a research scientist at OpenAI, has created some of the key algorithms in a branch of machine learning called reinforcement learning. It’s just what it sounds like: you train AI agents in the same way you might train a dog, by offering a treat for a correct response. For a machine, the “treat” might be to rack up a high score in a video game.</p>  <p>Which explains why Schulman is so excited about the 1991 video game Sonic the Hedgehog. The game, he says, is a perfect benchmark for testing how well new machine-­learning algorithms transfer learned skills to new situations. Since Sonic is the world’s fastest hedgehog, the game moves rapidly, and it also depicts some interesting physics. Once an AI agent learns how to play, it’s easy for researchers to test its ability to transfer that knowledge to different scenarios.</p>  <p>These algorithms, once trained, might be applied in the real world, and they can be used to improve robot locomotion. Traditional approaches have been specialized for certain situations—which means that on new terrain, a robot programmed using older methods might fall down. One that uses reinforcement learning, ­Schulman hopes, would be able to get back up and try new things until it solves the problem.</p>  <p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Humsa Venkatesh</td>
      <td>She discovered a secret to cancer growth that could lead to a new class of drugs.</td>
      <td>32</td>
      <td>Stanford University</td>
      <td>pioneers-2018</td>
      <td><p>Humsa Venkatesh’s research revealed how cancers hijack the activity of neural networks to fuel their own growth. Her discovery sparked a novel area of research targeting a type of activity seen in many different types of cancer. “These neuronal systems are signaling inputs that instruct how the tumor grows and functions,” she says. The results could lead to therapies that work against tumor cells in all their diversity.</p>  <p><span class="s1">When Venkatesh was a teenager in California, her uncle, who lived in India at the time, learned he had kidney cancer. Though he sought treatment in both India and the US, the only options available to him were standard radiation and chemotherapy, neither of which was effective. He died less than two years after the diagnosis. The experience made Venkatesh realize how little doctors understood the fundamental mechanisms of tumor growth. </span></p>  <p>So instead of becoming a doctor, as she’d originally hoped, she devoted herself to studying that. “I wanted my contribution to be not just treating these patients on an individual level, but really advancing cancer research in a way that would help us come up with new ways to treat [them],” she says.</p>  <p>Now Venkatesh is harnessing tumors’ essentially parasitic behavior within their environment to develop drugs that might neutralize the way they exploit neural networks. These therapies could be pushed into clinics faster than some others because prototypes of such drugs already exist—they were developed for other purposes before scientists found out about their potential in cancer treatment.</p>  <p><em>—Yiting Sun</em></p></td>
    </tr>
    <tr>
      <td>Gene Berdichevsky</td>
      <td>Exploring new materials for better lithium-ion batteries.</td>
      <td>34</td>
      <td>Sila Nanotechnologies</td>
      <td>inventors-2017</td>
      <td><p>As employee number seven at Tesla, Gene ­Berdichevsky was instrumental in solving one of its earliest challenges: the thousands of lithium-­ion batteries the company planned to pack into its electric sports car caught fire far more often than manufacturers claimed. His solution: a combination of heat transfer materials, cooling channels, and battery arrangements that ensured any fire would be self-contained.</p>  <p>Now Berdichevsky has cofounded Sila Nanotechnologies, which aims to make better lithium-ion batteries. The company has developed silicon-based nanoparticles that can form a high-capacity anode. Silicon has almost 10 times the theoretical capacity of the material most often used in lithium-ion batteries, but it tends to swell during charging, causing damage. Sila’s particles are robust yet porous enough to accommodate&nbsp;that swelling, promising longer-lasting batteries. <br><br>—<em>James Temple</em></p></td>
    </tr>
    <tr>
      <td>Radha Boya</td>
      <td>The world’s narrowest fluid channel could transform filtration of water and gases.</td>
      <td>32</td>
      <td>University of Manchester’s Graphene Research Institute</td>
      <td>inventors-2017</td>
      <td><p>Beneath a microscope in Radha Boya’s lab, a thin sheet of carbon has an almost imperceptible channel cutting through its center, the depth of a single molecule of water. “I wanted to create the most ultimately small fluidic channels possible,” explains Boya. Her solution: identify the best building blocks to reliably and repeatedly build a structure containing unimaginably narrow capillaries. She settled on graphene, a form of carbon that is a single atom thick.</p>  <p>She positions two sheets of graphene (a single sheet is just 0.3 nanometers thick) next to each other with a small lateral gap between them. That is sandwiched on both sides with slabs of graphite, a material made of many layers of graphene stacked on top of each other. The result is a channel 0.3 nanometers deep and 100 nanometers wide, cutting through a block of graphite. By adding extra layers of graphene, she can tune the size of the channel in 0.3-nanometer increments.</p>  <p>But what fits through something so narrow? A water molecule—which itself measures around 0.3 nanometers across—can’t pass through the channel without application of pressure. But with two layers of graphene, and a 0.6-nanometer gap, water passes through at one meter per second. “The surface of graphene is slightly hydrophobic, so the water molecules stick to themselves rather than the walls,” says Boya. That helps the liquid slide through easily.</p>  <p><span class="s1">Because the gaps are so consistently sized, they could be used to build precisely tuned filtration systems. Boya has performed experiments that show her channels could filter salt ions from water, or separate large volatile organic compounds from smaller gas molecules. Because of the size consistency, her technology can filter more efficiently than others. </span></p>  <p><span class="s1">Boya currently works at the University of Manchester’s Graphene Research Institute in the U.K.—a monolithic black slab of a building that opened in 2015 to industrialize basic research on the material. It brands itself as the “home of graphene,” which seems appropriate given that Boya’s office is on the same corridor as those of Andre Geim and Kostya Novoselov, who won a Nobel Prize for discovering the material. <br><br>—<em>Jamie Condliffe</em></span></p></td>
    </tr>
    <tr>
      <td>Ian Goodfellow</td>
      <td>Invented a way for neural networks to get better by working together.</td>
      <td>31</td>
      <td>Google Brain Team</td>
      <td>inventors-2017</td>
      <td><p><span class="s1">A few years ago, after some heated debate in a Montreal pub, Ian Goodfellow dreamed up one of the most intriguing ideas in artificial intelligence. By applying game theory, he devised a way for a machine-learning system to effectively teach itself about how the world works. This ability could help make computers smarter by sidestepping the need to feed them painstakingly labeled training data.</span></p>  <p><span class="s1">Goodfellow was studying how neural networks can learn without human supervision. Usually a network needs labeled examples to learn effectively. While it’s also possible to learn from unlabeled data, this had typically not worked very well. Goodfellow, now a staff research scientist with the Google Brain team, wondered if two neural networks could work in tandem. One network could learn about a data set and generate examples; the second could try to tell whether they were real or fake, allowing the first to tweak its parameters in an effort to improve. </span></p>  <p><span class="s1">After returning from the pub, Goodfellow coded the first example of what he named a “generative adversarial network,” or GAN. The dueling-neural-network approach has vastly improved learning from unlabeled data. GANs can already perform some dazzling tricks. By internalizing the characteristics of a collection of photos, for example, a GAN can improve the resolution of a pixelated image. It can also dream up realistic fake photos, or apply a particular artistic style to an image. “You can think of generative models as giving artificial intelligence a form of imagination,” Goodfellow says. <br><br>—<em>Will Knight</em></span></p></td>
    </tr>
    <tr>
      <td>Svenja Hinderer</td>
      <td>A design for a heart valve that’s biodegradable—potentially eliminating the need for repeat surgeries.</td>
      <td>32</td>
      <td>Fraunhofer Institute</td>
      <td>inventors-2017</td>
      <td><p><strong>Problem: </strong>Over 85,000 Americans receive artificial heart valves, but such valves don’t last forever, and replacing them involves a costly and invasive surgery. In children, they must be replaced repeatedly.</p>  <p><strong>Solution:</strong> Svenja Hinderer, who leads a research group at the Fraunhofer Institute in Stuttgart, Germany, has created a biodegradable heart valve that studies strongly suggest will be replaced over time by a patient’s own cells.</p>  <p>To accomplish this, Hinderer created a scaffolding of biodegradable fibers that mimic the elastic properties of healthy tissues. To it she attaches proteins with the power to attract the stem cells that naturally circulate in the blood. The idea is that once implanted, her heart valve would be colonized and then replaced by a patient’s own cells within two to three years. <br><br>—<em>Russ Juskalian</em></p></td>
    </tr>
    <tr>
      <td>Lorenz Meier</td>
      <td>An open-source autopilot for drones.</td>
      <td>32</td>
      <td>Swiss Federal Institute of Technology</td>
      <td>inventors-2017</td>
      <td><p>Lorenz Meier was curious about technologies that could allow robots to move around on their own, but in 2008, when he started looking, he was unimpressed—most systems had not yet even adopted the affordable motion sensors found in smartphones.</p>  <p>So Meier, now a postdoc at the Swiss Federal Institute of Technology in Zurich, built his own system instead: PX4, an open-source autopilot for autonomous drone control. Importantly, Meier’s system aims to use cheap cameras and computer logic to let drones fly themselves around obstacles, determine their optimal paths, and control their overall flight with little or no user input. It has already been adopted by companies including Intel, Qualcomm, Sony, and GoPro. <br><br>—<em>Russ Juskalian</em></p></td>
    </tr>
    <tr>
      <td>Franziska Roesner</td>
      <td>Preparing for the security and privacy threats that augmented reality will bring.</td>
      <td>31</td>
      <td>University of Washington</td>
      <td>inventors-2017</td>
      <td><p>What would hacks of augmented reality look like? Imagine a see-through AR display on your car helping you navigate—now imagine a hacker adding images of virtual dogs or pedestrians in the street.</p>  <p>Franzi Roesner, 31, recognized this challenge early on and is leading the thinking into what security and privacy provisions AR devices will need to protect them, and ourselves. Her research group at the University of Washington created a prototype AR platform that can, for example, block a windshield app from hiding any signs or people in the real world while a car is in motion.</p>  <p>&nbsp;“I’ve been asking the question, ‘What could a buggy or malicious application do?’” she says.<br><br><em>—Rachel Metz</em></p></td>
    </tr>
    <tr>
      <td>Olga Russakovsky</td>
      <td>Employed crowdsourcing to vastly improve computer-vision system.</td>
      <td>31</td>
      <td>Princeton University</td>
      <td>inventors-2017</td>
      <td><p>“It’s hard to navigate a human environment without seeing,” says Olga Russakovsky, an assistant professor at Princeton who is working to create artificial-intelligence systems that have a better understanding of what they’re looking at.</p>  <p>A few years ago, machines were capable of spotting only about 20 objects—a list that included people, airplanes, and chairs. Russakovsky devised a method, based partly on crowdsourcing the identification of objects in photos, that has led to AI systems capable of detecting 200 objects, including accordions and waffle irons.</p>  <p>Russakovsky ultimately expects AI to power robots or smart cameras that allow older people to remain at home, or autonomous vehicles that can confidently detect a person or a trash can in the road. “We’re not there yet,” she says, “and one of the big reasons is because the vision technology is just not there yet.”</p>  <p>A woman in a field dominated by men, Russakovsky started AI4ALL, a group that pushes for greater diversity among those working in artificial intelligence. While she wants greater ethnic and gender diversity, she also wants diversity of thought. “We are bringing the same kind of people over and over into the field,” she says. “And I think that’s actually going to harm us very seriously down the line.”</p>  <p>If robotics are to become integral and integrated into our lives, she reasons, why shouldn’t there be people of varying professional backgrounds creating them, and helping them become attuned to what all types of people need?</p>  <p><span class="s1">Russakovsky took a rather conventional path from studying mathematics as an undergrad at Stanford, where she also earned a PhD in computer science, to a postdoc at Carnegie Mellon. But, she suggests, “We also need many others: biologists who are maybe not great at coding but can bring that expertise. We need psychologists—the diversity of thought really injects creativity into the field and allows us to think very broadly about what we should be doing and what type of problems we should be tackling, rather than just coming at it from one particular angle.”</span><br><br>—<em>Erika Beras</em></p></td>
    </tr>
    <tr>
      <td>Michael Saliba</td>
      <td>Finding ways to make promising perovskite-based solar cells practical.</td>
      <td>34</td>
      <td>Swiss Federal Institute of Technology</td>
      <td>inventors-2017</td>
      <td><p>Crystalline-silicon panels—which make up about 90 percent of deployed photovoltaics—are expensive, and they’re already bumping up against efficiency limits in converting sunlight to electricity. So a few years ago, Michael S­aliba, a researcher at the Swiss Federal Institute of Technology in Lausanne, set out to investigate a new type of solar cell based on a family of materials known as perovskites. The first so-called perovskite solar cells, built in 2009, promised a cheaper, easier-to-process technology. But those early perovskite-based cells converted only about 4 percent of sunlight into electricity.</p>  <p>Saliba improved performance by adding positively charged ions to the known perovskites. He has since pushed solar cells built of the stuff to over 21 percent efficiency and shown the way to versions with far higher potential. <br><br>—<em>Russ Juskalian</em></p></td>
    </tr>
    <tr>
      <td>Gregory Wayne</td>
      <td>Using an understanding of the brain to create smarter machines.</td>
      <td>34</td>
      <td>DeepMind</td>
      <td>inventors-2017</td>
      <td><p>Greg Wayne, a researcher at DeepMind, designs software that gets better the same way a person might—by learning from its own mistakes. In a 2016 <em>Nature</em> paper that Wayne coauthored, it was demonstrated that such software can solve things like graph problems, logic puzzles, and tree structures that traditional neural networks used in artificial intelligence can’t.</p>  <p>Wayne’s computing insights play off his interest in connections between neurons in the human brain—why certain structures elicit specific sensations, emotions, or decisions. Now he often repurposes the concepts behind those brain structures as he designs machines. <br><br>—<em>Caleb Garling</em></p></td>
    </tr>
    <tr>
      <td>Abdigani Diriye</td>
      <td>A computer scientist who founded Somalia’s first incubator and startup accelerator.</td>
      <td>33</td>
      <td>Innovate Ventures, IBM Research Africa</td>
      <td>entrepreneurs-2017</td>
      <td><p>“Like many Somalis, I ended up fleeing my homeland because of the civil war, back in the late 1980s. At age five&nbsp;I moved to the U.K. because I had family there and was able to get asylum. I grew up in a fairly nice part of London and went on to get a PhD in computer science at University College London.</p>  <p>“At university I started becoming more aware of the world and realized I was quite fortunate to be where I am, to have had all the opportunities that I did. So, in 2012, I helped start an organization called Innovate Ventures to train and support Somali techies. The first program we ran was a two-week coding camp in Somalia for about 15 people. Though the impact was small at the time, for those individuals it meant something, and it was my first time going back to the continent; I hadn’t visited in more than two decades.</p>  <p>“I started to think how Innovate Ventures could have a much bigger impact. In 2015, we teamed up with two nonprofits that were running employment training for Somali youths, found some promising startups, and put them through a series of sessions on marketing, accounting, and product design. Five startups came out of that five-month incubator, and we awarded one winner around $2,500 in seed money to help kick-start its business.</p>  <p>“The next year saw us partner with Oxfam, VC4Africa [an online venture-capital community focused on Africa], and Telesom [the largest telco in Somaliland], and we ran a 10-week accelerator for startups. We were hoping to get 40 to 50 applicants, but we ended up getting around 180. We chose 12 startups for a two-week bootcamp and 10 to participate in the full 10-week training and mentoring program. The top four received a total of $15,000 in funding.</p>  <p>“This year, the accelerator will be 12 weeks long, and we’ve received almost 400 applicants. There are some large Somali companies that are interested in investing in startups and we want to bring them on board to help catalyze the startup scene. We also hope to persuade the Somali diaspora, including some of my colleagues at IBM, to donate their skills and invest in the local technology scene.</p>  <p>“Countries like Kenya and Rwanda have initiatives to become technology and innovation hubs in Africa. Somaliland and Somalia face fundamental challenges in health care, education, and agriculture, but innovation, technology, and startups have the potential to fast-track the country's development. I think we’ve started to take steps in that direction with the programs we’ve been running, and we’re slowly changing the impression people have when they view Somalia and Somaliland.”<br><br><em>—as told to Elizabeth Woyke</em></p></td>
    </tr>
    <tr>
      <td>Tallis Gomes</td>
      <td>An “Uber for beauty.”</td>
      <td>30</td>
      <td>Singu</td>
      <td>entrepreneurs-2017</td>
      <td><p>Tallis Gomes had spent four years as the CEO of EasyTaxi, the “Uber of Brazil,” when he decided in 2015 to aim the same concept in a new direction—the beauty industry.</p>  <p>His on-demand services platform, called Singu, allows customers to summon a masseuse, manicurist, or other beauty professional to their home or office. Scheduling is done by an algorithm factoring in data from Singu and third parties, including location and weather. The professionals see fewer customers than they would in a shop, but they make more money because they don’t have to cover the overhead. Gomes says the algorithm can get a manicurist as many as 110 customers in a month, and earnings of $2,000—comparable to what a lawyer or junior engineer might make. <br><br><em>—Nanette Byrnes</em></p></td>
    </tr>
    <tr>
      <td>Kathy Gong</td>
      <td>Developing new models for entrepreneurship in China.</td>
      <td>30</td>
      <td>Wafa Games</td>
      <td>entrepreneurs-2017</td>
      <td><p>Kathy Gong became a chess master at 13, and four years later she boarded a plane with a one-way ticket to New York City to attend Columbia University. She knew little English at the time but learned as she studied, and after graduation she returned to China, where she soon became a standout among a rising class of fearless young technology entrepreneurs. Gong has launched a series of companies in different industries. One is Law.ai, a machine-learning company that created both a robotic divorce lawyer called Lily and a robotic visa and immigration lawyer called Mike. Now Gong and her team have founded a new company called Wafa Games that’s aiming to test the Middle East market, which Gong says most other game companies are ignoring. <br><br><em>—Nanette Byrnes</em></p></td>
    </tr>
    <tr>
      <td>Rachel Haurwitz</td>
      <td>Overseeing the commercialization of the promising gene-editing method called CRISPR.</td>
      <td>32</td>
      <td>Caribou Biosciences</td>
      <td>entrepreneurs-2017</td>
      <td><p>Rachel Haurwitz quickly went from lab rat to CEO at the center of the frenzy over CRISPR, the breakthrough gene-editing technology. In 2012 she’d been working at Jennifer Doudna’s lab at the University of California, Berkeley, when it made a breakthrough showing how to edit any DNA strand using CRISPR. Weeks later, Haurwitz traded the lab’s top-floor views of San Francisco Bay for a sub-basement office with no cell coverage and one desk. There she became CEO of Caribou Biosciences, a spinout that has licensed Berkeley’s CRISPR patents and has made deals with drug makers, research firms, and agricultural giants like DuPont. She now oversees a staff of 44 that spends its time improving the core gene-editing technology. One recent development: a tool called SITE-Seq to help spot when CRISPR makes mistakes. <br><br><em>—Antonio Regalado</em></p></td>
    </tr>
    <tr>
      <td>Bill Liu</td>
      <td>His flexible components could change the way people use electronics.</td>
      <td>34</td>
      <td>Royole</td>
      <td>entrepreneurs-2017</td>
      <td><p>Bill Liu thinks he can do something Samsung, LG, and Lenovo can’t: manufacture affordable, flexible electronics that can be bent, folded, or rolled up into a tube.</p>  <p>Other researchers and companies have had similar ideas, but Liu moved fast to commercialize his vision. In 2012, he founded a startup called <a href="http://royole.com/">Royole</a>, and in 2014 the company—under his leadership as CEO—unveiled the world’s thinnest flexible display. Compared with rival technologies that can be curved into a fixed shape but aren’t completely pliable, <a href="http://royole.com/flexible-display">Royole’s displays</a> are as thin as an onion skin and can be rolled tightly around a pen. They can also be fabricated using simpler manufacturing processes, at lower temperatures, which allows Royole to make them at lower cost than competing versions. The company operates its own factory in Shenzhen, China, and is finishing construction on a 1.1-million-square-foot campus nearby. Once complete, the facility will produce 50 million flexible panels a year, says Royole.</p>  <p>Liu dreams of creating an all-in-one computing device that would combine the benefits of a watch, smartphone, tablet, and TV. “I think our flexible displays and sensors will eventually make that possible,” he says. For now, users will have to settle for a <a href="http://royole.com/moon">$799 headset</a> that they can don like goggles to watch movies and video games in 3-D. </p>  <p><em>—Elizabeth Woyke</em></p></td>
    </tr>
    <tr>
      <td>Jianxiong Xiao</td>
      <td>His company AutoX aims to make self-driving cars more accessible.</td>
      <td>33</td>
      <td>AutoX</td>
      <td>entrepreneurs-2017</td>
      <td><p><span class="s1">Jianxiong Xiao aims to make self-driving cars as widely accessible as computers are today. He’s the founder and CEO of AutoX, which recently demonstrated an autonomous car built not with expensive laser sensors but with ordinary webcams and some sophisticated computer-vision algorithms. Remarkably, the vehicle can navigate even at night and in bad weather. </span></p>  <p>AutoX hasn’t revealed details of its software, but Xiao is an expert at using deep learning, an AI technique that lets machines teach themselves to perform difficult tasks such as recognizing pedestrians from different angles and in different lighting.</p>  <p><span class="s1">Growing up without much money in Chaozhou, a city in eastern China, Xiao became mesmerized by books about computers—fantastic-sounding machines that could encode knowledge, logic, and reason. Without access to the real thing, he taught himself to touch-type on a keyboard drawn on paper. </span></p>  <p><span class="s1">The soft-spoken entrepreneur asks people to call him “Professor X” rather than struggle to pronounce his name. He’s published dozens of papers demonstrating clever ways of teaching machines to understand and interact with the world. Last year, Xiao showed how an autonomous car could learn about salient visual features of the real world by contrasting features shown in Google Maps with images from Google Street View. </span></p>  <p><span class="s1"><em>—Will Knight</em></span></p></td>
    </tr>
    <tr>
      <td>Viktor Adalsteinsson</td>
      <td>Working to improve cancer diagnosis and treatment.</td>
      <td>29</td>
      <td>Broad Institute</td>
      <td>visionaries-2017</td>
      <td><p>In his lab at the Broad Institute in Cambridge, Massachusetts, Viktor Adalsteinsson has put an automated system in place that scans blood samples for traces of tumor DNA<em>—</em>a so-called liquid biopsy. Collecting genetic information on advanced cancers might lead to clues about what drives the disease in later stages and what drugs to give patients. Adalsteinsson, whose mother succumbed to breast cancer while he was earning his PhD, is now looking to improve treatment as part of several projects, including one that sends blood collection tubes to women fighting breast cancer across America. “The doctors and patients cross their fingers and there’s a lot of watching and waiting,” says Adalsteinsson. “Now we can closely monitor patients’ responses to therapy and see what’s causing treatments to fail.” <br><br><em>—</em><em>Antonio Regalado</em></p></td>
    </tr>
    <tr>
      <td>Greg Brockman</td>
      <td>Trying to make sure that AI benefits humanity.</td>
      <td>28</td>
      <td>OpenAI</td>
      <td>visionaries-2017</td>
      <td><p>Human-like artificial intelligence is still a long way off, but Greg Brockman believes the time to start thinking about its safety is now. That’s why, after helping to build the online-payments firm Stripe, he cofounded OpenAI along with Elon Musk and others. The nonprofit research group focuses on making sure AI continues to benefit humanity even as it increases in sophistication. Brockman plays many roles at the firm, from recruiting to helping researchers test new learning algorithms. In the long term, he says, a general AI system will need something akin to a sense of shame to prevent it from misbehaving. “It’s going to be the most important technology that humans ever create,” he says, “so getting that right seems pretty important.” <br><br><em>—Mike Orcutt</em></p></td>
    </tr>
    <tr>
      <td>Tracy Chou</td>
      <td>Bringing tech’s dismal diversity numbers out into the open.</td>
      <td>29</td>
      <td>Project Include</td>
      <td>visionaries-2017</td>
      <td><p>Silicon Valley loves data. But until recently, there was one subject where tech companies showed little interest at all in the numbers: the diversity of their workforces. It’s not that the statistics were downplayed—the numbers didn’t even exist.</p>  <p><span class="s1">Today most big tech companies have issued public reports on diversity, and there’s an independent, crowdsourced data repository at GitHub that collects information on tech workforces. And this has happened in no small part because Tracy Chou, a Pinterest software engineer at the time, wrote a post on Medium in the fall of 2013 called simply “Where are the numbers?”</span></p>  <p>Chou wrote the post after returning from a conference where she heard Facebook COO Sheryl Sandberg say the number of women in tech was dropping. “I didn’t think she was wrong,” Chou says. “But I also thought: ‘How does she know? There are no numbers.’ I knew there was this problem.”</p>  <p>Chou’s Medium post quickly went viral. And soon the numbers began to flow—first via Twitter, and then via that GitHub repository, which Chou set up. Within a few weeks, Chou had data on more than 50 companies (the repository now has numbers for hundreds), and by the summer of 2014, a host of the Valley’s most powerful companies had released demographic reports on their workforces. The numbers were dismal—in general, somewhere between 10 and 20 percent of workers in technology positions were women, and one study found that 45 percent of Silicon Valley companies didn’t have a single female executive. But at least the data now existed.</p>  <p><span class="s1">As this was happening, Chou continued her coding work at Pinterest, but she also found herself in demand as a speaker and panelist. Last spring, she teamed up with a group of seven other women—including venture capitalist Ellen Pao and Slack engineer Erica Joy Baker—to form Project Include, an organization designed to help CEOs implement diversity and inclusion strategies at their companies.</span></p>  <p>Chou isn’t, and doesn’t want to be, a professional activist. “It’s fulfilling to work on this issue, and I can have an impact here,” she says. “But I see it as a complement to my main work, which is building things and making products.” Nonetheless, she’s become a voice of authority on tech’s diversity problem because she’s unusually good at articulating the connections between the personal experience of women in the Valley and the systemic sexism they face, while also identifying how a lack of diversity hurts companies themselves. For instance, there is clearly a pipeline problem when it comes to gender and technology—not enough young women take classes in science, technology, engineering, and math or graduate with STEM degrees. But it’s also true, as Chou argues, that the pipeline problem can’t explain the high rate of attrition for women in tech, or the lack of women in senior positions. In other words, the pipeline for women gets even more narrow once you’re inside a company.</p>  <p>Sometimes that’s because of extraordinarily retrograde, garden-variety sexism, exemplified by the recent problems at Uber or the men who regularly told Chou, “You’re too pretty to be a coder.” It’s also because at many companies there’s an implicit (and sometimes explicit) assumption that women are less naturally adept at coding, and less willing to work hard.</p>  <p><span class="s1">Chou, for example, went to Stanford for an undergrad degree in electrical engineering and got a master’s there in computer science, and had internships at Facebook and Google. Yet at her first job she regularly dealt with casually dismissive sexism, making her question whether she belonged in the industry. “I loved coding,” she says. “But I just felt something was off. I felt out of place, and I had serious questions about whether I was going to stay in tech. And I really thought the problem was me.”</span></p>  <p>A large body of research shows that making organizations and teams more diverse also improves their performance. Diversity makes teams less likely to succumb to groupthink and helps companies reach untapped markets. “Products tend to be built to solve the problems of the people building them,” Chou says. “And that’s not a bad thing, necessarily. But it means that in the Valley lots of energy and attention goes into solving the problems of young urban men with lots of disposable income, and that much less attention goes to solving the problems of women, older people, children, and so on.”</p>  <p><span class="s1">Despite the evidence, plenty of companies still need convincing. “There’s lots of diversity theater and lip service paid to the concept,” Chou says. “And maybe we’ve helped weed out some of the most egregious actors. But there’s a long way to go.” <br><br><em>—James Surowiecki</em></span></p></td>
    </tr>
    <tr>
      <td>Anca Dragan</td>
      <td>Ensuring that robots and humans work and play well together.</td>
      <td>30</td>
      <td>UC Berkeley</td>
      <td>visionaries-2017</td>
      <td><p>Anca Dragan, an assistant professor of electrical engineering and computer science at UC Berkeley, is working to distill complicated or vague human behavior into simple mathematical models that robots can understand. She says many conflicts that arise when humans and robots try to work together come from a lack of transparency about each other’s intentions. Teaching a robot to understand how it might influence a person’s behavior could solve that. One pressing application for this work is in helping self-driving cars and human-driven cars to anticipate each other’s next moves. <br><br>—<em>Julia Sklar </em></p></td>
    </tr>
    <tr>
      <td>Adrienne Felt</td>
      <td>Leading the push for a more secure Internet.</td>
      <td>30</td>
      <td>Google Chrome</td>
      <td>visionaries-2017</td>
      <td><p>The next time you open up Google’s Chrome Web browser, take a look at the little green icon that appears in the left corner of the URL bar whenever you’re on a secure website. It’s a lock, and if it’s green it signals that the website you’re on is encrypting data as it flows between you and the site. But not everyone knows what it is or what it represents, and that’s where Adrienne Felt comes in.</p>  <p>As a software engineer for Chrome, Felt has taken on the task of making the Internet more secure and helping users of the world’s most popular browser make smart, informed choices about their safety and privacy while online. This includes heading a years-long push to convince the world’s websites, which traditionally used the unencrypted HTTP to send data from one point to another, to switch to the secure version, HTTPS.&nbsp;</p>  <p><strong>Why is it tricky to come up with online security measures that work for all kinds of people?</strong></p>  <p>Part of it is that security measures generally stop people from doing things. The way we keep you safe is by telling you no. But this has very real costs. You can scare people … you can keep people from using the Internet at all. On the other hand, if you don’t do anything you put people and their data at very real risk. So you have to figure out how to strike just the right balance. And with multiple billion users it’s very difficult to find a balance that makes everyone happy.</p>  <p><strong>One way you are trying to make people safer while they’re online is by encouraging websites to use HTTPS. What makes this a complicated process?</strong></p>  <p>Think about a site like the Washington Post. When you go to the Washington Post’s home page, there’s going to be 100 different [assets from various websites] that are loaded. All of those have to support HTTPS before the Washington Post itself can do it. Sites need to make sure there’s no revenue hit, they need to make sure there’s no [search] ranking hit, they need to make sure there’s no performance hit. And then they can switch. All these things can be done. Sites are transitioning very successfully at scale now. But it is work.</p>  <p><strong>Now that many of the biggest websites have made the switch from HTTP to HTTPS, what are you focusing on?</strong></p>  <p><span class="s1">The long tail is a big problem. There are lots and lots of sites that are out there. Some that are barely maintained, some that are run by your dentist, your hairdresser, a teacher at a local elementary school, and I don’t see them rushing to add support for HTTPS. The question is now, “Okay, we’ve hit all the really popular sites, we’re starting to get to the medium sites—what do we do for the rest of the Internet?” I don’t want to get in a state where oh, great, you’re secure if you go to a big company but not if you go to a small, independent site. Because I still want people to feel like they can go everywhere on the Web. <br><br><em>—Rachel Metz</em></span></p></td>
    </tr>
    <tr>
      <td>Neha Narkhede</td>
      <td>Helping companies make sense of all the data.</td>
      <td>32</td>
      <td>Confluent</td>
      <td>visionaries-2017</td>
      <td><p>The business world is drowning in data, but Neha Narkhede is teaching companies to swim. As an engineer at LinkedIn, Narkhede helped invent an open-source software platform called <a href="https://kafka.apache.org/" target="_blank" rel="noopener noreferrer">Apache Kafka</a> to quickly process the site’s torrent of incoming data from things like user clicks and profile updates. Sensing a big opportunity, she co-founded <a href="https://www.confluent.io/" target="_blank" rel="noopener noreferrer">Confluent</a>, a startup that builds Apache Kafka tools for companies, in 2014. She’s been the driving force behind the platform’s wide adoption—Goldman Sachs uses it to help deliver information to traders in real-time, Netflix to collect data for its video recommendations, and Uber to analyze data for its surge-pricing system. Confluent’s products allow companies to use the platform to, for example, sync information across multiple data centers and monitor activity through a central console.</p>  <p>“We view our technology as a central nervous system for companies that aggregates data and makes sense of it within milliseconds, at scale,” she says. “We think virtually every company would benefit from that and we plan to bring it to them.”<em><br><br>—Elizabeth Woyke</em></p></td>
    </tr>
    <tr>
      <td>Amanda Randles</td>
      <td>Personalized simulations of blood flow in the body.</td>
      <td>34</td>
      <td>Duke University</td>
      <td>visionaries-2017</td>
      <td><p>Amanda Randles, an assistant professor of biomedical engineering at Duke University, is building software that simulates blood flowing throughout the human body in a model based on medical images of a particular person. The code base is called “HARVEY,” after William Harvey, a 17th-century surgeon who first described the circulatory system. The software requires a supercomputer to crunch calculations on the fluid dynamics of millions of blood cells as they move through the blood vessels. Randles has other plans for her fluid-dynamic model of the circulatory system. Next up: scanning newborns with heart problems to guide surgeons and predicting how cancer cells move through the body. <br><br><em>—Antonio Regalado</em></p></td>
    </tr>
    <tr>
      <td>Gang Wang</td>
      <td>At the forefront of turning AI into consumer-ready products.</td>
      <td>34</td>
      <td>Alibaba</td>
      <td>visionaries-2017</td>
      <td><p><span class="s1">Artificial intelligence has reached “a critical point,” says Gang Wang—it’s moved beyond the lab and is now ready for mass-market consumer products. Wang, who joined Alibaba’s AI lab in March, is at the forefront of the push to make AI practical for consumer products, and he’s doing it for one of the world’s most ambitious companies in the world’s biggest consumer market. He was one of the scientists behind the Tmall Genie, Alibaba’s first AI-based product, released in July. Analogous to Amazon’s Echo, the device can make purchases on Alibaba’s shopping sites and perform other tasks, such as playing music and checking calendars through voice commands.</span></p>  <p><span class="s1">“The design of neural networks needs to be intertwined with real-world applications,” says Wang. “Only in this way can we create a product that’s useful in a commercial environment.”<em><br><br>—Yiting Sun</em></span></p></td>
    </tr>
    <tr>
      <td>Eyad Janneh</td>
      <td>Rescuing endangered civilians in Syria, using local materials.</td>
      <td>31</td>
      <td>Field Ready</td>
      <td>humanitarians-2017</td>
      <td><p>In the video, two flat black bags resembling large hot-water bottles expand slowly, gradually lifting a collapsed concrete-and-rebar wall and creating a space between the wall and a mound of rocks beneath. The film shows a test of a design by Eyad Janneh and his team at nonprofit Field Ready that is now being deployed in Syria, where it is used to lift heavy debris during searches for civilians following bomb attacks.</p>  <p>Janneh was raised in Syria but left in 2010 and now works in Istanbul. His team designs and tests tools that can be made locally from available materials. The airbags, for example, are made from a polyester fabric with a rubber sheet cover and some binding accessories<em>—</em>repurposing materials already being used as covers for cargo trucks. In April one of these airbags was used in Syria to help rescue two people trapped in rubble. <br><br><em>—Nanette Byrnes</em></p></td>
    </tr>
    <tr>
      <td>Suchi Saria</td>
      <td>Putting existing medical data to work to predict sepsis risk.</td>
      <td>34</td>
      <td>Johns Hopkins University</td>
      <td>humanitarians-2017</td>
      <td><p><strong>Problem:</strong> Sometimes the difference between life and death is a quick and accurate diagnosis. With sepsis, a life-threatening reaction to an infection, there’s no definitive single test doctors can use to diagnose the condition.&nbsp;</p>  <p><strong>Solution:</strong> Suchi Saria, an assistant professor at Johns Hopkins University, wondered: what if existing medical information could be used to predict which patients would be most at risk for sepsis? Algorithms that she subsequently created to analyze patient data correctly predicted septic shock in 85 percent of cases, by an average of more than a day before onset. That is a 60 percent improvement over existing screening tests.&nbsp;<br><br><em>—Emily Mullin</em></p></td>
    </tr>
    <tr>
      <td>Katherine Taylor</td>
      <td>Her simple water pump could transform the lives of millions of farmers in India.</td>
      <td>28</td>
      <td>Khethworks</td>
      <td>humanitarians-2017</td>
      <td><p><span class="s1">Irrigation shouldn’t be a problem for the 30 million small farms in the water-rich Ganges River basin in eastern India. But today most farmers have to choose between cultivating a single crop each year during the monsoon rains and spending up to 90 percent of their profits to hire diesel or kerosene pumps during the dry seasons to access the plentiful, shallow groundwater.</span></p>  <p><span class="s1">Most plots stay uncultivated; to make up the income, farmers often resort to dangerous and demeaning migratory labor in diamond mines or clothing factories, leaving their families for months at a time.</span></p>  <p><span class="s1">This is what motivated engineer Katherine Taylor to uproot her life in the U.S. and move to India to found Khethworks, which builds an affordable solar-powered irrigation system that lets farmers cultivate year-round.</span></p>  <p><span class="s1">“Sometimes I get asked if I would have wanted a job at a high-tech company instead. But this was never a sacrifice for me, it was always the goal,” says Taylor. “The potential for keeping families together, for having people doing work they feel is dignified—it’s those kinds of stories we want to enable.” </span></p>  <p><span class="s1">Originally, as part of the mechanical engineering master’s program at MIT, Taylor focused on developing low-pressure drip irrigation systems, but during a visit to India, farmers helped her spot the real gap in the market. “They said, look, drip is great, but what we need is an affordable pump,” she says. “Who cares about drip if we can’t afford to irrigate year-round?” </span></p>  <p><span class="s1">In response, she and Khethworks cofounders Victor Lesniewski and Kevin Simon designed a centrifugal pump with triple the efficiency of similar-size pumps. That meant it could be powered by one-third as many photovoltaic panels—by far the most expensive component. This reduces the cost and makes the system portable so farmers can rent it out.</span></p>  <p><span class="s1">Taylor and Lesniewski moved to Pune in 2016 and will ship their first commercial product next spring.</span></p>  <p><span class="s1">Not that it’s been easy. Endless red tape has been frustrating, she says, and they’ve had to adapt to a business culture with a different attitude toward deadlines. “The most important thing is having a good sense of humor,” she says. But Taylor nevertheless believes it’s “absurd” that bigger players haven’t been designing for these farmers.</span></p>  <p><span class="s1">Going after these customers means Taylor and her cofounders haven’t been able to stick to the standard advice for startups to focus on core competencies. It’s likely they’ll have to do everything from engineering to developing distribution models. “You don’t necessarily have the luxury of doing exactly what you think you’re best at,” says Taylor.&nbsp;</span></p>  <p><span class="s1">—<em>Edd Gent</em></span></p></td>
    </tr>
    <tr>
      <td>Jessica Brillhart</td>
      <td>A pioneer in virtual-reality filmmaking.</td>
      <td>33</td>
      <td>Independent filmmaker</td>
      <td>pioneers-2017</td>
      <td><p>Traditional filmmaking techniques often don’t work in virtual reality. So for the past few years, first as the principal filmmaker for virtual reality at Google and now as an independent filmmaker, Jessica Brillhart has been defining what will.</p>  <p>Brillhart recognized early on that in VR, the director’s vision is no longer paramount. A viewer won’t always focus where a filmmaker expects. Brillhart embraces these “acts of visitor rebellion” and says they push her to be “bold and audacious in ways I would never have been otherwise.” She adds: “I love how a frame is no longer the central concept in my work. I can build worlds.” <br><br><em>—Caleb Garling</em></p></td>
    </tr>
    <tr>
      <td>Joshua Browder</td>
      <td>Using chatbots to help people avoid legal fees.</td>
      <td>20</td>
      <td>DoNotPay</td>
      <td>pioneers-2017</td>
      <td><p><span class="s1">Joshua Browder is determined to upend the $200 billion legal services market with, of all things, chatbots. He thinks chatbots can automate many of the tasks that lawyers have no business charging a high hourly rate to complete.</span></p>  <p><span class="s1">“It should never be a hassle to engage in a legal process, and it should never be a question of who can afford to pay,” says Browder. “It should be a question of what’s the right outcome, of getting justice.”</span></p>  <p><span class="s1">Browder started out small in 2015, creating a simple tool called DoNotPay to help people contest parking tickets. He came up with the idea after successfully contesting many of his own tickets, and friends urged him to create an app so they could benefit from his approach. </span></p>  <p><span class="s1">Browder’s basic “robot lawyer” asks for a few bits of information—which state the ticket was issued in, and on what date—and uses it to generate a form letter asking that the charges be dropped. So far, 375,000 people have avoided about $9.7 million in penalties, he says.</span></p>  <p><span class="s1">In early July, DoNotPay expanded its portfolio to include 1,000 other relatively discrete legal tasks, such as lodging a workplace discrimination complaint or canceling an online marketing trial. A few days later, it introduced open-source tools that others—including lawyers with no coding experience—could use to create their own chatbots. Warren Agin, an adjunct law professor at Boston College, created one that people who have declared bankruptcy can use to fend off creditors. “Debtors have a lot of legal tools available to them, but they don’t know it,” he says.</span></p>  <p><span class="s1">Browder has more sweeping plans. He wants to automate, or at least simplify, famously painful legal processes such as applying for political asylum or getting a divorce. </span></p>  <p><span class="s1">But huge challenges remain. Browder is likely to run into obstacles laid down by lawyers intent on maximizing their billable hours, and by consumers wary of relying too heavily on algorithms rather than flesh-and-blood lawyers. <br><em>—Peter Burrows</em></span></p></td>
    </tr>
    <tr>
      <td>Phillipa Gill</td>
      <td>An empirical method for measuring Internet censorship.</td>
      <td>32</td>
      <td>University of Massachusetts, Amherst</td>
      <td>pioneers-2017</td>
      <td><p>Five years ago, when Phillipa Gill began a research fellowship at the University of Toronto’s Citizen Lab, she was surprised to find that there was no real accepted approach for empirically measuring censorship. So Gill, now an assistant professor of computer science at the University of Massachusetts, Amherst,&nbsp; built a set of new measurement tools to detect and quantify such practices. One technique automatically detects so-called block pages, which tell a user if a site has been blocked by a government or some other entity. In 2015, Gill and colleagues used her methods to confirm that a state-owned ISP in Yemen was using a traffic-filtering device to block political content during an armed conflict. <br><br><em>—Mike Orcutt</em></p></td>
    </tr>
    <tr>
      <td>Fabian Menges</td>
      <td>A method for measuring temperatures at the nanoscale.</td>
      <td>32</td>
      <td>IBM Research in Zurich</td>
      <td>pioneers-2017</td>
      <td><p><strong>Problem: </strong>Complex microprocessors<em>—</em>like those at the heart of autonomous driving and artificial intelligence<em>—</em>can overheat and shut down. And when it happens, it’s usually the fault of an internal component on the scale of nanometers. But for decades, nobody who designed chips could figure out a way to measure temperatures down to the scale of such minuscule parts.</p>  <p><strong>Solution:</strong> Fabian Menges, a researcher at IBM Research in Zurich, Switzerland, has invented a scanning probe method that measures changes to thermal resistance and variations in the rate at which heat flows through a surface. From this he can determine the temperature of structures smaller than 10 nanometers. This will let chipmakers come up with designs that are better at dissipating heat. <br><br><em>—Russ Juskalian</em></p></td>
    </tr>
    <tr>
      <td>Volodymyr Mnih</td>
      <td>The first system to play Atari games as well as a human can.</td>
      <td>34</td>
      <td>DeepMind</td>
      <td>pioneers-2017</td>
      <td><p>Volodymyr Mnih, a research scientist at DeepMind, has created the first system to demonstrate human-level performance in almost 50 Atari 2600 video games, including Pong and Space Invaders. Minh’s system was the first to combine the playful characteristics of reinforcement learning with the rigorous approach of deep learning, which mirrors the way&nbsp; the human brain processes information—learning by example. His software learned to play the games much as a human would, through playful trial and error, while using the game score as a measurement by which to hone and perfect its technique for each game. <br><br><em>—Simon Parkin</em></p></td>
    </tr>
    <tr>
      <td>Austin Russell</td>
      <td>Better sensors for safer automated driving.</td>
      <td>22</td>
      <td>Luminar</td>
      <td>pioneers-2017</td>
      <td><p>Most driverless cars use laser sensors, or lidar, to map surroundings in 3-D and spot obstacles. But some cheap new sensors may not be accurate enough for high-speed use. “They’re more suited to a Roomba,” says Austin ­Russell, who dropped out of Stanford and set up his own lidar company, Luminar. “My biggest fear is that people will prematurely deploy autonomous cars that are unsafe.”</p>  <p><a href="https://www.technologyreview.com/s/604136/college-dropout-says-hes-cracked-self-driving-cars-most-crucial-component/" target="_blank" rel="noopener noreferrer">Luminar’s device</a> uses longer-wavelength light than other sensors, allowing it to spot dark objects twice as far out. At 70 miles per hour, that’s three extra seconds of warning. <br><br><em>—Jamie Condliffe</em></p></td>
    </tr>
    <tr>
      <td>Angela Schoellig</td>
      <td>Her algorithms are helping self-driving and self-flying vehicles get around more safely.</td>
      <td>34</td>
      <td>University of Toronto</td>
      <td>pioneers-2017</td>
      <td><p>Safety never used to be much of a concern with machine-learning systems. Any goof made in image labeling or speech recognition might be annoying, but it wouldn’t put anybody’s life at risk. But autonomous cars, drones, and manufacturing robots have raised the stakes.</p>  <p>Angela Schoellig, who leads the Dynamic Systems Lab at the University of Toronto, has developed learning algorithms that allow robots to learn together and from each other in order to ensure that, for example, a flying robot never crashes into a wall while navigating an unknown place, or that a self-driving vehicle never leaves its lane when driving in a new city. Her work has demonstrably extended the capabilities of today’s robots, enabling self-flying and self-driving vehicles to fly or drive along a predefined path despite uncertainties such as wind, changing payloads, or unknown road conditions.</p>  <p><span class="s1">As a PhD student at the Swiss Federal Institute of Technology in Zurich, Schoellig worked with others to develop the Flying Machine Arena, a 10-cubic-meter space for training drones to fly together in an enclosed area. In 2010, she created a performance in which a fleet of UAVs flew synchronously to music. The “dancing quadrocopter” project, as it became known, used algorithms that allowed the drones to adapt their movements to match the music’s tempo and character and coordinate to avoid collision, without the need for researchers to manually control their flight paths. Her setup decoupled two essential, usually intertwined components of autonomous systems—perception and action—by placing, at the center of the space, a high-precision overhead motion-capture system that can perfectly locate multiple objects at rates exceeding 200 frames per second. This external system enabled the team to concentrate resources on the vehicle-control algorithms. </span></p>  <p><span class="s1"><em>—Simon </em></span><em>Parkin</em></p></td>
    </tr>
    <tr>
      <td>Jenna Wiens</td>
      <td>Her computational models identify patients who are most at risk of a deadly infection.</td>
      <td>31</td>
      <td>University of Michigan</td>
      <td>pioneers-2017</td>
      <td><p>A sizable percentage of hospital patients end up with an infection they didn’t have when they arrived.</p>  <p><span class="s1">Among the most lethal of these is <em>Clostridium difficile</em>. The bacterium, which spreads easily in hospitals and other health-care facilities, was the source of almost half a million infections among patients in the United States in a single year, according to a 2015 report by the Centers for Disease Control and Prevention. Fifteen thousand deaths were directly attributable to the bug.</span></p>  <p>Jenna Wiens, an assistant professor of computer science and engineering at the University of Michigan, thinks hospitals could learn to prevent many infections and deaths by taking advantage of the vast amounts of data they already collect about their patients.</p>  <p>“I think to really get all of the value we can out of the data we are collecting, it’s necessary to be taking a machine-learning and a data-mining approach,” <br> she says.</p>  <p><span class="s1">Wiens has developed computational models that use algorithms to search through the data contained in a hospital’s electronic health records system, including patients’ medication prescriptions, their lab results, and the records of procedures that they’ve undergone. The models then tease out the specific risk factors for <em>C. difficile</em> at that hospital.</span></p>  <p><span class="s1">“A traditional approach would start with a small number of variables that we believe are risk factors and make a model based on those risk factors. Our approach essentially throws everything in that’s available,” Wiens says. It can readily be adapted to different types of data. </span></p>  <p>Aside from using this information to treat patients earlier or prevent infections altogether, Wiens says, her model could be used to help researchers carry out clinical trials for new treatments, like novel antibiotics. Such studies have been difficult to do in the past for hospital-acquired infections like <em>C. difficile</em>—the infections come on fast so there’s little time to enroll a patient in a trial. But by using Wiens’s model, researchers could identify patients most vulnerable to infections and study the proposed intervention based on that risk.</p>  <p><span class="s1">At a time when health-care costs are rising exponentially, it’s hard to imagine hospitals wanting to spend more money on new machine-learning approaches. But Wiens is hopeful that hospitals will see the value in hiring data scientists to do what she’s doing. </span></p>  <p><span class="s1">“I think there is a bigger cost to not using the data,” she says. “Patients are dying when they seek medical care and they acquire one of these infections. If we can prevent those, the savings are priceless.”<br></span></p>  <p><span class="s1"><em>—Emily Mullin</em></span></p></td>
    </tr>
    <tr>
      <td>Hanqing Wu</td>
      <td>A cheaper solution for devastating hacking attacks.</td>
      <td>32</td>
      <td>Alibaba Cloud</td>
      <td>pioneers-2017</td>
      <td><p>During a distributed denial of service (DDoS) attack, an attacker overwhelms a domain-name server with traffic until it collapses. The traditional way of fending off an attack like this is to pile up bandwidth so the server under attack always has more than enough volume to handle what the attacker has released. But as hackers become capable of attacks with bigger and bigger data volumes, this is no longer feasible.</p>  <p>Since the target of DDoS attacks is a website’s IP address, Hanqing Wu, the chief security scientist at Alibaba Cloud, devised a defense mechanism through which one Web address can be translated into thousands of IP addresses. This “elastic security network” can quickly divert all benign traffic to a new IP address in the face of a DDoS attack. And by eliminating the need to pile up bandwidth, this system would greatly reduce the cost of keeping the Internet safe. <br><br><em>—Yiting Sun</em></p></td>
    </tr>
    <tr>
      <td>Muyinatu Bell</td>
      <td>Creating clearer imaging to spot cancer earlier and more accurately.</td>
      <td>32</td>
      <td>Johns Hopkins University</td>
      <td>inventors-2016</td>
      <td><p>When biomedical engineer Muyinatu Lediju Bell was an undergraduate at MIT, her mother died of breast cancer. Bell thought her mother might have survived if she had been diagnosed sooner, so she decided to investigate what makes some ultrasound images blurry, a problem that limits a doctor’s ability to screen for and diagnose cancer and other diseases.</p>  <p>As a doctoral candidate at Duke University, Bell developed and patented a novel signal processing technique that produces clearer ultrasound images in real time. The solution could particularly help diagnose problems in people who are obese, because fat tissue can scatter and distort ultrasound waves, delaying the detection of a serious disease. “I think it’s unfair that a long-standing technology does not serve a huge group of people that should be able to benefit from it,” she says.</p>  <p>Beyond ultrasound, Bell is now working to improve another type of noninvasive medical imaging technique. Called photoacoustic imaging, it uses a combination of light and sound to produce images of tissues in the body. She is especially interested in using it for real-time visualization of blood vessels during neurosurgeries to lower the risk of accidental harm to the carotid artery, which supplies blood to the brain. Her lab at Johns Hopkins plans to launch a pilot study of the technology in patients in 2017.</p>  <p><em>—Emily Mullin</em></p></td>
    </tr>
    <tr>
      <td>Dinesh Bharadia</td>
      <td>A seemingly impossible radio design will double wireless data capabilities.</td>
      <td>28</td>
      <td>MIT Computer Science and Artificial Intelligence Laboratory</td>
      <td>inventors-2016</td>
      <td><p>Dinesh Bharadia invented a telecommunications technology that everyone said would never work: he found a way to simultaneously transmit and receive data on the same frequency.</p>  <p>Because the signal from broadcasting a radio transmission can be 100 billion times louder than the receiving one, it was always assumed that outgoing signals would invariably drown out incoming ones. That’s why radios typically send and receive on different frequencies or rapidly alternate between transmitting and receiving. “Even textbooks kind of assumed it was impossible,” Bharadia says.</p>  <p>Bharadia developed hardware and software that selectively cancel the far louder outgoing transmission so that a radio can decipher the incoming message. The creation of the first full-duplex radio, which eventually could be incorporated into cell phones, should effectively double available wireless bandwidth by simply using it twice. That would be a godsend for telecom companies and consumers alike.</p>  <p>Bharadia took a leave of absence from his PhD studies at Stanford so he could commercialize the radio through the startup Kumu Networks. Germany-based Deutsche Telekom began testing it last year, but since Bharadia’s prototype circuit board is too large to fit in a phone, it will be up to other engineers to miniaturize it.</p>  <p><em>—Ryan Cross</em></p></td>
    </tr>
    <tr>
      <td>Adam Bry</td>
      <td>Building drones that can navigate the world and serve as airborne assistants.</td>
      <td>27</td>
      <td>Skydio</td>
      <td>inventors-2016</td>
      <td><p>“At the company I cofounded, ­Skydio, we looked at all the things people wanted to do with drones and realized that the products are primitive compared to what’s possible. Today the typical consumer experience is you take it out of the box and run it into a tree.</p>  <p><span class="s1">“We’re building a drone for consumers that understands the physical world, reacts to you intelligently, and can use that information to make decisions. It has cameras positioned in a way so that computer vision can track its motion and understand the 3-D structure of the world. It also understands ‘This is a person,’ ‘This is a tree.’ We’ve demonstrated the ability to fly autonomously in close proximity to obstacles such as trees safely and reliably, and to follow someone walking, running, or cycling. </span></p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/adam2x1000.jpg" alt=""><figcaption>Building drones that can navigate the world and serve as airborne assistants.</figcaption></figure>\n <p>“On a week-to-week basis you can see the thing getting smarter and being capable of more. It shows up in the way it behaves and responds in different situations.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/files/adam.bry.final-copy.mp4" alt=""><figcaption></figcaption></figure>\n <p>“We aren’t saying a lot about our product yet, but it’ll be a high-end consumer device smart enough to fly itself as well as or better than an expert pilot. Devices that understand the world and can respond to you and take actions will open up things that don’t exist today. A flying camera that can be anywhere around you would be a very powerful thing. Drones are likely to be the first widely deployed category of mobile robot. As they start to get out into the world and people start to interact with them, it’s going to lead to some interesting places.”</p>  <p><em>—as told to Tom Simonite</em></p></td>
    </tr>
    <tr>
      <td>Wei Gao</td>
      <td>The engineer has built sweatbands that monitor your health.</td>
      <td>31</td>
      <td>University of California, Berkeley</td>
      <td>inventors-2016</td>
      <td><p>“I grew up in a small village in Xuzhou, China. When I was a child I saw a lot of people around me dying of different diseases. Many people don’t realize there’s a problem until it’s too late. I thought, in the future I should design a wearable electronic device to monitor health and tell us what’s going on and what’s going wrong before it gets bad.</p>  <p>“Our body is generating data all the time. There are so many wearable devices now—the Apple watch, the Fitbit—but they mainly track physical activities or vital signs. They can’t provide information at the molecular level.</p>  <p>“It came into my mind: what about sweat?”</p>  <p>This year, Gao made a sweatband that combines sensors with electronic processors and a Bluetooth transmitter on a flexible printed circuit board. If you wear the band, it wirelessly transmits data about what’s in your sweat to a cell phone running an app.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/wei1x2000.jpg" alt=""><figcaption></figcaption></figure>\n<figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/wei2x1100.jpg" alt=""></p>\n<figcaption>Gao wears his sweatband that uses sensors on a flexible circuit board.</figcaption></figure>\n<figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/wei3x1100.jpg" alt=""></p>\n<figcaption></figcaption></figure>\n <p>Gao’s device has sensors that interact with chemicals including glucose and lactate, causing a detectable change in their electrical current. Other sensors change their voltage in response to sodium or potassium. A recent addition includes sensors that can pick up on toxic heavy metals excreted in the sweat.</p>  <p>The challenge now is to figure out whether and how these measurements correspond to meaningful changes in health. So Gao is working with exercise physiologists on clinical studies to look for correlations that will help spot signs of trouble before it’s too late.</p>  <p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Jiawei Gu</td>
      <td>The AI expert designs interfaces that let technology assist rather than annoy.</td>
      <td>30</td>
      <td>Baidu</td>
      <td>inventors-2016</td>
      <td><p><span class="s1">When we meet at a café in Beijing’s 798 Art District, a creative hub in China’s capital, Jiawei Gu has turned off the notification pings from Tencent’s WeChat, China’s ubiquitous messaging app, on his smartphone. When he glances quickly to check the screen, he has “more than 17,000 unread messages.” The way we interact with information technology is broken, he says. “I don’t want to be captive for checking buzzes,” Gu says. </span></p>  <p><span class="s1">Gu is Baidu’s go-to engineer for designing better models of “human-computer interaction.” One example, DuLight, is an AI interface that helps blind or vision-impaired people. A camera mounted on a headset or a user’s phone can scan bills, train schedules, labels on boxes, or just about anything; the objects or words are then identified, using deep—learning algorithms and the processor on a mobile phone, and translated into speech that the user hears through an earpiece. “The facial recognition function is also getting really good,” says Gu. </span></p>  <p><span class="s1">Gu’s vision of the future is one in which people can enjoy the benefits of technology without being captive to cords and notification buzzes. “I want to bring humans back to an unplugged age,” he says. </span></p>  <p><span class="s1">—<em>Christina Larson</em></span></p></td>
    </tr>
    <tr>
      <td>Alex Hegyi</td>
      <td>A new type of camera could let smartphones find counterfeit drugs or spot the ripest peach.</td>
      <td>29</td>
      <td>PARC</td>
      <td>inventors-2016</td>
      <td><p>No matter how good your smartphone camera is, it can show you only a fraction of the detail Alex Hegyi can with the one he’s built at Xerox’s PARC in Palo Alto, California. That’s because Hegyi’s camera also records parts of the spectrum of light that you can’t see.</p>  <p>Since Hegyi’s camera logs a wider range of wavelengths, it can be used for everything from checking produce at the grocery store (fruits increasingly absorb certain wavelengths as they ripen) to spotting counterfeit drugs (the real ones reflect a distinctive pattern). In the near future, Hegyi hopes, his technology can be added to smartphone cameras, so anyone can make and use apps that harness so-called hyperspectral imaging.</p>  <p>Such systems have been around for years, but they have been big and expensive, limiting them to non-consumer applications like surveillance and quality control for food and drugs. His version, which is much simpler and more compact, relies on a black-and-white USB camera. He adds a liquid crystal cell, set between polarizing filters, in front of its image sensor. He also created software, which he runs on a connected tablet computer, to process the images.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/alex2x1200_0.jpg" alt=""><figcaption>Hegyi’s camera records parts of the spectrum that you can’t see.</figcaption></figure>\n<figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/alex3x700_0.jpg" alt=""></p>\n<figcaption>Hegyi’s prototype is a modified USB camera. Software lets him look at images in a new light, revealing novel details.</figcaption></figure>\n <p>Three to five years from now, Hegyi thinks, your phone could be revealing information that isn’t available in the visible spectrum of light. With such a tool, he says, “consumers themselves don’t have to know anything about wavelengths—they can take a picture and the display can say ‘counterfeit’ or ‘real.’” Or it might say the peach is ripe.</p>  <p>—<em>Rachel Metz</em></p></td>
    </tr>
    <tr>
      <td>Kendra Kuhl</td>
      <td>She developed a simple reactor to turn carbon dioxide into useful chemicals.</td>
      <td>34</td>
      <td>Opus 12</td>
      <td>inventors-2016</td>
      <td><p>Growing up in rural Montana, Kendra Kuhl watched the namesake ice formations of nearby Glacier National Park shrink. “We could see global warming happening,” she says. The sight drove her professional ambitions. “I liked the idea of putting atoms together in new ways that are potentially friendly to the environment,” she says.</p>  <p>That’s just what Kuhl hopes to do through the startup she cofounded in 2014. Opus 12 is working on a reactor that will take the carbon dioxide emitted by power plants and make useful chemicals from it.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/kendra2x1200.jpg" alt=""><figcaption>Kendra Kuhl’s reactor uses novel catalytic nanoparticles (black square in these two photos).</figcaption></figure>\n<figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/kendra3x1200.jpg" alt=""></p>\n<figcaption></figcaption></figure>\n<figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/kendra5x1200.jpg" alt=""></p>\n<figcaption>The reactor has inputs for carbon dioxide and outputs for the chemicals.</figcaption></figure>\n <p>At Cyclotron Road, a startup incubator at the Lawrence Berkeley National Laboratory, Kuhl shows off one of Opus 12’s prototypes, a small reactor with an input for carbon dioxide and an output spigot connected to an instrument that analyzes the products. The key to the technology is the design of the reactor, which incorporates a family of catalysts she collaborated on during her graduate work at Stanford University. Sandwiched inside the metal reactor chamber is an electrode that uses a membrane coated with the catalysts. They enable the carbon reactions to occur at low temperature and pressure, without requiring large amounts of energy.</p>  <p>Opus 12 is not the first company to work on converting carbon dioxide into widely used chemicals. But its improved catalysts and scalable reactor design set the company apart, says Kuhl. Still, the company has far to go before it can begin competing with traditional chemical suppliers. By the end of 2017, Opus 12 plans to build a reactor with a stack of electrodes that can produce several kilograms of product a day. <br><br><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Desmond Loke</td>
      <td>Throw away your RAM and flash drive. Here’s a better type of memory.</td>
      <td>33</td>
      <td>Singapore University of Technology and Design</td>
      <td>inventors-2016</td>
      <td><p><span class="s1">Computer designers have long desired a universal memory technology to replace the combination of RAM—which is fast but expensive and volatile, meaning it requires a power supply to retain stored information—and flash, which is nonvolatile but relatively slow. </span></p>  <p>The urgency is increasing as Moore’s Law, which for so long governed the blistering pace at which silicon transistors shrank, begins to peter out. If we can’t fit many more transistors on a RAM chip, we need to find a fast, cheap new nonvolatile memory technology that can store vast amounts of data.</p>  <p>One promising alternative to the combination of RAM and flash is phase-change materials. This new type of memory stores data not by turning electric current on and off in transistors but by switching a type of material called chalcogenide glass between amorphous and crystalline states. Potentially, it is fast like RAM and nonvolatile like flash. Since 2010, Desmond Loke and his colleagues have solved several critical problems holding up its commercialization.</p>  <p><span class="s1">As a result of the advances, the Singapore researcher has now created a version of phase-change memory that is as fast as RAM chips and packs in many times more storage capacity than flash drives. </span></p>  <p><span class="s1">For years, researchers have been unable to get the speed at which a material changes from an orderly crystal to amorphous glass—the <em>1</em> and <em>0</em> states—any faster than about 50 nanoseconds, whereas RAM chips take less than a nanosecond to switch transistors on or off. But by applying a small, constant charge to the material, Loke found he could reduce switching time to half a nanosecond. He and his coworkers also reduced the size of a memory-cell bit to just a few nanometers. And he figured out how to vastly reduce power consumption and allow cells to be stacked in three dimensions to pack in even more memory capacity. </span></p>  <p><span class="s1">—<em>Michael Reilly</em></span></p></td>
    </tr>
    <tr>
      <td>Evan Macosko</td>
      <td>A breakthrough in probing how cells create complex tissues and organs.</td>
      <td>34</td>
      <td>Harvard Medical School</td>
      <td>inventors-2016</td>
      <td><p><strong>Problem</strong></p>  <p>To truly understand the human genome, we need better insight into how individual cells differ. While every cell in a person’s body has basically the same DNA blueprint, there’s great variation in the way that genetic information is actually acted on, or expressed, at any given time. It’s the reason one cell becomes a neuron that plays a role in memory, while another cell becomes part of a person’s toenail. Even a given organ, like the brain, encompasses different types of cells, and individual cell types, too, have variations. Inadequate knowledge about how genes are expressed in different cells is greatly hampering progress in genomic medicine.</p>  <p><strong>Solution</strong></p>  <p>Evan Macosko has helped invent a technology called Drop-Seq, which allows a researcher to look at thousands of cells, one by one, to determine how each is carrying out its genetic instructions. Such analysis of a single cell can be done with existing tools, but it is typically painstaking, expensive work that involves dropping individual cells into tiny wells. “If you get two cells in a well, you’re screwed,” says Macosko.</p>  <p>To greatly speed up the process, Macosko figured out how to take each cell he wanted to analyze, break it apart, and attach the expressed genes to a tiny bar-coded bead. Once material from each cell is labeled, the genes can be analyzed rapidly<em>—</em>all for a cost of just seven cents a cell.</p>  <p>Macosko says he and his team have nearly finished profiling hundreds of thousands of cells spanning most of the mouse brain. Next stop: the 86 billion neurons and innumerable other cells that make up the human brain. By analyzing the great variation in the cells in our brains, he hopes to identify the rogue cells that are malfunctioning or interfering with normal function in disorders like schizophrenia, autism, and Alzheimer’s.</p>  <p><em>—Michael Reilly</em></p></td>
    </tr>
    <tr>
      <td>Heather Bowerman</td>
      <td>Cheap hormone tests could begin to address gender disparities in health care.</td>
      <td>31</td>
      <td>Dot Laboratories</td>
      <td>entrepreneurs-2016</td>
      <td><p><strong>Problem</strong></p>  <p>“There are significant differences in the ways that men and women experience many diseases and drugs, and until this problem is solved, women will be forced to make do with therapies that may be of limited benefit,” says Heather Bowerman.</p>  <p>For example, hormones cause plaque to form differently in the arteries of men and women. Yet drugs to treat cardiovascular&nbsp;disease are tested disproportionately on men, and as one consequence, their death rates from that illness are declining faster than women’s. Detailed hormonal data could help doctors tailor drugs and treatment regimens so that they work better for women.<span class="Apple-converted-space">&nbsp; &nbsp;</span></p>  <p><strong>Solution</strong></p>  <p>Bowerman is CEO of a startup, Dot Laboratories, that is developing a cheap and easy way to test female sex hormone levels and track them online. A patient spits into a tube at specific times and mails the tubes to Dot Laboratories. The company then delivers data on hormone levels in an app for the woman or her doctor to review. It’s still in a beta test; the company plans to publish data on the efficacy of its methods and release the diagnostic product in 2017.</p>  <p>Developing more drugs that take hormonal changes into account will take time. Even so, Anula Jayasuriya, a doctor who invests in life sciences companies, says such tests will help end the “sex bias in basic research and clinical medicine.”</p>  <p><em>—David Talbot</em></p></td>
    </tr>
    <tr>
      <td>Kelly Gardner</td>
      <td>This bioengineer figured out how to handle a key challenge facing biotech startups.</td>
      <td>31</td>
      <td>Zephyrus Biosciences</td>
      <td>entrepreneurs-2016</td>
      <td><p><strong>Your company makes a test that can measure protein levels in single cells. Why is this important?</strong></p>  <p>Proteins are the functional molecules of the cell. Measuring them is vital to understanding and targeting disease. But they’re much more challenging to measure than DNA because they can’t be amplified—you have to measure the molecules that are actually in the cell.</p>  <p>Measuring proteins in single cells could help us understand a tumor. Are all the cells in a tumor going to be targeted by a drug, or do some of them lack the drug target? Which cells will metastasize?</p>  <p><strong>Who uses your test?</strong></p>  <p>Right now we’re focused on the research market. Before we started our product development, we interviewed over 100 biomedical researchers to find out what applications people were interested in, and designed our hardware to meet that need.</p>  <p><strong>You say you followed the “lean startup” model, which comes from the software industry. Why did you adopt it?</strong></p>  <p>You see a lot of academic publications that are innovative, but they never make it out of the lab. One barrier is the willingness of investors to fund early-stage biotech companies. Life sciences startups can be incredibly expensive. We did it with only $1.8 million in private and public funding and seven employees. We were acquired by ProteinSimple [a division of a public company called Bio-Techne] this spring, after two and a half years.</p>  <p><strong>Are you already antsy to start another company?</strong></p>  <p>I’m an entrepreneur at heart, and in the Bay Area it’s hard not to be distracted by shiny things. But it’s important for me to make sure this technology is successful. </p>  <p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Meron Gribetz</td>
      <td>An augmented-reality dreamer tries to turn his vision into a business.</td>
      <td>30</td>
      <td>Meta</td>
      <td>entrepreneurs-2016</td>
      <td><p>Meron Gribetz has a hard time sitting down when he’s talking about his augmented-reality startup, Meta. Grinning, he stands or paces as he explains that he had always wanted to create a way to bring digital information into the real world to make it easier to absorb. Then in 2011, sunlight shimmering through an airplane window hit the lens of his sunglasses and made him realize how he would do it.</p>  <p>Since then, he’s managed to raise $73 million in funding to go up against rivals like Microsoft and its HoloLens device. Why the excitement?</p>  <p>This year, Gribetz unveiled the company’s latest headset, the Meta 2, which sells for less than a third of what the HoloLens headset is going for. It lets you do things like grab and prod 3-D imagery with your hands, or conduct a video call with another Meta user, who can hand you a virtual object that you can then inspect from any angle.</p>  <p>Both the Meta and the HoloLens are aimed at software developers, who will have to come up with applications. But Gribetz, who was raised in Israel by American parents, is aggressively optimistic about the technology because he thinks it will let us ditch devices like laptops, smartphones, and tablets for one super-mobile package. Within five years, he imagines, AR headsets will be reduced to a strip of glass over your eyes that’s “nearly invisible.”</p>  <p>Meta is building software meant to be more intuitive to navigate than windows and icons. Gribetz believes so deeply in AR’s promise, in fact, that he’s pushing his own employees to stop using computer monitors and mouses with their laptops by next spring; instead, the company will rely on Meta 2 and its hand-tracking capabilities to help them get their work done.</p>  <p>—<em>Rachel Metz</em></p></td>
    </tr>
    <tr>
      <td>Christine Ho</td>
      <td>Her startup is commercializing thin, flexible, printable batteries that she developed at UC Berkeley.</td>
      <td>33</td>
      <td>Imprint Energy</td>
      <td>entrepreneurs-2016</td>
      <td><p><strong>You say we’ll want Imprint Energy’s zinc batteries for wearable electronics, health-monitoring patches, and small sensors. Why can’t we put existing batteries into such devices?</strong></p>  <p>A lot of these batteries need a lot of plastic housing or metal housing. They need protective circuitry. Because you’re doing everything you can to tame a very, very wild and reactive system. What’s interesting about Imprint’s approach is we’re using an inherently more stable chemistry that doesn’t need that hermetic sealing. [That results in] the packaging being much more simplistic and thinner. What’s nice about zinc batteries is the materials are really cost-effective and easy to acquire. They’re also nontoxic.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/christine2x1000.jpg" alt=""><figcaption>Ho says devices using Imprint Energy’s batteries could appear by 2018. The company is working with manufacturers<br />\n­to screen-print batteries on sheets like this one.</figcaption></figure>\n <p><strong>Why isn’t zinc already widely used to power electronics?</strong></p>  <p>There’s usually a very nasty corrosive electrolyte used [with it]. Especially for on-body applications, you don’t want to put in something nasty like that. The other thing is, zinc is not traditionally a rechargeable system.</p>  <p><strong>How did you get around those issues?&nbsp;</strong></p>  <p>Batteries are stacked; they look like a stacked sandwich. The middle layer, like the jelly in the jelly sandwich, is called the electrolyte. What I realized was that if we eliminated that and replaced it with something that is stable with the zinc system and rechargeable, we could open up a whole new market space. I looked at lots of different materials, literally throwing everything in a bucket and hoping that it worked. We started to get some really interesting results with one of these material sets we were looking at. We could basically take this material and cast it into a solid film. So you could cut it, you could stretch it and whatnot, but inside it had ions that moved.</p>  <p><em>—Rachel Metz</em></p></td>
    </tr>
    <tr>
      <td>Samay Kohli</td>
      <td>After greasing the wheels of India’s e-commerce boom, this executive eyes overseas expansion.</td>
      <td>30</td>
      <td>GreyOrange</td>
      <td>entrepreneurs-2016</td>
      <td><p>Homegrown e-commerce companies in India are slashing prices and delivery times as they battle to serve the country’s burgeoning middle class. Many of these companies are able to do it because of warehouse automation technologies developed by Samay Kohli and his team at the robotics firm GreyOrange.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/samay2x1400.jpg" alt=""><figcaption>Two of GreyOrange’s Butler robots, which are designed to be warehouse workhorses.</figcaption></figure>\n <p>GreyOrange sells swarms of “Butler” robots, which store products and bring shelves to human workers, and “Sorters,” which automatically scan and sort packages of any size or shape. The company boasts 92 percent of India’s warehouse automation market, a sector that Kohli thinks “can become humongous.”</p>  <p>With offices in Hong Kong and Singapore, the company isn’t content serving India alone. It plans to expand into the Middle East and China this year, and within two years Kohli expects to be exporting warehouse robots to Europe. He hopes to get a first-mover advantage over other robotics startups chasing the same opportunity—one that became even larger after Amazon bought the warehouse automation company Kiva Systems in 2012 and brought its technology in house rather than selling it to Amazon’s e-commerce rivals.</p>  <p>Kohli and his cofounder Akash Gupta launched the company in 2011, after developing, while in college, what they believe to be India’s first humanoid robot. Seeing China’s e-commerce boom, they spotted “an industry ripe for disruption,” says Kohli.</p>  <p>—<em>Edd Gent</em></p></td>
    </tr>
    <tr>
      <td>Stephanie Lampkin</td>
      <td>She sees a way to make Silicon Valley’s workforce look more like the rest of society.</td>
      <td>31</td>
      <td>Blendoor</td>
      <td>entrepreneurs-2016</td>
      <td><p>When Stephanie Lampkin applied for an analytics job at a major tech company, she was offered a position in sales instead. To her, this was evidence of bias; she had a degree in management science and engineering from Stanford and had held other engineering positions. Whether or not her race or gender played a role (she is African-American), there’s evidence that recruiters often make initial judgments that have little to do with qualifications. A&nbsp;<a href="http://ces.univ-paris1.fr/membre/jacquemet/HomophilyWP.pdf" target="_blank" rel="noopener noreferrer">2014 study</a>&nbsp;concluded that a foreign-sounding name on a résumé could hurt the applicant’s chances of even getting an interview.</p>  <p>So Lampkin declined the sales job and sat down to code Blendoor, a job-search platform that hides the candidates’ names and photos during the initial stages of the process. So far more than 5,000 people have signed up, and the platform is being used by recruiters at Twitter, Airbnb, Facebook, Google, Microsoft, and Intel.&nbsp;</p>  <p>Lampkin hopes Blendoor chips away at the lack of diversity in Silicon Valley. “We’ve identified the greatest need with large tech companies,” she says. But while early users tend to be women and minorities, she says, “we want this to become a de facto recruiting tool for everyone.”<span class="Apple-converted-space">&nbsp; </span></p>  <p>—<em>David Talbot</em></p></td>
    </tr>
    <tr>
      <td>Ari Roisman</td>
      <td>Why the future of communication could be on your wrist.</td>
      <td>32</td>
      <td>Glide</td>
      <td>entrepreneurs-2016</td>
      <td><p><span class="s1">Ari Roisman clearly covets human connection. Minutes after meeting me, the 32-year-old CEO of Glide gladly settles into a conversation about the role of Judaism in his life and how he gave up a promising career in clean energy to move to Jerusalem. “My entire consciousness of this world is that it is a gift,” he says, intently. </span></p>  <p><span class="s1">Since 2012, Roisman has been striving to create a more human alternative to text messaging. Rather than typing short messages on tiny smartphone keys, sometimes adding emojis in a desperate stab to impart nonverbal emotion, you can use Glide’s app to send video messages with a single button push. To illustrate, Roisman shows a Glide message he sent to his mother, featuring his daughter singing at a kindergarten event with the seriousness of a brain surgeon. Mom quickly responded with a video of herself laughing at the performance. “If we’re going to be glued to these devices, at least we should be connected in a way that is more authentic,” he says. </span></p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/ari3x1000.jpg" alt=""><figcaption>Roisman believes video messaging will flourish on watches, whose screens are too tiny for typing.</figcaption></figure>\n <p><span class="s1">A few million people are using Glide, he says, but that’s a pittance in social networking, especially as Instagram and Facebook pour millions into their own video-messaging <a href="http://www.gadgetgestures.com/facebook-going-all-video-17925-2/83417925" target="_blank" rel="noopener noreferrer">plans</a>. Glide laid off 25 percent of its staff this spring. </span></p>  <p><span class="s1">Roisman says he scaled back on marketing and customer service to ensure his startup’s staying power. He wants the company to focus on a technology he says will make visual messaging the primary mode of communication: the smart watch. He is convinced that having a small screen just a wrist away will do for video messaging what the PC did for e-mail. </span></p>  <p><span class="s1">—<em>Peter Burrows</em></span></p></td>
    </tr>
    <tr>
      <td>Nora Ayanian</td>
      <td>To build better machines, a roboticist goes far outside her field for guidance.</td>
      <td>34</td>
      <td>University of Southern California</td>
      <td>visionaries-2016</td>
      <td><p>Nora Ayanian calls robots people. It’s not some weird affectation; it helps her with her work.</p>  <p>She’s a computer scientist who thinks machines should work together to get things done. Let’s say a farmer wants to have drones autonomously survey crops and take soil samples. You couldn’t program each drone with the same set of commands, because each would have a different task and would have to solve different problems as it navigated. You know what is good at solving problems on the fly, in a group that draws on various skills from different individuals? People.&nbsp;</p>  <p>So Ayanian studies robot coördination by studying people. One way is by having groups of humans play a simple video game that limits their senses and stifles communication. They need to figure out how to do “something meaningful” together, as she puts it, such as arranging their on-screen figures into a circle. Ayanian watches how people coöperate on such tasks with as little information as possible.&nbsp;</p>  <p>Why not just create a dictator robot—one machine that sees the whole field and directs other drones? Well, Ayanian counters, what happens when the dictator robot runs out of power? Or crashes? Distributed and diverse teams, she says, are always better at problem-solving, once they learn to work together. <br><br>—<em>Ryan Bradley</em></p></td>
    </tr>
    <tr>
      <td>Jonathan Downey</td>
      <td>The creator of control software for drones has foreseen the advantages of autonomous aircraft for years.</td>
      <td>32</td>
      <td>Airware</td>
      <td>visionaries-2016</td>
      <td><p><strong>2002–2006<br></strong>As an engineering and computer science student at MIT, Downey starts a group that builds drones and competes against other colleges.</p>  <p><strong>2005– 2010<br></strong>While working for Boeing, he develops flight-control software for an autonomous helicopter funded by the Pentagon.</p>  <p><strong>2011<br></strong>Founds a startup called Airware out of frustration with what he calls “inflexible and costly” autopilot systems for unmanned aircraft that made it hard to add new capabilities. Also spends five months flying tourists in a turboprop plane between Las Vegas and the Grand Canyon.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/jonathan1x1200.jpg" alt=""><figcaption>Airware has raised more than $70 million in venture capital to make it easy for companies to do things with drones.</figcaption></figure>\n <p><strong>2012<br></strong>Airware ships its first control software to drone manufacturers.</p>  <p><strong>2014<br></strong>General Electric invests in Airware, saying drones could help make it safer and cheaper to maintain industrial equipment such as power lines.</p>  <p><strong>2015<br></strong>Airware launches several products intended to help big companies use drones. For instance, software designed by former game developers lets companies take aerial photos of sprawling facilities as easily as you would click on a map. State Farm uses Airware’s technology to inspect roofs after weather damage.</p>  <p><strong>2016<br></strong>U.S. regulators remove rules that had tightly limited what companies could do with drones, clearing a path for many more companies to use Airware’s services.</p>  <p><strong>2025<br></strong>An industry group, the Association for Unmanned Vehicle Systems, predicts commercial drones will have created $80 billion in business value and 100,000 jobs by this time. “We will not be able to imagine doing our jobs without them,” says Downey.<br><br><em>—Tom Simonite</em></p></td>
    </tr>
    <tr>
      <td>Kevin Esvelt</td>
      <td>A scientist who is developing new gene-editing techniques also warns of their potential.</td>
      <td>34</td>
      <td>MIT</td>
      <td>visionaries-2016</td>
      <td><p><strong>His Job<br></strong>Works at MIT’s Media Lab to develop ways of influencing how ­ecosystems evolve.</p>  <p><strong>The Back Story<br></strong>Visited the Galápagos Islands at age 10. “I knew evolution would impact what I wanted to do.”</p>  <p><strong>His Burning Issue<br></strong>Gene drives, a new technology that could be used to quickly spread traits among wild creatures such as mosquitoes.</p>  <p><strong>What’s at Stake<br></strong>Wiping out ­mosquitoes, and maybe malaria. “Unimaginable amounts of suffering occur in the wild, and evolution doesn’t care,” he says.</p>  <p><strong>The Dilemma<br></strong>Are gene drives safe enough to ever use in the open, or will they have ­dangerous ­unintended ­consequences?</p>  <p><strong>Esvelt’s Take<br></strong>No gene drive able to spread globally should be released, he argues. Or even tested. ­Scientists need to ­disclose their plans.</p>  <p><strong>His Solution<br></strong>He’s designed safer gene drives that can be controlled.</p>  <p><strong>The Reviews<br></strong>Raising awareness about the potential threats of gene drives is “a home run for ­bio­security,” says the FBI.</p>  <p><strong>Hobbies<br></strong>Risky ones. Unicycling and hang-gliding.<br><br><em>—Antonio Regalado</em></p></td>
    </tr>
    <tr>
      <td>Maithilee Kunda</td>
      <td>People on the autism spectrum are inspiring her novel approach to creating artificial intelligence.</td>
      <td>32</td>
      <td>Vanderbilt University</td>
      <td>visionaries-2016</td>
      <td><p><span class="s1">“My research began in graduate school when I was working on artificial-intelligence systems and read <em>Thinking in Pictures</em> by Temple Grandin, a professor of animal science who talks about how her autism gives her this unique visual way of thinking compared to most people. </span></p>  <p>“I thought: That’s interesting. Most AI systems are not ‘visual thinkers’ like her. Most AI systems use variables, numbers, lists, and so on, and they reason using mathematical and logical operations. These systems are ‘verbal thinkers.’ What if you had an AI system that used data made up entirely of images and reasoned only using visual operations, like rotating images around or combining images together? If Temple Grandin can do amazing things because of her visual thinking abilities, it seemed to me that the same should be true of AI systems.</p>  <p><span class="s1">“I’ve been taking what we learn from people on the autism spectrum who have interesting visual abilities and building that into AI systems. It’s early, but I expect that they ultimately will be very valuable. If we want to help students learn to solve difficult problems, then we ought to have several AI tutors that can show students different ways of solving the same problem. If we want to help doctors find patterns of disease outbreaks, then we ought to have multiple AI analysts that can sift through the data using different styles of pattern finding.”<br></span></p>  <p><span class="s1"><em>—as told to David Talbot</em></span></p></td>
    </tr>
    <tr>
      <td>Evan Spiegel</td>
      <td>The cofounder of Snapchat figured out that people wanted something different from social media.</td>
      <td>26</td>
      <td>Snapchat</td>
      <td>visionaries-2016</td>
      <td><p><span class="s1">At the center of Snapchat—the disappearing-photo social network valued at $20 billion, used by 150 million people—sits an exotic-car-driving, engaged-to-a-supermodel 26-year-old genius. Or jerk. Or both—it’s hard to tell. Evan Spiegel is kind of a recluse. The guy behind this new media empire follows only about 50 people on the mobile app he helped create. (One of them is the magician David Blaine.) He declined to speak to me, which is fitting, because what Snapchat is, what Spiegel understands better than anyone, might be the opposite of an interview with a magazine.&nbsp;</span></p>  <p>Snapchat is often compared to Facebook, and Spiegel to Mark Zuckerberg. Which makes sense, especially since Facebook tried to buy Snapchat for $3 billion before releasing its own knockoff versions that promptly fell into irrelevance. And both founders are college dropouts (Spiegel from Stanford, Zuckerberg from Harvard). But Facebook is a company built on making your personal data public and delivering targeted ads; the whole point of Snapchat is to delete your images or videos after you send them to your friends. Snapchat, Spiegel has said, is based on the idea that “ephemeral should be the default.”&nbsp;</p>  <p>In its six years of existence—an epoch in startup time—the company has outlasted rivals like Poke and Ansa and Gryphn and Vidburn and Clipchat and Efemr (I swear I’m not making these up) and Wink and Blink and Frankly and (I promise you) Burn Note and Glimpse and Wickr. It reaches 41 percent of U.S. 18- to 34-year-olds <em>every day</em> and generates revenue from media companies and advertisers that publish snaps in dedicated channels. What did Snapchat do right that others didn’t? One thing you immediately notice upon downloading the app is how much it requires of you. You can’t just sit back and watch—you, too, must snap. The home screen practically begs you to take a picture or shoot a video. Photography once was all about capturing a moment forever; Spiegel’s great insight was that now the best way to make people pay attention is to capture that moment, share it, and watch as it disappears.&nbsp;</p>  <p>—<em>Ryan Bradley</em></p></td>
    </tr>
    <tr>
      <td>Jean Yang</td>
      <td>Why don’t computers keep our personal data secure by default?</td>
      <td>29</td>
      <td>Carnegie Mellon University</td>
      <td>visionaries-2016</td>
      <td><p>When programmers create a feature for an app or a website, even something as simple as a calendar, they should code in protections so the personal information that the feature needs to access—such as your location—doesn’t slip out onto the Internet. Needless to say, they sometimes fail, leaving our data to be exploited by hackers. “Just like there are many ways to sink a boat,” says Jean Yang, “there are many ways to leak information.”</p>  <p>That’s why Yang created Jeeves, a programming language with privacy baked in. With Jeeves, developers don’t necessarily have to scrub personal information from their features, because Yang’s code essentially does it automatically. <span class="s1">“It is a double hull for information leaks,” Yang says.</span></p>  <p>She has uploaded the code to open-source libraries for anyone to use. And this fall she begins as an assistant professor of computer science at Carnegie Mellon, where she can try to get her ideas to spread further. “Giving people tools to create technology is incredibly empowering,” she says.</p>  <p>—<em>Patrick Doyle</em></p></td>
    </tr>
    <tr>
      <td>Jagdish Chaturvedi</td>
      <td>This doctor can laugh about the complex path he took to becoming an innovator.</td>
      <td>32</td>
      <td>InnAccel</td>
      <td>humanitarians-2016</td>
      <td><p>“I invented a low-cost ear, nose, and throat<em>—</em>ENT<em>—</em>imaging device. So I call myself the first ENTrepreneur! Sorry<em>—</em>cheesy joke; I’m also an amateur standup comedian. I love performing. It’s how I de-stress. But I also find comedy helps sharpen my observational skills.</p>  <p><span class="s1">“Those skills helped me invent Entraview, which has helped 200,000 patients. As a trainee doctor I saw many farmers with advanced throat cancer. I discovered that expensive imaging systems were only available in major cities, so rural doctors relied on outdated mirrors and headlamps. I asked my boss why no one had tried attaching endoscopes to small off-the-shelf cameras. He said, ‘Why don’t you?’</span></p>  <p><span class="s1">“Entraview was a big learning curve for me. I worked with a design firm but got too involved trying to create a one-size-fits-all device. I’d nearly exhausted my funds when my boss said, ‘Go learn the right way to do this.’</span></p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/jagdish2x1200.jpg" alt=""><figcaption>Chaturvedi advises a patient’s relatives and uses an early version of the Entraview to examine a man’s ear in Bangalore.</figcaption></figure>\n<figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/jagdish3x1000.jpg" alt=""></p>\n<figcaption>The prototype attached to an off-the-shelf camera.</figcaption></figure>\n <p>“The Stanford-India Biodesign program teaches Indian doctors and engineers how to invent. Their process showed me where I’d gone wrong and gave me the connections to arrange a pitch with Medtronic. We simplified and focused on ears. Not the original goal, but the path of least resistance to market, and now the platform can evolve.</p>  <p>“I’ve since contributed to 18 medical-device inventions, and I’m now clinical lead at a med-tech incubator, InnAccel, where I help multiple startups while still practicing medicine, to keep me grounded with clinical needs.</p>  <p>“India imports 75 percent of its medical tech. We have great inventors, but most make the same mistakes because they don’t get the innovation process. The first step is finding the right team.”</p>  <p>—<em>as told to Edd Gent</em></p></td>
    </tr>
    <tr>
      <td>Ehsan Hoque</td>
      <td>If you want to be the life of the party, practice by talking to a machine first.</td>
      <td>34</td>
      <td>University of Rochester</td>
      <td>humanitarians-2016</td>
      <td><p>Can computers teach us to be our best selves? Ehsan Hoque, a researcher at the University of Rochester, believes so. He has created two computer systems that train people to excel in social settings.</p>  <p>One program has a virtual businesswoman that can recognize your expressions and statements so she can nod, smile, and prompt you with further questions as you chat with her. At the end of the conversation she’ll give you feedback about your interpersonal performance, including your body language, intonation, and eye contact.</p>  <p><span class="s1">Hoque also designed a pared-down mobile version, free for anyone with Internet access to use. There’s no animated character; instead, it records video and sends you a write-up about your social skills, noting the speed of your speech, the pitch and loudness of your voice, the intensity of your smiles, and whether you overused certain words. </span></p>  <p><span class="s1">All of Hoque’s research comes back to his brother, a teenager with Down syndrome. Hoque is his brother’s primary caretaker and has seen how difficult social interactions of any kind can be for him, especially in school. But Hoque hopes his tools will be useful to all kinds of people—individuals with Asperger’s, customer service representatives, nervous students with looming class presentations, or even just someone gearing up for a date or an interview.</span></p>  <p><em>—Julia Sklar</em></p></td>
    </tr>
    <tr>
      <td>Kelly Sanders</td>
      <td>A researcher in drought-ridden California tries to better account for the ways we use water.</td>
      <td>31</td>
      <td>University of Southern California</td>
      <td>humanitarians-2016</td>
      <td><p><span class="s1">Just about all power plants use water in some way—primarily for cooling. In fact, generating electricity accounts for about 40 percent of all the fresh water that is drawn from reservoirs, rivers, and other surface sources in the United States. Kelly Sanders, an assistant professor of civil and environmental engineering at the University of Southern California, has developed new methods of analyzing the complex relationship of water and energy—and is showing how both resources can be managed more wisely.</span></p>  <p>Although power plants typically return water to the source after it runs through cooling systems, those withdrawals and returns can be disruptive to the environment. Many newer coal and natural-gas plants reuse water in their cooling systems so they do not need to withdraw as much of it from reservoirs and rivers, but in the process they lose more water to evaporation. And that means, as Sanders has highlighted, that many newer plants end up consuming more water overall. She also looks carefully at the water individual nuclear power plants use to keep from overheating and causing a meltdown. If the water source <a href="http://green.blogs.nytimes.com/2012/08/13/heat-shuts-down-a-coastal-reactor/">gets too warm</a> and must cool down before it can be used, forcing the power station to scale back production, are the costs of the plant being miscalculated?</p>  <p>Having reframed how we measure water and energy usage, Sanders is becoming influential in policy and planning. She briefed Congress as it considered the Nexus of Energy and Water for Sustainability Act, which takes initial steps to have the federal government measure water usage not just in gallons but also in units of energy. “We select our power based on price,” she says, “but how do we define what’s cheap?”</p>  <p>—<em>Ryan Bradley</em></p></td>
    </tr>
    <tr>
      <td>Ronaldo Tenório</td>
      <td>A mobile app gives deaf people a sign-language interpreter they can take anywhere.</td>
      <td>30</td>
      <td>Hand Talk</td>
      <td>humanitarians-2016</td>
      <td><p>A deaf person walks into a bar. That isn’t the beginning of a joke, but a potentially frustrating situation—unless the bartender happens to know sign language. That’s where Hand Talk comes in. It translates spoken words into sign language that an avatar then conveys on a smartphone screen.</p>  <p>For now, Hand Talk can only translate Portuguese into Libras, the sign language used in Brazil—the home of the program’s creator, Ronaldo Tenório. But Brazil alone has at least 10 million deaf people, one million of whom have downloaded Hand Talk’s mobile app.</p>  <p>The users hold up their smartphone to a hearing person, who sees a message on the screen that says “Speak to translate.” As soon as the person starts talking, an animated avatar named Hugo begins signing.</p>  <p>Turning the audio into animations of gestures requires laborious programming because everything has to be exactly right, all the way down to Hugo’s facial expressions, which also carry meaning in sign language. Tenório and his team feed their program thousands of example sentences every month and match them with 3-D animations of sign language. They constantly push these improvements out through app updates.</p>  <p>Tenório plans to roll out different versions of the avatar in the future so users can switch the gender or race of their Hugo in an effort to broaden the appeal and accessibility of having a virtual translator in one’s pocket.<span class="Apple-converted-space">&nbsp;</span></p>  <p>—<em>Julia Sklar</em></p></td>
    </tr>
    <tr>
      <td>Sonia Vallabh</td>
      <td>A devastating personal diagnosis led her to become a scientist on the trail of a cure.</td>
      <td>32</td>
      <td>Broad Institute</td>
      <td>humanitarians-2016</td>
      <td><p>Five years ago, Sonia Vallabh graduated from Harvard Law School and went to work at a small consulting company. But a stunning medical diagnosis made her change course completely: she learned she has a genetic mutation that causes a deadly brain disease. Today she and her husband work in a lab at the Broad Institute of MIT and Harvard and have <a href="http://stm.sciencemag.org/content/8/322/322ra9">published</a> research showing a possible pathway to a treatment. As she told the tale at an event on precision medicine with President Obama in February:</p>  <p>“At the heart of my story is a single typo in my genome.</p>  <p>“We all carry around thousands of typos in our DNA, most of which don’t matter much to our health—but my typo is an unusually clear-cut case. It’s a single change in a particular gene that causes fatal genetic prion disease, where patients can live 50 healthy years but then suddenly fall into deep dementia and die within a year. And there’s no treatment—at least, not yet.</p>  <p>“In 2010, I watched this disease unfold firsthand. I had just married my husband, Eric Minikel. My mom, healthy at 51, had single-handedly organized our beautiful wedding. Then, all of a sudden, we were watching her waste away before our eyes. We had no name for what we were seeing. It was only from her autopsy that we learned there was a 50 percent chance I’d inherited the genetic mutation that killed her.</p>  <p>“We decided right away I’d get tested. We wanted to know what we were up against. After months in agonizing limbo, a geneticist confirmed our greatest fear: <em>The same change that was found in your mother was found in you.</em></p>  <p><span class="s1">“Knowing the hard truth has given us a head start against our formidable medical enemy. We waged a campaign to educate ourselves—taking night classes, attending conferences, and eventually taking new jobs in research labs. We retrained as scientists by day and applied what we were learning to understanding my disease by night. Four years later, we’re devoting our lives to developing therapeutics for my disease.</span></p>  <p>“We know the road ahead is uncertain—no amount of hard work can guarantee there will be a treatment for me when I need one. We are going to do everything we can, hand in hand with creative allies from every sector, to build this bridge as we walk across it and develop a treatment that could save my life, and the lives of many others.”&nbsp;</p>  <p>—<em>Antonio Regalado</em></p></td>
    </tr>
    <tr>
      <td>Qing Cao</td>
      <td>His inventions are helping IBM in its decade-plus quest to replace silicon transistors with more efficient carbon nanotubes.</td>
      <td>32</td>
      <td>IBM Research</td>
      <td>pioneers-2016</td>
      <td><p><strong>2001</strong></p>  <p>IBM researchers devise a way to produce arrays of carbon-­nanotube transistors.</p>  <p><strong>2002</strong></p>  <p><span class="s1">IBM researchers show that nanotube transistors can carry more than twice the electric current of top-performing silicon transistor prototypes. This is interpreted as the first evidence that nanotubes can outperform silicon transistors.</span></p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/qing2x1400.jpg" alt=""><figcaption>Cao at IBM’s Watson Research Center.</figcaption></figure>\n <p><strong>2006</strong></p>  <p>The first integrated circuit using a single carbon nanotube is built at IBM.</p>  <p><strong>2008</strong></p>  <p>During his doctoral studies at the University of Illinois, Qing Cao invents a way to print circuits of nanotubes on flexible plastic substrates.</p>  <p><strong>2013</strong></p>  <p>At IBM, Cao develops a technique that applies mechanical force to push purified nanotubes in water together into high-­density, neatly ordered arrays.</p>  <p><strong>2015</strong></p>  <p>Cao overcomes a fundamental roadblock to commercially viable nanotube transistors. He <a href="https://www.technologyreview.com/s/541921/ibm-reports-breakthrough-on-carbon-nanotube-transistors/">devises a way</a> to connect metal wires to carbon nanotubes by welding metal atoms to the nanotubes’ ends.</p>  <p><strong>2016</strong></p>  <p>IBM incorporates carbon nanotubes into its in-house semiconductor research line to figure out how to refine and scale up the technology.</p>  <p><strong>2020–2025</strong></p>  <p>IBM aims to have its nanotube transistors ready to replace silicon transistors. The company estimates that nanotube transistors will perform two to three times better than silicon and require half as much power.</p>  <p><em>—Elizabeth Woyke</em></p></td>
    </tr>
    <tr>
      <td>Ying Diao</td>
      <td>She knows how to print perfect plastic solar cells.</td>
      <td>33</td>
      <td>University of Illinois</td>
      <td>pioneers-2016</td>
      <td><p><strong>Problem</strong></p>  <p>Flexible solar cells that are cheap to make could be “printed” on many surfaces, even windows. But the polymers that would be required have so far been lackluster at converting sunlight to electricity. One reason is that unlike more efficient solar materials such as crystalline silicon, polymer-based materials have a messy molecular structure that looks like cooked spaghetti.</p>  <p><strong>Solution</strong></p>  <p>Ying Diao is creating printing techniques that bring order to the otherwise chaotic assembly of plastic molecules. She has made organic solar cells with double the efficiency of previous ones. Diao came up with a microscopic “comb” that controls the flow of the molecules and lets them assemble into orderly structures during printing.</p>  <p><em>—Ryan Cross</em></p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/ying1x2000.jpg" alt=""><figcaption>A polymer solar cell printed on glass.</figcaption></figure>\n</td>
    </tr>
    <tr>
      <td>Vivian Ferry</td>
      <td>She uses nanocrystals to trap light and increase the efficiency of solar cells.</td>
      <td>32</td>
      <td>University of Minnesota</td>
      <td>pioneers-2016</td>
      <td><p><span class="s1">With her hands cloaked in aquamarine rubber gloves, Vivian Ferry, an assistant professor of chemical engineering and materials science, picks up a lipstick-size test tube filled with clear liquid. When she shines UV light through the tube, its contents turn a glowing shade of fluorescent orange. Tiny crystals suspended in the liquid explain the vial’s fiery glow: they absorb high-energy blue wavelengths and emit lower-energy reds. </span></p>  <p><span class="s1">Existing solar cells tend to absorb limited wavelengths of light, letting most of the sun’s energy pass through uncaptured. If solar cells could grab more light, they would generate more electricity and make solar power even cheaper. So in addition to the luminescent crystals, Ferry turned to tiny mirrors made of nanostructured metals that can trap specific wavelengths and steer light toward the solar cell. </span></p>  <p><span class="s1">For now, Ferry makes her luminescent nanocrystals with cadmium selenide and cadmium sulfide, neither of which is ideal since cadmium is a toxic metal. But her improvements—and subsequent drops in cost—stand to become so significant that the technology could still work well using substances that are more abundant and less toxic. </span></p>  <p><span class="s1"><em>—Emily Sohn</em></span></p></td>
    </tr>
    <tr>
      <td>Sergey Levine</td>
      <td>He teaches robots to watch and learn from their own successes.</td>
      <td>29</td>
      <td>University of California, Berkeley</td>
      <td>pioneers-2016</td>
      <td><p>While serving a nine-month stint at Google, Sergey Levine watched as the company’s AlphaGo program defeated the world’s best human player of the ancient Chinese game Go in March. Levine, a robotics specialist at the University of California, Berkeley, admired the sophisticated feat of machine learning but couldn’t help focusing on a notable shortcoming of the powerful Go-playing algorithms. “They never picked up any of the pieces themselves,” he jokes.</p>  <p><span class="s1">One way that the creators of AlphaGo trained the program was by feeding 160,000 previous games of Go to a powerful algorithm called a neural network, much the way similar algorithms have been shown countless labeled pictures of cats and dogs until they learn to recognize the animals in unlabeled photos. But this technique isn’t easily applicable to training a robotic arm. </span></p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/sergey2x1400.jpg" alt=""><figcaption>Sergey Levine has demonstrated that his algorithms can help a robotic arm teach itself how to manipulate various objects.</figcaption></figure>\n <p>So roboticists have instead turned to a different technique: the scientist gives a robot a goal, such as screwing a cap onto a bottle, but relies on the machine to figure out the specifics itself. By attempting the task over and over, it eventually attains the goal. But the learning process requires lots of attempts, and it doesn’t work with difficult tasks.</p>  <p>Levine’s breakthrough was to use the same kind of algorithm that has gotten so good at classifying images. After he gives the robot some easy-to-solve versions of the task at hand—instructing it to screw on the cap, for example—the robot then retrospectively studies its own successes. It observes how the data from its vision system maps to the motor signals of the robotic hand doing the task correctly. The robot <em>supervises its own learning</em>. “It’s reverse--engineering its own behavior,” Levine says. It then can apply that learning to related tasks.</p>  <p>With the AI technique, previously insoluble robotics tasks have suddenly become approachable, thanks to the massive increase in training efficiency. Suddenly, robots are getting a lot more clever.&nbsp;</p>  <p><em>—Andrew Rosenblum</em></p></td>
    </tr>
    <tr>
      <td>Oriol Vinyals</td>
      <td>Showing computers how to learn might seem like a game, but it’s also serious business.</td>
      <td>33</td>
      <td>Google DeepMind</td>
      <td>pioneers-2016</td>
      <td><p><span class="s1">When he was 15 years old, Oriol Vinyals became obsessed with StarCraft, a video game in which three factions vie for control of the map—like chess if it were played not only with black and white pieces but also with red ones. Vinyals soon became the top-ranked player in Spain. “I almost knew the game would return later in my life,” he says. “I was fascinated by the artificial-intelligence problems it presents.” </span></p>  <p><span class="s1">It was more than a decade before Vinyals’s premonition came to pass. While he was studying at UC Berkeley, he helped to create an AI bot that was able to play StarCraft unassisted. The bot, forebodingly dubbed Overmind, represented a triumph in machine learning. </span></p>  <p><span class="s1">Later, while he was working on the Google AI team creating new techniques for language translation, inspiration struck. Vinyals decided to see whether a computer could accurately write a description of an image. It’s a form of translation, albeit from pixel to caption. “I remember it so well,” he says. “I changed a single line of code: instead of translating from French, I changed my code to input an image instead.” The next day, Vinyals showed his program a photograph of a busy market stall, the ground beside it littered with bananas. The caption read: “A group of people standing in the market buying fruits.” “It worked!” he recalls. “It wasn’t just saying ‘People on the street.’ It was reading the image with sophistication.” The technology, now being incorporated into Google Image Search, allows computers to caption images and show them to people who enter relevant search terms. </span></p>  <p><span class="s1">Vinyals and his coworkers have developed a technology now used in Gmail called Smart Reply, which automatically suggests short replies to e-mails. And now, having joined the team at Google DeepMind in London, he has come full circle. There, he is working to create computers that can teach themselves how to play and win complex games—not by hard-coding the rules but by enabling them to learn from experience. </span></p>  <p><span class="s1"><em>—Simon Parkin</em></span></p></td>
    </tr>
    <tr>
      <td>Aleksandra Vojvodic</td>
      <td>A computation whiz speeds up the search for catalysts that will make green chemistry possible.</td>
      <td>34</td>
      <td>University of Pennsylvania</td>
      <td>pioneers-2016</td>
      <td><p><span class="s1">Using enzymes honed over hundreds of millions of years of evolution, plants readily split water into oxygen and hydrogen that’s used to fuel metabolic reactions. Humans, too, could use hydrogen as a fuel and a way to store energy from intermittent renewable sources. But we don’t have millions of years to figure out how to make practical catalysts.</span></p>  <p>Aleksandra Vojvodic uses supercomputers to design new catalysts for water splitting and other reactions. The idea behind her work, she explains, is to “circumvent the trial and error of nature”—and of the chemistry lab.</p>  <p>Splitting water requires two catalysts, one for making hydrogen and the other for making oxygen. “The things that work efficiently are usually rare or expensive,” says Vojvodic. That’s where computational chemistry comes in. To predict the behavior of a catalyst, Vojvodic makes computer models that relate a material’s functions to its structure using the rules of quantum mechanics. Chemists know what functions the catalyst needs to have, and they know how different kinds of atoms and structures are likely to behave. Vojvodic’s computer experiments, at the SLAC National Accelerator Lab, have yielded oxygen--producing catalysts that match or outperform those made of expensive materials.</p>  <p>Researchers have been using powerful computers to try to design better catalysts for years, with varying degrees <span class="s1">of success. But today’s supercomputers are now capable of doing much more complex calculations. And Vojvodic has been exceptionally talented at taking advantage of computing power; identifying new ways to represent electronic properties, chemical structure, nanostructure, and other properties in mathematical calculations; and writing programs to carry them out. Working with experimentalists, she and her coworkers have recently made extremely efficient water-splitting catalysts that her modeling work predicted. The researchers are now eyeing other catalysts, including ones that can convert nitrogen and other abundant molecules into useful chemicals.</span></p>  <p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Yihui Zhang</td>
      <td>Pop-up nanostructures make it far easier to fabricate very tiny shapes.</td>
      <td>30</td>
      <td>Tsinghua University</td>
      <td>pioneers-2016</td>
      <td><p><span class="s1">Yihui Zhang likes to invite visitors to his office to stretch a piece of highly elastic silicone that has a soccer-ball-like structure attached to it. Once the silicone is pulled taut from four corners, the three-dimensional structure becomes a two-dimensional pattern that looks like a wheel with many adjacent hexagons and pentagons in the center. When the silicone is relaxed again, the flattened pattern pops back into its three-dimensional shape.</span></p>  <p><span class="s1">With this trick, Zhang has solved the challenge facing many researchers: how to fabricate complex three-dimensional nanoscale structures. Although the demonstration is done at the macro level, the idea works with nanostructures, too: easily created two-dimensional patterns can be attached to a substrate stretched taut and then buckled into three-dimensional structures as the substrate is relaxed. This process works with a wide range of materials such as metals and polymers.</span></p>  <p><span class="s1">The technique could be used to create nanostructures for a variety of uses. Ultimately, Zhang hopes to develop a database or algorithm that allows researchers to easily map the three-dimensional structures they want onto two-dimensional precursors. “It’s a tool,” he says. “People from different disciplines can build their own innovations.” </span></p>  <p><span class="s1"><em>—Yiting Sun</em></span></p></td>
    </tr>
    <tr>
      <td>Jia Zhu</td>
      <td>What to do if there is no clean water around.</td>
      <td>34</td>
      <td>Nanjing University</td>
      <td>pioneers-2016</td>
      <td><p>Water is everywhere; safe drinking water is not. So Jia Zhu has created a thin metal sheet capable of floating on the surface of a body of water, absorbing lots of sunlight and using the energy to generate steam that condenses into clean water.<span class="Apple-converted-space">&nbsp; </span>“It only needs two things. The first is water—no matter what kind of water<span class="Apple-converted-space">&nbsp; </span>you have—and the second is the sun,” says Zhu.</p>  <p>The device could be used to desalinate seawater or treat polluted water: after the water is turned into steam, what’s left are salts or solidified contaminants that can be easily collected.</p>  <p>He also envisions other ways to put the ingenious apparatus to use. “The steam doesn’t have to be condensed,” he says, suggesting that it could be used to produce power.</p>  <p><em>—Yiting Sun</em></p></td>
    </tr>
    <tr>
      <td>Yunji Chen</td>
      <td>Improvements in artificial intelligence call out for new hardware.</td>
      <td>32</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>Yunji Chen, iconoclastic and cosmopolitan, is sporting an untucked flannel shirt and sipping a mango smoothie at an Italian coffee shop in Beijing. He is talking about how he can make deep learning, a hot field of artificial intelligence, far more useful to people.</p><p>Once an obscure research branch, deep learning has quickly improved image search, speech recognition, and other aspects of computing (see “<a href="http://www.technologyreview.com/featuredstory/540001/teaching-machines-to-understand-us/" target="_blank" rel="noopener noreferrer">Teaching Machines to Understand Us</a>”). Companies such as Google and Baidu are heavily invested in using it to get computers to learn about the world from vast quantities of data without having to be manually taught. However, the technology is resource-intensive: when the Google Brain project trained a computer to recognize a cat face in 2012, it required 16,000 microprocessor cores. That dismays Chen. “The expense and energy consumption is quite high,” he says, noting that only large companies can afford it.</p><p>The reason is that most processors can quickly repeat basic math functions but need “hundreds of instructions” to perform the more elaborate functions needed in advanced AI techniques, Chen says. So he is designing dedicated deep-learning processors, optimized “to compute the basic blocks of machine learning.” In his lab at the <strong>Institute of Computing Technology</strong>, research assistants run a computer program that simulates how precise tweaks in chip blueprints will affect processing speeds. “We are changing the wires, the connections, the circuits,” he says. His latest design appears to be hundreds of times faster than today’s central processing units, yet it requires only a thousandth as much energy.</p><p>As impressive as that may be, Chen, who entered college at age 14 and raced through his PhD in computer science by 24, envisions reducing energy consumption by a factor of 10,000, which could let deep-learning functions work on mobile or wearable devices. “After five or more years,” he says, “I think each cell phone can be as powerful as Google Brain.”</p><p><em>—Christina Larson</em></p></td>
    </tr>
    <tr>
      <td>Canan Dagdeviren</td>
      <td>A master of flexible sensors and batteries sees opportunities for a new class of medical devices.</td>
      <td>30</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>What do you do when your mother complains that she can’t tell if her skin cream is working? If you’re the Turkish materials scientist Canan Dagdeviren, you build a device that can measure changes in skin quality too slight to be detected by human touch. While working with dermatologists to develop the instrument, however, Dagdeviren found that it could be put to a more significant use: screening for skin cancer, either to catch it earlier or to help patients avoid unnecessary biopsies.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.inv_.dagdeviren.secondary.2x519.jpg" alt=""><figcaption>Dagdeviren’s stretchable skin sensor for detecting early signs of cancer.</figcaption></figure>\n<p>One early indicator of cancer is a patch of skin slightly thicker than the skin around it. It turns out that Dagdeviren’s device, a tiny sensor and battery embedded in a translucent patch of stretchy rubber, can detect variations in skin density more accurately than a doctor’s fingers. It can be pulled over skin anywhere on the body to take such measurements.</p><p>As a PhD student at the University of Illinois, Urbana-Champaign, Dagdeviren also developed a device that can be permanently implanted inside the body and harvest energy from the movements of organs. It can send that power directly to devices like pacemakers or be used to charge a battery. Today, pacemaker batteries are bulky and need to be surgically replaced every five to eight years. Dagdeviren’s self-powering device, which has been tested in animals, could make life with a pacemaker that much easier.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/so15-inventors-3.jpg" alt=""><figcaption>Flexible, implantable devices that harvest energy from the movement of organs.</figcaption></figure>\n<!-- noembed: ad --> <p>While the flexible energy harvester works by a different mechanism than her skin sensor, both projects fit with the overall goal Dagdeviren is pursuing as a postdoctoral researcher at <strong>Harvard </strong>and<strong> MIT</strong>: creating a new class of biomedical electronics that are far less rigid and clunky than what we use today. </p><p><em>—Julia Sklar</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-canan-dagdeviren/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Lisa Seacat DeLuca</td>
      <td>A software engineer makes a habit of going after everyday problems.</td>
      <td>32</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>With more than 150 patents, Lisa Seacat DeLuca is <strong>IBM</strong>’s most prolific female inventor ever. Her inventions include a way for people on conference calls to get alerts when a certain topic comes up or a certain person starts talking; a system that can guide cell-phone users as they walk and talk so they don’t lose service; a necklace that lights up every time a given Twitter hashtag is used; and a locator service in cars that can track items like, say, a wallet that falls under the seat.</p><p>“The idea generation isn’t the slow part,” DeLuca says. “Anyone can come up with ideas very quickly. It’s taking the time to write them down and do research to figure out if it’s a great idea or how to make it an even better idea—that’s really the bottleneck in innovation.”</p><p>Most of that research happens outside the office on nights and weekends. By day, she works on mobile computing and commerce for IBM. Her latest project is an app for retailers that can send shoppers targeted offers based on their location in a store. DeLuca has filed nine patents related to the app and is testing out the necessary Bluetooth beacons in her own home. She also recently bought a 3-D printer that she plans to use for prototyping ideas. First up: a Fitbit key chain for her husband, who always forgets his fitness tracker on his way to work.</p><p>—<em>Suzanne Jacobs</em></p></td>
    </tr>
    <tr>
      <td>Travis Deyle</td>
      <td>He has built robots that can be powered wirelessly and ones that can bring people medication. Now Google has him trying to use technology to improve health care.</td>
      <td>32</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p class="nodropcap"><strong>Q: At the Google X research lab, you’ve been part of the team that is building glucose-measuring contact lenses. Now you’re working on a different, undisclosed health-care-related project. How do you apply your robotics experience at Google X?</strong></p>  <p>A: Almost every field can benefit from robotics. “Robotics” is really just a nice way of saying “massive multidisciplinary everything,” because you have sensing, perception, controls, machine learning, mechanics—everything. Automation. And having <a href="http://www.travisdeyle.com/vision.html" target="_blank" rel="noopener noreferrer">that broad exposure</a> lets you plug in to any group, regardless of the domain, and make massive contributions.</p>  <p><strong>Q: What impact do you hope to make?</strong></p>  <p>A: Improving people’s lives is the key thing. Health care is one of those things that’s been stagnant for a while, and there’s a lot of regulatory reasons for that, but there’s also just a lot of risk aversion. I think by taking a more agile approach we can actually make giant leaps and bounds.</p>  <p><strong>Q: Why is Google in any kind of position to solve big problems, such as those in health care?</strong></p>  <p>A: It has buy-in from the highest level. Google’s founders take risks that no one else will. It reminds me a lot of the amazing things that came out of Bell Labs, like the <a href="http://www.pbs.org/transistor/album1/" target="_blank" rel="noopener noreferrer">transistor</a>, which obviously drove entire revolutions in technology. So I think they have the right mind-set to embrace innovation and failure in ways that other organizations just won’t.</p>  <p><em>—Rachel Metz</em></p>  <p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-travis-deyle/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Richard Lunt</td>
      <td>Making invisible solar cells for electronic devices requires some exceptional creativity.</td>
      <td>33</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>Richard Lunt invented solar cells you can see through. They’re made of molecules that absorb ultraviolet and infrared light—wavelengths that we can’t see—and convert it into electricity while letting visible light through. Applied as a coating on the screen of a phone or smart watch, they generate power so the gadget lasts longer between charges. Some low-power devices with the coating, such as e–readers, might not need to be plugged in at all.</p><p>Prototypes of devices with these materials are on display at a company that Lunt cofounded, Ubiquitous Energy (the CEO, Miles Barr, was an <a href="http://www.technologyreview.com/lists/innovators-under-35/2014/entrepreneur/miles-barr/" target="_blank" rel="noopener noreferrer">Innovator Under 35</a> in 2014). However, one challenge in developing the technology is that it is complex to manufacture, especially for larger screens. So Lunt is also trying a second approach.</p><p>Lunt, a materials scientist based at <strong>Michigan State University</strong>, has concocted a combination of see-through materials that convert ultraviolet and infrared light to wavelengths that are then directed to photovoltaic cells at the edges of the screens. Because this design is simpler than the original approach of putting transparent solar cells directly on the surface of a screen, it could be cheaper to manufacture, especially for bigger devices.</p><p>The technology could boost conventional photovoltaic designs, too. If included as a coating on a standard solar panel, Lunt says, the new materials could increase the panel’s power output by converting more of the sun’s energy to electricity.</p><p><em>—David Talbot</em></p></td>
    </tr>
    <tr>
      <td>Rohan Paul</td>
      <td>To create an affordable obstacle detection system for blind people, he began by simply asking them what they needed.</td>
      <td>30</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>“In 2005, I was at the Indian Institute of Technology in Delhi as an undergraduate. As part of a course intended to design solutions for real-life challenges, we visited the National Association for the Blind in Delhi. We heard stories of how people with blindness get hurt when out walking<em>—</em>abruptly hitting open windows, tree branches, or vehicles. It creates so much fear that they are reluctant to step out without assistance.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/so15-inventors-18.jpg" alt=""><figcaption>These ultrasonic sensors detect obstacles. The device vibrates in patterns that indicate the distance to ­obstacles.</figcaption></figure>\n<p>We envisioned a sensing system on canes. By the end of the first year we had a basic prototype using ultrasonic ranging for detection and vibrations for feedback. You could see the users smile once they detected an obstruction; many refused to give back the prototypes!</p><p>We involved the users from the very beginning. They insisted that the device has to be small; if it falls it should not break; and it should allow any gripping or holding style. It has to detect everything, from signboards, people, parked cycles, or even cattle blocking the path<em>—</em>and also respond to obstacles approaching fast.</p><p>Women told us they wanted a device to be small enough so the cane can fold and fit into their purse. And they debated about color. Why? Because they would show it to someone else and say: ‘Am I looking smart with this?’ Men wanted to know if it will prevent touching or colliding with people; they told of women turning around and slapping them after such unintentional accidents. They don’t want to say, ‘Oh … excuse me, I didn’t see.’ It is about dignity as well as everyday safety. We engineers at times overlook the human side of a technology like this.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/so15-inventors-19.jpg" alt=""><figcaption>The full system includes a foldable cane for easy storage. It can also be mounted on a traditional cane.</figcaption></figure>\n<p>We ended up with a sleek handle-shaped attachment that fits on the traditional white cane. When we tested it in 2012 we saw users had 95 percent fewer collisions. We released it as a product in early 2014. The SmartCane costs only about $50 and is already in the hands of about 10,000 people. Our aim is to help one million or more worldwide.</p><p>It is a ‘people’s product’<em>—</em>a humble tribute to the Mahatma, who inspired innovators to harness science and technology for the masses.”</p><p><em>—as told to David Talbot</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-rohan-paul/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Jamie Shotton</td>
      <td>He gives computers new ways to see the world.</td>
      <td>34</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>For his PhD at the University of Cambridge and then at <strong>Microsoft Research</strong>, Jamie Shotton developed a way for a computer to identify different objects in a moving video. By dividing pixels into segments according to color, the software could separate, for example, a sheep from a field, or a bookshelf from a desk.</p><p>This brought Shotton widespread attention, and one evening he received a call asking him to join a secret team working on a new video-game control system for Microsoft. The group hoped to have the system classify individual human body parts in a video stream and then allow people to interact with a game using nothing but their bodies. In the shower one day, Shotton realized that he could segment objects according to their distance from the camera rather than their color.</p><p>That led to Kinect, a motion sensor for the Xbox 360 game console that was a monumental development in computer vision and machine learning. It has not represented a sea change in computer interaction, though, perhaps because it requires too much physical effort to use one’s body in such a way for a sustained length of time. Shotton remains undeterred. Some of his hand-gesture control software will debut in <a href="http://www.technologyreview.com/news/537196/microsoft-making-fast-progress-with-hololens/">HoloLens</a>, Microsoft’s forthcoming augmented-reality device. He’s also working on allowing even basic depth-sensing webcams <a href="http://research.microsoft.com/en-us/projects/handpose/default.aspx" target="_blank" rel="noopener noreferrer">to interpret subtle hand movements</a>. A user can zoom in with a simple pinch of the fingers in space, or enter a password using nothing but hand signals. “There are new and better ways of interacting with computers in the future,” he says.</p><p><em>—Simon Parkin</em></p><p><em>This story was updated on August 18 to clarify Shotton’s PhD work and to correct that his latest research is not yet related to HoloLens.<br /></em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-jamie-shotton/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Benjamin Tee</td>
      <td>A synthetic sense of touch could help both people and machines.</td>
      <td>33</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>“As a kid I was always curious about things, and I tended to break things,” says Benjamin Tee. “One of the things I broke was my great-grandmother’s alarm clock—you know, back then it was a winding alarm clock, it was one of those really old antiques, and she got really upset when I broke it and I couldn’t fix it.”</p><p>The experience only made Tee more curious about how things worked, and now, through innovations in electronic skin and pressure-sensing devices, he is addressing much more complex problems than fixing an alarm clock.</p><p>As a PhD student at Stanford, Tee and colleagues built what he calls “a smart bandage.” Tape it on your wrist, “and it can detect your pulse on the radial artery near the wrist,” he says. “We did it in such a high-resolution manner that we can tell if your arteries are actually healthy.”</p><p>He also developed a highly pressure-sensitive electronic skin, which could someday coat prosthetic limbs to give them some of the sense of touch that human skin has. “Your brain needs a lot of feedback to do your daily activities, and the skin allows you to do that,” Tee explains. “The fact that I’m sitting down and not falling over—a large part is really because I’m getting sensory information from the chair.”</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.inv_.tee_.secondaryx519.jpg" alt=""><figcaption>Small pyramids in ­Tee’s ­electronic skin distort with ­pressure, altering the electrical charge they hold.</figcaption></figure>\n<p>Such sensors have other applications: for example, a tiny wireless monitor can be implanted in the skull to measure pressure inside the brain, a technology he has tested in mice. Measuring cranial pressure is extremely important for people who have had brain injuries or are recovering from brain surgery, and doctors usually do it by implanting a catheter that runs through a small hole in the skull.</p><p>Today Tee has a Singapore-based startup, <strong>Privi Medical</strong>, that is developing diagnostic and treatment technologies. It should offer him more chances to fix problems, given that health care, he says, is “ripe for disruption.” </p><p>—<em>Anna Nowogrodzki&nbsp;</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-benjamin-tee/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Conor Walsh</td>
      <td>This robotics researcher might have something in just your size.</td>
      <td>33</td>
      <td></td>
      <td>inventors-2015</td>
      <td><p>Most robotics labs don’t contain sewing machines. But there’s a room full of them in Conor Walsh’s lab, along with three full-time textile experts and a wall of fabrics in neat plastic bins. There’s a rack that looks as if it belongs in a sporting goods store, with a row of what could be some new kind of running shorts in an array of sizes.</p><p>For Walsh, a robot is not necessarily a rigid metal machine. He’s working on robots that are soft, lightweight, and flexible so people can wear them to enhance their abilities.</p><p>The running shorts are part of an exosuit for the legs. Sensors in the suit measure a person’s movement and then tell a motor to pull on cables attached to the fabric in order to assist the muscles at the right moment. The exosuit could support soldiers as they walk, to increase their endurance. Or it could help patients who have trouble walking. “For people whose limbs don’t work very well, there’s really no good technologies that exist today,” says Walsh, a faculty member at <strong>Harvard </strong>and its <strong>Wyss Institute for Biologically Inspired Engineering</strong>. In a video of one trial, a stroke patient walks visibly faster, and with a more symmetrical gait, when the robot is turned on.</p><p>Using fabric and cables keeps the exosuit lightweight. But the suit also needs to fit just right, so it can apply forces to the body without restricting movement. “The textile component is probably the most critical,” says Walsh. Hence the sewing machines.</p><p>—<em>Anna Nowogrodzki</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-conor-walsh/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Patrick Collison</td>
      <td>He and his brother started Stripe to make money flow easily online.</td>
      <td>26</td>
      <td></td>
      <td>entrepreneurs-2015</td>
      <td><p>I grew up in very rural Ireland. The Internet was a connection to the greater world. It was very clear just how potent a force the Internet was and could be. While my brother John and I were tinkering with some new apps in Ireland and then in Boston and Silicon Valley, we experienced firsthand the difficulty of accepting online payments. We were just baffled at how convoluted and awkward the process appeared to be. The ecosystem seemed designed to reduce the number of Internet businesses.</p><p>“The same way Google exists as a foundational component of the Internet around information retrieval, it felt like there should be a developer-focused, instant-setup payment platform. Many people in financial services told us it couldn’t work.</p><p>“Stripe now processes billions of dollars a year for thousands of businesses, from startups to publicly traded companies. There’s a ton of database and distributed-system work that has to be done to make that experience possible. We have a 10-person machine-learning team that works on compliance, risk, fraud, identity verification, all of those things behind the scenes.</p><p>“Making it so easy to participate in the online economy has a far larger effect than one might imagine. We’re enabling new business models, like crowdfunding. And mobile marketplaces, like Lyft, Postmates, and Instacart. That enables more people in society to take advantage of these services. My youngest brother is disabled, and for him it’s not just a convenience. He can now do grocery shopping in a way that he could not before.”</p><p><em>—as told to Robert D. Hof</em></p></td>
    </tr>
    <tr>
      <td>Jini Kim</td>
      <td>A stint helping the government altered her view of her health-care business.</td>
      <td>34</td>
      <td></td>
      <td>entrepreneurs-2015</td>
      <td><p>The phone call that changed Jini Kim’s life came at 2 a.m. in November 2013. The White House needed the former Google product manager’s help with Healthcare.gov, which had been meant to help people buy health insurance but was riddled with embarrassing glitches. She hopped on a plane that day and worked marathon hours to fix the site, giving up Thanksgiving, Christmas, and her birthday. By the time she left, six months later, the site had enrolled eight million people in insurance plans—and Kim had gained insight that would be crucial for her own health-care analytics company, <strong>NunaHealth</strong>.</p><p>Founded in 2010, Nuna helps companies shape their health-insurance benefits and wellness programs. It analyzes anonymized data about employees’ behavior to determine the answers to questions such as “Are there differences in how people in certain demographic groups seek health care?” or “Can more generous health insurance help improve the productivity of someone with a seriously ill family member?”</p><p>Before she bailed out Healthcare.gov, Kim viewed the government the way many people in Silicon Valley do: as a hindrance to innovation.Accordingly, Nuna originally sold its services only to corporations. But during her stint working for the Obama administration, she saw the enormous potential the government had to effect change. “You can touch millions of people so easily,” says Kim, recalling a day at a Healthcare.gov call center when she overheard desperate people crying because they were unable to sign up for insurance.</p><p>Upon her return to San Francisco, Kim expanded Nuna so that it now also works with local, state, and national governments. For example, the company helps the Centers for Medicare and Medicaid Services find patterns in their vast amounts of data.</p><p>For Kim, reforming health care is not a theoretical issue. Her 33-year-old brother, Kimong,has severe autism. She has been involved in his care since she was nine years old and had to sign him up for Medicaid on behalf of her immigrant parents. She still lives at home to help out. Nuna’s meeting rooms are named after Kimong’s favorite <em>Sesame Street</em> characters, and she brings him to work regularly to give her parents a break. The name “Nuna” comes from the Korean word for “big sister,” one of three words he knows.</p><p>—<em>Yukari Iwatani Kane</em></p></td>
    </tr>
    <tr>
      <td>Dena Marrinucci</td>
      <td>Her startup bets it can track cancer from an early stage, without any biopsies.</td>
      <td>33</td>
      <td></td>
      <td>entrepreneurs-2015</td>
      <td><p class="nodropcap"><strong>Problem:<br /></strong> Tumor cells that metastasize through the blood are generally very difficult to detect until they have spread to the point of being deadly.</p><p><strong>Solution:<br /></strong> Dena Marrinucci cofounded <strong>Epic Sciences</strong> in 2008 to commercialize a cell detection and analysis technology that she developed to find cancer earlier. It can find and profile nearly all the tumor cells in two tablespoons of blood taken from a patient. On average, a sample that size has 50 billion red blood cells, 50 million white blood cells, and only a few circulating tumor cells. “You’re basically looking for needles in a haystack,” says Marrinucci.</p><p>Other technologies miss some circulating tumor cells because they are scanning for only one biological marker or are filtering cells by size. Epic says it finds more because it detects not only genomic abnormalities but also other biological markers, such as protein expression in cells. That should be useful in tracking the progress of a patient’s cancer over time, so that treatments can be adjusted as the disease evolves. Twenty-six pharmaceutical companies are using Epic’s technology in clinical trials of cancer drugs.</p><p>Marrinucci had just begun graduate school at the Scripps Research Institute in San Diego in 2004 when her grandmother was diagnosed with advanced melanoma. Less than a year earlier, however, doctors had given her grandmother an all-clear after a PET scan. “By the time you see cancer cells on a PET or CT scan, there are thousands of them,” she says. “And that’s what we’re trying to change.”</p><p> <em>—Eilene Zimmermann</em></p></td>
    </tr>
    <tr>
      <td>Rikky Muller</td>
      <td>Hardware that buzzes the brain at the right moments could help treat debilitating mental disorders.</td>
      <td>34</td>
      <td></td>
      <td>entrepreneurs-2015</td>
      <td><p>One of the most audacious projects funded last year under the Obama administration’s BRAIN initiative aims to intervene in mental disorders using <a href="http://www.mercurynews.com/portlet/article/html/imageDisplay.jsp?contentItemRelationshipId=6108229" target="_blank" rel="noopener noreferrer">an electrical brain interface</a>. The plan is to develop a system that both senses and modulates abnormal electrical activity, in hope of helping patients with conditions ranging from severe anxiety to post-traumatic stress disorder. Rikky Muller, an Israeli-born entrepreneur and the cofounder of <strong>Cortera Neurotechnologies</strong>, is designing the implantable hardware intended to interact directly with the brain.</p><p>Muller has long been interested in brain interfaces with clinical potential. After training as an electrical engineer and then designing chips for digital cameras, she gravitated toward neuroscience. In graduate school at Berkeley, she worked on neural implants that might decode human thought to control robotic prostheses. She also built a wireless device that could interpret brain signals in detail while resting on the surface of the cortex, rather than deeper in the brain. That work led to the founding of Cortera, in 2013, during the final year of her PhD studies. “We thought it could change patients’ lives,” she says.</p><p>Devices that record electrical activity directly from the surface of the brain—similar to Cortera’s founding work—are already used clinically to map the cortex during surgery and to pinpoint the location of seizures. In theory, these devices could also monitor severe neurological or psychiatric conditions on an ongoing basis. Muller is cagey, however, when it comes to Cortera’s plans in the growing neuromodulation market. “We do have a specific application in mind,” she says, “but we are not disclosing what it is.” </p><p> —<em>Amanda Schaffer</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-rikky-muller/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Ben Rubin</td>
      <td>The cofounder of a live-streaming video app explains what makes it tick.</td>
      <td>27</td>
      <td></td>
      <td>entrepreneurs-2015</td>
      <td><p>Ben Rubin is talking about the key qualities of <strong>Meerkat</strong>, an app that helped fuel a live-streaming craze this year. Type in a subject, press a button to start filming with your smartphone camera, and Meerkat sends out a tweet with a link that your friends can click to watch<em>—</em>and comment on if they want. That’s all it had to be, he says: “The medium is new, and if you make a complicated product in a medium that already makes people uncomfortable, you end up with zero adopters.”</p>  <p>One thing Rubin couldn’t control, however: after Meerkat got popular, Twitter began offering a similar app, Periscope, and cut off Meerkat’s access to its network. That made it harder for new users to find friends who also use Meerkat. The company has since let users connect Meerkat to their Facebook profiles.</p>  <p>Rubin envisions live-streaming eventually giving rise to a new form of entertainment: “an ongoing live show that is taking place in real time and involves the audience and everyone. Something where you’re no longer the couch potato; you’re part of the script.”  </p>  <p></p></td>
    </tr>
    <tr>
      <td>Kevin Systrom</td>
      <td>Instagram’s cofounder maintains his sharp focus.</td>
      <td>31</td>
      <td></td>
      <td>entrepreneurs-2015</td>
      <td><p>Kevin Systrom started <strong>Instagram</strong> in 2010, when he was 26, with a guy he’d befriended in a San Francisco coffee bar. Eighteen months later, when the company was just 13 people and still without a business plan, Mark Zuckerberg came calling with an offer of $300 million in cash and $700 million in Facebook’s pre-IPO stock. Systrom said yes only after he persuaded Zuckerberg to keep the Instagram brand alive and to let him and cofounder Mike Krieger run it.</p><p>Three years later, it’s clear that the creation of Instagram was remarkably well timed and well executed. The service is like Twitter, but with pictures and videos primary rather than text. It works because people like to tell stories with pictures: it’s easy, and it has impact across languages and cultures. Instagram has more than 300 million users, who post more than 70 million photos and videos every day.</p><p>One big question still faces Systrom, though: can he turn all this attention into a real business? He started rolling out an advertising program last fall and remains coy about how it’s doing. Systrom says he just has to find a way to present the ads without upsetting his users, the vast majority of whom are younger than 30.</p><p>Systrom himself is something of a model for an emerging kind of high-tech entrepreneur, at the intersection of technology and the liberal arts. He’s a jock, having been captain of his high school lacrosse team. He’s also artistic, having effectively minored in photography while getting an engineering and management degree at Stanford. He knows the corporate world: he’s on the board of Walmart. And he’s an extrovert, as comfortable with runway models in New York and movie stars in Hollywood as he is with coders in Silicon Valley. As mobile applications and social networking permeate more of our economy, people who understand how these technologies make the physical world more interesting or productive will become as important as the hard-core engineers. </p><p>—<em>Fred Vogelstein</em></p></td>
    </tr>
    <tr>
      <td>Melonee Wise</td>
      <td>Affordable robots for the warehouse and beyond.</td>
      <td>33</td>
      <td></td>
      <td>entrepreneurs-2015</td>
      <td><p>Melonee Wise imagines that all homes will have autonomous robots—something like <em>The Jetsons</em>’ Rosie the robot maid, minus the apron and Brooklyn accent. Just one problem: Wise, chief executive of the year-old startup <strong>Fetch Robotics</strong>, thinks it won’t happen in her lifetime, because the challenges in hardware and software are too big. “I’m probably one of the most pessimistic roboticists you’ll ever meet,” she admits.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.ent_.wise_.secondaryx235.jpg" alt=""><figcaption>Wise’s robots use only 500 unique parts. Top: The Freight robot moves a crate. Bottom: Fetch waits at a row of shelves.</figcaption></figure>\n<p>Nonetheless, Wise still thinks smaller and more powerful computers, affordable sensors, more adept machine vision, and better artificial intelligence are coming together to make robots capable of a wide range of tasks—if not yet all in a single machine. That’s why Fetch Robotics is going after one promising area: warehouses and e-commerce fulfillment centers, which are plagued with high turnover, injuries, employee theft, and a chronic shortage of workers, who, of course, also have a biological need to sleep.</p><p>Although dedicated robots are common in giant distribution centers (see “<a href="http://www.technologyreview.com/photoessay/539511/inside-amazon/" target="_blank" rel="noopener noreferrer">Inside Amazon</a>”), Wise thinks there’s a bigger market for more flexible “mobile manipulation” robots that can help smaller companies ease into automation. In a simulated warehouse set up in a corner of Fetch’s San Jose headquarters, a knee-high, cylindrical rolling robot called Freight smoothly follows Wise like a very attentive dog as she picks up boxes of crackers and cereal from shelves. She drops them in a plastic crate atop the robot, and when she’s done with the fake order, it zips off to a mock shipping area.</p><!-- noembed: ad --> <p>Another robot, Fetch, is intended not to aid but to replace warehouse workers. It has one jointed arm with a gripper on the end, along with a “head” that uses a depth camera similar to a Microsoft Kinect game controller, so it can identify and pluck items from a shelf and place them in Freight’s crate. Both robots are taught to navigate by leading them around the warehouse to create a map. They’re even trained to recognize people’s legs, so they can follow particular individuals. Unlike some robots that navigate using radio beacons or bar codes on the floor, Fetch’s robots use 3-D laser scanners to get around and avoid obstacles, expected or otherwise.</p><p>Wise won’t disclose the exact price of Fetch robots, but she says they will be in the tens of thousands—much less than the cost of an employee. The company has sold some of its initial run of 40 robots to unnamed pilot customers, with plans for a much larger run if the automated workers can do the job.</p><p>—<em>Robert D. Hof</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-melonee-wise/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Lars Blackmore</td>
      <td>Would space travel flourish if we could reuse the rockets?</td>
      <td>34</td>
      <td></td>
      <td>visionaries-2015</td>
      <td><p>Sixty years after <em>Sputnik</em> blasted into space, escaping our atmosphere remains absurdly expensive. Lars Blackmore, an engineer at <strong>SpaceX</strong>, is working on changing that with rockets that could be flown back to Earth in reverse.</p><p>As things stand, every time a space rocket takes off and releases its payload, it breaks up and falls into the ocean. “It’s basically like flying a 747 across the country and then, instead of refueling it, throwing it away,” says Blackmore, a soft-spoken Brit who leads a team at SpaceX that’s developing the onboard software necessary for a rocket to come down gently in an upright position onto a platform in the ocean.</p><p>SpaceX has come agonizingly close to sticking a rocket landing several times, but it didn’t get a chance to try again in its most recent flight, when the Falcon 9 rocket exploded during takeoff.</p><p>Landing a rocket backwards is an insane trick. The descent is extraordinarily unpredictable, and rockets aren’t meant to travel in reverse, so it requires extremely fine control over the boosters and guidance fins. Blackmore has devised algorithms to enable a rocket’s onboard computer to deal with this chaotic situation while safely controlling the craft’s fall.</p><p>If the feat can be perfected, it would change the economics of space travel entirely. Fuel accounts for less than half of 1 percent of the cost of a rocket launch, so refurbishing a rocket would make the next launch considerably cheaper. How much cheaper would depend on how well the booster could be reconditioned following the extreme stress of takeoff.</p><p>Blackmore grew up dreaming of working at NASA Mission Control. After a PhD at MIT, he joined NASA’s Jet Propulsion Lab, where he worked on precision landing systems and a climate probe called SMAP. He went to SpaceX in 2011. “I’d heard that Elon [Musk] had these dreams of making reusable rockets,” Blackmore says. “And since I was working on precision landing for Mars, I thought I would be the right guy to do that.”</p><p>Would he want to go back to NASA someday? “When you hear about the Apollo program in its heyday, it was a bunch of young kids, and no one told them what they could do,” he says. “That is exactly what I’ve found at SpaceX.” </p><p>—<em>Will Knight</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-lars-blackmore/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Adam Coates</td>
      <td>Artificial intelligence could make the Internet more useful to the millions of people coming online for the first time.</td>
      <td>33</td>
      <td></td>
      <td>visionaries-2015</td>
      <td><p class="nodropcap"><b>Q: You invented ways to put more computing power behind deep learning. Now you lead a lab in Silicon Valley for the Chinese search company Baidu. Why did it need a lab there?</b></p><p>A: They spin up new projects very fast. It’s partly driven by the dynamism in China<em>—</em>tech companies have to go quickly from having nothing to having state-of-the-art something. My lab’s mission is to create technology that will have an impact on at least 100 million people; it is intended to move rapidly, like a startup. We’re recruiting AI researchers and many people in Silicon Valley who have amazing skills from working on products and haven’t thought they could use that to make progress on artificial intelligence.</p><p> <b>Q: What is the lab working on?</b></p><p>A: The first technology that we are focusing on is speech recognition. Touch screens on phones are fine for some things but really awful for others, and there are all kinds of other devices that are crying out for better interfaces. People don’t use speech today because it doesn’t work well enough. Our goal is to get it to a level where it’s as easy to talk to your devices as it is to talk to the person next to you. In December we hit our first milestone with DeepSpeech, a speech engine we built quickly from scratch using deep learning. When there’s a lot of background noise it’s dramatically better.</p><p> <b>Q: Why would that have an impact on 100 million people?</b></p><p>A: In rapidly developing economies like in China, there are many people who will be connecting to the Internet for the first time through a mobile phone. Having a way to interact with a device or get the answer to a question as easily as talking to a person is even more powerful to them. I think of Baidu’s customers as having a greater need for artificial intelligence than myself. </p><p> <em>—Tom Simonite</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-adam-coates/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Zakir ­Durumeric</td>
      <td>A computer scientist sees a way to improve online security.</td>
      <td>26</td>
      <td></td>
      <td>visionaries-2015</td>
      <td><p>“It’s absolutely astounding what people attach to the Internet,” Zakir Durumeric says. He would know, because he invented a way to probe every computer online in just minutes. “We have found everything from ATM machines and bank safes to industrial control systems for power plants,” he says. “It’s kind of scary.” </p><p>A bank safe! Why would someone put that online? So someone in the bank can operate it from home?</p><p>“Yes. You sit there and you wonder: who on earth thought this was a good idea?”</p><p>Bad computer security practices like that can be mitigated far more readily with the ZMap scanning system -Durumeric developed. It determines not only which machines are online at any given moment, but also whether they have security flaws that should be fixed before miscreants exploit them. It finds everything from obvious software bugs to subtle problems like the ones that can be caused if an IT administrator fails to properly implement an arcane aspect of a cryptography standard. </p><p>Pinging all four billion devices on the Internet took weeks until Durumeric, who is pursuing a PhD at the <strong>University of Michigan</strong>, came up with a process that now takes about five minutes. He has used it to quickly inform website administrators about their vulnerability to catastrophic flaws such as the Heartbleed bug in 2014, and he hopes other security researchers will routinely do the same when they find weaknesses. “There’s always been this period where a vulnerability is [found] and then it takes weeks, months, or years for administrators to patch their servers,” he says. “We have an opportunity to change that.” </p><p><em>—Brian Bergstein</em></p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/R1.tr35.vis_.durumeric.secondaryx519.jpg" alt=""><figcaption></figcaption></figure>\n<p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-zakir-durumeric/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Cigall Kadoch</td>
      <td>A major vulnerability of certain kinds of cancer is becoming clear.</td>
      <td>30</td>
      <td></td>
      <td>visionaries-2015</td>
      <td><p class="nodropcap"><strong>Problem:<br /></strong> The exact biochemical mechanisms involved in many kinds of cancer remain unknown.</p><p><strong>Solution:<br /></strong> While completing her PhD at Stanford, Cigall Kadoch discovered a link between a genome regulator in cells called the BAF protein complex and a rare cancer called synovial sarcoma. She and colleagues later showed that mutations of BAF are involved in at least 20 percent of human cancers, opening the door for research on drugs that target mutated BAFs.</p><p>BAF’s job in the cell is to open and close DNA to allow the right genes to be expressed at the right time. When mutated, it can “activate sites that it shouldn’t”<em>—</em>including genes that drive cancer, says Kadoch,who has appointments at <strong>Harvard Medical School </strong>and the<strong> Broad Institute of Harvard and MIT</strong>.</p><p>She learned this by focusing on one particular subunit of BAF. This piece of the protein has a deformed tail in 100 percent of patients with synovial sarcoma. When Kadoch put the deformed subunit into normal cells, she detected “blazing cancer,” she says. “That little tail is entirely responsible for this cancer.”</p><p>The good news is that this is reversible. If she added enough normal pieces of the subunit to cells in a petri dish, it replaced the mutated form, killing the cancerous cells on the spot. </p><p><em>—Anna Nowogrodzki</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-cigall-kadoch/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Ilya Sutskever</td>
      <td>Why one form of machine learning will be particularly powerful.</td>
      <td>29</td>
      <td></td>
      <td>visionaries-2015</td>
      <td><p>Artificial-intelligence researchers are focusing on a method called deep learning, which gets computers to recognize patterns in data on their own (see “<a href="http://www.technologyreview.com/featuredstory/540001/teaching-machines-to-understand-us/" target="_blank" rel="noopener noreferrer">Teaching Machines to Understand Us</a>”). One person who demonstrated its potential is Ilya Sutskever, who trained under a deep-learning pioneer at the University of Toronto and used the technique to win an image-recognition challenge in 2012. He is now a key member of the <strong>Google Brain research team</strong>. I asked him why deep learning could mimic human vision and solve many other challenges.</p><p>“When you look at something, you know what it is in a fraction of a second,” he says. “And yet our neurons operate extremely slowly. That means your brain must only need a modest number of parallel computations. An artificial neural network is nothing but a sequence of very parallel, simple computations.</p><p>“We started a company to keep applying this approach to different problems and expand its range of capabilities. Soon, we joined Google. I’ve shown that the same philosophy that worked for image recognition can also achieve really good results for translation between languages. It should beat existing translation technology by a good margin. I think you will see deep learning make a lot of progress in many areas. It doesn’t make any assumptions about the nature of problems, so it is applicable to many things.” </p><p><em>—Tom Simonite</em></p></td>
    </tr>
    <tr>
      <td>Yevgen Borodin</td>
      <td>A software tool conceived for blind people could offer an intuitive way for anyone to listen to online material.</td>
      <td>34</td>
      <td></td>
      <td>humanitarians-2015</td>
      <td><p>Yevgen Borodin, an assistant professor at <strong>Stony Brook University</strong> and CEO of Charmtech Labs, is making it easier for people who are blind—and everyone else, too—to listen to content published only as text online.</p><p>Borodin’s software, Capti Narrator, serves as a hub for spoken material drawn from many written sources: Dropbox, Google Drive, Web pages, e-book repositories such as Bookshare and Gutenberg, and more. To create the software, Borodin and his team at Charmtech devised ways of extracting content from documents and websites and running it through text-to-speech engines. The software also lets users start listening on one device and continue on another, picking up where they left off.</p><p>“Blind people easily [take] far longer to do simple computer tasks than others do, and I decided that I had to do something about it,” says Borodin, who grew up in Ukraine and came to the United States for college. His ultimate goal is for his invention to follow the path of assistive technologies such as optical character recognition and speech-to-text, which started out as niche tools for people with disabilities but became mainstream. Capti Narrator was unveiled at the 2014 Consumer Electronics Show and has been downloaded hundreds of thousands of times worldwide.              </p><p> —<em>David Talbot</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-yevgen-borodin/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Duygu Kayaman</td>
      <td>What her parents did for her, she hopes to do for many other blind people.</td>
      <td>26</td>
      <td></td>
      <td>humanitarians-2015</td>
      <td><p>Turkey is a tough place to live without sight. A dearth of social services and education for blind children means families often seclude them at home. Daily activities are riddled with peril: in cities, shoddily built sidewalks are littered with broken paving stones and sudden drop-offs. Gainful employment is a distant aspiration for many.</p><p>Duygu Kayaman lost her vision to an optic nerve tumor at two and a half. Growing up in Istanbul, she was determined to attend school with seeing students, but the lack of textbooks for the blind made it hard for her to compete. Her parents spent evenings and weekends dictating lessons into a tape recorder to help her keep up.</p><p>Those homemade audio books later inspired Kayaman to develop a mobile-phone application, Hayal Ortağım (My Dream Partner), to make daily activities easier for the visually impaired. It offers news and editorial columns through text-to-speech technology. Books, courses from the Khan Academy, and chess and guitar lessons are at hand. Location services help users find pharmacies and hospitals, and navigation systems for indoor spaces guide them through shopping centers; airports and subways are to be added soon. Also in the works is a function for restaurants: it will alert staff through a Bluetooth beacon that a blind customer has arrived, and then transcribe the menu for the patron.</p><p>Some 150,000 Turks use My Dream Partner, out of an estimated visually impaired population of 700,000. Kayaman developed it with other vision-impaired members of an Istanbul-based organization, Young Guru Academy, and the support of Turkey’s biggest mobile-phone operator, Turkcell.</p><p>Today she works as a sales specialist for <strong>Microsoft</strong> while studying for her MBA at Istanbul’s Bilgi University. “It is only recently that people with disabilities are being hired by corporate firms,” she says. “Managers simply did not know that a person with blindness or another physical disability could work in these environments. My friends and I are breaking down those stereotypes.” </p><p> —<em>Ayla Jean Yackley</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-duygu-kayaman/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Rahul Panicker</td>
      <td>This engineer from India returned home after graduate school with a new approach to helping premature babies.</td>
      <td>34</td>
      <td></td>
      <td>humanitarians-2015</td>
      <td><p>“Humanity has known for over 100 years that keeping premature babies warm dramatically increases their survival rates. Yet most vulnerable babies around the world don’t benefit from this knowledge.</p><p>“In 2007 I and three classmates at Stanford were encouraged to do fieldwork in Nepal. The first thing we realized was that low cost is not always the solution. Donated incubators were being used as filing cabinets, because there wasn’t the electricity or the expertise to use them. Secondly, we found that parents desperate to keep their children alive were the users we should focus on, rather than doctors.</p><p>“We needed to reframe the problem. So we came up with a prototype incubator that costs 1 percent as much as traditional solutions and can be operated by a non-expert. It uses phase-change materials to keep babies at the ideal temperature of 37 °C for up to six hours without electricity. When heated with hot water or another source, a phase-change material melts, and it can release heat the baby needs at a constant temperature.</p><p>“NGOs we’d partnered with passed on the design. We realized if we didn’t take this forward, no one else would. After a year of working on the project in my free time, we finally had our seed capital, and in 2009 I quit my job, moved to Bangalore with my three cofounders, and started <strong>Embrace</strong>. Since then our warmers have been used in 15 countries to help nearly 200,000 babies. We’ve implemented a hybrid for-profit/not-for-profit business model that lets us scale much faster than a charity.</p><p>“I hope future generations look to us as role models and take inspiration to go down the route of social entrepreneurship. Too many young people, especially in India, don’t take risks because they worry about their futures. But I realized many years ago that someone with my education was never going to starve.”</p><p><em>—as told to Edd Gent</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-rahul-panicker/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Saurabh Srivastava</td>
      <td>Voice and gestural interfaces could make digital technologies available to the world’s poorest people.</td>
      <td>30</td>
      <td></td>
      <td>humanitarians-2015</td>
      <td><p>More than 750 million people lack basic reading and writing skills. Saurabh Srivastava, a researcher at <strong>Xerox</strong> <strong>India</strong>, has been prolific in crafting technologies that could eventually make it easy for people with limited literacy to obtain information and use online services by simply speaking into phones or making gestures picked up by inexpensive cameras.</p><p>Building such interfaces is very hard because of the wide variation in cultural norms, not to mention languages and dialects. In some of his most recent work, in the rural Assam province, Srivastava investigated a system pregnant women might use to disclose medical problems to a Web interface that could refer them to free tests and services. The system used a $150 Microsoft Kinect camera to detect arm gestures, which in turn controlled displays of information.The display included animated representations of female health aides to guide the patients. Among the findings: the system should not require any gestural input that involves shoulder movements, since shoulders were often obscured by the women’s saris. And when indicating medical complaints (say, a headache), women didn’t understand why they should point to an on-screen picture of a head, but instead would point to their own head.</p><p>Improving health services this way could make a dent in big problems—such as the fact that nearly 63,000 women in India die in childbirth every year. </p><p>—<em>David Talbot</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-saurabh-srivastava/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Rebecca Steorts</td>
      <td>Big data could cut through the fog of war.</td>
      <td>32</td>
      <td></td>
      <td>humanitarians-2015</td>
      <td><p class="nodropcap"><strong>Problem:<br /></strong> Determining the number of people killed in wars is immensely difficult: chaos, poor communication, and propaganda can wildly distort the figures.</p><p><strong>Solution:<br /></strong> Rebecca Steorts, an assistant professor of statistics at <strong>Duke University</strong>, is using advanced data-analysis techniques to help human rights groups get definitive casualty counts.</p><p>Since the Syrian civil war began in 2011, six private organizations have been building databases of death totals. There is also an “official” governmental tally. But compiling them into one master document is a data nightmare because of duplicates, misspelled names, inaccurate dates, and even wrong genders. One estimate showed that running a basic comparison algorithm on the combined lists would take 57 days. In 2013, Steorts realized that by combining a Bayesian statistical approach with a machine-learning technique called blocking, she could reliably merge the databases<em>—</em>and do it in less than a day.</p><p>Blocking works by placing items that are similar to one another<em>—</em>say, similar names or approximate dates of death<em>—</em>in the same group for comparison. (A simple analogy: if you were trying to compile one whole set of cards out of two incomplete decks, you’d separate them into suits first and then discard the duplicates.) Only after it has assembled the various blocks does Steorts’s software do the intensive work of linking individual records.</p><p>The Human Rights Data Analysis Group, a nonprofit that publishes a death toll for Syria once every year, is testing Steorts’s method to see if it can be incorporated into the estimate it will release in 2016. </p><p><em>—Patrick Doyle</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-rebecca-steorts/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Polina Anikeeva</td>
      <td>A creative scientist sees new ways to record and stimulate brain activity.</td>
      <td>32</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>“For my PhD at MIT, I worked on quantum-dot LEDs, and having zero biological experience, I chose to spend two years in Karl Deisseroth’s neuroscience lab at Stanford. When I saw that they were developing methods to control the brain optically and investigate brain function, I was really blown away. [But] the tools we were using were too large and too bulky, and didn’t have enough capability. Since my background was nano–optoelectronics and nanofabrication, I felt that we should be able to do better. That became the foundation of my lab [at MIT].</p><p>The lab is divided into two main directions. One is using <a href="http://www.technologyreview.com/photoessay/536806/a-swiss-army-knife-for-neuroscience/">fiber fabrication</a> to create neural probes that have multiple functions. The other is to figure out if we can interact with the nervous system in an essentially wireless and noninvasive way.</p><p>Ultimately, you want to figure out how specific patterns of neural activity correspond to specific behaviors. What we’re trying to do is push the resolution of our recording and stimulation capability, which will allow us to decipher those neural circuits. If you’re trying to, say, restore function after spinal-cord injury, if we were able to record signals from both sides [of the injury] and convert them into patterns of stimulation, we would be able to start building a synthetic bridge across that connection. Right now, we would love to work with people and get this technology into as many labs as we can.”</p><p><em>—as told to Courtney Humphries</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-polina-anikeeva/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Gozde Durmus</td>
      <td>It’s amazing what you can learn about a cell when you levitate it.</td>
      <td>30</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>Cells that are dying, turning cancerous, or responding to drugs undergo physical changes. They might become stiffer or squishier. Or they might get heavier or lighter. The instruments for detecting these changes in individual cells are usually complex and expensive, which is why microbiologists still assess the state of a disease by waiting for cells to grow in a lab, and why doctors examine whether a drug is working by waiting to see whether the patient worsens or improves.</p><p>Gozde Durmus has invented a simple, fast method for detecting cells’ telling physical characteristic: making them levitate in a magnetic field and measuring how high they rise. White blood cells, red blood cells, cancer cells, and different bacteria each rise to a different height, because they have a characteristic density that determines the balance between the pull of gravity on the cell and the push of the magnetism. And Durmus has found that when a bacterial cell has responded to an antibiotic, it tends not to rise as high in the magnetic field as it did before. This change can be detected in about an hour, instead of the day traditionally required to determine how a microbe responds to a drug.</p><p>At her bench at the <strong>Stanford</strong> Genome Technology Center, Durmus makes cell-levitating devices by sliding a few laser-cut pieces of plastic over two small bar magnets. This keeps them from flipping and sticking together, so a magnetic field can be created in the space between them. She puts a thin capillary tube into that space. Then she adds two mirrors that will beam an image of the tube up to a conventional microscope. Samples of the cells to be levitated go into the tube along with a solution of gadolinium, an element that’s used as an MRI contrast agent. “It helps the cells fly in the magnetic field,” says Durmus. Their height can then be measured under the microscope.</p><p>Durmus knows from experience how important rapid, personalized drug monitoring could be. When she was a child in İzmir, Turkey, she had a bacterial infection that lasted three years, and she vividly remembers going to the hospital for painful and ineffective penicillin shots until she got the right treatment.</p><p>Her work also has a more whimsical inspiration. In 1997, physicists in the Netherlands used an ultrastrong magnet to levitate a living frog. Subsequent efforts to levitate things in weak magnetic fields—even objects much smaller than frogs—required toxic magnetic solvents. Durmus figured out how to do levitation without toxic materials, using only cheap magnets and some pieces of plastic.</p><p><em>—Katherine Bourzac</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-gozde-durmus/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Gilad Evrony</td>
      <td>Single-neuron genome sequencing is revealing clues about what goes wrong in the brain.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>From studying 300 neurons one at a time, <strong>Harvard Medical School</strong> researcher Gilad Evrony helped make a surprising discovery: brain cells sitting right next to each other don’t always have the same genetic codes. This could provide insight into age-related cognitive decline and brain disorders such as epilepsy and schizophrenia.</p><p>When scientists sequence DNA, they typically examine genetic material from thousands or millions of cells at a time. Decoding the genome of an individual cell is more challenging. Although researchers had done it with cells from other parts of the body, Evrony developed a way to do it with neurons from cadavers. Then he painstakingly mapped the origins of the mutations he found.</p><p>The implications are remarkable. For one thing, finding out the precise location of mutations indicates that some mental disorders can be traced back to just a few bad neurons. Crucially, such mutations apparently are not inherited; they crop up in brain cells during development or over our lifetimes—and accumulate as we age. The rate at which those errors occur is not clear, though, and figuring that out could help explain how cognitive decline sets in and how it might be staved off.</p><p>Such insights appear to be just the beginning of what we might discover by analyzing individual neurons. The National Institutes of Health has organized a consortium of labs that will study several mental disorders using this method, among others. Evrony calls the technology “the brain’s new microscope.”</p><p><span>—</span><em>Julia Sklar</em></p><p><em>This story was updated on August 21 to clarify the nature of the mutations.</em></p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/R1.tr35.vis_.evrony.secondaryx519.jpg" alt=""><figcaption></figcaption></figure>\n<p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-gilad-evrony/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Jeannette Garcia</td>
      <td>A chance discovery sparked a quest for plastics that are both strong and recyclable.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>If Jeannette “Jamie” Garcia hadn’t been so obsessed with understanding what things are made of, she probably would have “red-canned” her big discovery—that is, tossed it in the trash.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.pio_.garcia.secondaryx235_0.jpg" alt=""><figcaption>Top: A material Garcia created that solidifies under ultraviolet light but can become flexible again. </p>\n<p>Bottom: A sample of her super-strong yet recyclable plastic.</figcaption></figure>\n<p>It was the young chemist’s first week at <strong>IBM</strong>, and she had a simple task: mix three ingredients together in a flask and heat them up, the goal being to use one of those ingredients—a solution made from broken-down plastic bottles—as the basis for an even stronger material. After she combined the first two ingredients, she went off to weigh out the third. By the time she got back, the solution had solidified into something so hard that she needed a hammer to break it free. “A lot of people would’ve considered it a failed experiment,” Garcia says. But she adds: “I didn’t really want to just drop it. I wanted to try to figure out what I had made.”</p><p>It turned out that the plastic was not only much stronger than what she had originally been trying to make but entirely recyclable. Those properties made it a promising gateway to desirable new materials.</p><!-- noembed: ad --> <p>Plastics that harden when heated are nothing new; we use them in everything from electronics to airplanes. But these so-called thermosets are not remoldable once hardened and mostly end up as garbage because they are very difficult to recycle. The thermoset plastic that Garcia made, on the other hand, completely reverted to its base compound, or monomer, when soaked in acid. “As chemists,” she says, “if we understand what we’re doing well enough, then we can actually go in and undo it too, in just as efficient a way as we built it.”</p><p>Now, with the right monomers and the right temperatures, Garcia can make both super-strong recyclable plastics and moldable gels that solidify in their desired shape under ultraviolet light. She has nicknamed the first class of materials Titan and the second one Hydro.</p><p>There’s still work to do before they are ready for commercial applications. But now that we know recyclable thermosets are possible, Garcia says, we can think of how they might replace materials we’ve been using for decades.</p><p class="p1">—<em>Suzanne Jacobs</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-jeannette-garcia/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Jun Ge</td>
      <td>Why we might use tiny flowers, trees, and spindles to create the pharmaceuticals of the future.</td>
      <td>32</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>Manufacturing pharmaceuticals is typically a messy business. Catalyzing the necessary chemical reactions often requires toxic solvents and large amounts of energy. Jun Ge hopes to clean up the process substantially by instead harnessing enzymes, nature’s catalysts, to do the work.</p><p>Lots of people have had that idea. The challenge is that enzymes tend not to hold up well in industrial processes, and protecting them by attaching them to other materials greatly lessens their activity level. But Ge, a slender and soft-spoken chemical engineer at China’s elite <strong>Tsinghua University</strong>, had an insight a few years ago. While working as a postdoc at Stanford, he had a hunch that adding copper ions to a solution containing a certain enzyme could help activate and stabilize it. What he didn’t expect to find were the wondrously strange structures that soon precipitated at the bottom of his test tube: “very beautiful structures, like flowers made of protein and crystal.” Significantly, the enzymes held in this extraordinary “nano-flower” shape are stable and seven times more active than when they float freely in a solution. The findings made the cover of <a href="http://www.nature.com/nnano/journal/v7/n7/full/nnano.2012.80.html" target="_blank" rel="noopener noreferrer"><em>Nature Nanotechnology</em> in 2012</a>.</p><p>Today Ge is studying a range of enzyme nanostructures—which he dubs “nano-trees” and “nano-spindles”—and exploring whether they could be used in everything from the production of a cancer drug to a next-generation glucose strip for diagnosing diabetes. </p><p>—<em>Christina Larson<br></em></p>\n<figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/R1.tr35.pio_.ge_.secondaryx519.jpg" alt=""><figcaption></figcaption></figure>\n</td>
    </tr>
    <tr>
      <td>Zhen Gu</td>
      <td>Diabetics are tired of sticking themselves with needles. Someday they may not have to.</td>
      <td>34</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p class="nodropcap"><strong>Problem:<br /></strong> People with diabetes must monitor their blood sugar and inject themselves with insulin several times a day. Even those with insulin pumps risk complications from injecting too much or too little insulin.</p><p><strong>Solution:<br /></strong> Zhen Gu, a researcher at the <strong>University of North Carolina </strong>and<strong> North Carolina State University</strong> whose grandmother died from diabetes complications, is developing insulin delivery mechanisms that could be better. The most recent one is a fingernail-size patch covered in more than 100 microneedles. When you put the patch on your skin, you feel momentary pinpricks as the needles poke into your blood vessels. The needles are full of tiny sacs containing insulin and an enzyme. The sac is just permeable enough to allow glucose inside, where the enzyme converts it to an acid that<em>—</em>when blood sugar is too high<em>—</em>makes the sac open and release the insulin. The sacs fall apart at different rates, so the insulin is released over hours rather than in one burst.</p><p class="p4">When Gu tested the patch on five mice, it controlled their blood sugar for nine hours, although it takes half an hour to work, and people without diabetes naturally regulate their blood sugar much faster than that. Now he has begun testing the patch on pigs, whose thin skin is more similar to humans’. Eventually, Gu hopes, people with diabetes could slap on a patch every two or three days to reliably and precisely control blood sugar without much pain or effort.</p><p><em>—Anna Nowogrodzki</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-zhen-gu/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Elizabeth Mormino</td>
      <td>A telltale protein seen in people’s brains before they have Alzheimer’s could offer a clue about possible treatments.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>Elizabeth Mormino knows it’s too late to save her grandfather, whose Alzheimer’s disease was diagnosed a few years ago. “It’s really hard to see a familiar face go through this, knowing that there’s really no drugs that work right now,” she says. But her work may help future patients by showing an intriguing new path to treating the disease.</p><p>Mormino has figured out a way to combine two imaging technologies to detect the protein beta-amyloid, which is found in patients with Alzheimer’s, and has used them to look at the brains of people with no signs of cognitive decline. Although researchers have already been using one of the imaging technologies, called PIB-PET, to see beta-amyloid in the brains of living patients for a few years, Mormino is able to identify brain regions more accurately by combining PIB-PET and MRI data.</p><p>“I feel like we’re taking snapshots of people’s brains,” she says. “It feels very personal and intimate.”</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.pio_.mormino.secondaryx519.jpg" alt=""><figcaption>These brain scans intrigue Mormino because both come from healthy patients, and yet the one on the right is riddled with amyloid, seen in red.</figcaption></figure>\n<p>The most surprising insight from her work is that some outwardly normal people are “walking around with a head full of amyloid, and oftentimes as much amyloid as somebody who actually has clinical Alzheimer’s disease,” she says.</p><p>How could this be? One hypothesis is that amyloid causes neurons to die, which then causes the clinical symptoms of Alzheimer’s. So by the time patients have Alzheimer’s, anti-amyloid treatment is too late—the protein has already damaged too many brain cells. (Indeed, anti-amyloid drugs have not proved effective at treating Alzheimer’s.) But some of her healthy patients could have protective factors, whether in their genes or in their lifestyle, that allow them to tolerate high amyloid levels without developing Alzheimer’s.</p><!-- noembed: ad --> <p>Understanding such protective factors might “offer some insights into successful aging or the ability to remain resilient,” says Mormino. And there is a chance it could help specifically with Alzheimer’s prevention. To that end, researchers at the University of California, San Diego, and <strong>Massachusetts General Hospital</strong>, where Mormino is an assistant in neuroscience, have started clinical trials in which people who have high amyloid levels but no Alzheimer’s symptoms are getting anti-amyloid infusions to see if that staves off the disease.</p><p>The hope is that eventually Alzheimer’s could be prevented by regularly checking and treating amyloid levels, much the way heart attacks are averted by monitoring cholesterol.</p><p>—<em>Anna Nowogrodzki</em></p></td>
    </tr>
    <tr>
      <td>Michelle O’Malley</td>
      <td>Understanding a tricky kind of single-cell creature could help reduce the cost of biofuels.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>Chemical engineer Michelle O’Malley is trying to figure out how an understudied type of microbe could be harnessed to make better biofuels or pharmaceuticals. O’Malley works with anaerobic microbes—organisms that can’t live in the presence of oxygen, making them extremely difficult to cultivate. In fact, her lab at the <strong>University of California, Santa Barbara</strong>, is the only one in the United States that is able to study the behavior of anaerobic microbial communities.</p><p>Why go to all the trouble? Because these organisms are more efficient than aerobic ones at chewing up plant material and secreting something else, like a biofuel. They also create fewer unintended by-products, which are costly to deal with.</p><p>O’Malley is particularly interested in how different kinds of anaerobic microbes function in concert. Sometimes in such communities, whether in landfills or our guts, microbes work together to attack substances in their midst, while other times they interact peacefully with their environment. Their behavior, it seems, is determined by a complex communication system: microbes can physically attach to each other and exchange nutrients, or they can secrete chemicals into the environment that another microbe can metabolize.</p><p>Understanding this process is the first step in getting anaerobic microbes to churn out more cost-effective fuels or pharmaceutical products—and things we can’t yet imagine. After all, O’Malley explains, many of the enzymes produced in anaerobic microbe communities “perform chemistries never seen before.”</p><p class="p3">—<em>Julia Sklar</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-michelle-omalley/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Aaswath Raman</td>
      <td>Your next air-conditioning system might save energy by beaming heat into outer space.</td>
      <td>30</td>
      <td></td>
      <td>pioneers-2015</td>
      <td><p>Aaswath Raman holds a thin, silvery disc. It looks like a very clean mirror, but it’s hardly ordinary: it gets colder under direct sunlight and stays about 5 °C cooler than the surrounding air.</p><p>Raman is a practical person with a gentle personality; his button-down shirt and flip-flops blend in on the campus of <strong>Stanford</strong>, where he is a postdoctoral researcher. This mirror, he calmly explains, has a coating that sends heat into the vastness of outer space—which could make it ideal for air-conditioning and refrigeration systems that would require very little or no electricity.</p><p>The cooling material takes advantage of a fascinating phenomenon. Objects are always cooling down by radiating heat—this is why dew forms on blades of grass at night. Some of the radiation occurs at frequencies that send the energy right through Earth’s atmosphere and into space, allowing the object’s temperature to drop below that of the surrounding air.</p><p>During the day, the sun’s heat usually overwhelms the cooling effect. But while reading through old papers on the subject from the 1960s, Raman thought of a way around that. He applied his knowledge of nanoscale manufacturing techniques that didn’t exist decades ago to make something with optimum levels of thermal radiation and solar reflection. It is a multilayered film of hafnium dioxide, silica, and other materials deposited at carefully controlled thicknesses. It can be made over large areas using the same manufacturing techniques that are used to coat windows.</p><p>Coating the roof of a small structure with some of his material would wick heat away and keep the inside cool without electricity, as long as the roof wasn’t insulated. Since most buildings in developed areas have insulated roofs, Raman is working on integrating the material into existing air-conditioning infrastructure. He has a prototype on the roof of Stanford’s Packard Electrical Engineering Building. It is made up of a sheet of the passive cooling material about a square meter in area, mounted in a custom-machined plexiglass box patterned with water channels. In a finished system, the water would circulate through the building air-conditioning system, then go into the cooler box to chill and back into the building system. However, he still needs to demonstrate that his prototype can chill a substantial volume of water.</p><p>He has already partnered with a manufacturer that can produce large sheets of the cooling material for further development. He jokes that many researchers in his branch of physics tend to stay in their labs all day and “don’t like to go outside.” But he adds: “If you just go outside, there’s opportunity.”</p><p>—<em>Katherine Bourzac</em></p><p>   <span>Watch this Innovator at EmTech 2015</span><br /><a href="http://www.technologyreview.com/emtech/15/video/watch/innovators-under-35-aaswath-raman/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Emily Cole</td>
      <td>Can we cheaply convert carbon dioxide into something useful?</td>
      <td>31</td>
      <td></td>
      <td>inventors-2014</td>
      <td><p>As the chief science officer of a startup called Liquid Light, Emily Cole is attempting to accomplish something that has long thwarted chemists: finding an economical and practical way to turn carbon dioxide, the chief culprit in greenhouse warming, into useful chemicals.</p><p>The idea that could make this possible came from a visit to the Princeton University lab of Andrew Bocarsly. Back in 1994, Bocarsly had published an intriguing but largely ignored paper reporting a way to convert carbon dioxide into methanol without using a lot of energy. Bocarsly couldn’t get funding to pursue the research, and the work sat on the shelf until he mentioned it to Cole. She was fascinated and decided to join his lab as a graduate student.</p><p>Cole kept tinkering with different catalysts and conditions, increasing the yields of the reactions and learning how to produce other valuable chemicals. The researchers have gone on to show they can convert carbon dioxide into isopropanol, acetone, and more than 30 other chemicals. Moreover, they have shown that light can be used to drive the reactions.</p><p>In 2009, Cole and Bocarsly cofounded Liquid Light in Monmouth Junction, New Jersey. The company is working to scale up the conversion process and hopes to market ethylene glycol, a chemical widely used to make plastics, as soon as 2017.</p><p>—<em>Stephen S. Hall</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-emily-cole/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Tanuja Ganu</td>
      <td>Simple devices allow consumers to cheaply and easily monitor India’s rickety power grid.</td>
      <td>31</td>
      <td></td>
      <td>inventors-2014</td>
      <td><p>Using the small box plugged in between a wall socket and an appliance, Tanuja Ganu can tell you when the electric grid in India is likely to shut down. Sensors inside the device, called nPlug, detect the voltage and frequency of the incoming electricity; analyzing that data over time, the box can determine the periods of maximum power demand on the grid and predict when the need for power will exceed the supply. With that information, the box can schedule when to run water heaters and dishwashers to avert outages, allowing utilities to more easily meet peak demand.</p><p>Ganu hopes that the simple data-­harvesting gadget and others she is developing will help India’s consumers navigate the country’s notoriously unreliable power system. Growing up in a small town in India, she studied for exams by candlelight and endured hot days with no fan or air conditioner because the power would shut off for hours with no warning.</p><p>She joined IBM Research in Bangalore in 2011 and quickly understood that the basic premise of the so-called smart grid—a two-way connection between consumers and the grid that helps optimize the production and consumption of power—is a nonstarter in her home country. “If you build any solution that requires computation and communications, that’s not going to be practical for many developing countries,” she says.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.inv_.secondaryx235.jpg" alt=""><figcaption>Tanuja Ganu’s boxes are a simple way to monitor unreliable power grids.</figcaption></figure>\n<p>Instead, she’s designed devices that work autonomously. In tests, nPlug is able to infer the status of the grid using simple pattern-recognizing algorithms and a few weeks’ worth of data. For example, voltage dips during spikes in demand, such as morning hours and early evenings. The device can also identify when outages are likely to occur: the frequency of the electric current drops substantially when grid operators can’t supply enough power.</p><p>If deployed widely, these simple gadgets could help address India’s energy deficit without requiring expensive infrastructure investments. “With the amount of data available, there’s a lot we can still do with the available power,” says Ganu.</p><p>—<em>Martin LaMonica</em></p></td>
    </tr>
    <tr>
      <td>Shyam Gollakota</td>
      <td>An expert on wireless technology figures out how to power devices without batteries.</td>
      <td>28</td>
      <td></td>
      <td>inventors-2014</td>
      <td><p>The energy demands of wireless devices have held back the spread of cheap sensors that could be monitoring our homes, the environment, and physical infrastructure such as bridges. Shyam Gollakota has an ingenious solution—a way for these wireless devices to operate without batteries.</p><p>Gollakota’s prototypes use the fog of radio noise that surrounds us from TV stations, cell towers, and other sources as an energy supply and a means of communicating. By absorbing and reflecting those ambient signals, the devices can send messages to one another and even link to the Internet.</p><p>When Gollakota became an assistant professor in the wireless lab at the University of Washington in 2012, he joined a team already working on using ambient radio waves as an energy source. The group had found ways to power simple sensors such as those used for measuring temperature and humidity. But transmitting that data is more challenging. The researchers’ devices stored up the trickle of harvested power and occasionally sent out data using a transmitter.</p><p>Gollakota saw that a better solution lay in skipping the conventional, power-­hungry transmitter. His battery-free devices—the latest prototype is half the size of a credit card—have antennas that switch between reflecting and absorbing ambient radio signals. In the absorbing mode, they collect enough energy to power chips, sensors, LEDs, and even black-and-white displays. In the reflecting mode, they scatter ambient radio signals in a way that nearby devices can detect. The design makes it possible to deploy battery-free sensors or other devices just about anywhere at low cost, Gollakota says.</p><p>His latest prototypes can send and receive signals over 20 meters and between different rooms in a building. They can also connect to the Internet, by communicating up to two meters over Wi-Fi with smartphones or home routers.</p><p>Gollakota believes that eventually his energy-scavenging designs will make it possible for ambient radio waves to power stripped-down devices. Many poorer parts of the world lack reliable electricity sources but have strong cellular coverage. Even “a primitive computer or device that can only send e-mails by harvesting these signals,” he says, could be valuable.</p><p>—<em>Tom Simonite</em></p></td>
    </tr>
    <tr>
      <td>David He</td>
      <td>This watch could finally get your blood ­pressure under control.</td>
      <td>28</td>
      <td></td>
      <td>inventors-2014</td>
      <td><p>David He wants to change how we manage our own health. But at first, he was just trying to find a noninvasive way for hypertension patients to continuously keep tabs on their blood pressure. It was 2009, and He, then a graduate student at MIT, figured people might be helped by a wearable gadget that could record an <a href="http://www.nhlbi.nih.gov/health/health-topics/topics/ekg/" target="_blank" rel="noopener noreferrer">electrocardiogram</a>—a measure of the heart’s electrical activity also known as an ECG.</p><p>Since the ear is a good place to monitor the body’s physiology and pretty easy to hook a device to, He started there: he bought a hearing aid on eBay, removed its guts, and added his own electronics. After doing a lot of jumping jacks and other exercises while wearing the gadget, He looked at the data and saw something odd: a signal that looked similar to an ECG, but with a sharp peak.</p><p>There were other weird things, too. The signal was larger than the one from an ECG gathered simultaneously from a heart-rate monitor on his chest, even though the ear was farther away from the heart, and it was noticeably delayed from the chest ECG. As it turned out, what He tracked was actually a ballistocardiogram, or BCG, which is a mechanical signal indicating the tiny body movements that result as the heart pumps blood. First spotted in the 1870s, it gives a more direct view of the heart’s mechanical performance than an ECG can, capturing the strength and timing of a person’s heartbeats. But it fell out of favor over time, in part because it was difficult to track.</p><p>In 2012, He cofounded <a href="http://www.quanttus.com/" target="_blank" rel="noopener noreferrer">Quanttus to build</a> a watch-like gadget. There are plenty of wristbands already on the market that track things like steps taken and calories burned, but they don’t measure vital signs like heart rate and blood pressure as accurately as Quanttus expects a BCG-based device to do. An optical sensor on the underside of the wristband shines light onto the skin and keeps track of the tissue’s selective light absorption, detecting volumetric changes in blood vessels that occur with each heartbeat. This information can be used to deduce heart rate, while an accelerometer measures the body movements that occur as a result of heartbeats.</p><p>Though the wristband doesn’t yet have a release date, Quanttus has tested it at Massachusetts General Hospital in Boston. The results have been encouraging enough to help the company raise $22 million in venture capital.</p><p class="p1">—<em>Rachel Metz</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-david-he/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Jinha Lee</td>
      <td>Finding more powerful ways to manipulate and interact with digital data.</td>
      <td>27</td>
      <td></td>
      <td>inventors-2014</td>
      <td><p>“I’m keen to explore better ways to interact with data and environments,” says Jinha Lee. “What would be the tools that help us think better? What would be the tools that help us reflect ourselves better?” Statements about his research often come after a pause of 15 to 20 seconds; it is, he says, the time he needs to picture his thoughts in images and translate them into words.</p><p>Among the projects Lee worked on as a graduate student at the MIT Media Lab is one he began developing as a research intern at Microsoft Applied Sciences Group; it is a 3-D desktop that allows a user to “reach inside” the screen, flipping through digital documents and windows. He also created a physical pixel that levitates and moves freely about, allowing users to physically manipulate data in three-­dimensional space.</p><p>Lee, who is from South Korea, cultivated his algorithmic and artistic sense by making origami with his mother, a professional teacher of the art form. These days, as leader of the Interactive Visualization Lab at Samsung Electronics in Suwon, Korea, he is working on user interfaces for the company’s next-generation products, including its interactive TVs.</p><p>—<em>Yewon Kang</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-jinha-lee/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Maria Nunes Pereira</td>
      <td>Patching holes in the hearts  of sick infants.</td>
      <td>28</td>
      <td></td>
      <td>inventors-2014</td>
      <td><p class="nodropcap"><strong>Problem:</strong><br />Each year, an estimated 40,000 babies in the United States alone are born with congenital heart defects. Some are treated with open-heart surgery, which is invasive and can be risky. Sutures or staples are used to close the holes between the chambers of the heart, but these can damage the fragile tissue. Additional surgery may also be needed as the tissue grows.  </p><p><strong>Solution: <br /></strong>Maria Nunes Pereira has created a biocompatible glue that a surgeon could use to patch the holes in the hearts of these infants. It can be applied and activated during a minimally invasive procedure. And the adhesive is strong and flexible enough to work in one of the harshest environments in the body—inside a beating heart. Unlike sutures and staples, the glue doesn’t harm the tissue when it’s applied to the heart, and it doesn’t need to be replaced as the child grows. </p><p>Pereira developed the glue as a graduate student in the MIT-Portugal program; working with a team of surgeons at Brigham and Women’s Hospital in Boston, she demonstrated the adhesive inside a beating pig heart. The procedure required only a single incision. Today, she works at a startup called Gecko Biomedical in Paris, where she is hoping to adapt the technology to human patients within the next two years. </p><p>The material could be used in other parts of the body where repairs are invasive or require potentially damaging sutures. “I think these materials have potential to change how surgery is performed and how defects in the body are closed,” she says. </p><p><em>—Alexandra Morris</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-maria-nunes-pereira/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Tak-Sing Wong</td>
      <td>Carnivorous plant inspires solution to “sticky” problems.</td>
      <td>33</td>
      <td></td>
      <td>inventors-2014</td>
      <td><p>Tak-Sing Wong has invented one of today’s most intriguing and potentially useful new materials. Called SLIPS, for “slippery liquid–infused porous surface,” it repels any type of liquid, from oil to water to blood, and prevents organisms like bacteria and barnacles from sticking. </p><p>The range of possible applications for the new material is wide: it could be used to coat medical devices such as catheters to decrease the potential for bacterial contamination or cover the hull of a ship to prevent barnacles from adhering to the surface. </p><p>Working at the Wyss Institute for Biologically Inspired Engineering at Harvard University, Wong modeled the SLIPS material after the carnivorous pitcher plants<em> Nepenthes</em>, which produce a surface that can upend even the oily feet of an ant and send the bug hydroplaning into the stomach of the plant. He assembled micro- and nanoscale structures and filled the empty spaces within the structures with a lubricant that repels both liquids and solids, including ice and bacterial biofilm.</p><p>Now an assistant professor of mechanical engineering at Pennsylvania State University, Wong continues to invent novel materials based on nature’s inspiration. He hopes to develop wearable devices with camouflage capabilities or gadgets that use a gecko’s ability to adhere to walls. “Like Spider-Man, we could walk on walls,” he says, “or [use] camouflage like a chameleon that can change color on demand.”</p><p>—<em>Alexandra Morris</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-tak-sing-wong/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Fadel Adib</td>
      <td>Here’s how you can use Wi-Fi to track people moving around in other rooms.</td>
      <td>25</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p>“I was born in Tripoli, Lebanon, in 1989. At the time, there was much political violence. The Lebanese civil war ended a year later. Unfortunately, the postwar stability did not last long. When I went to the American University of Beirut, I remember we used to have assassinations or bombings almost every week. When I came to MIT as a PhD student in the Computer Science and Artificial Intelligence Lab, the first thing that shocked me was that I could focus all the time on research.&nbsp;</p>  <p>“In one of our projects, we were just making our Wi-Fi faster by maximizing throughput between nodes. Every once in a while, the system would get messed up, and we would stop getting good results. We realized that there was some person walking in the hallway, and that person’s walking was basically changing the channel.&nbsp;</p>  <p>“If I shine a wireless signal at the wall, a huge amount of this signal is going to reflect off the wall. A tiny part of that signal will traverse the wall, reflect off anything that’s behind it, and then come back. We realized that we can sense motion using these wireless signals, and that’s how we started working on seeing through walls.</p>  <p>“You can track people as they move. You can monitor multiple people’s heart rates and breathing. Retail stores that want to understand how people are moving in their stores can track when a person reaches out for a product, looks at it, and puts it back. The police could track if there’s a person behind a wall. One of the applications we’re thinking of: can you monitor the heart rate of a fetus in the mother’s womb without touching the body in any way?&nbsp;</p>  <p>“When I went home to Lebanon and I was talking to my grandmother about it, she was like, ‘So, for example, can I put it over here in my living room, and if I fall in the bedroom or in the bathroom, it’s going to going to detect my fall and send an SMS to one of my children? Please, make this a product and put it here.’”&nbsp;</p>  <p><em>—as told to Suzanne Jacobs</em></p>  <p>   <span>Watch this Innovator at EmTech 2014</span><br><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-fadel-adib/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Miles Barr</td>
      <td>The CEO of a solar startup hopes you never see his product.</td>
      <td>30</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p>Miles Barr shows me into a hot and sunny conference room. He opens a metal case and reveals neat rows of e-readers, smartphones, and tablets.</p><p>Barr hands me two of the phones, each displaying the same colorful picture of a tree, and says one of them is getting electricity from a solar panel on its screen. I squint at them, trying to tell them apart, but I can’t. The same holds for device after device in his case. Even indoors, his e-reader, which requires much less power than the phones, is getting enough energy from the see-through photovoltaic coating to make plugging it in totally unnecessary.</p><p>The see-through panels aren’t yet on the market, but it’s easy to tell that they’d be a hit. Although you can already buy phones with solar cells on the back, they generate power only if you leave them face down. These transparent solar cells work as you use the device normally.</p><p>Barr’s solar cells can’t be seen because they are made of dye-like molecules that absorb wavelengths of light humans can’t see, letting visible light pass right through. In 2011, he cofounded a company called Ubiquitous Energy to develop the technology, starting with solar cells that could still be seen faintly on the screen. Since then, the startup has gotten them effectively invisible and made them efficient enough for low-power applications like e-readers and watches. Now it is trying to improve the reliability of the manufacturing process so the coatings can be integrated into existing assembly lines for electronic devices.</p><p>Barr pairs his inventiveness with a flair for salesmanship. In grad school he showed off solar cells printed on paper by folding the sheet into a paper airplane and attaching electrical leads to demonstrate that it could generate electricity. His demos have helped raise $8 million for Ubiquitous Energy, which recently left the Cambridge Innovation Center near MIT to set up shop in Silicon Valley.</p><p>Barr thinks he can go well beyond powering portable electronics. In his demonstration he holds up two sheets of window glass, one equipped with his invisible solar cells. By absorbing infrared and ultraviolet light, windows with this technology could help keep a room cool and generate power.</p><p>—<em>Kevin Bullis</em></p><p><iframe src="//www.youtube.com/embed/en0e2LxjOTA" frameborder="0" width="480" height="270"></iframe></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-miles-barr/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Ayah Bdeir</td>
      <td>Electronic blocks that link with one another also connect art and engineering.</td>
      <td>31</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p>Growing up in Beirut, Ayah Bdeir was taught that art and engineering occupied separate realms. “In Lebanon, as in most of the world, there is little blurring of the boundaries between the professions: doctor, teacher, scientist, and designer exist in separate silos,” she says. The company she founded in 2011, called LittleBits Electronics, goes against that idea by making technology accessible across all disciplines and ages. It sells a library of modular electronic units that can be easily connected for projects as diverse as a sound machine, a night light, or a lifelike robotic hand.</p><p>LittleBits makes roughly 50 different modules, which cost up to $40 each or come in kits of $99 and up. Each module is a thin rectangle measuring between one and four inches in length and containing complex hidden circuitry. Blue modules provide power. Pink ones allow for inputs, like switches, microphones, and motion sensors. Green ones are for outputs like lights, motors, and speakers. Orange ones provide wires or logic functions. Bdeir designed all the modules so they fit together magnetically, ensuring that users join circuits correctly.</p><p>Her New York–based company has sold hundreds of thousands of units in about 80 countries, and Bdeir takes pride in the fact that the product appeals to girls and boys, children and adults, designers and engineers. “A screwdriver is a screwdriver for everybody,” she says. “It doesn’t matter who you are or how you use it. Every person will find what they want.”</p><p>—<em>Amanda Schaffer</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-ayah-bdeir/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Rand Hindi</td>
      <td>Guiding your life using the power of big data.</td>
      <td>29</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p>Rand Hindi once put on more than 70 pounds just to see if data could help him take the weight off. He tracked every aspect of his life—what he ate and drank, how long he slept—and fed the results into software that determined which behaviors were bad for him. Sure enough, after heeding the software’s advice, he lost the weight.</p><p>Now what Hindi wants to reduce is the “friction” of urban life. In 2012 he founded a Paris-based company called Snips, which analyzes data in hopes of making city living more efficient. For example, Snips partnered with France’s national railway to create an app that predicts up to three days in advance how crowded different trains will be. By mining such sources as weather information, historical passenger counts, and real-time check-ins from users of the app, it can advise people to stay away from particular stations or guide them to trains with more seats available. Now Snips is developing ways to use an urbanite’s context—location, weather, interests—and deliver useful information before he or she even asks for it.</p><p>—<em>Suzanne Jacobs</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-rand-hindi/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Aaron Levie</td>
      <td>The founder of Box wants to reconfigure the way we work.</td>
      <td>29</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p>He has come a long way since the fifth grade, when he sold cloth bags filled with rice as heating pads to soothe sore muscles—only to recall the product when the twist ties used to seal the bags burst into flames in customers’ microwaves. Today, Aaron Levie is CEO of Box, a company that he founded in 2005; it is now on the verge of an IPO.</p><p>Box is often described as being like Dropbox for businesses: it makes it easy to store files in the cloud. But Levie envisions something <a href="http://www.technologyreview.com/news/522081/the-continuous-productivity-of-aaron-levie/" target="_blank" rel="noopener noreferrer">bigger than mere file sharing</a>. Because Box offers features such as electronic signatures and tools that aid regulatory compliance, he views it as a platform for connecting people not just inside companies but also across entire industries—suppliers, partners, customers, contractors, and so on. “Maybe we can save 10 percent of an employee’s time, but the organization as a whole is moving 20 percent faster, and it’s working with a new network of partners,” he says. “At each level the change becomes more ­transformative.”</p><p>High-profile clients such as General Electric validate the power of this idea. The sprawling company is using Box to keep employees in 170 countries on the same page. </p><p><em>—Ted Greenwald</em></p><p> <iframe width="480" height="270" src="//www.youtube.com/embed/Q4WdJZx5am8" frameborder="0" allowfullscreen=""></iframe>  </p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/aaron-levie-mobile-collaboration/" target="_blank" rel="noopener noreferrer">Mobile Collaboration</a></p></td>
    </tr>
    <tr>
      <td>Alex Ljung</td>
      <td>SoundCloud is changing how music gets made.</td>
      <td>32</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p><strong>Q: How did you come to create a service that is like a YouTube for music, letting people upload and embed tracks, find new artists, and leave comments while listening to songs?</strong></p><p>A: After high school, I started working as a sound designer in a postproduction studio in Stockholm. I would do sound effects and music for movies and for TV. [When] I started studying engineering at the Royal Institute of Technology in Stockholm, that’s where I met Eric [Wahlforss], my cofounder, who it turned out had a very similar background. We were both recording and creating music and sound, and we just didn’t have a good way of being able to share it with each other and then get some feedback on it. </p><p><strong>Q: In the beginning, a small group of musicians used SoundCloud to share their songs. Now it reaches more than 250 million listeners per month. How are they using it?</strong></p><p>A: What’s really cool about it is that it affords a lot of different user experiences. We have somebody who might just open up their phone and say “Oh great, there’s a brand-new track from 50 Cent. I just want to listen to this one now and enjoy it.” And then on the other side of the spectrum, you have these more intense engagements. Snoop Dogg has used it to find a bunch of artists that he wants to work with. He found this artist Iza Lach from Poland and signed her to his record label.</p><p><strong>Q: How is this reshaping the music business?</strong></p><p>A: We have people who could be anywhere in the world at the moment, creating a completely new genre that hasn’t been known before, and within a very short amount of time, that may be the biggest thing in the world. I still think it’s amazing that not even two years ago Lorde was just a young artist in New Zealand that nobody knew of. And [after releasing her first songs through SoundCloud] all of a sudden she’s one of the largest stars in the world, topping all the charts. That kind of speed is something that is really interesting.</p><p><em>—Kristin Majcher</em></p><p> <iframe width="480" height="270" src="//www.youtube.com/embed/waoLduHy0ZE" frameborder="0" allowfullscreen=""></iframe></p></td>
    </tr>
    <tr>
      <td>Palmer Luckey</td>
      <td>If you can make virtual reality affordable for consumers, things fall into place.</td>
      <td>21</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p>Palmer Luckey grew up mesmerized by the transcendent virtual reality depicted in&nbsp;<em>Star Trek</em>&nbsp;and&nbsp;<em>The Matrix</em>. But when his video screen faded to black, he was back in the real world, where virtual technology remained trapped in niche ­applications.</p><p>So Luckey, a self-taught engineer who had been exploring technology journalism in college, began tinkering. In 2009 he hacked together his first prototypes of a virtual-reality headset in his parents’ basement. He eventually called it the Oculus Rift and&nbsp;posted designs to Internet forums. In 2012, John Carmack, the creator of the Doom and Quake video-game franchises, took notice, and the two began an online dialogue. Luckey sent Carmack a prototype, which Carmack demonstrated at the E3 video-gaming conference. Then things really heated up. Luckey tried raising $250,000 for Oculus Rift on Kickstarter and got $2.5 million.&nbsp;A year later Oculus, based in Irvine, California,&nbsp;received $91 million in venture capital. Software developers began producing games for the Rift, which is expected to hit the market by 2016 for about $300. And in March, Luckey sold his&nbsp;startup to Facebook for $2 billion.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.ent_.secondaryx235.jpg" alt=""><figcaption>The Rift, shown here in a rendering, has inspired Sony to make a rival device.</figcaption></figure>\n<p>For Luckey, it’s just a matter of reality finally catching up with the imagined possibilities. “The sale might have been mind-boggling two years ago,” he says. “It’s less so now after we’ve shipped about 70,000 development kits. It’s very clear that virtual reality is going to take off. I think people are going to look back and actually think it was a very low price to get a foot in the door on that VR future.</p><p>“We’re going to get to the point where virtual reality is indistinguishable from reality itself. And much sooner than that, we’re going to have the visual side indistinguishable from reality. It’s going to take longer to get all of the other senses working, but it’s a clear path. What we say around the office is: virtual reality isn’t the next platform, it’s the final platform. Once it’s perfect, you won’t need to perfect any other platform. That’s going to change the way artists work with content and how they create.</p><p>“This is beyond gaming. You can have education. You can put people anywhere in the world, not just as it exists today, but as it existed in the past. You can put people in a concert, you can put people courtside at any sports game, you can hover above the playing field. Things are a long way off in terms of being perfect, but we have a road map.”</p><p>—<em>Adam</em>&nbsp;<em>Popescu</em></p><p> <iframe width="480" height="270" src="//www.youtube.com/embed/cs58OrTG6LU" frameborder="0" allowfullscreen></iframe></p></td>
    </tr>
    <tr>
      <td>Michael Schmidt</td>
      <td>There aren’t enough data  scientists to go around—unless you automate them.</td>
      <td>32</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p class="nodropcap"><strong>Problem:<br /></strong>Demand for statisticians and data experts outstrips supply. The shortfall in the U.S. alone could reach 190,000 workers by 2018, <a href="http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0CCsQFjAC&url=http%3A%2F%2Fwww.mckinsey.com%2F~%2Fmedia%2FMcKinsey%2Fdotcom%2FInsights%2520and%2520pubs%2FMGI%2FResearch%2FTechnology%2520and%2520Innovation%2FBig%2520Data%2FMGI_big_data_full_report.ashx&ei=r6apU8jnO8TUsAToj4HgDw&usg=AFQjCNEJyZHEjRELMRKoDqUgW1FR6PgxrA&sig2=12m_B03Nsm-izPxOSZN5fA&bvm=bv.69620078,d.cWc" target="_blank" rel="noopener noreferrer">according to estimates by McKinsey & Company</a>. </p><p><strong>Solution: </strong><br />Michael Schmidt has created an automated data scientist that can take in observations about the world and spit out theories to explain them. </p><p>Schmidt <a href="http://www.sciencemag.org/content/324/5923/81.abstract" target="_blank" rel="noopener noreferrer">showed it could be done</a> in 2009. He then wrote software that could examine raw data and derive laws of physics, like the one that describes the swinging of a pendulum. </p><p>Since then Schmidt has refined the software, named Eureqa, so that it can handle more than just physics questions: <a href="http://arxiv.org/pdf/1302.5129.pdf" target="_blank" rel="noopener noreferrer">astronomers</a> have used it to characterize galaxies, and doctors have used it to predict <a href="http://www.nutonian.com/assets/nutonian-appendicitis.pdf" target="_blank" rel="noopener noreferrer">which children will have acute appendicitis</a>. Since 2011, Schmidt has been running a startup, Nutonian, that offers the software to business users who aren’t math experts. It hopes to win over businesses like the retailer Lowe’s, which has piles of sales data and yearns to uncover equations that might help it sell more gas grills or two-by-fours. “The people with the skills are going to Google or SpaceX or to Wall Street, not to home-improvement chains,” says Schmidt. “Our mission is to help with that, and show that you don’t need to be a data scientist to make useful discoveries.” </p><p><em>—Antonio Regalado</em></p></td>
    </tr>
    <tr>
      <td>Bret Taylor</td>
      <td>The former CTO of Facebook is reimagining the word processor.</td>
      <td>34</td>
      <td></td>
      <td>entrepreneurs-2014</td>
      <td><p>At 34, Bret ­Taylor already has one of the most impressive résumés in Silicon Valley. He has been a creator of Google Maps; a cofounder of FriendFeed, one of Facebook’s earliest acquisitions; a creator of Facebook’s ubiquitous “Like” button; and Facebook’s chief technology officer. He is one of those rare engineers who are equally comfortable writing code and taking a stage to tell people about it.</p><p>Yet even the best engineers and entrepreneurs mess up, and that’s where my mind went when I learned of Quip, his latest venture. Quip is rethinking the word processor and other aspects of the “productivity software” that Microsoft has dominated for a generation. Apple and Google have made small inroads into Microsoft’s Office empire during the past half-decade, but their marketing and software development budgets are effectively unlimited. Why would a startup try it?</p><p>Taylor understands—even embraces—the skepticism. But what gives Quip a chance against the likes of Microsoft, Apple, and Google is that the rapid shift from desktop and laptop PCs to tablets and smartphones is changing what consumers want from their software, and Quip wasn’t conceived for a desktop- or laptop-dominated world. It is meant for people who often collaborate on documents while away from a desk in a traditional office, possibly on many separate devices over the course of a day (see “<a href="http://www.technologyreview.com/featuredstory/526526/mobile-collaboration/" target="_blank" rel="noopener noreferrer">10 Breakthrough Technologies: Mobile Collaboration</a>,” May/June). Today, we might use a combination of e-mail, file attachments, and instant-messaging streams to deal with this. Quip puts all those functions in one place, keeping track of who changed what in a document and who said what about those changes. It makes it possible to have quick back-and-forths with a group of people without dragging them into a meeting room or setting up a conference call.</p><p>Many people thought Taylor was being irrational when he left Facebook. Though he’d made millions in its IPO, he left more on the table by leaving. But ­Taylor knew exactly what he wanted next on his résumé. “I had influence at Facebook,” he says, “but at the end of the day I was executing someone else’s strategy.”</p><p> —<em>Fred Vogelstein</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/bret-taylor-mobile-collaboration/" target="_blank" rel="noopener noreferrer">Mobile Collaboration</a></p></td>
    </tr>
    <tr>
      <td>Rumi Chunara</td>
      <td>Crucial information about disease outbreaks can be gleaned earlier.</td>
      <td>32</td>
      <td></td>
      <td>visionaries-2014</td>
      <td><p class="nodropcap"><strong>Problem:<br /></strong>Our systems for detecting outbreaks of disease are unreliable. Typically, word of outbreaks bubbles up as patients see health professionals, who report cases to authorities. Those authorities often can’t piece the reports together in time to prevent significant numbers of other people from getting sick.</p><p><strong>Solution: </strong><br />Rumi Chunara, a researcher at Boston Children’s Hospital and Harvard Medical School, is mining social media and other online sources for information outside of medical settings. </p><p>In one study, Chunara found that a rise in cholera-related Twitter posts in Haiti correlated with an outbreak of the disease. “That’s important, because it takes the ministry of health in Haiti a couple of weeks to get their data aggregated,” she says. In future outbreaks, tweets could help direct medical workers earlier and ensure that supplies like water purification tablets get where they’re needed. </p><p>Chunara knows that digital disease detection is not necessarily better. For instance, researchers have spotted inaccuracies in Google’s Flu Trends service, which analyzes Web searches and estimates the pervasiveness of the flu. But her goal is not to supplant the traditional chain of command in public health; instead she is augmenting it with new tidbits of information.</p><p>To get beyond what might be found from social media, she offered two-cent rewards to people in India who completed a survey about malaria, generating information that could guide deployment of diagnostic and treatment kits. For the United States, she helped develop Flu Near You, a site that creates flu maps based on user-submitted information about symptoms and diagnoses. She’s showing that you can get good data even from people who haven’t seen doctors.</p><p><em>—Courtney Humphries </em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-rumi-chunara/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Severin Hacker</td>
      <td>A novel approach to learning languages is making the Web more accessible.</td>
      <td>30</td>
      <td></td>
      <td>visionaries-2014</td>
      <td><p>In 2009, Severin Hacker and Luis Von Ahn were holed up in the computer science department at Carnegie Mellon University, turning over a seemingly impossible challenge: how to translate all one trillion pages on the Web, which are mainly in English, for people who speak other languages.</p><p>Neither Hacker, a native of Switzerland who was then a PhD student, nor Von Ahn, who was raised in Guatemala and served as Hacker’s advisor, was very impressed with the options. Feeding Web pages into Google Translate usually generated gobbledygook, while trying to hire enough translators was impossible. “Translating is a task that people don’t want to do,” Hacker says. “It is work.”</p><p>So Hacker made a game out of it. Known as Duolingo, it teaches foreign languages to anyone with a smartphone or an Internet connection, for free. Unlike most language classes, with their reliance on rote memorization, Duolingo offers constant interaction. You respond to multiple-choice questions and complete sentences by typing in answers, and you practice phrases by speaking into the microphone. If you answer incorrectly, the app shows you where you went wrong; if you make too many mistakes in a section, you’ll have to repeat it. Each course takes around 35 hours to complete and promises intermediate-level proficiency.</p><p>But the real genius of Duolingo is the way it solves the problem that first stumped Hacker and Von Ahn. When you reach the highest levels of a course and translate sentences into the language you’re learning, Duolingo compiles your work with that of other students. That aggregated work tends to produce accurate translations, and media companies such as Buzzfeed and CNN are paying Duolingo—now spun out as a company, with Hacker as CTO—for foreign translations of their English Web pages.</p><p>Duolingo offers courses in 30 languages and counts 30 million users. Hacker himself recently used it to learn Spanish in order to travel to Guatemala for Von Ahn’s wedding. Relying just on the app’s lessons, he navigated the airport, hotel, and restaurants, read the newspaper, and got a haircut. “Ten minutes of Duolingo,” he says, “is worth, like, an hour of class.” </p><p><em>—Patrick Doyle</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-severin-hacker/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Sarah Kearney</td>
      <td>A financial innovator is crafting a way for foundations to invest in clean energy.</td>
      <td>29</td>
      <td></td>
      <td>visionaries-2014</td>
      <td><p>Sarah Kearney wants philanthropists to act more like venture capitalists.</p><p>She’s created a nonprofit called Prime Coalition to help private foundations invest in energy-related startups. Given that venture funding for clean energy technologies has dropped substantially in the past few years, Kearney’s idea could open up a source of much-needed capital from long-term backers.</p><p>Radically new energy technologies have proved too risky for most private—and even government—investors. But foundations might not mind those risks, and they need to give away a small portion of their endowments every year if they are to maintain their tax-exempt status. Why not use it to fund companies whose primary goal is fighting climate change?</p><p>So far, seven foundations have bought into her vision, giving her money to fund Prime Coalition. Next, she hopes to facilitate deals between philanthropists and startups working in renewable energy, energy storage, and related technologies.</p><p>Creating the necessary legal and financial structures is a long, complex process. There are potential pitfalls, too. If a startup gets money from a chari­table foundation and private investors, will the foundation’s social mission be at odds with the goals of the profit-­seeking capitalists? But Kearney says foundations that want to do something about climate change should be involved with technology startups somehow. “Nothing is going to happen at scale unless people are making money,” she says.</p><p>—<em>Martin LaMonica</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-sarah-kearney/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Quoc Le</td>
      <td>Frustration with waiting for computers to learn things inspired a better approach.</td>
      <td>32</td>
      <td></td>
      <td>visionaries-2014</td>
      <td><p>Growing up in rural Vietnam, Quoc Le didn’t have electricity at home. But he lived near a library, where he read compulsively about great inventions and dreamed of adding to the list. He decided around age 14 that humanity would be helped most by a machine smart enough to be an inventor in its own right—an idea that remains only a dream. But it set Le on a path toward pioneering an approach to artificial intelligence that could let software understand the world more the way humans do.</p><p>That technology sprang from the frustration Le felt at the Australian National University and then as a PhD candidate at Stanford as he learned about the state of machine intelligence. So-called machine learning software often needed a lot of assistance from humans. People had to annotate data—for example, by labeling photos with and without faces—before software could learn from it. Then they had to tell the software what features in the data it should pay attention to, such as the shapes characteristic of noses. That kind of painstaking work didn’t appeal to Le. Although personable with other humans, he is uncompromising in his expectations for machines. “I’m a guy without a lot of patience,” he says with a laugh.</p><p>While at Stanford, Le worked out a strategy that would let software learn things itself. Academics had begun to report promising but very slow results with a method known as deep learning, which uses networks of simulated neurons. Le saw how to speed it up significantly—by building simulated neural networks 100 times larger that could process thousands of times more data. It was an approach practical enough to attract the attention of Google, which hired him to test it under the guidance of the AI researcher Andrew Ng (see “<a href="http://www.technologyreview.com/featuredstory/530016/a-chinese-internet-giant-starts-to-dream/" target="_blank" rel="noopener noreferrer">A Chinese Internet Giant Starts to Dream</a>”).</p><p>When Ng’s results became public in 2012, they sparked a race at Facebook, Microsoft, and other companies to invest in deep-learning research. Without any human guidance, his system had learned how to detect cats, people, and over 3,000 other objects just by ingesting 10 million images from YouTube videos. It proved that machines could learn without labored assistance from humans, and reach new levels of accuracy to boot.</p><p>The technique is now used in Google’s image search and speech-recognition software. The ultra-intelligent machine Le once imagined remains distant. But seeing his ideas make software smart enough to assist people in their everyday lives feels pretty good.</p><p>—<em>Tom Simonite</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-quoc-le/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Manu Prakash</td>
      <td>Imaginative inventions liberate science from the ivory tower.</td>
      <td>34</td>
      <td></td>
      <td>visionaries-2014</td>
      <td><p>Manu Prakash is determined to push down the cost of doing science. Expensive facilities, he says, limit knowledge and expertise to a privileged elite. So from his lab in Stanford’s bioengineering department, he’s producing instruments that enable people to undertake scientific explorations on the cheap.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.vis_.secondaryx235.jpg" alt=""><figcaption>Prakash’s ­Foldoscope is assembled like a paper toy.</figcaption></figure>\n<p>Many of Prakash’s inventions have a surreal quality. Consider his $5 microfluidic chemistry lab. At a holiday gift exchange, his wife received a hand-cranked music box that used a piano-roll-style punch tape to sound notes. Prakash recognized the mechanism’s potential to combine chemical reagents according to a program (the punch tape), without electricity (thanks to the hand crank), at a fraction of the usual cost. He now makes the tiny labs from scratch.</p><p>Prakash was raised in northern India and has done fieldwork in Uganda, Ghana, and other developing countries, giving him a view of problems that might not be apparent in most well-equipped academic labs. His insights have led to devices like the Foldoscope, a research-grade microscope made of plastic-impregnated paper, which costs a mere 55 cents, and the OScan, a 3-D-printed smartphone add-on that helps diagnose the oral carcinomas that are responsible for 40 percent of cancer-related deaths in India. His aim, he says, is to put scientific tools in the hands of anyone with a question.</p><p>—<em>Ted Greenwald</em></p><p> <iframe width="480" height="270" src="//www.youtube.com/embed/pBjIYB5Yk2I" frameborder="0" allowfullscreen></iframe>  </p><p>   <span>Watch this Innovator at EmTech 2014</span><br><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-manu-prakash/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Julie Shah</td>
      <td>This MIT engineering professor is turning robots into ideal colleagues for humans.</td>
      <td>32</td>
      <td></td>
      <td>visionaries-2014</td>
      <td><p>“In factories there are usually physical barriers between people and robots. Originally, this was for safety<em>—</em>industrial robots were unwieldy and unyielding. Although robots are increasingly designed to safely share human workspaces, even in these settings, people do one set of jobs and robots do another. </p><p>“Imagine if robots could be truly collaborative partners, able to anticipate and adapt to the needs of their human teammates. Such robots could greatly extend productivity. That possibility is really exciting to me.</p><p>“Human interaction isn’t part of the traditional curriculum for training roboticists. Our field is always pushing to make our systems more autonomous, and have richer capabilities and intelligence, but in that push we tend to look past the fact that these systems are, and always will be, working in human contexts. </p><p>“My lab is now focused on how to create robots that make flexible plans and reconsider their best next action based on changing conditions. It’s a challenging problem, because it’s so hard to model people<em>—</em>to know exactly what they’ll do and when. You also have a computational challenge, because the robot needs to reason on all these possible futures so quickly (the way humans naturally do so well). And you need to make the robot interact in a way that a person will accept. But experiments show that when people work with the adaptive robots we have designed, they can complete their task faster, with less idle time, and they even feel safer and more comfortable.</p><p>“The interesting thing about this is that there’s evidence to suggest the techniques can translate to better human-machine teamwork in almost any setting<em>—</em>from manufacturing to operating rooms to military applications. I think the insights will apply very broadly. After all, good teamwork is good teamwork.”</p><p><em>—as told to Will Knight</em></p><p> <iframe width="480" height="270" src="//www.youtube.com/embed/15Hv3Y2V1SU" frameborder="0" allowfullscreen=""></iframe>  </p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/julie-shah-robots-at-work/" target="_blank" rel="noopener noreferrer">Machines Like Us: Robots and Drones at Work</a></p></td>
    </tr>
    <tr>
      <td>George Ban-Weiss</td>
      <td>A USC professor who studies climate and pollution influences policy in California.</td>
      <td>33</td>
      <td></td>
      <td>humanitarians-2014</td>
      <td><p>“Most roofs, historically, have been dark. They absorb sunlight, then transfer heat into the building and into the atmosphere. A very simple solution to that is to design roofs to reflect sunlight rather than absorb it. Cool roofs. Cool roofs could counter somewhere between a half and two degrees Celsius of warming in urban areas.</p><p>“In March 2013, an organization called Climate Resolve organized a one-day workshop on cool roofs, with the idea of bringing together researchers and policy makers, including Los Angeles mayor Antonio -Villaraigosa. I [had done] a study to take high-resolution aircraft imagery and used that imagery to quantify how much sunlight is reflected versus absorbed. At the workshop I showed a map of Los Angeles with the corresponding reflectivity of each roof in the city. This visual made it clear that roofs cover a large fraction of Los Angeles, and most roofs absorb nearly all heat from the sun. In December 2013 the city council passed a law requiring any new or refurbished roofs on residential buildings to be cool roofs. </p><p>“It was extremely fulfilling to know that results from my research contributed to the evidence justifying the first such policy a city has ever passed. </p><p>“I try to follow Einstein’s suggestion that if you can’t explain it to a six-year-old, you don’t understand it yourself. I use my own six-year-old as a test bed.” </p><p><em>—</em><em>as told to Adam Popescu</em></p><p> <iframe width="480" height="270" src="//www.youtube.com/embed/FcRkStS0FHY" frameborder="0" allowfullscreen=""></iframe>  </p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-george-ban-weiss/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Kuang Chen</td>
      <td>A novel way to get data off paper records and into the digital age.</td>
      <td>34</td>
      <td></td>
      <td>humanitarians-2014</td>
      <td><p class="nodropcap"><strong>Problem: <br /></strong>Much of the world still relies on paper forms and documents. Getting information off those files into a format that can be searched and analyzed by computers generally requires manual data entry by people, which is costly, slow, and error-prone.</p><p><strong>Solution:</strong><br />Kuang Chen founded a company called Captricity that uses a clever combination of computing and brainpower to read information on paper forms dozens of times faster and more cost-effectively.</p><p>Chen developed the technology to capture paper-bound data in countries that had yet to fully harness the power of computing. After false starts in Malawi and Uganda, he put his ideas to the test in Mali in 2011, when he processed nearly 37,000 survey pages detailing perceptions of the government. The job would have taken two clerks an estimated eight months even before they double-checked it. Instead, Chen uploaded snapshots of the forms to Dropbox. Then his software broke up the images into small pieces that were distributed to human readers on Amazon’s Mechanical Turk crowdsourcing platform. The Turk transcriptions were used to train machine learning algorithms that progressively took over the work; ultimately, human readers were used only to interpret the most ambiguous entries. The process took a week.</p><p>The same approach that works in African villages can be useful in any organization that still relies heavily on paper forms. Captricity funds its free or low-cost services in poor countries in part with revenue from paying customers such as Dell, Harvard Law School, and the U.S. government.</p><p><em>—Ted Greenwald</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-kuang-chen/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Kurtis Heimerl</td>
      <td>Inexpensive boxes could help bring mobile coverage to the billion people who lack it.</td>
      <td>30</td>
      <td></td>
      <td>humanitarians-2014</td>
      <td><p>Projects intended to help poor, rural communities often founder&nbsp;when innovators lack familiarity with life off the grid. Kurtis Heimerl won’t make that mistake. Having spent much of his childhood in the remote mountains of Alaska, he understands the rigors of living without electricity, transportation, and other conveniences. That’s one thing that makes his Village Base Station a good bet to bring cellular coverage to regions forsaken by the major carriers. </p><p>Heimerl’s innovation comes in a gray box roughly the size of a microwave oven. It has solar panels on the outside to power cellular equipment inside, along with the software for management functions like billing and analytics. Secure the box somewhere and link it via satellite to a voice-over-IP network, and you’re ready to open shop as a mobile service provider. Heimerl’s nascent company, Endaga, sells it for $10,000, promising a return on investment within five years. “In a rural community, your only option is to ask someone like AT&T for coverage, but they just don’t care,” he says. “So for us to say to local entrepreneurs ‘Here, do it yourself’ is enormously powerful.”</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.hum_.secondaryx235.jpg" alt=""><figcaption>Heimerl’s box, with attached antenna, lets anyone offer ­cellular service.</figcaption></figure>\n<p>Heimerl didn’t start out as a telecom revolutionary. He enrolled at the University of Washington in 2002 hoping to join the Internet gold rush. However, internships at Amazon and Google soured him on corporate work. Five years later, he went to India for Microsoft Research and became enthralled with bringing communications to underserved areas. When he left Microsoft and joined UC Berkeley’s Technology and Infrastructure for Emerging Regions program, he encountered OpenBTS, programming code that bridges Internet telephony and&nbsp;cellular phone networks. “It just popped out at me,” says Heimerl, who is still at Berkeley as a postdoc. “We need to take this technology and make it so individuals can operate it.”</p><p>The Village Base Station debuted last year in an Indonesian village that is a four-hour drive over muddy tracks from the nearest city. The community has trouble keeping doctors and teachers, who must journey back to the city just to make a phone call. Heimerl’s system brought coverage to 350 subscribers and generated $1,000 per month in revenue for the operator—and it’s still going strong.</p><p>Just one hitch: it’s illegal. Regional mobile providers hold licenses to the necessary airwaves. Indonesian officials were willing to look the other way, but in general, regulation is a significant hurdle for Heimerl’s vision of universal access. To resolve that issue, he has helped develop a “white space” workaround that occupies unused radio frequencies until another network needs them. He plans a trial in South Africa this year to demonstrate that it doesn’t interfere with other communications. From there, he hopes to expand into any place with an isolated population, an open spectrum, and an entrepreneurial spirit.</p><p><em>—Ted Greenwald</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-kurtis-heimerl/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Santiago Villegas</td>
      <td>An online reporting system encourages crime victims and witnesses to speak up.</td>
      <td>29</td>
      <td></td>
      <td>humanitarians-2014</td>
      <td><p>Five years ago, Santiago Villegas was sitting in his parked car on a street in Medellín, Colombia, when a man came up to him, pulled a gun, and demanded his keys. Villegas handed them over, and the man drove off. Villegas headed to a police station, where it took hours to report the crime. He realized that many people in his position wouldn’t have even bothered, given the widespread fear of retaliation. </p><p>“Martin Luther King said that those who see evil and do not protest support that evil,” he says. “But perhaps he did not consider that in a city like Medellín, protest could mean death.”</p><p>That’s when Villegas, a computer scientist, decided to shine more light on crime. He created a system called the Online Safety Project, which lets people report everything from disturbance of the peace to homicide in a matter of seconds, anonymously. Witnesses and other people can add comments or pictures and vote on whether any report is “true” or “not true” and whether it “affects me.”</p><p>The system got funding from a company that manages security in Medellín and recently expanded to Bogotá. Employees monitor the site around the clock and contact the police when necessary. Every report also gets added to an online map, letting people see which neighborhoods are safest. “This kind of information,” Villegas says, “is vital for any person.” </p><p><em>—Suzanne Jacobs</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-santiago-villegas/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Emily Balskus</td>
      <td>More precise knowledge of the bacteria in our guts could lead to better-targeted treatments for chronic conditions.</td>
      <td>34</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p class="nodropcap"><strong>Problem:<br /></strong>Some 100 trillion bacteria live in our intestines, and their activities are strongly linked to illnesses like heart disease and colon cancer—and are critical in maintaining our general health. Although we know these microbes play an essential role in metabolizing drugs and digesting food, we know relatively little about the chemical transformations they use to get the job done. Learning more about them will be essential to creating new drugs and therapies and shaping dietary guidelines for individual patients.</p><p><strong>Solution:<br /></strong>Emily Balskus, an assistant professor of chemistry and chemical biology at Harvard, uses a variety of approaches, including advanced DNA sequencing, to discover new metabolic pathways and to study how gut bacteria use chemical reactions to survive. In one example of her success, Balskus’s Harvard lab has been credited with uncovering the bacterial enzymes in the human gut that convert the essential nutrient choline to trimethylamine, a metabolite linked to heart disease. Because a majority of choline comes from food, learning more about its relationship to intestinal bacteria could illuminate the link between diet and the risk of heart disease. </p><p><em>—Kristin Majcher</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-emily-balksus/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Duygu Kuzum</td>
      <td>Brain-inspired chips could mean better computer processing and neural implants.</td>
      <td>31</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>Inspired by the architecture of the brain, Duygu Kuzum has designed electronic devices that mimic the behavior of synapses, the connections between neurons. When she was a graduate student at Stanford, Kuzum initially focused on high-­performance electronics for computer processors. But during a summer internship at Intel, she had a kind of neuro-epiphany. “I was always thinking, ‘Okay, now I’m designing and trying to increase the performance of these electronic components and trying to build a computer to be used by another computer, which is the human brain,’” she says. “And I realized that these two computers are built on and operate on fundamentally different principles.”</p><p>So Kuzum set out to design a computer chip based on the way the brain’s synapses process information. Unlike computer circuits, which are based on the binary choices of on or off, <em>0</em> or <em>1</em>, synapses can operate more like a dimmer switch, with variations in strength. Using that insight, Kuzum and her Stanford colleagues created “nanoelectric synaptic grids”—miniaturized computer circuits that can understand and recall rather sophisticated patterns. The prototype opens the way to the development of small, portable, energy-­efficient computers that can process complex sources of data, such as visual and auditory information. That same architecture, Kuzum believes, can also be used to design neural implants and prosthetic devices that act as ­supple, realistic interfaces between computer controls and living brain tissue.</p><p>Kuzum, who grew up and went to university in Ankara, Turkey, moved to a postdoc position at the University of Pennsylvania in 2011 and is now trying to create a new type of brain electrode using graphene, a form of carbon that is both flexible and transparent. Implanted in neural tissue, the electrodes could let researchers record the activity of nerve cells while simultaneously imaging their behavior.</p><p>“We cannot 100 percent replicate the brain,” Kuzum concedes. But, she suggests, maybe we can “build a system that’s more brain-inspired.”</p><p>—<em>Stephen S. Hall</em></p><p> <iframe width="480" height="270" src="//www.youtube.com/embed/pPk42xyNpSA" frameborder="0" allowfullscreen=""></iframe>  </p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-duygu-kuzum/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Megan McCain</td>
      <td>Heart on a chip paves the way for personalized cardiac medicines.</td>
      <td>31</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>What if there were a way to use a patient’s own cells to test his or her response to a cardiac drug before it was administered? Megan McCain, an assistant professor at the University of Southern California, is developing a so-called heart on a chip, roughly the size of a quarter, to do just that.</p><p>When she was a postdoc at Harvard, McCain began collaborating with cardiologists at Boston Children’s Hospital. Her colleagues took skin cells from a patient, reprogrammed them to become stem cells, and turned the stem cells into heart cells. “Those heart cells should work pretty much the way your native heart cells should work,” she says. “They’ll have the same genetic information.” McCain then engineered tissues from these heart cells and used the heart-on-a-chip system to examine how the structure and function of healthy tissues differed from that of diseased tissues. The patient-specific cells living on a chip offer a more accurate way to predict how an individual’s heart will respond to a drug than, say, tests using lab animals.</p><p>McCain and her team have used the technology to test drug treatment for Barth syndrome, a rare cardiac disease caused by a single-gene mutation. She hopes that this chip will someday be used to test treatments for genetically caused cardiac diseases in general.</p><p>Other researchers have also created simulated organs on chips, but the heart presents specific challenges. “It is very mechanical, and it has an electrical side,” says McCain. “I appreciate how delicate, complex, and interesting the heart is.”</p><p>—<em>Alexandra Morris</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-megan-mccain/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Maryam Shanechi</td>
      <td>Using control theory to build better interfaces to the brain.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>“I was born in Iran. My family immigrated to Canada when I was 16. My parents wanted a better education for me, my brother, and sister. I started out working on information theory, coding theory, and wireless communication. But I wanted to more directly impact people in my research. When I was looking for a PhD topic, I came across neuroscience, and I realized that the same principle could be used to treat brain disorders. </p><p>“So I moved from decoding wireless signals to decoding brain signals. I develop brain-machine interfaces that record the activity of neurons while someone plans a movement. This could one day allow disabled patients to move just by thinking about it. </p><p>“My work takes a lot of insight from control theory. Say you reach for a glass of water<em>—</em>your brain wants that to happen in a certain time frame, and it’s getting visual feedback, and you can adjust the speed. The brain acts as a ‘feedback controller,’ and I have built models for how that works. I also work on brain-machine interfaces for anesthesia. We decode the level of brain activity and adjust the anesthetic accordingly.</p><p>“I started as a professor at Cornell University and moved to the University of Southern California in July. As part of the Obama BRAIN initiative, I’m involved in a project to revolutionize treatments for neuropsychiatric disorders, such as PTSD and depression. We will create a brain-machine interface to decode the neuropsychiatric state of the brain, and decide on a set of electrical stimulation patterns to alleviate the symptoms in real time. This would be an automatic controller<em>—</em>a closed-loop system. And I will build that. </p><p>“We know nothing about the signatures of neuropsychiatric disorders in the brain. We need to discover those. I am really excited, because there is so much we don’t know.” </p><p class="p3"><em>—as told to Antonio Regalado</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-maryam-shanechi/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Kay Tye</td>
      <td>Identifying how the connections between regions of the brain contribute to anxiety.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>Neuroscience has often focused on dividing the brain into regions, pinpointing which individual neurons are responsible for specific functions. Kay Tye’s vision of the brain is defined less by discrete addresses than by the roads between them—the connections between groups of neurons. “I think neuroscience as a field is at this threshold of a new understanding of the brain in terms of circuits,” says Tye, a principal investigator at the Picower Institute for Learning and Memory at MIT. The connections a cell makes could be at least as important as its location, she believes.</p><p>As a postdoc at Stanford University, Tye took advantage of a relatively new technology called optogenetics, which allows researchers to use light to turn specific, genetically modified neurons on and off in lab animals. </p><p>Manipulating the connections in mice between a group of neurons in the amygdala with a group in the hippocampus, she precisely altered behaviors related to both anxiety and social interaction to tease apart the specific connections she suspected played a critical role in anxiety. When the circuit is inhibited, a mouse that normally avoids open areas explores them freely, and when it’s activated, the mouse runs for cover. In a subsequent study, Tye showed that inhibiting a circuit made a mouse sniff and nudge a strange mouse in its cage, while activating it made the mouse ignore the stranger—a test of the animal’s tendency toward social interaction. </p><p>The idea that manipulating connections between small bundles of brain cells could instantly reshape behavior opens up new possibilities for treating brain disorders. Current drugs, she says, “target the entire body and bathe the whole brain in this soup,” creating many unwanted side effects. If scientists can find a way to safely manipulate the human neural connections involved in feelings such as anxiety, therapies might be more precise and cause fewer side effects. </p><p>First, researchers will have to identify the various connections that can be manipulated this way. It’s an enormous task given the complexity of the brain. But at least Tye’s breakthroughs have helped get them on the right road. </p><p>—<em>Courtney Humphries</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-kay-tye/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Jonathan Viventi</td>
      <td>A high-resolution interface reveals the brain storms of people suffering seizures.</td>
      <td>32</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>On his cell phone, Jonathan Viventi, a biomedical engineer at New York University’s Polytechnic School of Engineering, displays what looks like a meteorologist’s map of a fast-moving storm: red, orange, yellow, green, and blue patches swirl in ominous, complex patterns. In fact, the video represents the highest-resolution electrical data yet recorded over a large surface of an animal’s brain during an epileptic seizure.&nbsp;</p><p>Previously, researchers using lower-resolution technology had observed repetitive spiking patterns during seizures. But those recordings were “vastly undersampling the electrical activity of the brain,” says Viventi. His innovation was to develop a better interface that could capture more detail, revealing patterns of waves rotating, changing direction, and moving across the brain’s surface.</p><p>The improved imaging is possible because of an implant that is roughly one centimeter square and can be positioned, in theory, anywhere on the surface of the brain. The implant incorporates flexible electronics into an array of sensors; indeed, Viventi was the first to move electronics, which are usually rigid and located far from such sensors, directly to the brain’s surface. “This allows us to amplify and combine signals directly at the source, so that we don’t need to have one wire for each sensor,” he says. That, he adds, “lets us build much higher-resolution interfaces with the brain.”&nbsp;</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/tr35.pio_.secondaryx235.png" alt=""><figcaption>Viventi’s brain ­interface has both an array of sensors and flexible electronics.</figcaption></figure>\n<p>Viventi imagines that doctors will use his implants as a temporary way to monitor seizures and plan treatment, including further surgery, in people with epilepsy. In the longer term, he hopes that permanent implants for patients with severe epilepsy can sense brain activity and stimulate the appropriate regions. He hopes to win approval for clinical trials of his devices, though to date the team has only done experiments on animals.&nbsp;</p><p>Viventi first became interested in epilepsy when he was a graduate student in bioengineering at the University of Pennsylvania. It was because he was struck by the crude technology used to evaluate the patients that he decided to develop a system for recording sensitive signals from thousands of sensors placed directly on the surface of the brain—a mission that at the time seemed “kind of crazy,” he says.</p><p>Ultimately, one of the biggest challenges will be adapting the electronic interface so that it doesn’t degrade over time. “Our bodies are full of salt water, and salt does not work well with electronics,” he says.</p><p>—<em>Amanda Schaffer</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-jonathan-viventi/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Kathryn Whitehead</td>
      <td>A systematic search discovered nanoparticles that could improve drug delivery.</td>
      <td>34</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>While still working on her PhD in chemical engineering at the University of California, Santa Barbara, Kathryn Whitehead created small experimental patches that, when swallowed, adhere to the intestine to deliver insulin. It is a promising alternative to the frequent painful insulin shots that people with diabetes typically need. </p><p>More recently, Whitehead has been focusing on small interfering RNA (siRNA), which can be used to target and shut off gene expression. These molecules have enormous potential for treating cancers and genetic disorders, but it’s difficult to deliver them to the appropriate cells. Though embedding siRNA in a protective nanoparticle seems like a promising approach, researchers have had difficulty finding nanoparticles that can both navigate to the desired tissue and deliver the molecule across the cell wall. </p><p>Instead of trying to make educated guesses at particles that might work, as others in the field were doing, Whitehead has systematically tested thousands. While working as a postdoc at MIT’s Koch Institute for Integrative Cancer Research, she screened thousands of potential nanoparticles, zeroing in on the handful with the best results. Four biotech companies have since licensed Whitehead’s patents in RNA delivery materials.</p><p>Now, as an assistant professor of chemical and biomedical engineering at Carnegie Mellon University in Pittsburgh, she is busy analyzing the next batch of nanoparticles and siRNA she’d like to test for various treatments, including some that target lymphoma tumors. Despite her remarkable achievements, she has not had any real “eureka moments” in her lab, she says. “Perseverance is the major theme.”</p><p> —<em>Patrick Doyle</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-kathryn-whitehead/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Hui Wu</td>
      <td>Cheaper and more powerful batteries could help reduce China’s deadly air pollution.</td>
      <td>31</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>Hui Wu grew up in a small, quiet city in central China. Few families owned televisions in the 1980s (his was one of the lucky ones), and even fewer had cars. His mother biked to the hospital where she was a nurse. His father, a middle-school chemistry teacher, let him tag along to classes when he was eight or nine years old, sparking an interest in science and experimentation. </p><p class="p2"><span class="s1">After earning a PhD at the elite Tsinghua University in Beijing, he went to Stanford as a postdoc, joining the lab of <a href="http://www2.technologyreview.com/tr35/profile.aspx?trid=117">Yi Cui</a>, one of the top battery chemists in the world. But later his father fell ill with lung cancer, and “as an only child, I don’t think I had any choice other than to come back to help my family,” he explains. In 2012, he took a job teaching and researching at Tsinghua. (His father came to Beijing to receive treatment but died last year.) </span></p><p>Wu uses nanostructured materials to improve the efficiency of batteries. And he feels the urgency of his quest even more back home, given the alarming levels of pollution in China’s large cities. Sitting in his office on the Tsinghua campus, with a blinking battery tester beside his desk, he reflects, “When I was in California, the sky was always bright blue, but I never see skies like that in Beijing.”</p><p class="p2">Longer-lasting batteries could extend the range of electric vehicles, which may be part of the solution to Beijing’s smog—vehicle emissions contribute roughly a third of the fine particles that blacken the skies. Better batteries could also increase storage capacity for solar and wind power, which would make those technologies more affordable in China.</p><p class="p2">Today’s consumer electronics and electric vehicles most commonly use lithium-ion batteries, in which lithium ions move between the electrodes during charging and discharging; the negative electrode is typically made of graphite. In theory, replacing graphite with silicon could vastly increase power density, giving batteries with the same weight a much longer life. But silicon swells in volume more than 300 percent as it charges, making it unstable. While at Stanford, Wu helped figure out (working in the same lab as <a href="http://www.technologyreview.com/lists/innovators-under-35/2014/pioneer/guihua-yu/">Guihua Yu</a>) how to use a porous polymer gel to encapsulate tiny particles of the silicon, allowing them to expand harmlessly in the space of the polymer matrix. </p><p class="p2">Wu prefers low-tech ways for himself: he lives with his lawyer wife and their toddler on the Tsinghua campus, and he rides a bicycle to his office. He appreciates practical solutions. “I don’t want to create a material that’s only feasible in the lab,” he says. “I’m interested in using science to solve practical problems of our daily life.”</p><p class="p2"> —<em>Christina Larson</em></p><p>   <span>Watch this Innovator at EmTech 2014</span><br /><a href="http://www.technologyreview.com/emtech/14/video/watch/innovators-under-35-hui-wu/" target="_blank" rel="noopener noreferrer">Meet the Innovators Under 35</a></p></td>
    </tr>
    <tr>
      <td>Guihua Yu</td>
      <td>Electronic gels could lead to sensors and batteries that are more like biological tissue.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2014</td>
      <td><p>Since starting his lab at the University of Texas at Austin in 2012, materials scientist Guihua Yu has been controlling the three-dimensional nanostructure of materials to make electrically conductive gels that can serve as electronic skin, more efficient battery electrodes, or tunable chemical sensors. </p><p>Hydrogels, which are flexible, squishy networks of polymers, are great for supporting the growth of cells in research experiments or binding together active ingredients for drug delivery. But they typically are lousy at conducting electricity. In contrast, electrically conductive polymers are valuable in electronics—for example, in new types of plastic solar cells—but typically can only be made into thin films. Yu figured out how to link conductive-polymer building blocks to make nanostructured gels that had the best qualities of both materials.</p><p>One gel can be used to hold glucose-binding enzymes and nanoparticle catalysts, key elements of a rapid, highly sensitive glucose sensor that might be used for diabetes management. Another makes for a more resilient battery electrode with higher energy density. </p><p><em>—Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Vijay Balasubramaniyan</td>
      <td>Determining the origin of a phone call cuts fraud, including identity theft.</td>
      <td>33</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p class="p1"><span class="s1"><strong>Problem:</strong></span><span class="s2"> Fraud over the telephone costs banks and retailers more than $1.8 billion a year. Criminals who call customer service lines pretend to be legitimate customers and often dupe the operators into approving a transfer or divulging sensitive account information. </span></p><p class="p2"><strong><span class="s1">Solution:</span></strong><span> Vijay Balasubramaniyan can detect where a call is coming from by analyzing its audio quality and the noise on the line. If a call purportedly from one place has the audio signature of a call from the other side of the world, his technology can sound an alert. The company he founded, Pindrop Security, counts several banks and an online brokerage firm as customers.</span></p><p class="p3">The audio quality of a phone call is affected in subtle ways by many factors, including the networks and cables it travels through. Pindrop makes hundreds of phone calls per hour to build a database of what, for example, a cell phone on a particular network in India sounds like. The service can then compare those files with the audio patterns in calls to customer service centers to determine whether a call is coming from where it says it is. </p><p class="p1"><em>—Conor Myhrvold</em></p></td>
    </tr>
    <tr>
      <td>David Fattal</td>
      <td>A revolutionary type of 3-D display could provide a new look to moving images.</td>
      <td>34</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p>David Fattal, a French-born quantum physicist who is now a researcher at HP Labs, is a master of nanoscale light tricks, and the feat he unveiled this year is his most impressive yet. It’s a new kind of display that can project colorful moving images, viewable in three dimensions from multiple angles without any special glasses.</p><p>Fattal’s invention, which he calls a “multidirectional backlight,” consists of a thin piece of glass (or plastic) with light-emitting diodes mounted on its edge. Thanks to its particular design, which governs the angle at which the light is propagated, the device takes advantage of total internal reflection—the same optical phenomenon used in fiber optics.</p><p>Light from the LEDs doesn’t escape from the material until it hits nanoscale features etched or imprinted on the surface—what Fattal calls “directional pixels.” Composed of grooves smaller than the wavelength of the light, the pixels allow for precise control over the direction in which individual rays are scattered, shooting the different colors of light in specific directions. The result is colorful images that “seem to come from nowhere,” says Fattal.</p><p>In a paper published in <em>Nature</em> in March, Fattal and colleagues presented prototypes capable of projecting static and moving images viewable from 200 angles. They performed the trick by overlaying their novel backlight with an ink-printed mask that blocked certain colors and allowed others through. One of the first images they produced was that of a turtle hovering immediately above the glass. Fattal has also used a modified liquid crystal display to produce simple moving images.</p><p>Since the setup creates realistic, hologram-like 3-D images without the need for bulky optical equipment, it could be attractive for use in smartphones, tablets, smart watches, and other mobile devices.</p><p>Projecting high-quality images, however, will require much larger and more complicated pixel arrays and advanced mechanisms for handling a huge number of data-rich images quickly. And creating 3-D content that can be enjoyed from all the many vantage points accommodated by this technology will be no small task either. But in his ingenious use of nanotechnology, Fattal has given us the possibility of seeing images and videos in a whole new light.</p><p>—<em>Mike Orcutt</em></p><p><iframe src="//www.youtube.com/embed/-7brRONyY0M" frameborder="0" width="560" height="315"></iframe></p></td>
    </tr>
    <tr>
      <td>Christine Fleming</td>
      <td>Images of the beating heart could make it easier to detect and treat heart disease.</td>
      <td>30</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p>Christine Fleming is trying to give cardiologists a powerful new tool: high-resolution movies of the living, beating heart, available in real time during cardiac procedures. Such technology might also one day help physicians pinpoint the source of dangerous irregular heart rhythms without invasive biopsies. It could even help monitor treatment.</p><p>Her invention uses optical coherence tomography (OCT), a technique that captures three-dimensional images of biological tissue. A specialized catheter with a laser and small lens near its tip is threaded through the arteries. When the laser light reflects off the heart tissue, it is picked up and analyzed to create an image. OCT has a higher resolution than ultrasound and captures images faster than magnetic<span>resonance imaging, or MRI. But today OCT has limited cardiac application—usually to search the arteries for plaques. Fleming, an electrical engineer who joined the faculty at Columbia University this year, has designed a new type of catheter capable of imaging heart muscle.</span></p><p><span>One of the primary uses of the technology will be to locate, and monitor treatment for, irregular heart rhythms that are typically caused by disruption of the heart’s regular tissue structure. In patients with arrhythmias, which can lead to heart failure, surgeons often burn away the affected tissue with targeted radio-frequency energy. Currently they perform the procedure somewhat blind, using their sense of touch to determine when they have come in contact with the muscle wall. “Since the physician doesn’t have a view of the heart wall, sometimes the energy is not actually being delivered to the muscle,” says Fleming, who adds that the procedure can last for hours. Fleming has shown in animal tests that her catheter, which uses a novel forward-facing lens, can successfully monitor the ablation in real time. Algorithms that help distinguish untreated from treated tissue offer further guidance.</span></p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/inventors.flemingx519.jpg" alt="Abnormal orientation of cells"><figcaption>Abnormal orientation of cells in the heart wall is a clue to arrhythmias, which can be fatal. These images, created using optical coherence tomography, show the orientation of a rabbit’s heart-muscle cells. Christine Fleming’s approach to diagnosing arrhythmias could be an alternative to invasive biopsies.</figcaption></figure>\n<p>Fleming is also developing algorithms to help improve the detection of arrhythmias by precisely measuring the three-dimensional organization of heart muscle. The technique works best when the tissue has been chemically treated to make it clearer, and thus easier to image. But her team at Columbia is now improving the algorithms so that the method works without this treatment. She hopes that in time the technology could supply an alternative to invasive biopsies, which are sometimes used to diagnose unexplained arrhythmias or to monitor heart health after transplants.</p><p>Fleming’s arrival at Columbia earlier this year was something of a homecoming. As a high-school student in New York City, she interned at the NASA Goddard Institute for Space Studies, which is down the street from her current lab. But in the intervening years her engineering interests have increasingly become tied to medicine; her inspiration for studying the electrical properties of the heart came when she studied electrical engineering and computer science as an undergraduate at MIT. Working with physicians is especially exciting, she says, because “you get the sense that one day your technology will be used.”</p><p>—<em>Emily Singer</em></p></td>
    </tr>
    <tr>
      <td>Hao Li</td>
      <td>Smarter animation bridges the gap between the physical and digital worlds.</td>
      <td>32</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p>Hao Li remembers watching <em>Jurassic Park</em> as a kid: “That moment of seeing something that didn’t exist in reality, but it looked so real—that was definitely the one that made me think about doing this,” he says. Li tells me the story one afternoon while we dine at the cafeteria of Industrial Light & Magic, the famed San Francisco visual-effects studio where he has been working on a way to digitally capture actors’ facial expressions for the upcoming <em>Star Wars</em> movies. When <em>Jurassic Park</em> came out, Li was 12 years old and living in what he calls the “boonie” town of <span>Saarbrücken</span>, Germany, where his Taiwanese parents had moved while his father completed a PhD in chemistry. Now, 20 years later, if all goes to plan, Li’s innovation will radically alter how effects-laden movies are made, blurring the line between human and digital actors.</p><p>Visual-effects artists typically capture human performances through small balls or tags that are placed on an actor’s face and body to track movement. The data capturing the motion of those markers is then converted into a digital file that can be manipulated. But markers are distracting and uncomfortable for actors, and they’re not very good at capturing subtle changes in facial expression. Li’s breakthrough involved depth sensors, the same technology used in motion gaming systems like the Xbox Kinect. When a camera with depth sensors is aimed at an actor’s face, Li’s software analyzes the digital data in order to figure out how the facial shapes morph between one frame and the next. As the actor’s lips curl into a smile, the algorithm keeps track of the expanding and contracting lines and shadows, essentially “identifying” the actor’s lips. Then the software maps the actor’s face onto a digital version. Li’s work improves the authenticity of digital performances while speeding up production.</p><p>Li is amiably brash, unembarrassed about proclaiming his achievements, his ambitions, and the possibilities of his software. His algorithm is already in use in some medical radiation scanners, where it keeps track of the precise location of a tumor as a patient breathes. In another project, the software has been used to create a digital model of a beating heart. Ask him if his technology can be used to read human emotions or if he’ll find some other far-off possibility, and he’s likely to say, “I’m working on that, too.”</p><p>When I ask if he speaks German, Li smiles and says he does—“French, German, Chinese, and English.” This fall, he will begin working in Los Angeles as an assistant professor in a University of Southern California computer graphics lab. But Hollywood movies are not the end game. “Visual effects are a nice sandbox for proof of concepts, but it’s not the ultimate goal,” Li says. Rather, he sees his efforts in data capture and real-time simulation as just a step on the way to teaching computers to better recognize what’s going on around them.</p><p>—<em>Farhad Manjoo</em></p></td>
    </tr>
    <tr>
      <td>Markus Persson</td>
      <td>After hitting the video-game jackpot, an independent game developer reflects on his success.</td>
      <td>34</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p>Markus Persson—better known as Notch to his millions of followers—is an unlikely technology megastar. A quiet, unassuming Swede, he looks like the typical video-game programmer, with thinning hair and a thickening torso; his defining features are twin dimples when he smiles and a jet-black fedora, an accessory he is rarely seen without. But Minecraft, an independent video game he created and released on the Internet in May 2009, has sold 30 million copies, making him rich and famous. </p><p>Persson is now a hero to a generation of young game players, who hang on his every tweet. Last year he earned more than $100 million from Minecraft and its associated merchandise. But the programmer appears largely unchanged by the money. While he routinely travels by private jet and is well-known for hosting lavish parties in Minecraft’s name, his main material indulgence is ensuring he always has the latest computer.</p><p>Though Persson might be little changed by success, Minecraft has transformed video games. A rudimentary-looking Java game that doesn’t require the latest computer to run, it places its player in the <a href="http://www.technologyreview.com/review/516051/the-secret-to-a-video-game-phenomenon/">middle of a pastoral landscape that represents a unique and randomly generated world</a>. Trees, sand, gravel, and rocks are each represented by a different type of block, and these can be harvested and subsequently “crafted” into different objects and tools. One mouse button is used to harvest the blocks, the other to place them. In this way players are able to shape the game’s world to suit their whims. The blocks can be rearranged to create structures and settlements as elaborate as the player’s imagination permits. </p><p>Persson believes his success is a once-in-a-lifetime event, a freakish hit of the sort that strikes some creative people with unrepeatable fortune. Minecraft’s popularity has brought unfamiliar attention to the designer, whose every idea is now pored over by a watching world. Regardless of the scrutiny and accompanying creative jitters, Persson continues to be a prolific and ambitious game inventor. His next project is a resource-trading game set in space.</p><p>—<em>Simon Parkin</em></p></td>
    </tr>
    <tr>
      <td>Morgan Quigley</td>
      <td>Open-source software is making it nearly as easy to program a robot as it is to write an app.</td>
      <td>32</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p>Three decades ago, the availability of many versions of DOS helped spark the boom in personal computers. Today, Robot Operating System, or ROS, is poised to do the same for robots. Morgan Quigley programmed the first iteration of what grew into ROS as a graduate student in 2006, and today his open-source code is redefining the practical limits of robotics. Since version 1.0 was released in 2010, ROS has become the de facto standard in robotics software.&nbsp;</p><p>To visit Quigley’s office at the Open Source Robotics Foundation in Mountain View, California, the organization he cofounded last summer to steward ROS, is to step into a future of robotics where hardware is cheap, and it’s quick and easy to snap together preëxisting pieces to create new machines. Quigley’s workspace is littered with dozens of mechanical fingers—modules that form a robotic hand. “The hands themselves can talk ROS,” Quigley says. His T-shirt is emblazoned with a programming joke: <em>shirtcount++;</em>.</p><p>Unlike more conventional robotic technology, Quigley’s four-fingered hand is not controlled by a central processor. Its fingers and palm distribute computing chores among 14 low-cost, low-power processors dedicated to controlling each joint directly. That greatly simplifies the internal communication and coördination required to execute a task such as picking up a pencil. Both the software and electronics are open source. Any robot builder can take Quigley’s design and use or improve upon it.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/inventors.quigley.1x519.jpg" alt=""><figcaption>Left: The robotic fingers Quigley is working on  have their own processors that separately control each of the joints.</figcaption></figure>\n<p>Ultimately, Quigley hopes, these innovations will lead to more agile, more capable robots that can perform a variety of jobs and don’t cost tens or hundreds of thousands of dollars. And no longer will engineers have to start from scratch to design the functions that go into a robot—they’ll have an open-source base of code and hardware. Already, engineers using ROS are working on robots that do everything from folding laundry to repetitive operations in advanced manufacturing. “It will allow applications we couldn’t dream of before,” Quigley says.&nbsp;</p><p><strong>Masterstroke<br></strong><span>Unlike many children of the 1980s and 1990s, Quigley wasn’t enthralled by </span><em>Star Wars</em><span>’ C-3PO or </span><em>Star Trek: The Next Generation</em><span>. Rather, he was mesmerized by the far more mundane but real Apple II computer at his elementary school. In class, he typed commands in the Logo language to move an animated turtle around the screen—the ancestor of ROS’s turtle mascot. But it wasn’t until 1998, when he entered Brigham Young University in Provo, Utah, that he encountered robots. He was hooked. “Robots are the meeting place between electronics, software, and the real world,” he says. “They’re the way software experiences the world.”</span></p><p>When he arrived at Stanford for graduate study in machine learning, Quigley joined Andrew Ng’s lab, where the students were collaborating on the Stanford Artificial Intelligence Robot, or STAIR. Typical industrial robots execute a single tightly defined task in a controlled environment, like an advanced automobile factory. Ng, however, envisioned a general-purpose robot that could execute diverse tasks in an uncontrolled environment. The signature STAIR challenge was getting the robot to respond productively to the request “Fetch me a stapler.” To bring back the stapler, STAIR needed to understand the request, navigate hallways and elevators to an office, open the door, make its way to the desk, identify a stapler among other items of roughly the same size, pick it up, bring it back, and hand it off.&nbsp;</p><p>As Ng’s teaching assistant, Quigley realized that the class needed a software framework that could integrate contributions from a few dozen students working asynchronously without bringing down the robot when one of their programs crashed. ROS was his solution: a distributed peer-to-peer system designed to connect all the resources—technological and human—required to make a robot work.&nbsp;</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/inventors.quigley.2x299.jpg" alt=""><figcaption>ROS makes various projects possible, as is evident from Quigley’s cluttered desk; among the machines relying on ROS is Rethink Robotics’ Baxter.</figcaption></figure>\n<p>In 2007, he began collaborating with Willow Garage, a Silicon Valley company that works on robots and open-source software. For the next two years, Quigley oversaw the ROS architecture while Willow Garage’s programmers extended his initial work. Released in 2010, ROS quickly became the dominant software framework for robotics.&nbsp;</p><p>Despite its name, ROS isn’t really an operating system. It’s a framework that enhances conventional operating systems (theoretically, any OS; in practice, Linux). It provides software modules for performing common robotics functions such as motion planning, object recognition, and physical manipulation. So if you want a robot to map its surroundings, you don’t have to write that code; you can simply plug in the ROS software module. As an open-source product that can be freely modified, it attracts a community of users who are constantly improving and extending its capabilities.&nbsp;</p><p>Any number of independent modules can run at a given time. Modules can be connected for testing, disconnected for debugging, and reinstated without destabilizing the network as a whole. In this way, ROS allows a robot to be controlled by any number of computers running any number of programs—a laptop focusing on navigation, a server performing image recognition, an Android phone issuing high-level instructions. It all happens in real time as the robot wanders about.&nbsp;</p><p>The masterstroke in Quigley’s design is not strictly technical but social. Members of the community who produce a finished release can distribute it themselves, rather than having to house it on central servers. “That’s a big deal in terms of giving people the credit they deserve and allowing them to control their contributions,” Quigley says. “Their code isn’t lost in this beast called ROS.”&nbsp;</p><p><strong>Grand Plan<br></strong><span>Quigley’s ambition is to make ROS a productive starting point for any kind of robotic system—large or small, expensive or cheap, academic or commercial, networked or stand-alone.&nbsp;</span></p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/inventors.quigley.3x519.jpg" alt=""><figcaption>Some of the circuit boards used in the robotic hand.</figcaption></figure>\n<p>Adapting ROS for low-cost processors is critical if the software is to play a key role in next-generation designs. Cheap processors are becoming more capable, opening an opportunity to bring the intelligence that has been concentrated in desktop-class processors to the CPUs that manage robotic wheels, joints, and cameras. Where image recognition was once a function of a rack of servers, soon it might be managed within the camera.</p><p>Quigley also wants ROS, which was designed to control one robot at a time, to move into environments that use multiple robots. Settings such as warehouses or factory floors would benefit from squadrons of them operating in a coördinated way. Beyond that, it’s not hard to imagine robot fleets managed in the cloud: users could send ROS commands to a data center and from there to an automaton. “ROS might tie into an online knowledge base,” Quigley says, “so if someone says, ‘Get the stapler off my desk,’ it might retrieve a CAD model of a stapler from the cloud.”&nbsp;</p><p>—<em>Ted Greenwald</em></p></td>
    </tr>
    <tr>
      <td>Kira Radinsky</td>
      <td>How good can computers get at predicting events?</td>
      <td>27</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p>In 2012, when Cuba suffered its first outbreak of cholera in 130 years, the government and medical experts there were shocked. But software created by Kira Radinsky had predicted it months earlier. Radinsky’s software had essentially read 150 years of news reports and huge amounts of data from sources such as Wikipedia, and spotted a pattern in poor countries: floods that occurred about a year after a drought in the same area often led to cholera outbreaks.</p><p>The predictions made by Radinsky’s software are about as accurate as those made by humans. That digital prognostication ability would be extremely useful in automating many kinds of services.</p><p>Radinsky was born in Ukraine and immigrated to Israel with her parents as a preschooler. She developed the software with Eric Horvitz, co-director at Microsoft Research in Redmond, Washington, where she spent three months as an intern while studying for her PhD at the Technion-Israel Insitute of Technology.</p><p>Radinsky then started SalesPredict, to advise salespeople on how to identify and handle promising leads. “My true passion,” she says, “is arming humanity with scientific capabilities to automatically anticipate, and ultimately affect, future outcomes based on lessons from the past.”</p><p>—<em>Matthew Kalman</em></p></td>
    </tr>
    <tr>
      <td>Matt Rogers</td>
      <td>The cofounder of Nest, which invented a thermostat that learns people’s preferences, explains what’s next.</td>
      <td>30</td>
      <td></td>
      <td>inventors-2013</td>
      <td><p><strong>You and Tony Fadell, one of the creators of the iPhone and iPod, started Nest after both of you left Apple. Wasn’t being in charge of iPod and iPhone software development your dream job?</strong></p><p>I had a Mac Plus when I was three years old, and I loved Apple as a company. I flew out to California [from Gainesville, Florida] with my grandparents on my 13th birthday to go out to Cupertino. And I told my grandparents then, “Yeah, I’m going to work at Apple, for sure.”</p><p><strong>Then why leave at just 26 years old?</strong></p><p>Basically, I pushed as hard as I could, worked incredibly hard, built tons of stuff, built teams, built products, and loved it. But somewhere around my four-and-a-half-year anniversary at Apple, we were working on another generation of iPods and another generation of iPhones and starting work on the third generation of iPads, and I was ready for something new.</p><p><strong>Going from smartphones to smart thermostats isn’t an obvious jump.</strong></p><p>Tony and I had lunch back in October of 2009. I told Tony, “I’m thinking about leaving Apple; I’m thinking about starting my own company, and I’m looking at smart-home stuff.” And he stops me right there. He goes, “You know what? A smart home is for geeks. No one wants a smart home—it’s a stupid idea. Focus on doing one thing and doing it really well.”</p><p>Programmable thermostats existed before the Nest, but they were awful.</p><p>The programming was tough. They were like the early ’80s VCRs, where you’d push a button 15 times to change it to Tuesday and change the temperature there. Part of it is that the product was designed to be sold to a contractor and not designed for a user.</p><p><strong>In contrast, the Nest is a lot like the iPhone—<span class="s1">it’s easy to figure out how to use.</span></strong></p><p>The product that we built is basically a smartphone on the wall.</p><p>And there’s nothing I have to push 15 times. There aren’t even any buttons<strong>—</strong>you just turn the entire metallic case. That’s very Apple-like.</p><p>When we were building Nest, we were going to build it like any great product and design company. You’d have great industrial design, great hardware engineering, great software engineering, great services, great consumer marketing—all those things.</p><p><strong>One way the Nest saves energy is by detecting when no one’s home. But there’s got to be much more you can do on the back end, to make plans based on weather forecasts and other data.</strong></p><p>There’s always more. Since we’ve launched the product, we’ve done something like 21 software updates, of which I’d say five or six have included major energy-saving algorithm improvements, and we’re always finding more. The more detail we have, the more users we work with, the more homes we’re in, the more we’re learning. It’s a very long tail of things we could be doing. You can see multiple products.</p><p><strong>Which brings us back to your original ideas about a smart home. The Nest could become a hub for controlling many things, not just heating and cooling.</strong></p><p>It could be, yes.</p><p><strong>But yet you guys say only geeks want smart homes—</strong></p><p>Wait, wait. I don’t believe in networking connectivity just for the sake of having things connected. There’s got to be a really good reason why you’d want to do it. You don’t want to put networking in your microwave oven. What would it do?</p><p class="p6"><strong>So what does make sense? What might a home in the future do differently?</strong></p><p class="p7">Today when you arrive home, the Nest sensor sees you and starts cooling your home so you’re comfortable. And if you extrapolate to the future, you’re driving home from work; your phone knows that you’re driving home, or your car itself knows you’re driving home, and lets Nest know, “Matt will be home in 15 minutes; we’ll start preparing the home for his arrival.” And then, as you get closer to the door, things might change—it might turn the song list on and play my favorite music, or turn the lights on—or, when I leave, do the opposite.</p><p><strong>That sounds like a geek dream to me—less about reducing energy than increasing comfort.</strong></p><p>These things go hand in hand, actually. Part of the promise of Nest is that we’re going to keep your home comfortable, and may actually even make you more comfortable, while also helping you save.</p><p><span><em>—Brian Bergstein</em></span></p></td>
    </tr>
    <tr>
      <td>Dmitri Alperovitch</td>
      <td>The cofounder of the security company CrowdStrike wants to help cyberattack victims strike back.</td>
      <td>32</td>
      <td></td>
      <td>entrepreneurs-2013</td>
      <td><p>“After the investigation of Operation Aurora, the cyberattack on Google from within China that was revealed in 2010, I realized a completely new type of security strategy and technology was needed. I was leading research at McAfee and had been involved in investigations of criminal activity online, working closely with law enforcement. Aurora put us up against a nation-state, not a criminal. I was briefing the State Department as they crafted statements for Hillary Clinton to make publicly about the issue.</p><p>The online criminal problem was and is a big issue, but it pales in comparison to what nation-state attacks are doing to this country and our allies. Google has one of the best security teams on the planet, better than most government organizations, but they and many other companies with very good security practices were still getting hit. The problem was not the security widgets and technology they were using; it was the strategy. That’s why I left McAfee to start CrowdStrike.</p><p>The industry and the government were using a passive strategy of trying to detect and block cyberattacks, and that doesn’t work against an actor that’s really determined. China’s army is not going to give up and say, ‘Well, we’re out of the cyber-espionage business.’ What you really want is for a cyberattack to be very costly and risky, so it is used only rarely and only against really high-value targets. </p><p>Today security companies look for malware and software exploits, but they change constantly. And new ones are launched by the hundreds of thousands each day. At CrowdStrike we look for traces of the adversary and try to find out who the adversary is, what they are after, and what their tradecraft is. We also disseminate that information to enable collective action. It doesn’t have to just be every company for themselves—they can band together and maybe join with government to put pressure on the enemy. We’re starting to see that with some of the public disclosures about China, including ones I’ve done, leading the U.S. administration to start talking openly about the problem. That helped lead to Obama raising the issue at his summit with the Chinese president.</p><p>We use data from many sources to detect traces of adversaries and uncover everything we possibly can about them. Our customers can find out who is targeting them and how. We’ve showed how we could see the Chinese navy crafting spear-phishing e-mails so we could warn targets before they even received one.</p><p>We call this new strategy ‘active defense.’ We respect the law, but we’re in discussions with Congress about making changes because most relevant laws were written in 1986. We should enable the private sector to engage in self-defense in the cyber world, like we do in the physical world. Mall cops protect property the government doesn’t have the resources to protect. A cyber-world equivalent could be allowing some licensed cybersecurity companies or individuals to take certain actions in defense of a network. That should not involve retaliations; hacking back to destroy the other guy’s machine has no useful purpose and should be illegal. But if you see your data going to some other network, why can’t you go into that network for the purpose of getting your data back, or take data off that machine to mitigate the damage? Allowing the private sector to do things like that can help companies make themselves a much less attractive target.”</p><p><em>—as told to Tom Simonite</em><span><br /></span></p></td>
    </tr>
    <tr>
      <td>Leah Busque</td>
      <td>In the jobless economic recovery, an online labor marketplace thrives.</td>
      <td>33</td>
      <td></td>
      <td>entrepreneurs-2013</td>
      <td><p>When Leah Busque worked as a software engineer for IBM’s Lotus group, her favorite part of the job was attending an annual conference at Disney World, because it was the only time developers in her division got to meet customers. It made her realize she wanted to start a business of her own.</p><p>So in 2008, just before the financial crisis hit, she quit IBM to work on an idea she had: that people should be able to go online and easily hire their neighbors to do quick errands and other odd jobs. She later called it TaskRabbit.</p><p>She assumed that the jobs would mainly attract college students who needed extra cash. But the interest turned out to be much wider. Today, 13,000 TaskRabbits bid for jobs in 14 U.S. cities. Three-quarters of them hold bachelor’s degrees; 5 percent have PhDs. These “micro-entrepreneurs,” as Busque calls them, include retirees, mothers, the unemployed, and the underpaid. They do everything from delivering lunches and fixing toilets to dressing up as a hot dog for a surprise birthday party (true story). Pay might be as low as $10 per task, but some skilled jobs fetch hundreds, especially for TaskRabbits with high reputation rankings on the site. The employer pays a 20 percent commission to TaskRabbit.</p><p>Busque says TaskRabbit has just scratched the surface of what it can do. It recently expanded to help small businesses or event planners find temp workers without going through expensive placement agencies or the wilds of Craigslist.</p><p>“Our vision is huge: to revolutionize the way people work,” she says. “It’s about offering people more choice on how they work, what their schedules are like, how much they get paid, [and the choice of] being their own bosses.”</p><p>—<em>Jessica Leber</em></p><p><iframe src="//www.youtube.com/embed/4vmfcxR0Frw" frameborder="0" width="530" height="285"></iframe></p></td>
    </tr>
    <tr>
      <td>Anthony Goldbloom</td>
      <td>A startup called Kaggle tries to bring smart people to knotty problems.</td>
      <td>30</td>
      <td></td>
      <td>entrepreneurs-2013</td>
      <td><p>Anthony Goldbloom had been a data analyst when he founded Kaggle, a startup that helps companies outsource thorny problems to data crunchers like him. Yet when he was launching Kaggle, he relied on no data at all. He just figured it would work.</p><p>Back in 2008, Goldbloom was taking a break from his job as an analyst at the Australian Treasury. He had a reporting internship at <em>The Economist</em> in London—a position he snagged by winning an essay contest. While working on a story about predictive modeling, he spoke to people at large companies who told him how hard it was for them to make sense of data they had collected. Many companies didn’t even have anyone who could do it.</p><p>That gave Goldbloom the idea: he would create a website where data scientists could compete to win cash in their spare time by solving such problems for companies. He didn’t know much about programming, so he taught himself to code and built the website in his bedroom in Melbourne, Australia.</p><p>The site launched in 2010 with a contest that Goldbloom conceived and sponsored himself: $1,000 to the person who could determine most accurately how countries would vote in the annual Eurovision Song Contest. The BBC picked up the story, as did the tech news site Slashdot, which helped Goldbloom get the attention of institutions including the University of Pennsylvania and NASA. The insurance company Allstate offered $6,000 to whoever could come up with an algorithm for predicting the bodily-injury liability payments that result from accidents involving particular kinds of cars. An actuarial consultant in Australia took that prize.</p><p>As more and more companies began putting forward challenges, more and more data geeks joined Kaggle to vie for the opportunities. Now the user base exceeds 100,000, large enough to give the company another revenue stream: for a fee, it will match up companies with specific top performers.</p><p>“If you look around in the professional world, I can’t think of another labor market that’s truly meritocratic,” Goldbloom says. “That’s what we’re trying to create: the better you are, the more you earn, the more work you get.”</p><p>—<em>Rachel Metz</em></p></td>
    </tr>
    <tr>
      <td>Dmitry Grishin</td>
      <td>When the Internet was getting big in Russia, he was in the right place at the right time. Now he hopes to do it again with personal robotics.</td>
      <td>34</td>
      <td></td>
      <td>entrepreneurs-2013</td>
      <td><p>Dmitry Grishin was born on a missile base in the Soviet Union. He grew up around technical people working on secret projects; his father designed radar systems for the MiG-29 jet fighter.</p><p>In Russia, every boy wanted to be a spaceman. But Grishin was taken by robotics. He remembers seeing his first Western VCR when he was about 12 and being fascinated by the mechanical movement that drew the tape into the player. There were Russian robots to admire as well, like Lunokhod 2, a remote-controlled lander that had set down on the moon in 1973. “That you can sit on Earth and drive the device—I thought it was so cool,” he says.</p><p>Then came the end of the Soviet Union and the tarnishing of its glories. Grishin left home for Moscow State Technical University with a few rubles. But he had a knack for programming and for managing others. By the time he was 20, he was overseeing programmers in Florida for a computer-aided design company from his student hostel in Moscow.</p><p>Those were the early days of the Russian-language Internet, known as Runet. The goal was to copy U.S. ideas, much as eBay was copied by Molotok.ru, an auction site Grishin joined in 2000. To stretch Molotok’s limited resources, Grishin hunted online for equipment being sold off by failed U.S. dot-coms, scooping up $100,000 networking devices for $5,000. Later, to expand Mail.ru, an e-mail service, he bought cheap servers from China and used software to create redundancies. “We played a lot of tricks to create a big technology,” he says.</p><p>By 2001, Molotok and other struggling Web projects were swept together by Yuri Milner, the Russian financier who later made a killing on Facebook shares. Milner made Grishin CEO of the combined company, which is now called Mail.ru Group. Was it typical in Russia to be picked as CEO at just 24? “There’s not that much typical stuff in Russia,” Grishin deadpans.</p><p>To be sure, Mail.ru is Russia’s Yahoo, not its Google. It’s the site with cat pictures and tacky come-ons. It owns chat services, e-mail, and a social network, Odnoklassniki (“classmates”), that attracts a lower-tech crowd. Even so, when Mail.ru staged the first large IPO by a Russian Internet firm, in 2010, it raised $912 million. Grishin has managed to steadily increase the profits from ads and online games. “If you watch the performance of the company, then you’d say he’s an innovative visionary who built well on the business model,” says investment banker Terry Schallich of Pacific Crest Securities, which helped manage Mail.ru’s IPO.</p><p>Russia’s non-Roman alphabet made foreign services slow to enter the country. But now that Russia has more Internet users than any other country in Europe, it’s not clear how long the domestic Internet firms can maintain their separate fiefdom. Facebook has started to become very popular. Grishin’s response has been to try to expand Mail.ru outside of Russia, or “to go on the attack,” as he says. In 2012, Mail.ru launched a Twitter rival that it built in a month; it offered big pictures and video (which Twitter now offers too). It didn’t succeed, but Grishin has invested heavily in massive multiplayer games that may yet find an international market.</p><p>What has most raised Grishin’s profile outside Russia was his launch in 2012 of Grishin Robotics, a venture firm dedicated to what he calls “personal robotics,” in which he invested $25 million, or about 15 percent of his net worth, he said in a 2012 interview. His fund has invested up to half a million dollars each in companies like DoubleRobotics, maker of a $2,500 telepresence robot, and RobotAppstore, a site to download games or instructions into toy robots.</p><p>There’s something childlike about Grishin’s interest in robotics. He likes to imagine automated chairs that would swoop to wherever someone wants to sit. Or drones that fly over a wedding to snap pictures. The holdup to these visions has been technology. Now, with inexpensive sensors and software, he thinks robots—like e-mail in Russia a decade ago—are ready for mass consumer markets.</p><p>—<em>Antonio Regalado</em></p></td>
    </tr>
    <tr>
      <td>Ben Milne</td>
      <td>Digital payment systems dreamed up in the Web era still piggyback on credit card networks. There ought to be a faster and cheaper way.</td>
      <td>30</td>
      <td></td>
      <td>entrepreneurs-2013</td>
      <td><p>The Internet can move data from one person to another in a fraction of a second. Why can’t it do the same for money? Ben Milne asked himself that question, and the answer led him to found Dwolla, a digital payment network that could make it faster, easier, and safer for money to change hands.</p><p>Dwolla is on track to process over $1 billion for 250,000 consumers and businesses in 2013. It has amassed $22.5 million in venture capital and emerged as a threat not only to the likes of PayPal but also to venerable institutions such as Visa. Yet Milne is not a financier or a university-educated wunderkind. He sports the shaved head and full beard of a San Francisco hipster, but he’s an Iowan who is building his company in Des Moines.</p><p>Seated in a conference room at the Silicon Valley offices of his latest investor, Andreessen Horowitz, where the founders of Twitter and Skype got funding that led to Internet glory, Milne discusses the complex world of payments with confidence and liberal use of the phrase “the reality is.”</p><p>“The reality is, the way we exchange money makes money worth less,” he says. If you sell something for $100 with a $10 margin, your profit would be $7.50 or less if the customer paid with a credit card. “You can’t drive down the fees with regulation, because that’s the technical cost,” he says. “To remove it, you need a better mechanism for exchanging value. That’s Dwolla.”</p><p>Milne grew up in Cedar Falls, Iowa, where he passed the time playing soccer and repairing broken appliances his grandmother collected. When he was in middle school, his father, a dentist, was diagnosed with Parkinson’s disease but was determined to do as much as possible while he still could: he built a public soccer stadium and golf course. Those actions held an important lesson for Milne. “I remember thinking, he didn’t know anything about that, but he figured it out and did it,” he says. “I realized that all you need to do, a lot of the time, is decide what you want to do and just get it done.”</p><p>Milne started his first company, which made audio speakers, with $1,200 in savings in 2001, while he was a senior in high school. He dropped out of the University of Northern Iowa to build the business, and by 2008 he was racking up $1.5 million in sales annually. But he was troubled by costs. “We were spending $55,000 a year in credit card fees,” he recalls. “I thought, that’s insane. I’m making the sales, and I just sent these people’s kids to college.”</p><p>Milne became convinced that no solution existed and that the only way to get one was to build it himself. Over the next two years, he figured out how to do it. “He would commit himself to doing seemingly impossible things,” recalls Matt Harris of Bain Capital Ventures, who funded Dwolla during this period as a managing partner at Village Ventures. “Then we’d meet three months later, and he would have done them and have a new set of impossible things.”</p><p>Dwolla launched nationally in December 2010 and was moving $1 million a day in July 2011. By the end of last year it was doing nearly three times that volume. “It was not a beautiful, predictable, calculated process,” Milne says. “It was ‘Don’t go broke and don’t stop.’”</p><p>In a market overflowing with mobile payment services and digital cash schemes, Milne’s service is unique. Nearly all electronic payment systems, including PayPal, are built on the four financial networks that carry noncash transactions. Dwolla (as in “dollar” plus “Web”) can avoid all of them. It has built its own network, known as FiSync, that connects to banks directly. So Dwolla doesn’t need to pay fees to anyone. It can be used in just about any scenario: at a cash register, from a phone or a desktop PC, person to person, business to business, bank to bank.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/ent.milnex299.jpg" alt="Ben Milne with sledgehammer"><figcaption></figcaption></figure>\n<p>Merchants get the most obvious benefit: the recipient of a Dwolla transfer pays 25 cents per transaction over $10, but nothing for deals worth less than that. Compare that with the 2 to 3 percent plus 30 cents per transaction typical of credit cards and gateways to credit networks. For consumers, the system is simple: they can send money to an e-mail address, phone number, Twitter handle, or Facebook friend; the recipient will get a message prompting him or her to sign up with Dwolla to accept the money. And banks benefit because Dwolla can move money in real time, a capability no other network has. The Automated Clearing House, or ACH, the bank-to-bank transfer system that credit and debit cards depend on, theoretically settles in 24 hours. But in practice it can take up to five days, creating a risk that payers will turn out not to have the money they thought or claimed they had at the moment of a transaction.</p><p>FiSync also adds layers of security. Among other things, money is transferred by means of digital tokens that confer authorization to execute specific transactions; account details themselves are not transmitted. Consequently, Dwolla claims fraud rates an order of magnitude smaller than other transaction systems do.</p><p>Technically, FiSync is simple. Logistically, it requires that Dwolla ink deals with every bank in the country. That’s because each bank maintains its own database of accounts. A given institution can transfer funds electronically within its own walls instantly and freely, but to go outside, it needs to use the ACH or wire networks. FiSync would replace those by connecting to every bank’s database directly.</p><p>Milne has signed up only 16 financial institutions but says he is on the verge of dramatically expanding that number. It will take a lot of legwork, but he is ready to proceed bank by bank. “In Silicon Valley, people are looking for a silver bullet,” he says. “I look at it like a Midwesterner: I have an ax and I’m going to cut down a tree. You close the first customer, then the second, then the third. It’s hard work, but that’s the way you do it.”</p><p>—<em>Ted Greenwald</em></p></td>
    </tr>
    <tr>
      <td>Bright Simons</td>
      <td>The mPedigree Network, based in Ghana, lets people determine with a text message whether their medicine is legitimate.</td>
      <td>31</td>
      <td></td>
      <td>entrepreneurs-2013</td>
      <td><p>“I grew up in Ghana, where we’d inherited the British boarding school system. At Presbyterian Boys High School, many upperclassmen were abusive toward the younger students. Once, I was made to stay awake all night in a kneeling position outside. But in my final year at school I became student council president and led efforts to reduce abuses. That experience opened my eyes to a whole new world of fighting the system—of being an activist. And this led directly to my becoming a technology innovator.</p><p><span>A few years later, after studying astrophysics at Durham University in the U.K., I transferred that instinct to try to help African farmers. They grow food organically by default, because they don’t have money for chemicals. But they also don’t have money for the organic certification process that would let them get better prices. So in 2005, I led a team of PhD students to try to implement a solution using mobile technology.</span></p><p>The idea was that at the point of sale there’d be a code on the product. You’d enter that in a mobile device, and up will pop the history and even pictures of the farm. But we realized a big flaw: farmers have to be trained to do the coding. This was not practical.</p><p>But picking up a fruit and wanting to know if it is organically grown is similar to picking up a pack of medicine and seeing if it was properly tested and certified. About 2,000 people die every day from counterfeit medicine. So we shifted the idea to pharmaceuticals.</p><p>In 2007 we set up a nonprofit organization in Ghana and rolled out a pilot, and the next year Nigerian health officials invited us to replicate the concept there. But we wanted to get to a point where a big company like Sanofi-Aventis would use us. We learned that most companies won’t do business with an NGO, so in 2009 we launched mPedigree as a business.</p><p>You can send a free text message and get a reply in a few seconds verifying [that a medicine] is authentic. In addition, distributors and other middlemen can check the codes to verify that the supply has not been compromised. This helped reveal to a major Indian company that there was pilfering at a depot. Genuine antimalarial medicines would be replaced by counterfeits. The shady characters cannot get away with this anymore. If we had not stopped these leakages in the supply chain, they could have put thousands of patients at risk.</p><p>The system is used in Ghana, Nigeria, Kenya, and India, with pilots in Uganda, Tanzania, South Africa, and Bangladesh. We’ve got a relationship with many of the major regional—and a growing number of multinational—pharmas, including Sanofi-Aventis. In Nigeria our codes are on 50 million packs of antimalarial drugs alone, and we have just signed up two Chinese drug makers.</p><p>We are now expanding to seeds, cosmetics, and other businesses. And new applications are emerging that we hadn’t expected, in the areas of logistics, supply chain management, and marketing. If you send an SMS to check authenticity, you’ve also given good information about exactly where and when a drug was sold—as well as provided a potential marketing opportunity to dispense coupons. We have built a major platform for supply chains in the developing world. But back at my school, of course, they still remember me as the activist.”</p><p>—<em>as told to David Talbot</em></p></td>
    </tr>
    <tr>
      <td>Balaji Srinivasan</td>
      <td>Screening prospective parents for recessive diseases could be the first big hit in clinical genomics.</td>
      <td>33</td>
      <td></td>
      <td>entrepreneurs-2013</td>
      <td><p>No company performs more genomic screens for medical use than Counsyl, a startup cofounded by Balaji Srinivasan. It scans the DNA of parents in 3 percent of all births in the United States. And yet when Srinivasan founded the company in 2007 with friends from graduate school and his brother Ramji, a mathematician who was pursuing an MBA, just about everyone was advising against it.</p><p>Their father didn’t want them to go into medicine—which is somewhat surprising given that both of their parents are physicians. “He thought we should go into computer science,” Balaji Srinivasan says. And colleagues at Stanford, where he teaches computational biology and statistics, said that if he was going to found a company doing genetic analysis, it should test for genes that might be implicated in common illnesses like heart disease and diabetes. But Srinivasan didn’t want to get mired in the uncertainty over the complex ways genetics plays out in those kinds of diseases. With genome analysis only just beginning its march from research labs into doctors’ offices and other clinical settings, Srinivasan figured a successful company would need to start with a more straightforward problem. That’s why Counsyl began by testing only for recessive genetic diseases that are extremely well understood. “Anything that is a research question is premature for a business,” he says. “Running a business is hard enough. Your fundamental science has to be rock solid.”</p><p>Every year, three out of every 1,000 children are born with a genetic disease, such as cystic fibrosis, that did not afflict the parents—who most likely unknowingly carried a defective copy of a particular gene. If both parents carry a damaged copy, there is a 25 percent chance that their child will have the disease.</p><p>For around $99 (after insurance coverage), a couple’s doctor can order a test from Counsyl, which will extract DNA from the parents’ saliva or blood and sequence more than 100 different genes linked to recessively inherited diseases. If prospective parents both carry a broken copy of the same gene, then they can decide what to do: try to conceive naturally despite the risk, avoid conceiving, or use in vitro fertilization to conceive and have doctors screen out embryos that carry the double dose of defective genes. Counsyl is now screening the parents in about 120,000 births each year.</p><p>“Diagnostics is going to be completely reinvented by genomics,” Srinivasan says. “And we are one of the first to get out there.”</p><p>—<em>Susan Young</em></p></td>
    </tr>
    <tr>
      <td>Julie Kientz</td>
      <td>If you want to use technology to make life better for people with autism and their families, the trick is to make the technology secondary.</td>
      <td>33</td>
      <td></td>
      <td>visionaries-2013</td>
      <td><p>Julie Kientz is an expert in human-computer interaction. But unlike many other computer scientists, she spends much of her time far away from a computer screen, figuring out the human side of the equation.</p><p>With her people-first perspective on technology, the <a href="http://depts.washington.edu/chilllab" target="_blank" rel="noopener noreferrer">University of Washington professor</a> is at the forefront of an emerging idea: using relatively simple and common computing tools to improve human health. Kientz has created novel ways of helping people with sleep disorders and families with autistic children, such as a program that uses Twitter to help track key developmental milestones. “I think a lot of people in our area are like, ‘I have a hammer, let’s find a nail,’” says A. J. Brush, a senior researcher at Microsoft. “She’s really thinking hard about what’s the challenge, how to address it, how do I understand it.”</p><p>Kientz’s methods were formed in graduate school at Georgia Tech. Her doctoral advisor, <a href="http://www.gregoryabowd.com/" target="_blank" rel="noopener noreferrer">Gregory Abowd</a>, an expert in interactive computing and its use in health care, happens to have two sons with autism. His dedication to them inspired Kientz to investigate technology that could improve their care. But she didn’t begin with the technology. She trained to be a therapist for autistic children and worked as one for a year and a half.</p><p>During sessions with an autistic child, a therapist might ask the child to point to a specific item, like an apple, from an array of objects; to imitate a word or gesture; or to copy the therapist’s arrangement of blocks. Therapists use pen and paper to chart the child’s ability to perform such tasks over time.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/vision.kientzx299.jpg" alt="The Lullaby prototype."><figcaption>Lullaby, shown here as a prototype, is meant to collect data from people with sleep disorders.</figcaption></figure>\n<p>By working as a therapist and talking to others, Kientz identified problems with the paper-based method. One was that multiple therapists might need to review a child’s records, but there was only one copy of the binder filled with hand-marked charts and notes. And with data points trapped on paper, there wasn’t a good way to visualize broader trends or review negative blips in a child’s otherwise positive progress.</p><p>Kientz’s solution was for therapists to use a digital recording pen and special paper that could digitize their writing. The change was unobtrusive to the therapist and invisible to the child. But notes and chart inputs made their way automatically into a database and were synched with video recordings of each session. This meant therapists could project progress graphs at meetings and pinpoint moments when a child didn’t perform as well as expected. They could immediately access video from that moment in a therapy session; in one instance, therapists reviewed the video and agreed that they each had different standards for a “right” response. As a result, the child was given credit for mastering a skill and could move on to new challenges.</p><p>To Kientz, this human-centered use of computing was an antidote to frustrating internships she had held as an undergraduate at the University of Toledo, including one at Compaq in which she wrote debugging programs for a microchip. “It was really hard for me to see that connection between what I thought was the really impactful work and what I was doing on a day-to-day basis,” she says, speaking in an office littered with geek ephemera such as a software engineer Barbie doll. (Kientz is married to Washington professor <a href="http://www2.technologyreview.com/tr35/profile.aspx?TRID=814">Shwetak Patel, an Innovator Under 35 in 2009</a>.)</p><p>Through her work with autistic children, Kientz learned that federal health officials at the Centers for Disease Control and Prevention were looking for ways to spot signs of autism and developmental delays earlier in children’s lives. When she dove in, interviewing parents and doctors, she realized that many families were already recording information the government was looking for, but their formats—snapshots, video, baby books—were hard to integrate with the conventional tracking data gathered by health professionals.</p><p>Kientz wondered if there was a way to combine the two kinds of data gathering. That led her to build a computer program called Baby Steps while she was still in grad school. It combined traditional baby-book functions (asking parents to post pictures of sentimental moments like a child’s first trip to the zoo or to Grandma’s house) with ways to record specific developmental milestones (is the baby making eye contact?). Baby Steps has been tested by a handful of families, and Kientz has a $500,000 grant from the National Science Foundation to explore whether the program could scale up to track milestones for any child in Washington state whose parents want to take part.</p><p>In this project, too, Kientz is deciding how to develop the technology only after first understanding how people might use it. She found that many Hispanic families in Washington don’t have home PCs and are more likely to go online using phones. So she added phone-friendly features such as the ability to respond to prompts from text messages or Twitter. For example, parents can follow a Twitter account that corresponds to the month their child was born. They might get a prompt that includes an age-appropriate milestone and a code so that their reply will get filed in the database. They might see:</p><p class="p1"><span>@BabySteps_Nov2012: Does your baby turn his/her head in the direction of a loud noise? #baby68</span></p><p><span class="s2">And then they could respond:</span></p><p class="p1"><span>@juliekientz: #Yes #Maya turns her head in the direction of a loud noise #baby68</span></p><p>For another project, Kientz is trying to make it much easier for people with sleep disorders to figure out what’s wrong. Typically, they might have to go to a lab and get loaded up with electrodes for the night; later, they might sit in front of specialized equipment to test things like how their reaction time suffers when they’re experiencing a sleep deficit. Kientz wanted to help people do all this themselves, at home. So she and collaborators from UW’s medical and nursing programs built a prototype called Lullaby. It’s a box with light, temperature, and motion sensors sticking out, wired to a computer and a touch-screen tablet. Patients wear an unobtrusive commercial gadget such as the Fitbit, which tracks exercise by day and sleep patterns by night. They don’t have to fill out sleep logs, which are notoriously inaccurate. And to replace the lab exams measuring reaction times, Kientz’s group developed a smartphone app that lets people test themselves.</p><p>Getting inspiration from actual human problems is leading Kientz and her graduate students in surprising directions—such as software they recently developed to help visually impaired people do yoga. “I feel like there’s two routes you can go in research in my field,” she says. “You can help a lot of people in a little way. Or you can help a few people in a big way.”</p><p>—<em>Jessica Mintz</em></p></td>
    </tr>
    <tr>
      <td>Per Ola Kristensson</td>
      <td>New computing devices are inspiring new ways to input text.</td>
      <td>34</td>
      <td></td>
      <td>visionaries-2013</td>
      <td><p>Per Ola Kristensson is making it easy, fast, and intuitive to input text on mobile devices. He helped invent the popular gestural text-entry method known as ShapeWriter, but that’s just the beginning. Kristensson, a lecturer in human-computer interaction at the University of St. Andrews in Scotland, thinks gestures could be combined with speech recognition and even gaze recognition in a text-entry system that makes it easier to correct mistakes and enter unpronounceable information like passwords. “I’m interested in optimizing the flow of information from your brain into the computer,” he says.</p><p>ShapeWriter lets you enter text by dragging a finger over the letters in a word. The software then stores the squiggle or shape that you make when you touch those letters as a stand-in for the word itself. The shapes for common words are easy to recall; any time you want to enter such a word, you can quickly reproduce its shape instead of pecking at the letters again. Practiced users can gesture-type in excess of 30 words per minute—blinding speed on the typical mobile device. The ShapeWriter app was downloaded more than a million times from Apple’s App Store before it was bought by Nuance Communications in 2010. Now the technology is built into Android, where it’s called “gesture typing.”</p><p>Kristensson, who has a quick smile and an easy laugh, has always sought to fuse disparate fields of inquiry. Growing up in Sweden, he bucked an educational system designed to channel students into narrow specializations. He was drawn to computer science but couldn’t bear spending four years studying nothing else. So he opted for cognitive science, which enabled him to study not only computer science but also linguistics, philosophy, and psychology. That combination launched him on the path to creating user interfaces that are fundamentally changing the way we interact with computers.</p><p>His work on tools for disabled people illustrates his approach to problem solving. Many people who can’t speak and have very limited manual dexterity communicate by slowly typing words and prompting a computer to pronounce them. Their communication speed averages one or two words per minute. In such a laborious process, predicting the speaker’s intent can greatly accelerate the task. This requires what is known as a statistical language model. “I was amazed to find that in 30 years of development of this kind of technology, no one had produced a good statistical model for the things these people need to say,” Kristensson explains.</p><p>The main problem is the dearth of data from which to derive statistical relationships. You can’t wiretap the computers used by large numbers of disabled people. So Kristensson came up with an alternative: ask people who are not disabled to imagine what they would say if they had to communicate by this method. He used Amazon’s Mechanical Turk to crowdsource imagined communications—”Who will drive me to the doctor tomorrow?” and “I need to make a shopping list.” Then he combed through Twitter, blogs, and Usenet for phrases that were statistically similar to the ones generated by Mechanical Turk. After several iterations, he had the tens of millions of phrases he needed to build a useful model.</p><p>These days, Kristensson is working on technology that supports super-fast typing: a gargantuan statistical language model that accurately interprets typed input despite large numbers of mistakes. He’s also working on new ways to enter text in the absence of a touch screen or keyboard. Such technology will be necessary to make the most of wearable computing devices such as Google Glass, but it will have to work nearly perfectly to be of any benefit, given how frustrating a bad speech-to-text system can be. “In a few years, we’ll have amazing sensors that will help us generate contextual information to create truly intelligent, adaptive interfaces,” he says.</p><p>—<em>Ted Greenwald</em></p></td>
    </tr>
    <tr>
      <td>Eric Migicovsky</td>
      <td>How he invented the smart watch.</td>
      <td>27</td>
      <td></td>
      <td>visionaries-2013</td>
      <td><p>It’s 2008. Eric Migicovsky is racking up kilometers every day on his sturdy blue <em>opafiets</em>—the no-nonsense bicycle beloved by Netherlanders. He’s wheeling to classes at Delft University of Technology and other points in a city famous for its canals and blue-and-white pottery.</p><p>Life’s great for the young Canadian engineer on a year abroad from Ontario’s University of Waterloo. Except for one constant irritant. His cell phone never stops chiming, chirping, or vibrating. And prudence requires two hands firmly gripping the handlebars while veering through traffic between those picturesque canals.</p><p>“I read a survey that said the average person pulls out their cell phone 120 times a day,” he says. “It occurred to me, ‘Hey, what if I could just do it on my wrist?’”</p><p>Back in his dorm room, Migicovsky started fiddling with an electronic breadboard, an Arduino microcontroller, and bits scavenged from a Nokia 3310. The mishmash became a precursor to a prototype—a “smart” wristwatch wirelessly tethered to a cell phone so that it could display e-mails, texts, and other basic notifications. “Plus tell time,” he adds. “That still seemed a useful function for a watch.”</p><p>He eventually transformed his toy into one of this year’s most <a href="http://www.technologyreview.com/featuredstory/513376/smart-watches/">influential new technologies</a>—the Pebble smart watch. Today Migicovsky runs a company in Palo Alto that has 31 employees and sells watches in Best Buy for $150 apiece.</p><p>Copycats have sprung up, and Apple looms as a likely competitor. Migicovsky is already responding by rethinking how people might use the Pebble. It could become less of a notification display and more of an app platform in its own right. Migicovsky recently released a software developers’ kit intended to help other innovators devise applications solely for the watch—traffic trackers, weather predictors, exercise monitors, and games.</p><p>Getting here wasn’t easy. Back at Waterloo, Migicovsky worked with a few pals on an early version of the watch—the first generation was called “inPulse”—in the garage of their rented house. In 2011, the project was accepted into Y Combinator, which provides modest seed money, advice, and critical contacts for technologists. That brought Migicovsky to California. “If I had to pick someone who will be the next Steve Jobs, it would be Eric,” says Y Combinator founder Paul <span>Graham.</span></p><p>But big investments remained elusive. As a long shot, Migicovsky posted Pebble on the fund-raising site Kickstarter. He thought he might reel in $100,000. “In 30 days, we raised $10.2 million,” he says. “The smart watch revolution had begun.”</p><p>—<em>Colin Nickerson</em></p></td>
    </tr>
    <tr>
      <td>Lina Nilsson</td>
      <td>Lowering the  cost of basic biological research.</td>
      <td>33</td>
      <td></td>
      <td>visionaries-2013</td>
      <td><p>The UC Berkeley bioengineering lab where Lina Nilsson worked as a postdoc is filled with the kind of expensive equipment necessary for advanced biological research. But many labs around the world don’t have UC-level funding; they rely on hand-me-downs from well-heeled labs or simply do without. That makes it hard for them to find solutions to local problems such as the spread of malaria, never mind participating in the broader scientific enterprise.</p><p>Nilsson offers another option: DIY. As cofounder of Tekla Labs, an engineering collective on the Berkeley campus, she’s curating and distributing open-source, do-it-yourself designs for the gamut of common lab gear. A shaker for separating excess dye from stained cells, for instance, can be made from a discarded record turntable. A centrifuge can be fashioned from a modified kitchen blender. A thermal cycler for amplifying DNA requires only light bulbs and thermometers. In the hands of scientists who historically have lacked access to equipment, such tools can be powerful engines of innovation—generally, Nilsson says, at about one-tenth the price of high-end commercial equipment.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/vision.nilssonx519.jpg" alt=""><figcaption>Left: A magnetic stirrer was designed by a Tekla Labs contributor in New Zealand. Right: A rotator built by a member of the Tekla Labs team is designed to gently agitate biological samples.</figcaption></figure>\n<p>“Great ideas are everywhere, but opportunity is not,” she says. “My goal is to enable people to collaborate to solve global challenges.” Along with her work at Tekla Labs, she serves as innovation director at UC Berkeley’s Blum Center for Developing Economies, where she devises programs that bring together NGOs, scientists, engineers, and local organizations worldwide.</p><p>Nilsson was an outstanding, if uninspired, PhD candidate at the University of Washington in 2007 when, on a whim, she applied for a Bonderman Travel Fellowship, an open-ended program that gives students eight months to “come to know the world in new ways.” She traveled to Asia and South America, where she visited local biology labs. “It completely changed everything about how I see the world,” she says. “The discordance between the engagement of the scientists and their empty labs was jarring, and the vision for Tekla Labs started to emerge.”</p><p>The challenge now is to make sure Tekla Labs’ designs consistently yield devices precise and durable enough for serious research. After all, scientists everywhere need equipment they can rely on.</p><p>—<em>Ted Greenwald</em></p></td>
    </tr>
    <tr>
      <td>Steve Ramirez</td>
      <td>An MIT grad student can find and even change memories in a mouse’s brain.</td>
      <td>25</td>
      <td></td>
      <td>visionaries-2013</td>
      <td><p>“My parents came here from El Salvador in the late ’70s to escape from civil war. They worked 100-hour weeks to give me and my brother and sister the opportunity of a better life. Years later, we have all these opportunities that we couldn’t have dreamed of in El Salvador. I can’t think of any better motivator.</p><p>The first seeds of my interest in the brain were planted between junior high and high school, when my cousin went into labor. While under anesthesia during a C-section, she went into a coma that she’s been in ever since. The parts of her brain that are involved in producing consciousness and wakefulness were probably atrophied because they didn’t get enough oxygen for just a short period of time. It instantly hit me: all it takes are these little lumps of tissue in your brain to atrophy, and now everything that makes you <em>you </em>is evaporated.</p><p>Because the seemingly ephemeral stuff of cognition is based on the physical stuff of the brain, we can go in and manipulate it and see how something as complicated as memory works. When you are thinking of a memory, only a subset of brain cells are active, and those cells are specifically representing that memory. We can genetically modify neurons to produce a sensor that detects when brain cells are active and then installs an on-off switch in them. The switch is a protein that allows us to control the activity of a cell with light.</p><p>So now we can emit light and reactivate cells and see whether a mouse exhibits behaviors that show whether it is recalling a certain memory. We place the animal in a box where it gets mild foot shocks from the floor. Naturally, if we later put the mouse back in the box, it runs to a corner in fear—it sits there and freezes, crouching and monitoring. Next, we put the mouse in a completely different box—different smells, sights, floor texture. In this new box the mouse has no reason to be afraid. But when we shine a light to reactivate the cells involved in making that fear memory, the animal immediately goes into that defensive posture. We can also shine light and reactivate pleasurable memories, such as a male mouse’s memory of a female mouse.</p><p>In my second project, we tried to get a mouse to believe that it experienced something that it didn’t. We called it Project Inception. First, we label the brain cells that are involved in the memory of a chamber—environment A—where nothing bad happens. The next day we put the mouse in environment B, where it gets foot shocks, and we simultaneously shine a light to reactivate the memory of environment A. Then, when you put the mouse back in environment A, it displays freezing behavior. It is recalling falsely that it was shocked in environment A even though nothing happened there.</p><p>We are pushing this technology as far as possible. Perhaps we can alleviate post-traumatic stress disorder by erasing the underlying traumatic memory. Or perhaps we can treat certain types of depression by updating negative memories with positive emotions. Science fiction can often inform reality.”</p><p>—<em>as told to Susan Young</em></p><p><iframe src="//www.youtube.com/embed/kDXJhxLzmBQ" frameborder="0" width="530" height="285"></iframe></p></td>
    </tr>
    <tr>
      <td>Laura Schewel</td>
      <td>Looking more closely at the way people move through cities.</td>
      <td>29</td>
      <td></td>
      <td>visionaries-2013</td>
      <td><p class="p1"><span class="s1">When Laura Schewel worked </span>for an energy think tank and then the Federal Energy Regulatory Commission, she wanted to develop policies that would stimulate sales of electric cars. The trouble was, there wasn’t comprehensive and reliable data about where and when people drive.</p><p class="p2"><span class="s2">Typically, transportation experts construct predictive models to describe traffic patterns, or they conduct expensive surveys. Neither is particularly easy to do. “We have no idea what’s happening on the roads. Just none,” Schewel says. “When you compare that to what we know about what people watch on TV, it’s absurd.” </span></p><p class="p2">While in a PhD program at the University of California, Berkeley, she realized that people actually <em>were</em> revealing where they drive—to their cell-phone companies and GPS navigation services. She thought: what if I could get access to that data? It took a year to persuade companies to sell this valuable and sensitive information to a small startup she formed, StreetLight Data. The company, which aggregates and analyzes the signals from cell phones and dashboard GPS navigation systems, makes it easy for just about anyone to do what Schewel had long envisioned—see detailed maps of where, when, and how people travel through cities.</p><p class="p2"><span>With software that she and her team developed, Schewel can type in an address and find the demographics of the people who drive by or stop near that location. The system shows when they drive by, how frequently, and even what neighborhoods they’re coming from. (Importantly, Schewel’s algorithms analyze the movements of groups of these devices, rather than individual units. That means StreetLight’s analytics can’t be reverse-engineered to reveal any given individual’s movements.) </span></p><p class="p2">The information is appealing to customers far beyond the transportation–policy world. A medical office, an auto repair shop, and a small restaurant chain have been using StreetLight’s software to help them decide where to open new locations and place billboards. And the nonprofit Oakland Business Development Corporation is using the software to demonstrate that people with disposable income often spend time in Oakland even if they don’t live nearby. The data, the group hopes, will encourage small businesses and national chains to consider opening up shop in the city’s struggling downtown, which has 400 vacant storefronts and office buildings in one square mile.</p><p class="p2"><span class="s2">Schewel still believes she can make transportation more efficient. But rather than trying to persuade people to be green, she is focused on helping businesses—which have become “the most powerful behavioral-change force in America”—make it easy for people to do greener things. For example, if suburbanites can do some shopping near their offices in downtown Oakland on their commutes home, that might reduce the mileage they would otherwise have to drive. Naturally, Schewel backs up that idea with data: 30 percent of all miles driven in the U.S. are related to shopping. </span></p><p class="p2"><em>—Jessica Leber</em></p></td>
    </tr>
    <tr>
      <td>Yu Zheng</td>
      <td>Analyzing newly available data about the intricacies of urban life could make cities better.</td>
      <td>34</td>
      <td></td>
      <td>visionaries-2013</td>
      <td><p>Commuting through Beijing’s apocalyptic congestion and pollution can test anyone’s patience. But it has inspired big ideas from Yu Zheng, lead researcher for Microsoft Research Asia.</p><p>Take pollution. Most air-quality monitoring systems in China give a reading for an entire city. But air quality can vary greatly within cities depending on traffic, building density, and weather conditions. Zheng is taking that into account with a new project, <a href="http://www.uairquality.com" target="_blank" rel="noopener noreferrer">U-Air</a>. It analyzes current and past data from monitoring networks and many other sources to infer air quality at any given point in the city. Eventually Zheng expects the system to predict air quality one or even five hours in advance. That could help people figure out, say, when and where to go jogging—or when they should shut the window or put on a mask.</p><p>In an earlier project, Zheng and his team showed that online mapping services could recommend much better driving directions by taking gridlock into account rather than just finding the shortest routes. The trick was to learn from Beijing taxi drivers, who are forced to find the smartest routes every day. <a href="http://www.technologyreview.com/news/421560/adding-cabbie-know-how-to-online-maps">Zheng’s group analyzed GPS data from 33,000 Beijing cabbies</a> and figured out how to teach their subtle methods to a mapping program.</p><p>“When I see a problem,” he says, “I feel passionate about trying to solve it.”</p><p>—<em>Michael Standaert</em></p></td>
    </tr>
    <tr>
      <td>Caroline Buckee</td>
      <td>Cell phones can become a weapon against disease.</td>
      <td>34</td>
      <td></td>
      <td>humanitarians-2013</td>
      <td><p>In her work as an epidemiologist, Caroline Buckee thinks a lot about malaria—but the same could have been said when she was six years old. “There’s a story my dad tells about my dinnertime conversation when I was little,” she says. “I often used to say things like, ‘What’s your favorite disease?’ And it turns out my favorite was malaria.”</p><p>The obsession never quite waned, because malaria is caused by “a fascinating organism,” says Buckee, now an assistant professor at the Harvard School of Public Health. “It’s really a shape-shifter. It evolves very quickly to anything we throw at it. It’s a clever parasite.” And most disturbing, she says, even though it is treatable and preventable, malaria is still among the biggest infectious-disease killers of children.</p><p>In 2006, during a research trip to Kenya, it occurred to her that work her husband, Nathan Eagle (himself an <a href="http://www2.technologyreview.com/tr35/profile.aspx?TRID=802">Innovator Under 35 in 2009</a>), was doing with data about cell-phone use might be employed in the service of malaria prevention. What if, Buckee wondered, location data from cell phones were used to intuit a malaria outbreak’s point of origin? Locals might then be warned via text messages to avoid the area or use bed netting. Health officials could know where to concentrate their mosquito-spray efforts.</p><p>Indeed, when Buckee pored over data from 15 million Kenyan cell phones, telltale patterns emerged. People who had made calls or sent messages through a certain phone tower were extremely likely to later visit a region near Lake Victoria where malaria wound up erupting in force. The area near that tower was probably the original hot spot—and thus where health officials should focus.</p><p>Buckee and her colleagues are still figuring out the best way to use this data (which was one of <em>MIT Technology Review</em>’s <a href="http://www.technologyreview.com/featuredstory/513721/big-data-from-cheap-phones/">10 Breakthrough Technologies of 2013</a>). But the results so far give her confidence that she’s found a crucial tool for her work in epidemiology. “The ubiquity of cell phones is really changing how we think of diseases,” she says.</p><p>—<em>Timothy Maher</em></p><p><iframe src="//www.youtube.com/embed/ol2gu_rIpwY" frameborder="0" width="530" height="285"></iframe></p></td>
    </tr>
    <tr>
      <td>Rebeca Hwang</td>
      <td>Many innovations can’t happen without the right connections.</td>
      <td>33</td>
      <td></td>
      <td>humanitarians-2013</td>
      <td><p>Rebeca Hwang thinks the insularity of Silicon Valley stifles innovation. To fix this, she’s become what she calls a mega-connector, trying to make it easier for entrepreneurs anywhere to find opportunities.</p><p>Hwang has spent the past few years as CEO of San Francisco–based YouNoodle, which helps run competitions among technologists and entrepreneurs. For example, the Intel Foundation used YouNoodle’s online service Podium to run business-plan competitions in Latin America and Europe. The government of Chile used it to solicit requests for funding from entrepreneurs.</p><p>It’s one of many ways Hwang, who was born in South Korea and raised in Argentina, has tried to link far-flung people or ideas. As an MIT undergrad she studied chemical engineering; at Stanford she cofounded the Cleantech Open business accelerator and pursued a PhD in social-network theory before joining YouNoodle. </p><p>“I could have chosen to just go the academic route; I could have just done entrepreneurialism,” she says. “But I think I excelled most at the intersection—bringing all these parties together and coming up with solutions that have several perspectives.”</p><p>—<em>Rachel Metz</em></p></td>
    </tr>
    <tr>
      <td>Enrique Lomnitz</td>
      <td>A design student returned to his native Mexico City after college in the United States to help the megalopolis overcome its water crisis.</td>
      <td>30</td>
      <td></td>
      <td>humanitarians-2013</td>
      <td><p><span>“When I was at the Rhode Island School of Design, my friend and I worked on a project to develop sustainable housing for low-income sectors of Mexico City. We realized that access to water was getting worse, whereas telephones, pavement, security—all the other infrastructure—was improving. We became convinced that the city needed to develop an alternative way to get water. </span></p><p class="p2">About 70 percent of Mexico City’s water comes from the aquifer, and the water table drops something like a meter a year—it’s super stressed. The actual ground of the city sank more than 10 meters in the 20th century due to extraction of water. About 30 percent of the water is pumped 1,000 meters uphill from 150 kilometers or so away, which is just insane. They say it consumes as much electricity as the city of Puebla [which has 1.5 million people], and it takes up a major portion of the city’s budget. But by harvesting rainwater, you could achieve a massive systemic shift. Even with small cisterns, people could go for six months of the year just with rainwater, which is abundant during the rainy season. </p><p class="p2">Our initial challenge was to make a relatively low-cost system, which gives water of a certain quality using a simple filtration system, that you can retrofit onto existing houses. We interviewed this one woman who lives in one of these mountainside neighborhoods on the southern periphery of the city. My friend and I put one system with a cistern up at her house using about $1,000 out of our own pockets. Then I moved pretty much across the street from her and we started putting rainwater harvesting systems in the neighborhood, <a href="http://www.islaurbana.org/" target="_blank" rel="noopener noreferrer">building this concept</a>. Our rainwater systems hook up to cisterns, pumps, and the header tanks on roofs that feed water by gravity into a house.</p><p class="p2">We’ve installed close to 1,300 systems in four years, but we’ve been through many iterations, and it’s not something I ever see ending. We sell the systems; we’re starting to be able to offer philanthropic microloans, we have government funding, and we get donations, mostly corporate donations. We need to fish in a lot of ponds.”</p><p class="p2"><em>—as told to Martin LaMonica</em></p></td>
    </tr>
    <tr>
      <td>Evans Wadongo</td>
      <td>Growing up in Kenya, he strained to read by the dim light of a kerosene lantern. Now he’s making solar-charged lanterns and using them to spur economic development.</td>
      <td>27</td>
      <td></td>
      <td>humanitarians-2013</td>
      <td><p>Kenya’s unreliable electric grid doesn’t reach Chumvi, a village about two hours southeast of Nairobi, where many of the 500 residents live in mud-walled, grass-roofed homes and eke out a living raising goats and growing kale, maize, and other crops. Yet an economic transformation is taking place, driven by an unlikely source—solar-charged LED lanterns. It can be traced to the vision of Evans Wadongo, 27, who grew up in a village much like this one.</p><p>As a child, Wadongo struggled to study by the dim, smoky light of a kerosene lantern that he shared with his four older brothers. His eyes were irritated, and he often was unable to finish his homework. “Many students fail to complete their education and remain poor partly because they don’t have good light,” says Wadongo, who speaks slowly and softly.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/humanitarians.wadongo.1x519.jpg" alt=""><figcaption>In Chumvi, Kenya, Irene Peter helps her son with English homework by LED light, which is cleaner and less expensive than ­kerosene.</figcaption></figure>\n<p>As a student at the Jomo Kenyatta University of Agriculture and Technology, he happened to see holiday lights made from LEDs and thought about what it would take to bring LEDs to small villages for general lighting. After taking a leadership training course from a nonprofit group, he designed a manufacturing system for portable LED lamps that could be recharged by sunlight. While many such lamps are already for sale commercially—and are increasingly making their way into villages in poor countries—Wadongo decided that his lanterns would be made in local workshops with scrap metal and off-the-shelf photovoltaic panels, batteries, and LEDs.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/humanitarians.wadongo.2x299.jpg" alt=""><figcaption>Each lamp is stamped “Mwanga Bora,” which means “Good Light” in Swahili.</figcaption></figure>\n<p>Wadongo feared that the technology would be less likely to take hold if the lamps were simply given to people who had no financial stake in them. But the lanterns normally each cost 2,000 Kenyan shillings (about $23), which is out of many villagers’ reach. So he uses donations (including proceeds from a recent exhibition of his lamps at a Manhattan art gallery, at which donors gave $275 apiece) to provide initial batches of lamps to villages. Residents are generally quick to see the value in the LED lamps because of the money they save on kerosene. Wadongo then encourages them to put the resulting savings into local enterprises.</p><p>The transformation in Chumvi began two years ago, when a woman named Eunice Muthengi, who had grown up there and went on to study in the United States, bought 30 lanterns and donated them to women in the village. Given that the fuel for one $6 kerosene lamp can cost $1 a week, the donation not only gave people in the town a better, cleaner light source but freed up more than $1,500 a year. With this money, local women launched a village microlending service and built businesses making bead crafts and handbags. “We’re now able to save 10 to 20 shillings [11 to 23 cents] a day, and in a month that amounts to something worthwhile,” says Irene Peter, a 43-year-old mother of two who raises maize and tomatoes. “Personally, I saved and got a sheep who has now given birth.” She also got started in a business making ornaments and curios.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/humanitarians.wadongo.3x519.jpg" alt=""><figcaption>Christine Mbithi, a mother of four in Chumvi, chops spinach by LED lamplight.</figcaption></figure>\n<p>As profits rolled in from new enterprises like these, the women who got the original 30 lamps gradually bought new batches; according to Wadongo, they now have 150. “Their economic situation is improving, and this is really what keeps me going,” he says, adding that some people are even making enough to build better houses. “The impact of what we do,” he says, “is not in the number of lamps we distribute but how many lives we can change.”</p><p>Wadongo is also changing lives with the manufacturing jobs he is creating. In an industrial area of Nairobi, banging and clanking sounds fill a dirt-floored shack as two men hammer orange and green scraps of sheet metal into the bases of the next batch of lamps (soon to be spray-painted silver). Each base is also stamped with the name of the lamp—Mwanga Bora (Swahili for “Good Light”). The three men in the workshop can make 100 lamp housings a week and are paid $4 for each one. Subtracting rent for the manufacturing space, each man clears $110 per week—far above the Kenyan minimum wage.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/humanitarians.wadongo.4x519.jpg" alt=""><figcaption>A worker hammers scrap metal to form a lantern housing.</figcaption></figure>\n<p>Some of the lamps are completed in the kitchen of a rented house in Nairobi. Three LED elements are pushed through a cardboard tube so they stand up inside the lantern’s glass shade. The LED elements, photovoltaic panel, and batteries are sourced from major electronics companies. Overall, the devices are rugged; the steel in the housing of the lantern is a heavy gauge. If a housing breaks, it can be serviced locally—and the electronic parts are easily swapped out.</p><p>Wadongo now heads Sustainable Development for All, the NGO that gave him his leadership training, and he is focusing it on expanding the lamp production program. It has made and distributed 32,000 lamps and is poised to increase that number dramatically by opening 20 manufacturing centers in Kenya and Malawi. Wadongo says that teams in those centers will independently manufacture not only the lamps but “any creative thing they want to make.”</p><p>—<em>David Talbot</em></p></td>
    </tr>
    <tr>
      <td>Amos Winter</td>
      <td>Some problems aren’t apparent until you ask.</td>
      <td>33</td>
      <td></td>
      <td>humanitarians-2013</td>
      <td><p>“It bugs me sometimes the way people think about technology for the developing world,” says Amos Winter. “People think you can cobble it together from scrap parts, and undergrads can make it in a semester, and you can give it away for free. And none of that is necessarily true.”</p><p>Winter is lately renowned for having created a wheelchair specially tuned to the needs of people in poor countries: sturdy enough for uneven terrain, nimble enough to negotiate the indoors. The idea emerged when he was an MIT grad student visiting Tanzania in 2005; within three years he’d worked up a prototype to take back for a test run. That’s when his real education began. The chair was too heavy, users complained. It was too unwieldy to use inside. It wasn’t stable enough on hills.</p><p>Winter learned an important lesson: “We can’t just sit in this lab and make something on the lab bench and bring it to Tanzania and think it’s going to work,” he says. “It never works that way.”</p><p>Now a professor of mechanical engineering at MIT, Winter applies that lesson to other projects. In a cluttered back room of his lab, he holds aloft a prosthetic leg and points to a locked metal coupling, which is, he says, the most commonly used knee joint in poor countries. “When you walk with this, you walk with a peg leg,” he says. “In most developing countries there’s a stigma associated with disability, and walking around with this is a clear sign that you’re disabled.”</p><p>Winter’s goal is to make a low-cost leg that copies the natural gait of $50,000 advanced prosthetics. “A lot of it just comes down to ‘Let’s make something that performs as good as the rich-world technology, for a small fraction of the price,’” he says. That typically means cheaper materials, but it’s not quite as simple as that. Those new materials need to be readily available in the country where the product will be made. They are likely to weigh less, or more, and behave differently under stress—producing a whole new set of engineering challenges. Winter describes, with great enthusiasm, the massive amount of calculation required to get the torque of the knee just right at every point in the walker’s stride.</p><p>He’s more than a year away from a working prototype, but he has already asked potential users in India what they might hope to do if they had a better leg. “The highest-ranked thing was to be able to sit cross-legged,” he says. “With existing prostheses, you just don’t get the rotational twist you need. And I never would have guessed that. This is why it’s so important to get there on the ground.”</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/humanitarians.winterx519.jpg" alt=""><figcaption>From left: 1. Winter, with welding torch, builds prototypes by himself and with graduate students. 2. A knockoff of the popular Jaipur prosthetic foot. Winter is trying to design a better foot. 3. The single-axis, exoskeletal prosthetic knee forces those who use it to walk with a peg-leg gait. Winter wants to make a low-cost leg that affords a more natural stride. 4. The speed control of the lathe in Winter’s lab.</figcaption></figure>\n<p>Winter’s lab has the feel of a clubhouse; his students cheerfully mill about, and models and prototypes litter every tabletop. At the back end is a machine shop strewn with aluminum chips. You wouldn’t gather, at a glance, that these prototypes might touch anyone outside this room, but Winter talks about the “monumental potential for impact.” He gestures toward a mockup featuring a couple of plastic bins and some tubing: an experimental model of a drip irrigation system. To compensate for the often spotty power grids in poor countries, Winter’s version would use only a tenth of the pressure required by conventional systems and thus consume much less electricity. His system relies on an engineering trick involving plastic tubing that mimics the action of bronchia in lungs.</p><p>“If we crack this, and I think we’re going to, this is a billion-person problem,” he says. “Megafarms in Iowa can use this technology as well.”</p><p>—<em>Timothy Maher</em></p></td>
    </tr>
    <tr>
      <td>John Dabiri</td>
      <td>How is a  wind farm like a school of fish?</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p>Caltech professor John Dabiri uses his engineering expertise to try to understand how animals move in their natural environments. While researching the swimming patterns of fish, he recently came to a surprising insight: the way we’re thinking about wind power—specifically, the design of wind farms—is wrong.</p><p>Conventional wind farms are designed to minimize the turbulence caused by interactions between turbines. That creates an obvious problem, says Dabiri: “You space them out as far as possible. If you’re talking about a wind turbine that has a 100-meter diameter, then you’re talking about as much as a mile between wind turbines. That’s a lot of space that could be used to generate electricity, but can’t be because of these turbulent interactions.”</p><p>Dabiri thought of a solution while researching how fish form schools to minimize drag as they move about. “Fish can reduce the amount of energy that they use if they swim in certain coördinated arrangements as opposed to swimming alone,” he explains. “In fact, fish in large schools form precise, repeating patterns that allow them to move most efficiently. There’s some basic fluid-mechanics theory that you can use to explain why that might be the case. Jotting down the math for urban wind-turbine analysis, there was sort of a eureka moment where I realized that the equations were exactly the same equations that explain fish schooling.</p><p><span>“Why not use how fish form schools as a starting point for understanding how to design wind farms?” asks Dabiri. “We began to use the same tools that were used to determine the optimal configuration for fish schools to optimize the wind farm. We looked at an arrangement that’s been identified as optimal for fish, and we found that if we, in our computer models, arranged our wind turbines exactly in the same kind of diamond pattern that fish form, you get significant benefits in the performance of a wind farm.”</span></p><p>To maximize that performance, Dabiri would use vertical wind turbines, which have been around for years but are much less common than the familiar horizontal–axis turbines. Vertical turbines can perform better when they are packed together—at least if they are arranged in the optimal pattern Dabiri discovered. That raises the possibility of redesigning wind farms to increase the amount of power they produce and lower the cost. Dabiri says the turbines could be squeezed into existing wind farms so that they produce more power without taking up any more land. It’s a solution that could greatly reduce the drag on an industry that often seems to be swimming upstream.</p><p><span>—</span><em>Kevin Bullis</em></p><p><iframe src="//www.youtube.com/embed/x2audOlniaQ" frameborder="0" width="560" height="315"></iframe></p></td>
    </tr>
    <tr>
      <td>Leslie Dewan</td>
      <td>What if we could build a nuclear reactor that costs half as much, consumes nuclear waste, and will never melt down?</td>
      <td>28</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p>The nuclear power industry has a reputation for resisting innovative changes. But Leslie Dewan and a colleague have dared to invent a new type of nuclear reactor. “We were feeling on top of the world. We just passed our qualifying exams for our PhDs,” she says. “We thought, ‘We’re the smartest we’ve been in our lives. We can do anything. Let’s change the world with nuclear.’” Two years later, she’d designed a reactor that solves the main problems facing nuclear power. To commercialize it, she’d cofounded a startup, Transatomic Power.</p><p>For decades the nuclear industry has built one type of reactor, called a light-water reactor, almost exclusively. There are significant problems with that technology, which uses ordinary water to cool the fuel rods in which the nuclear reaction takes place. It requires expensive safeguards against a radiation-releasing meltdown if the fuel rods overheat; it produces waste products that are dangerous for 100,000 years. Dewan and a fellow graduate student, Mark Massie, designed an alternative based on molten-salt reactors that were originally proposed in the 1950s as a way to power aircraft. Though nuclear planes never became a reality, the reactor design has several key advantages. For one thing, it can be readily modified so that rather than producing large amounts of waste, it reuses much of the spent nuclear material as fuel.</p><p>It is also far safer than the light-water reactors, which require a constant source of electricity to pump in cool water and prevent the runaway nuclear reactions that lead to meltdowns. Molten salt serves as the coolant; it’s mixed with the nuclear materials, so the reactions take place right in the liquid. The heat of those reactions keeps the salt molten. A plug at the bottom of the reaction vessel is made of the same salt, kept solid by cooling it; if the plant’s electricity supply is lost, the plug warms up and liquefies, allowing the contents of the reactor to drain into a large containment tub and spread out so that the nuclear chain reactions come to an almost complete stop. The nuclear material and molten salt then cool down and turn into a contained solid that poses no danger of a meltdown.</p><p>The technology had one glaring problem, though: the reactors were large and, thus, expensive for the amount of power they produced. Dewan found a solution. “We realized that with some relatively modest changes to molten-salt reactors we could make them much more power dense and therefore a lot cheaper,” she says. She introduced new materials and a new shape that allowed her to increase power output by 30 times. As a result, the reactor is now so compact that a version large enough for a power plant can be built in a factory and shipped by rail to a plant site, which is potentially cheaper than the current practice of building nuclear reactors on site.</p><p>The reactor also makes more efficient use of the energy in nuclear fuel. It can consume about one ton of nuclear waste a year, leaving just four kilograms behind. Dewan’s name for the technology: the Waste-Annihilating Molten-Salt Reactor.</p><p><span class="s2">So far, the design exists as a 180-page document, computer simulations, and patent filings. Dewan has designed five experiments, each of which will cost about $1 million, to prove key aspects of the design. If those go well, she’ll still face a decade or more of further tests and U.S. federal certifications that could cost hundreds of millions of dollars. And she suggests that the future for new nuclear-power technology might not be in the United States. She points in particular to China, which is spending far more on new reactor designs and on the construction of nuclear plants.</span></p><p>But though it will be a long and uncertain route to commercialization of the technology, Dewan is driven by what is at stake. She’s part of a new generation of young researchers who see nuclear energy as one of the best hopes for averting disastrous climate change. Dewan originally looked to solar and wind power as ways to reduce carbon dioxide emissions, but “then I looked at the numbers,” she says. “I realized that nuclear power is the best low-carbon energy source that’s available and scalable.”</p><p>—<em>Kevin Bullis</em></p></td>
    </tr>
    <tr>
      <td>Roozbeh Ghaffari</td>
      <td>Inspired by the courage of his younger brother, MC10’s cofounder is finding ways to create novel electronic devices that improve human health.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p>When Roozbeh Ghaffari was five years old, his only sibling—a brother named Soran—was born three months prematurely. A few things would eventually emerge about Soran: he was blind and mildly intellectually impaired, he had remarkably acute hearing (and perfect pitch), and he was his older brother’s best friend, superfan, and inspiration. As the elder Ghaffari became an expert in the science and technology of body-machine interfaces and devices that can be integrated into the body (he now leads advanced technology development at MC10, a startup in Cambridge, Massachusetts), Soran remained physically at home in Los Angeles but frequently at his brother’s virtual side, standing by for nightly telephone updates and reading up on his work using text-to-speech software.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/pioneers.ghaffari.1x249.jpg" alt="Ultraviolet light is used to affix the sensors to balloon catheters that use arrays of electronics."><figcaption>Ultraviolet light is used to affix sensors to balloon catheters that use arrays of electronics.</figcaption></figure>\n<p>Indeed, while Roozbeh Ghaffari’s lifelong interest in the merger of biology and engineering was shaped partly by his parents—his mother is a microbiologist and his father an architect—it was inspired mainly by his brother, whose blindness was caused by retinal damage from excessive oxygen exposure in the neonatal intensive-care ward. “What I found was that my goals were all driven by him,” he says. “I wanted to work on the retinal implant project at MIT, right from year one as an undergraduate.”</p><p>He didn’t succeed at finding funding for that daunting challenge. But as a graduate student in the Harvard-MIT Division of Health Sciences and Technology, he shifted to another critical problem, this time inspired by his brother’s sharp hearing rather than his deficient eyesight. Ghaffari’s goal was to unravel the mysteries of the cochlea—that “biological black box with thousands of moving parts in a fluid” that transforms vibrations in the inner ear into nerve signals. “How do we hear with such remarkable sensitivity?” he asks. “How can we process both the roaring sound of jet engines and the sound of pins dropping?”</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/pioneers.ghaffari.2x249.jpg" alt="stretchable sensors and actuators embedded in the balloon catheters"><figcaption>The stretchable sensors and actuators embedded in the balloon catheters help diagnose and treat problems.</figcaption></figure>\n<p>Focusing on a cochlear structure called the tectorial membrane, he managed to build a system that could measure what the structure was actually doing. “It supports a traveling wave of energy that can propagate along the cochlea. That hadn’t been known before,” he says. And this could help explain how the human ear can detect both very loud and very soft sounds, as well as a wide range of pitches.</p><p>After taking a Harvard Business School class focusing on commercializing science, and meeting venture capitalist Carmichael Roberts and postdocs in the lab of Harvard chemist George Whitesides, Ghaffari helped develop a business plan for a company called Diagnostics for All, which is commercializing paper-based diagnostics invented in Whitesides’s lab.</p><p>Next, with Roberts and Whitesides serving as the matchmakers, Ghaffari met John Rogers, a materials scientist at the University of Illinois. Rogers was fabricating stretchable electronic devices using polymers and ultrathin semiconductors, such as silicon. But the technology was looking for an important problem to solve. So in 2008 Ghaffari was brought on as cofounder of MC10. The founders considered what kinds of flexible or stretchable products they might enhance with electronics (they even considered contact lenses), but within a couple of months they had settled on balloon catheters and health-monitoring skin patches.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/pioneers.ghaffari.3x249.jpg" alt="A chip with electrodes "><figcaption>A chip with electrodes and temperature sensors can be laminated on a heart.</figcaption></figure>\n<p>Today, the devices under development add electronics and sensors to balloon catheters. Existing versions of these devices are snaked into coronary arteries and inflated to compress accumulated plaques that can block blood flow. The new versions can, among other things, sense misfiring cardiac tissue that causes irregular heartbeats called arrhythmias. They can even ablate tiny patches of such tissue without harming the healthy tissue nearby. As always, Soran is eager to hear all about it. “He’ll go look up ‘ventricular tachycardia’ and grill me night and day: ‘What is this disorder? What are you guys doing?’” Ghaffari says.</p><p>Someday Ghaffari may yet build what his brother needs: a bionic replacement for his damaged retina. In the meantime, he is finding new ways to create other devices that promise to help others. While its catheters still need regulatory approval, MC10 has launched a thin $150 cap that athletes, such as football or hockey players, can wear inside their helmets to indicate the severity of blows to the head. By lighting up red, yellow, or green LEDs on the cap, the technology could indicate whether the wearer might have suffered a worrisome head impact.</p><p>When Soran comes to Boston, Ghaffari brings him to the MC10 lab and lets him hold and feel the electronic skullcaps and the instrumented catheters, with their intricate patterns of ultrathin, stretchable sensors. But even when Soran is home in Los Angeles, Ghaffari says, the following question he inspires is in the back of his mind every day: “How can we turn technology into something useful that integrates with the human body?” And every evening, Soran is on the other end of the line, helping him answer that question.</p><p>—<em>David Talbot</em></p></td>
    </tr>
    <tr>
      <td>Kuniharu Takei</td>
      <td>A novel fabrication  step for nano­materials could lead to fast, energy-efficient flexible electronics.</td>
      <td>32</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p><strong>Innovation:</strong> Kuniharu Takei, a professor at Japan’s Osaka Prefecture University, has led the development of cheap and robust methods for “printing” uniform, ultrathin patterns of different types of nanoelectronics on a wide range of surfaces.<br><br><strong>Why it matters:</strong> Nanoscale components made of materials other than silicon could lead to more versatile, less expensive electronic devices. Transistors made from so-called compound semiconductors, for instance, could be up to twice as fast and 10 times as energy efficient as silicon transistors.</p><figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/images/pioneers.takeix249.jpg" alt=""><figcaption>Kuniharu Takei is exploring new ways of printing different kinds of nano devices. An early prototype of electronic skin uses a plastic substrate and carbon nanotubes.</figcaption></figure>\n<p>Takei’s goal is to build circuits and sensor networks that simultaneously exploit the properties of several materials, each chosen because it offers a specific advantage. Nanomaterials made of compound semiconductors could be used to add high-speed radio-frequency components and efficient light emitters to silicon chips. But there is not yet a way to cheaply and reliably add such nanoscale components. Existing strategies involve highly specialized procedures for growing these materials on silicon or attaching them to silicon wafers; such methods are expensive and may not be practical for manufacturing. Printing processes like Takei’s could be an attractive alternative.</p><p><strong>Methods:</strong> In the process he uses to print compound-­semiconductor nanomaterials, Takei grows thin films of the chosen material on a suitable substrate, uses a lithography technique to create strips in the material, and releases the patterns from the substrate with a chemical etchant. He can then transfer the nanomaterial to a range of new surfaces, including silicon wafers and bendable plastics, by using a silicone rubber stamp that picks up the material and prints it. <br><br><strong>Next steps:</strong> Takei’s printing methods could be used to produce electronic devices that exploit the properties of multiple materials. For example, he says, organic light-emitting diodes could be combined with transistors made of inorganic nanomaterials to make low-power, bendable displays. He’s now working on a smart bandage that would be able to sense and respond to things like glucose level and skin temperature.</p><p>—<em>Mike Orcutt</em></p></td>
    </tr>
    <tr>
      <td>Liangfang Zhang</td>
      <td>A nanoengineering  scheme to make drugs more effective by fooling the immune system.</td>
      <td>33</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p><strong>Problem:</strong><span class="s2"> Scientists have worked for years to increase the longevity of targeted drugs, which promise to deliver treatment to a specific tissue within the body. These targeted treatments require new drug carriers such as polymers that are designed to evade the immune system. But too often, these carriers are destroyed before the drug can effectively target tumors and other localized sites of disease. Though the body’s own cells are <span>protected from the immune system by their protein-studded outer membrane, it’s not possible to re-create this complex matrix for synthetic </span><span>particles used in drug delivery.</span></span></p><p><strong>Solution:</strong> Why not cloak therapeutics in natural membranes? That’s the idea of Liangfang Zhang, a nanoengineering professor at UC San Diego.</p><p>Zhang derives red-blood-cell membranes from blood samples and uses them to coat polymer nanoparticles. Because these particles look like red blood cells on the surface, they can fool the immune system; loaded with drugs, they serve as robust and long-lived drug carriers. An unexpected bonus: they can also act like nanoscale sponges to suck up toxic proteins produced by infectious bacteria or introduced by snake or insect venom. If the particles flood the bloodstream, they will divert most of the toxin away from actual cells.</p><p>Born in Wuwei County, 45 minutes by plane from Shanghai, Zhang left home for the prestigious Tsinghua University in Beijing when he was just 15. By the time he was 20 years old, he could have opened a factory to produce exceptionally tough rubber materials he’d helped invent as a student. But Zhang says he “didn’t want to run a rubber factory all my life.” And he knew if he started a factory, some other young upstart would come up with a better technology and he might not be able to compete. So he decided to pursue an advanced graduate degree in engineering in the United States. Despite his accomplishments as a scientist, however, <span>he has never lost his desire to turn laboratory advances into practical breakthroughs.</span></p><p>—<em>Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Feng Zhang</td>
      <td>Genomic research may finally help dispel the ignorance shrouding many types of mental illness.</td>
      <td>31</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p>“There have been a lot of taboos about psychiatric diseases,” says Feng Zhang. “People would think depressed people are not mentally strong enough. But that’s not true. In this and the next decade, we will learn much more about the mechanisms that lead to these neurological problems. And that will change our way of interacting with these people, and it will also change how we can treat them.”</p><p>Zhang is an assistant professor at MIT and one of only 11 core faculty members at the Broad Institute, a leading center of genomic research. He’s spent much of his brief but impressive career developing tools to understand how the brain functions, including what goes wrong in people with mental illnesses. As a graduate student at Stanford, he played a key role in developing optogenetics, which uses light to affect the behavior of living animals by controlling specific neurons; he then used the technique in mice to pinpoint <span>brain cells that are associated with depression.</span></p><p>But truly understanding the genetics of mental illnesses will mean identifying the mutations causing the abnormal behavior. After getting his PhD, Zhang invented two new ways to “edit” animal genomes that were far cheaper and more effective than the existing technology. One method in particular, called CRISPR, promises to change how genomic engineering is done. It allows researchers to precisely snip out a short sequence of DNA so that they can substitute other genetic material or simply delete the sequence.</p><p>By inserting genetic mutations that others have linked to autism and schizophrenia into human stem cells that mature into neurons, Zhang is able to create brain cells with the specific genetic errors linked to those conditions. This makes it possible to study the abnormal cells directly: Do the neurons look different? Are there biochemical clues to what is going wrong? He has also engineered mice with the mutations to study how the changes affect behavior. Such research could not only help identify the causes of the disorders but suggest ways to identify and test drugs to treat them—and his genome-editing tools may even one day provide a way to “fix” the mutations.</p><p>Zhang has been interested in ways to “repair” diseases since he was in high school in Iowa, when he spent every afternoon working with a medical researcher at the Human Gene Therapy Research Institute, a part of Methodist Hospital in Des Moines. Though the gene therapies available at the time turned out to be too risky for widespread use in humans, Zhang never gave up hope of finding ways to directly fix the genetic mutations behind many diseases, using the increasing capabilities of genomic engineering. These days, bolstered by the success of his editing tools and other genomic advances, he is working to translate the technology into actual human therapies and exploring opportunities to start a company.</p><p>—<em>David Rotman</em></p></td>
    </tr>
    <tr>
      <td>Bowen Zhao</td>
      <td>What do your genes say about how smart you are?</td>
      <td>21</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p>Bowen Zhao dropped out of Beijing’s top high school to take a job at BGI-Shenzhen, the world’s largest DNA-sequencing organization. Soon after joining the company, he became involved in a new research effort: investigating the genetic basis of human cognitive abilities, including intelligence. “We want to know the genetic basis of IQ,” he says. Zhao thinks human intelligence is from 40 to 80 percent inheritable, and he wants to know which genes may influence the trait he calls “high cognitive ability.”</p><p>Zhao’s team is sequencing the DNA of more than 2,000 people with high IQs. Zhao is not looking for an IQ gene; rather, he expects to pinpoint multiple small variations in thousands of genes that shape the inheritable aspect of intelligence. Perhaps uniquely in the world, BGI has both the massive computing power and the manpower to handle a data–intensive approach to combing through the genetic clues. “We’re data driven, not hypothesis driven,” says Zhao.</p><p>The project involves sequencing more than six trillion DNA bases. This is not the first attempt to map the biological roots of human intelligence. But now, Zhao points out, DNA sequencing technology is so advanced that it’s possible to sequence and compare thousands of minute variations in extremely large samples.</p><p>Zhao is keenly aware that research into the heritability of intelligence is controversial and fraught with ethical dangers. But he says that <span>it is far too early to make any decisions or judgments based on his genomic studies. F</span><span>or the foreseeable future, he adds, if you want to </span><span>identify high-IQ individuals</span><span>, it will be far easier and more accurate to conduct a standard IQ test than </span><span class="s1">to</span><span> sequence the person’s DNA.</span></p><p>—<em>Christina Larson</em></p></td>
    </tr>
    <tr>
      <td>Xiaolin Zheng</td>
      <td>An ingenious solar sticker made with techniques drawn from nanotechnology could turn almost any surface into a source of power.</td>
      <td>34</td>
      <td></td>
      <td>pioneers-2013</td>
      <td><p>Stanford professor Xiaolin Zheng often works in the esoteric fringes of nanoscience, but she also likes to find simple ways to fabricate complex materials that can be put to use in practical applications like solar-fuel systems, solar cells, and batteries. Last year she created solar cells in the form of flexible stickers—only a 10th as thick as plastic wrap—that can be applied to a window, a piece of paper, the back of a mobile phone, or anything else you want. These solar cells produce just as much electricity as rigid ones made of the same materials.</p><p>Zheng got the inspiration for this invention from her father. One day when they were talking on the phone—he in China, she in California—he said that it should be possible to put solar cells on the walls of buildings, not just the roof. And Zheng’s daughter, like many kids, loves stickers.</p><p>All this was in the back of Zheng’s mind when she read a research paper about graphene, a novel type of nanomaterial. The researchers grew the material on a layer of nickel on top of a silicon wafer. When they put the whole thing in water, the nickel separated from the surface, taking the graphene with it. “I couldn’t believe that soaking in water would do this,” she says.</p><p>Zheng has demonstrated this water–soaking approach as a way to peel off thin-film silicon solar cells grown on a rigid substrate. It turns out the phenomenon—called water-assisted subcritical debonding—had been known since the 1960s, but no one before had tried using it to make flexible electronics. She hopes the technology will be scaled up beyond the one-square-centimeter devices she’s made so far, so that the sides of buildings can one day be papered with solar cells as her father suggested.</p><p>—<em>Katherine Bourzac</em></p></td>
    </tr>
    <tr>
      <td>Daniel Ek</td>
      <td>Making online music a paying business, without forcing people to pony up for one song at a time.</td>
      <td>29</td>
      <td>Spotify</td>
      <td>web-2012</td>
      <td><p>In 1999 Daniel Ek was a 16-year-old Swedish programmer, getting rich building websites, when he started asking what he himself now says was a dumb question: How do you get people to pay for music that can, if illegally, be downloaded free—and without charging them for each song, the way Apple’s iTunes service does now? <br><br>Ek’s eventual solution: Spotify, a jukebox in the cloud that provides legal, on-demand access to millions of songs. Supported by paying subscribers, as well as by radio-style ads played only to nonsubscribers, the service debuted in the United States last year after operating for three years in Europe; it now has more than 15 million users, four million of whom pay. With an estimated value of $4 billion, Spotify is one of the hottest Internet companies in the world.<br><br>Spotify isn’t the only service to let listeners stream music on demand. But it distinguishes itself from Internet radio services like Pandora and Slacker through the vastness of its music libraries and its deep integration into social media. Spotify lets users seamlessly share playlists and swap music on social networks like Facebook and Twitter. And Spotify makes it easy for others to build apps that work with its platform in order to give users yet more ways to discover and share music. “The trick was to think through the social aspect of the service from the very beginning,” says Ek. “We didn’t want it to be an afterthought.” <br><br>Spotify’s users can access some 16 million songs—about 15 times more than Pandora makes available. The service offers all those terabytes of music without revealing any of the licensing complexities involved in the process. Ironing out the needed deals with record companies while refining the service ate up two years of Ek’s time before he launched in Europe in 2008. And it took a team of software engineers—the company now has 250 of them—to make the service easy to use in spite of all the programming code that works in the background to prevent music from being illegally copied and distributed. “The best thing about Spotify is that it works at all,” says Ek. “If you’re in Spain and you want to share your music with someone in the U.K., you don’t want to see how we take care of paying licensing fees in both places.”<br><br>Now Ek is trying to find ways to make it as easy to find and play music as it is to find and play videos on YouTube. This year the company introduced a radio service for computers and mobile devices, launched its first iPad app, and made it possible to embed a Spotify play button into any website. The Huffington Post, the blogging site Tumblr, and Rolling Stone’s website are among the many that now offer music that way.<br><br>For a man capable of turning his teenage vision into a mushrooming empire, Ek claims a surprisingly simple strategy for continued growth. “I just keeping asking dumb questions,” he says.<br><br></p></td>
    </tr>
    <tr>
      <td>Shishir Mehrotra</td>
      <td>Turning a Web video phenomenon into a profitable business by making ads optional.</td>
      <td>33</td>
      <td>YouTube</td>
      <td>web-2012</td>
      <td><p>In 2008, when Shishir Mehrotra joined YouTube to take charge of advertising, the booming video-sharing service was getting hundreds of millions of views a day. ­YouTube, which had been acquired by Google in 2006, was also spending as much as $700 million on Internet bandwidth, content licensing, and other costs. With revenue of only $200 million, ­YouTube was widely viewed as Google’s folly.</p>  <p>Mehrotra, an MIT math and computer science alum who had never worked in advertising, thought he had a solution: skippable ads that advertisers would pay for only when people watched them. That would be a radical change from the conventional media model of paying for ad “impressions” regardless of whether the ads are actually viewed, and even from Google’s own pay-per-click model. He reckoned his plan would provide an incentive to create better advertising and increase the value for advertisers of those ads people chose to watch. But the risk was huge: people might not watch the ads at all.</p>  <p>Mehrotra’s gamble paid off. YouTube will gross $3.6 billion this year, estimates Citi analyst Mark Mahaney. The $2.4 billion that YouTube will keep after sharing ad revenue with video content partners is nearly six times the revenue the streaming video service Hulu raked in last year from ads and subscriptions. And that suggests Mehrotra has helped Google solve a problem many fast-growing Web companies continue to struggle with: how to make money off the huge audience that uses its service free.</p>  <p>In 2008, Mehrotra was working for Microsoft and hankered to have his own startup, but he agreed to talk to a Google executive he knew about working there instead. He decided against it—but that evening he kept thinking about how the exec was frustrated that most ad dollars go to TV, even though nobody watches TV ads. Yet at his Super Bowl party two weeks earlier, Mehrotra recalled, guests kept asking him to replay the ads. Was there a way, he wondered, to make TV ads as captivating as Super Bowl ads, every day?</p>  <p>The answer came to him in a flash. The next day, he had changed his mind about working at Google. After he tried his idea for skippable ads on a television project, the company asked him to bring the idea to YouTube.</p>  <p>YouTube was searching for alternatives to standard “pre-roll” ads, which performed poorly because viewers didn’t want to sit through a 30-second ad to watch a two-minute video. In 2010, Mehrotra’s alternative came to fruition as YouTube rolled out its TrueView ads. One type lets viewers choose from three ads. Another lets them skip an ad after five seconds; advertisers pay only if their ads are watched in their entirety, or for at least 30 seconds if the ads are ­longer than that.</p>  <p>Thousands of advertisers piled in. Now some 65 percent of ads inside YouTube videos are skippable. But YouTube has found that only 10 percent of viewers always skip ads, and viewership is 40 percent higher on videos running TrueView than on those with non-skippable ads. As a result, ­Mehrotra says, video viewed on YouTube brings in more ad revenue per hour than cable TV.</p>  <p>Thanks to Mehrotra’s ad model—and to Google’s crackdown on piracy of television shows and films—YouTube now attracts top-line content producers such as the nonprofit academic-tutorial producer Khan Academy, Paramount, and the NBA. Revenues paid to YouTube’s 30,000-plus video-making partners have doubled in each of the past four years. Thousands of partners get six-figure annual revenues from the ads, and a few take in tens of millions of dollars.</p>  <p>The result is a virtuous cycle. “The more money we bring in, the better content they produce, the more there is for viewers to watch, and so on,” Mehrotra says.</p>  <p>Now Mehrotra’s goal is to try to grab a big chunk of the $60 billion U.S. television business. But to do that, and fend off TV-content-oriented online rivals such as Hulu, YouTube has to become a bit more like conventional TV. To that end, it organized itself last year into TV-like channels, investing $100 million in cable-quality launches from Ashton Kutcher, Madonna, the Wall Street Journal, and dozens of others. More and more TV advertisers are being won over, says David Cohen, chief media officer at the media buying agency Universal McCann. “They’re getting marketers to think about YouTube as a viable outlet,” he says.</p>  <p>Mehrotra, who last year became ­YouTube’s vice president of product, envisions millions of online channels disrupting TV, just as cable’s 400 channels disrupted the four broadcast networks. “We want to be the host of that next generation of channels,” he says.</p>  <p></p></td>
    </tr>
    <tr>
      <td>Ben Silbermann</td>
      <td>A smartly designed social network for sharing images and interests.</td>
      <td>30</td>
      <td>Pinterest</td>
      <td>web-2012</td>
      <td><p>Pinterest became a household name seemingly overnight in the spring of 2012. Founder Ben Silbermann had seen what other tech companies were overlooking: existing social networks, while letting users share information in just about any form, did not offer an emotionally warm and visually rewarding experience tied to individual passions. Guided by this conviction and his interest in collecting things, ­Silbermann directed his engineers—he’s no programmer—to create a site that did.<br><br>Users of Pinterest create and curate virtual boards of photos clipped from websites and other users’ boards, gathering up shots of lusted-after products and other stimulating images. When you log in, you’re presented with a grid of new content that past activity suggests you might want to “pin” to your own boards. Silbermann describes it as a more interactive and social version of the lifestyle section of a newsstand: a place to find visually interesting, emotionally resonant content related to stuff you love—and often want to buy.<br><br>That vision initially gained momentum not at the elite colleges and California coffee shops that often function as the Web’s proving ground for new ideas but by word of mouth in Silbermann’s home state of Iowa. Perhaps as a result, Pinterest is big with the mainstream audience that other Web companies struggle to attract after they’ve conquered Silicon Valley. It’s used by 34 million people worldwide each month, mostly in the United States. Google’s DoubleClick advertising unit estimates that 79 percent of them are female.<br><br>Silbermann refined the idea for two mostly unpromising years after he talked a few friends into starting the company, running it from his own apartment until he received his first significant backing from investors in the summer of 2011. Though he initially had no users to offer feedback, he sweated countless details, having his lone designer, cofounder Evan Sharp, create 50 fully functional versions of the site’s basic layout that varied spacing and image sizes by just fractions of an inch. ­Silbermann personally wrote to the first few thousand users to gather their impressions.<br><br>Now with over 60 employees and a spacious office in San Francisco, Pinterest has received a total of $138 million in venture capital funding; in the last cash injection, the company was valued at $1.5 billion. Silbermann says he’s focused on improving the product rather than figuring out how to make money on it. But retail brands are discovering that they can use Pinterest to boost sales by encouraging people to share images of their products on what are essentially eye-catching shopping wish lists. And that would seem to leave the company well positioned to start charging brands for the privilege. There’s a lot of value in, as ­Silbermann puts it, “helping people to discover things that they didn’t know they wanted.”</p></td>
    </tr>
    <tr>
      <td>Christopher Soghoian</td>
      <td>On a tear against bad privacy practices online, he urges companies to change the way they operate—and sounds alarms if they don’t.</td>
      <td>30</td>
      <td>American Civil Liberties Union</td>
      <td>web-2012</td>
      <td><p>Christopher Soghoian sniffs out security holes and privacy shortcomings on the Web. Then he urges companies that are responsible—Google, AT&amp;T, and Dropbox have been among them—to halt practices that put consumers’ personal information at risk. If they don’t, he’ll write about the flaws publicly and try to get regulators to crack down. “I see myself as a combination horse whisperer and Paul Revere–type character,” he says.<br><br>Soghoian’s credentials as a computer scientist are substantial—he helped develop the Do Not Track mechanism that lets people prevent websites from following their online activity—but most of his work relies on techniques that suggest Woodward and B­ernstein more than a basement hacker: he seeks information by filing Freedom of Information Act requests or cajoling corporate lawyers and congressional aides over late-night beers in Washington, D.C.</p>  <p>Insinuating himself into the world of Washington as a privacy gadfly didn’t come easily to Soghoian, 30, an earnest geek with a beard and a ponytail. “I didn’t own a suit until 2009,” he says. Wearing one to face executives and lawyers is “not pleasant,” he adds. But he has learned that his impact as a security researcher is much greater if he steps into power corridors and directly addresses the people there.<br><br>That lesson began in 2006. Soghoian, then a grad student at Indiana University, wrote a blog post about how easily someone could gin up a legitimate-appearing boarding pass to get past airport security checkpoints. To prove the point, he put a widget on his blog that made it possible for people to create their own. That inflamed the Homeland Security apparatus, and the FBI seized his computers for a month. When the furor subsided, a few rational officials in Washington pointed out that Soghoian was actually helping the Transportation Security Administration by identifying a flaw in its defenses. The episode taught him that if he framed his message in the right way, he could get people to listen. <br><br>In 2009, while working as a student fellow at Harvard’s Berkman Center for Internet and Society, Soghoian led an effort to get Google to turn on SSL encryption in Gmail by default. SSL, the technique used to secure banking and e-commerce websites, essentially ensures that people using Gmail in a public Wi-Fi café aren’t vulnerable to having their accounts plundered by criminals. After Soghoian and 36 cosigners wrote an open letter to then-CEO Eric Schmidt, Google eventually said it would indeed turn on SSL by default. This doesn’t make Gmail totally private: law enforcement can still subpoena Google for an unencrypted look at the contents. But it does ensure that political dissidents’ e-mail is out of the reach of repressive governments with which Google doesn’t coöperate. Because of that, “if I’m 5 percent responsible for Google turning on SSL, it’s the most important thing I’ve done in my life,” Soghoian says. Today he’s lobbying for SSL to become the default setting on other online services, notably Facebook. (Facebook spokesman Frederic Wolens says the company is working on it; in the meantime, SSL is available to Facebook users who activate it themselves.)<br><br>In 2009, Soghoian stepped a bit too far into the establishment for his comfort: he became a staff technologist for the U.S. Federal Trade Commission. In October of that year, he went to a telecom-industry event and recorded a Sprint Nextel executive explaining how often the company fed data about subscribers to law enforcement. To him, this is a crucial subject—his recently completed PhD dissertation is all about the ways that police get around outdated wiretapping laws by having telecommunications and Web companies do surveillance for them. He argues that these companies, without sufficient public recognition, have effectively replaced judges as arbiters of whether the authorities are acting appropriately. But that’s not entirely in the FTC’s purview—and in any case, Soghoian had made the secret recording after using his FTC badge to get into the closed event. He ultimately lost his job.<br><br>Now he’s probably found a more natural outlet for his work: in September he will become a principal technologist and senior policy analyst for the American Civil Liberties Union, where he plans to keep raising alarms about how easily law enforcement, spies, and criminals can delve into our ever-growing storehouses of personal data. “My goal,” he says, “is to move to a world where everybody has access to secure communication.” <br></p></td>
    </tr>
    <tr>
      <td>Rana el Kaliouby</td>
      <td>Teaching devices to tell a frown from a smile.</td>
      <td>34</td>
      <td>Affectiva</td>
      <td>computing-2012</td>
      <td><p>Computers are good with information—but oblivious to our feelings. That’s a real shortcoming, believes MIT Media Lab scientist Rana el Kaliouby, because it leaves them unable to usefully respond to many of our needs until we take the trouble to tap out instructions. To close that gap, el Kaliouby has come up with technologies that help computers recognize facial expressions and other physical indicators of how someone is feeling. Someday this could help make our machines more adept at assisting us.<br><br>El Kaliouby is not the first researcher to try to map facial expressions. But where others have focused on trying to get computers to recognize a half-dozen exaggerated expressions recorded in the lab, she is identifying the more varied and subtle faces that people commonly make. “It’s a problem that requires pushing the state of the art of computer vision and machine learning,” she says.<br><br>To break the problem down, she zeroed in on 24 “landmarks” on the face. Then she trained a computer to identify how those parts of the face change shape in response to different emotions, creating expressions such as a furrowed brow. To ensure that the technology would work with people in different cultures, el Kaliouby, who lives in Cairo and spends one week a month at MIT, enlisted the help of thousands of people on six continents. They have allowed their computers’ embedded cameras to record their expressions while they watch a video, resulting in what she says is the largest database of facial images in the world. <br><br>One early experimental application of the technology was a set of camera-equipped glasses intended for people with Asperger’s syndrome, who tend to have difficulty recognizing others’ emotional states. The device could recognize whether someone facing the wearer appeared bored; if so, it could use small lights in the glasses to signal that to the wearer. (El Kaliouby herself was known to sport a head-cam in and out of the lab, tucked into the head scarf she wears.)<br><br>El Kaliouby has cofounded a company called Affectiva in Waltham, Massachusetts, to commercialize the facial recognition technology and a wristband that she helped develop to measure skin conductance, which is associated with emotional arousal and can be used to detect anxiety in real time. For now, Affectiva uses facial recognition mainly to give advertisers a better sense of how their ads are affecting viewers. The company convenes enormous virtual focus groups made up of online viewers who allow their expressions to be tracked, and then analyzes the resulting data. But in the longer term, el Kaliouby also wants to bring her technology to classrooms to help teachers identify which material students respond to best.<br><br>The technology could eventually become a critical component of many electronic devices, making it possible for them to recognize when we’re puzzled, frustrated, happy, or sad—and enabling them to respond with the right information, music, or human assistance. And there’s a lot to be said for getting our phones, PCs, and GPS systems to recognize when we just want to be left alone.</p></td>
    </tr>
    <tr>
      <td>Saikat Guha</td>
      <td>Letting advertisers send targeted pitches to your mobile phone without ever seeing your personal information.</td>
      <td>30</td>
      <td>Microsoft Research India</td>
      <td>computing-2012</td>
      <td><p>Saikat Guha is convinced that privacy and profit don’t have to conflict online. The Microsoft Research India computer scientist has developed a software platform that allows advertisers to precisely target potential customers without exposing the customers’ personal information.<br><br>The trick involves flipping the basic model of targeted advertising. Companies now track your browsing and purchasing behavior and then sell your data to advertisers. But instead of acquiring data from your phone or PC so that companies can send the right ads to websites you visit, Guha’s system calls for companies to send potential ads to you; then software on your device figures out which of them are targeted effectively. Thus, if you search for video games, the software will fetch entertainment-related ads. If your computer or phone recognizes that, say, you often buy DVDs, the device will pick out a DVD ad to show you. Guha’s ad-selecting software could be built into browsers, or into websites such as Facebook. And he estimates that the ads wouldn’t take up significant amounts of memory on your machine. <br><br>Since companies wouldn’t be able to see or store your data or toss it around the Web, risking accidental leakage, even data normally too private to share with advertisers could be brought to bear in picking from among them. <br><br>Today, for instance, Google can’t determine your birth date unless you offer it up. But Guha’s software might come across it on your PC and use it to enhance the targeting of Google’s ad network, without ever revealing the date to Google. It’s a privacy protection scheme that, unlike almost all others, indirectly gives businesses an even richer set of data to work with.<br><br>Guha has also addressed the privacy threat from smartphone apps that package and sell sensitive information such as a user’s name and location. “Today someone could construct a full history of where you are at any given time of the day,” he says. His idea is a platform that cryptographically splits information such as a person’s name, the name of the store the person is visiting, and the amount of time spent at the previous store into disconnected fragments before sending it to the cloud. Software on the phone or tablet could then use all or most of those fragments to target advertisements, but no party involved could connect them to create a privacy-violating portrait of the user.<br><br>There will always be those who will try to get around privacy protection schemes to scope out more about you than you care to share. Guha is on top of that problem, too. He’s working on algorithms that detect when websites and apps are surreptitiously using your personal data, so you can block them. <br></p></td>
    </tr>
    <tr>
      <td>Chris Harrison</td>
      <td>Liberating us from the touch screen by turning skin and objects into input devices.</td>
      <td>28</td>
      <td>Carnegie Mellon University</td>
      <td>computing-2012</td>
      <td><p>Chris Harrison recently helped develop an invention, called Touché, that can turn practically anything into a computer input device—a table, a doorknob, a pool of water, your hand. To do this, he relies on the natural conductivity of some things, or he adds electrodes to objects that aren’t conductive. Then he wires up a controller that registers the range of electronic signals the objects generate when they are changed by, say, a particular hand gesture or body posture. A sensor attached to a sofa, for instance, can continuously monitor voltage changes to detect the signatures of particular motions and events and link them to actions. A dog leaping on the couch might trigger a harsh noise to scare it off; a person sitting down might cause the TV to switch on. (Yes, even a couch potato’s life can be made easier.)<br><br>Harrison, a PhD student in Carnegie Mellon’s Human-Computer Interaction Institute, says his mission is to liberate our fingers from having to command our phones and other devices by poking at squished keyboards and teensy screens. “If you think about all the ways we use our hands, being limited to only poking would make the world really hard to use,” he says.</p>  <p>He is enlisting technologies ranging from cameras to stethoscopes to miniature projectors. Before Touché, which he developed while at Disney Research, he invented a device called Skinput that turns skin into the equivalent of an interactive touch screen: a tiny body-mounted optical system projects “buttons” onto the wearer’s hand and arm and detects any tapping of the buttons so that a device can be controlled. As an intern at Microsoft, he helped create OmniTouch, a roughly similar system that makes it possible to turn any object in the environment into a multitouch screen. And he’s made a device called Scratch Input that uses a modified stethoscope and generic microphone to convert the sound of a fingernail dragging over just about any surface into an electrical control signal. <br><br>Harrison notes that as computers become better integrated into almost everything we do, we will find it increasingly convenient to be able to interact with them in a variety of ways, without always having to resort to a screen or keyboard. “Eventually we’ll develop input technologies so good that we don’t need a touch screen,” he says. Our tired fingers salute that quest.</p></td>
    </tr>
    <tr>
      <td>John Hering</td>
      <td>Securing our smartphones from spyware and rogue apps, with a little help from the crowds</td>
      <td>29</td>
      <td>Lookout Mobile Security</td>
      <td>computing-2012</td>
      <td><p>In 2005 John Hering notoriously invented a hacking “rifle” called the BlueSniper that enabled him to take control of a Nokia handset from a record-setting distance of 1.2 miles. But though he’s been a hacker since childhood, Hering isn’t the kind of hacker you have to worry about. In fact, his mission is to keep your cell phone safe from malware.<br><br>The BlueSniper stunt was all about exposing security weaknesses in Bluetooth technology. ­Hering used the attention he got from it to further a more ambitious idea: that there should be a central database of information about phone malware. In 2007 he cofounded Lookout Mobile Security with two college buddies and created a free app that protects Android users from malicious apps—say, a fake version of a game that tacks an easy-to-miss $5 charge onto your monthly smartphone bill. Lookout found 1,000 instances of virus-infected apps last year and found that Android users had a 4 percent chance of encountering malware, a number expected to rise.<br><br>To stay on top of the bad guys, Lookout has built what it calls the Mobile Threat Network: a giant database, tallying more than a million rogue apps, that it continuously adds to as the company’s software scans and analyzes apps worldwide. When an Android smartphone owner uses Lookout’s app, it compares installed apps against its database of known threats and notifies the user when it detects a match. <br><br>Users can help by allowing Lookout to collect data from their mobile devices, essentially crowdsourcing the job of finding threats. That approach to identifying malware stands in contrast to the methods used by traditional security software for desktop computers, which rely on professionals working in the background to find threats in the digital wild. <br><br>Last year, Lookout blocked millions of mobile threats, according to the company. More than 20 million people have downloaded the app. (Most of Lookout’s revenue comes from users who pay $3 a month to subscribe to a premium service that also secures mobile devices’ Web browsers and makes it possible to lock or erase stolen phones remotely. But Hering won’t say whether the privately held company is profitable yet.)  <br><br>Hering says he thinks of his approach to mobile security as one that will empower users, not hamper them, as desktop security programs sometimes do. “Security is typically something that’s thought of as a burden,” he says. “It slows down your computer, it tries to scare you. It’s all these things that we don’t stand for.” <br><br><br></p></td>
    </tr>
    <tr>
      <td>Drew Houston</td>
      <td>Hiding all the complexities of remote file storage behind a small blue box.</td>
      <td>29</td>
      <td>Dropbox</td>
      <td>computing-2012</td>
      <td><p>One day in 2009, Drew Houston and his business partner, Arash Ferdowsi, pulled their Zipcar into Apple headquarters in Cupertino, California. “We went to the front desk,” Houston recalls. “And what do you say at that point? ‘We’re here to see Steve.’” <br><br>Steve Jobs had invited them largely because he wanted to explore acquiring Houston’s fast-growing company, Dropbox. Founded in 2007, Dropbox conferred iPhone-like ease and reliability on cloud-based file storage—something Apple itself hadn’t yet begun offering. People using any browser or operating system, on any kind of device, could drag any kind of file to Dropbox’s icon of an open blue box. The files were stored on Dropbox’s servers and synched each time you saved a file, so that it would be available on any device running Dropbox.<br><br>Houston and his team hammered out thousands of issues to create an easy system free of the typical annoyances. Dropbox knows that while Linux file names are case-sensitive, Windows file names aren’t, so a Windows file called “ABC.doc” will overwrite one called “abc.doc.” It can keep antivirus software from interfering with its file-synching system. It integrates smoothly with different user interfaces: on a Mac, for example, the Finder displays a check mark in the Dropbox icon when files are in sync.<br><br>Its ability to shield users from myriad mind-­numbing details and housekeeping chores—“the acrobatics to support all these different situations,” as Houston puts it—is what made Dropbox a hit. “It sounds like what we do is simple,” says Houston, who wrote the original code on a bus ride from Boston to New York and is now Dropbox’s CEO. “But sanding down the thousand rough edges to make something work 100 percent of the time is really, really hard. Even something simple, like synching a file, is actually really complicated to do in a bulletproof way a billion times.”<br><br>That’s how many times people are updating files with Dropbox every two days. And as consumers slide more stuff into their Dropbox folders, more blow past their free two-gigabyte limit and start paying $10 a month for additional storage. Dropbox says it now has more than 50 million users, with 4 percent paying.<br><br>The other big technical challenge was how to make Dropbox work fast on any device. Users often store thousands of files, and tracking and synching every one of them could easily eat up memory and processor time. The first version of the service hogged two full gigabytes of memory, but Dropbox eventually whittled that down to a mere 100 megabytes. And to keep Dropbox from dropping the ball when operating systems are revised or upgraded on users’ PCs, the company created custom analysis tools that rapidly detect and resolve any software conflicts.<br><br>Houston’s team is now working on advanced capabilities for synching and sharing photos, and gearing up for the demands that will be imposed on the software by continued rapid growth. “We’re designing a system that can connect billions of devices,” he says. The company has tripled its staff in the past year, to 150, and taken over a large office space in San Francisco. <br><br>Back at that meeting at Apple in 2009, Houston told Jobs he wasn’t interested in selling, after which Apple went on to bring out its competing iCloud service. But it’s hard to argue that Houston was being shortsighted, given that private investors recently valued Dropbox at $4 billion. <br></p></td>
    </tr>
    <tr>
      <td>Ren Ng</td>
      <td>By tracking the direction of light, a camera takes pictures that can be refocused on different objects in a scene.</td>
      <td>32</td>
      <td>Lytro</td>
      <td>computing-2012</td>
      <td><p>Today’s digital cameras do the focusing for you, but they occasionally blow the shot with a blurred subject. That’s never a problem with Ren Ng’s camera. His company, Lytro, sells a $399 model that captures light in a very different way from conventional cameras, recording the angle at which each ray enters the lens. The resulting photo can be sharply focused on any part of the scene, and then refocused on a different part—all long after the picture has been taken. “This is going to drive even larger transformations than the transition from film to digital photography,” says Ng.<br><br>Ng’s camera is at the leading edge of the new field of computational photography, which uses software to wring new tricks out of conventional optical components and a few novel ones. Lytro is preparing to release software upgrades that will allow shots taken with one of its cameras to be viewed in 3-D, and it is developing methods that could get professional-quality shots from cameras with cheap lenses, such as those on cell phones.</p>  <p>The focusing trick is an impressive enough start. When a photo taken with the Lytro camera is displayed on a computer, anyone can click on any object in the picture to get the software to instantly bring that object (and anything else in the photo that was the same distance from the camera) into sharp focus, leaving the rest artfully blurred. The focus point can then be changed with a click elsewhere in the photo. Friends can refocus Lytro photos for themselves when they are shared on Facebook or elsewhere online.</p>  <p>Whereas a conventional digital camera captures a focused image as light strikes a sensor chip, the Lytro camera has a plastic sheet of thousands of tiny lenses directly in front of its sensor. These lenses take rays that come into the camera at different angles and direct them to different points on the sensor. That leaves an unfocused image, but it doesn’t matter—because Ng’s software in the camera can use the information about the angle of the light rays to bring any part of the image into sharp focus.</p>  <p>In 2006 Ng was a PhD student at Stanford University studying the illumination of virtual objects. But he wanted to work on something with a more tangible impact, so he put off finishing his degree and started researching ideas for better camera designs. He wasn’t sure how to proceed until one day he found himself staring in frustration at a poorly focused photo he had recently taken. “I thought, ‘Does the camera have to focus before you take the shot?’” he recalls. He had a strong hunch the answer was no, and he immediately set out to prove it.</p>  <p>Once he hit on the idea for his camera system with multiple lenses inside, Ng started tearing apart and rejiggering conventional digital cameras to build prototypes. When he wasn’t screwing together camera parts, he was networking to scrounge up the expertise, technology, and funding he needed. After about nine months, he finally found himself at his kitchen table assembling what he hoped would be his first fully functioning prototype capable of after-the-fact focus. It worked, and became the subject of Ng’s prize-winning PhD thesis.</p>  <p>Ng decided to start a company based on the technology. The easier path would have been to license it to one of the established camera manufacturers, such as Nikon or Canon, rather than trying to take them on. But he feared that a big company would simply try to add the technology to its existing cameras as an incremental improvement. “A transformational technology requires a transformational product,” he says. So he started Lytro, and after four years of stealthy development, the company’s first camera began shipping in February.</p>  <p>Lytro has raised over $50 million in investments. It is currently working on introducing software to expand the capabilities of the existing camera model, with the 3-D upgrade expected this year. A bit further down the road, says Ng, could be cameras that will take refocusable videos.</p>  <p> —<em>Tom Simonite</em></p></td>
    </tr>
    <tr>
      <td>Hossein Rahnama</td>
      <td>Mobile apps that tell you what you need to know before you have to ask.</td>
      <td>32</td>
      <td>Flybits</td>
      <td>computing-2012</td>
      <td><p>PROBLEM: We’re forced to interact with smartphones in much the same way that we do with desktop computers—by selecting applications, typing in information, choosing from menus, hunting down snippets on websites, and clicking links. That’s okay at a desk, but it can be a huge inconvenience when you’re dealing with a tiny screen on the go.<br><br>SOLUTION: Hossein ­Rahnama, research and innovation director of the Digital Media Zone at Toronto’s Ryerson University, decided that smartphones ought to offer us useful information where and when we need it. <br><br>Through his startup, Flybits, Rahnama is laying the technical groundwork for a wave of mobile software that can identify and respond to contextual cues like location and time of day—and integrate them with information such as a user’s travel itinerary. It can then guess at what information would be most relevant to display, such as directions to a car-rental counter when you get off the plane after arriving at an airport.<br><br>Others have been working on so-called context-aware computing, but Rahnama’s software platform is already being used as the basis for inexpensive, commercially practical applications that also protect privacy. Several Canadian airports and the transit systems in Toronto and Paris have used the Flybits platform to create apps that automatically serve up personalized, location-keyed guidance to travelers, and a small U.K. telecommunications company is using it to develop apps that can route calls to the appropriate number to help you avoid roaming fees (for example, it knows to send your mom’s call to your hotel landline rather than your cell if it detects that you’re overseas).<br><br>Flybits can also make it easier to find the people most relevant to your location and interests. The company is rolling out a service called Flybits Lite that prompts users to form spontaneous social networks limited to a certain space, such as the office or a concert. So eventually, after you’ve navigated the Metro to the Louvre, perhaps you can find out who else is there to admire the Mona Lisa. <br><br></p></td>
    </tr>
    <tr>
      <td>Leila Takayama</td>
      <td>Applying the tools of social science to make robots easier to live and work with.</td>
      <td>31</td>
      <td>Willow Garage</td>
      <td>computing-2012</td>
      <td><p>People often find robots baffling and even frightening. Leila Takayama, a social scientist, has found ways to smooth out their rough edges. Through numerous studies and experiments that look at how people react to every aspect of robots, from their height to their posture, Takayama has come up with key insights into how robots should look and act to gain acceptance and become more useful to people.<br><br>Takayama has had an especially big influence on the design of an advanced robot from Willow Garage, the startup she works for in Menlo Park, California. Called PR2 (see “<a href="http://www.technologyreview.com/video/425195/robots-that-learn-from-people/" target="_blank" rel="noopener noreferrer">Robots That Learn from People</a>”), it’s an early prototype of a new generation of robots that promise to be indispensable to the elderly, people with physical challenges, or anyone who simply needs a little help around the home or office. <br><br>PR2 can fold laundry and fetch drinks, among other impressive tasks. But Takayama suspected that the nest of a half-dozen cameras originally perched on PR2’s head would alienate users. To find out, she turned to crowdsourcing, showing images of the robot head to an online audience recruited for the purpose. The results verified her concerns, and she successfully lobbied to jettison all but a few of the cameras, some of which were redundant.</p>  <p>More recently, Takayama has devoted effort to improving a robot called Project Texai, which is operated directly by humans rather than running autonomously. She ran an extensive field study to find out how Project Texai fit into the office environment of several different companies, coming by each office every two weeks to collect feedback and observe interactions between on-site staff and robots operated by remote colleagues. That study led to a surprising insight: “When you control a telepresence robot, there comes a point for a lot of people when they feel as if the robot is their body,” she explains. “They don’t want people to stand too close or touch the buttons on the screen.”<br><br>She also discovered that people in the offices ended up being less comfortable with Project Texai if they were allowed to dress it up. Personalizing the robot led people to feel more possessive about it and less accepting of the fact that someone else was controlling it. Project Texai should be personalized, Takayama concluded, but only by the “pilot,” and not by those who are around the machine. She also found that robot size can have a big impact on acceptance and is conducting a study to nail down the optimal height for Project Texai. Another key question: is it better to have the robot at eye level with a person who is sitting or standing? <br><br>Takayama is now conducting home interviews with the elderly and disabled to figure out which sorts of tasks would be most helpful to them. She predicts that someday soon, older people will employ personal robots to help them communicate with family and friends.<br><br></p></td>
    </tr>
    <tr>
      <td>Eben Upton</td>
      <td>His ultracheap computer is perfect for tinkering.</td>
      <td>34</td>
      <td>Broadcom</td>
      <td>computing-2012</td>
      <td><p>Eben Upton thought a new generation of youngsters might never develop valuable hardware and software hacking skills unless they had access to cheap, hobbyist-friendly computers. So he set out to build one himself. The resulting tiny box, which sells for just $25, has been a big hit. It could boost computer skills not only among children but among adults in poor countries as well.</p>  <p>Upton came up with the idea in 2006, when he was finishing his PhD in computer science at the University of Cambridge. Having agreed to help out with undergraduate computer science admissions, he was looking forward to interacting with teenagers who loved messing around with computers as much as he had when he was younger.</p>  <p>Upton had done all that messing around partly for the thrill of bending the machines to his will, and partly because the 1980s boom in video games had made it easy to imagine making a fortune working with computers. “I was a mercenary child,” he says, sounding a bit apologetic. “One of the things that drew me to computing was that there were 15-year-old kids who made so much money from computing they actually bought Ferraris.”</p>  <p>To judge by the applicants Upton was looking at, however, kids had lost interest. They were still messing around on computers, but they weren’t messing around with them. They weren’t writing programs and taking apart circuit boards. They were the kinds of kids who played World of Warcraft and exchanged cat pictures on Facebook. They had changed from active hackers to passive consumers.</p>  <p>Perhaps the dot-com bust had killed some of the enthusiasm for hacking. But to Upton, one other possible factor loomed large. In the 1980s, he and his friends had learned basic computer science on a BBC Micro, a line of computers built for the British Broadcasting Corporation by Acorn Computers and installed in most English schools. Small, rugged, inexpensive, and expandable, the Micro introduced a generation of British children to hardware engineering and software programming.</p>  <p>There was no contemporary equivalent to the Micro. “Sure, everyone in the middle class has a PC,” Upton says. “But even then, often there is only the one family PC. You won’t let kids screw around with it.” Schools aren’t going to let students take apart their machines, either. As a result, he observes, “computing” classes teach children how to use Microsoft Word and PowerPoint. “Even Microsoft wants schools to produce software engineers,” Upton says. To successfully restore literacy in computer tinkering, he decided, the world needed a modern analogue of the BBC Micro.</p>  <p>Being a hardware guy at heart, Upton went ahead and built a prototype of a next-generation hobbyist machine—the sort of stripped-down device that would enable its users to become acquainted with the guts of a computer. It would also allow its users to put the machine to work in projects ranging from robotics to wearable computing to gaming. He eventually took up a Cambridge professor’s suggestion to call his device Raspberry Pi, tipping his hat to the old tech tradition of naming computers after fruit. But he didn’t immediately see a way to produce Raspberry Pi in sufficient numbers to make a difference, so he reluctantly mothballed the project.</p>  <p>After finishing his PhD, Upton went to work at the Cambridge, U.K., office of Broadcom, a networking company based in Southern California. (He is now one of the company’s technical directors for Europe.) Upton was instrumental in the creation of Broadcom’s first microprocessor intended for multimedia applications—the BCM2835. Released in 2011, it is a single chip that’s small enough to fit in a phone but big enough to contain vital parts such as a central processing unit and a graphics processor. By some measures it was the most powerful chip in the mobile market at the time, and it was a tremendous success for Broadcom.</p>  <p>It was also, Upton realized, the way to restart Raspberry Pi, given that a single-chip computer would be much less costly to produce. He and half a dozen volunteers worked on the new version on evenings and weekends. But the BCM2835 wasn’t easy to deal with: it was dauntingly jammed with tiny components, including no fewer than five power supplies.</p>  <p>To keep Raspberry Pi small and cheap, the team wanted to build it on a ­single circuit board that could be stamped out, no further assembly required. But to enable the phone chip to work with computer peripherals and run full-scale computer software, they would, it appeared, need to build a board with more than eight stacked layers of circuitry, a prohibitively complex and expensive proposition. Working furiously to simplify the circuitry, the team eventually managed to shave the board design down to six layers.</p>  <p>The first prototypes were ready in December 2011, but Upton discovered, to his horror, that they didn’t work at all. Fighting panic at the thought of all the various subtle flaws that might be buried in all those layers of tangled circuitry, the team discovered that one pin on the chip had been inadvertently disconnected. It was a blessedly easy fix, and within minutes, his invention was popping to life.</p>  <p>The Raspberry Pi is strikingly unlike other computers. About the size of an Altoids box, the computer has no keyboard, monitor, or disk drive—it doesn’t even have an internal clock or an operating system. In other words, the machine requires a fair amount of hardware and software tinkering just to get started. It almost dares you to take it on and try to hack together a robot or gaming system.</p>  <p>It can’t get by on looks. Lacking a case, the Raspberry Pi offers a dense, bristling cluster of tiny electronics to the owner’s view, with five ports: HDMI, to hook the computer up to a television; USB, to hook it to multiple devices; Ethernet, for data; and analog TV and analog stereo. But having to face the guts of the device is a good thing, according to Upton. “Kids can see what they ordinarily can’t see, unless they smash a phone,” he says.</p>  <p>The really surprising feature of the Raspberry Pi is the $25 price: about a tenth the cost of the lowest-priced computers available in stores (if you ignore tablets, which no one can hack anyway).</p>  <p>It was intended for kids, but hackers of all ages wanted it, and so did budding computer scientists in poor countries. Almost the instant the Raspberry Pi went on sale, orders crashed the websites of its two vendors, RS Components and Premier Farnell. The companies reported that they were taking in orders fast enough to tear through the entire initial stock of 10,000 computers in minutes.</p>  <p>Thrilled with the reception, Upton is making more of the devices through a nonprofit Raspberry Pi Foundation he put together—his mercenary tendencies having abated over the years. In fact, he says, he intends to sell two million Raspberry Pis a year in order to reach a critical mass that will support an active community of owners to share tips and applications. He also hopes that the existence of this community will prompt schools to adopt the Raspberry Pi for courses.</p>  <p>Even more important, Upton hopes, is that kids start to take them apart. “That would be real success,” he says.</p>  <p></p></td>
    </tr>
    <tr>
      <td>Andreas Velten</td>
      <td>Spotting tiny problems with help from an ultrafast camera.</td>
      <td>32</td>
      <td>University of Wisconsin, Madison</td>
      <td>computing-2012</td>
      <td><p>Nothing moves too fast for Andreas Velten’s camera—not even light. Last year Velten, who built the camera while a postdoc at the MIT Media Lab’s Camera Culture Group, made a video of laser light zipping through a plastic soda bottle. Capturing the equivalent of 600 billion frames per second, the slow-mo footage showed a ghostly light moving from one end of the bottle to the other. Equally remarkable, the camera can harness light reflected off surfaces to see around corners. Because the camera is so fast, it can detect how long it takes the different light rays to reach it, and an image can be reconstructed from that information.</p>  <p>It’s not just amazing gimmickry. Velten’s technology could lead to ultrafast medical imagers and scanners that use light instead of sound to detect tiny imperfections, whether in cancerous tissue or in airplane wings. It also suggests an approach to taking high-quality photos of scenes lit only by the tiny flash on a cell phone.<br><br>Velten’s table-mounted camera uses 672 carefully positioned and timed optical sensors, each capable of capturing a trillionth of a second’s worth of reflected laser light. The technical advance was figuring out how to modify a streak camera, a common piece of equipment in chemistry labs that measures the optical properties of laser light. That type of camera can capture only one horizontal line, or “streak,” of light at a time. Velten, combining his expertise in optics and computer science, developed custom software to repeat the scan over and over and combine the resulting data. <br><br>Now at the Morgridge Institute at the University of Wisconsin, Velten is applying his ultrafast imaging techniques to help develop new types of microscopy and biomedical imaging for clinical applications. One of the tools he envisions, for example, is a less invasive endoscope that could travel shorter distances to see deeper inside the body. <br></p></td>
    </tr>
    <tr>
      <td>Judd Antin</td>
      <td>Learning what drives online collaboration</td>
      <td>32</td>
      <td>Yahoo Research</td>
      <td>web-2011</td>
      <td><p>“When you look at ­YouTube, Flickr, Facebook, or similar services, there’s so much collaborative work going on. But we don’t really understand why,” says Judd Antin, a research scientist in the Internet Experiences Group at Yahoo Research. Indeed, many of the marvels of the Internet age, such as Wikipedia, have come from rethinking traditional ideas about how workers should be organized and rewarded. Antin is finding out what motivates people to participate in such projects, in hopes of attracting the broadest possible spectrum of contributors and decreasing the likelihood that the projects will fizzle out after the novelty wears off. </p>  <p>One finding: using gamelike approaches and software–for example, to prompt people to reveal their location to advertisers—might be overrated as a way to shape behavior. The popular tactic of rewarding people with points and badges doesn’t motivate them for long on most websites, Antin says. </p>  <p>But he still believes some game dynamics will remain effective in the long term, and he’s working to figure out what those are. He also wants to learn how motivation varies across cultures. With those tools, he hopes, organizations will be able to consistently nurture the Web’s collaborative spirit and turn it to good use. </p></td>
    </tr>
    <tr>
      <td>Xiao Li</td>
      <td>Anticipating what Internet users are searching for.</td>
      <td>32</td>
      <td>Microsoft Research</td>
      <td>web-2011</td>
      <td><p>Search engines are pretty good at matching keywords with relevant websites. Xiao Li is helping teach Bing, Microsoft’s search engine, to go a step further: figure out the specific task a user is trying to tackle with a query, whether it’s buying a digital camera or booking a hotel room, and return the most useful results related to that task.</p>  <p>Li created software that can automatically crunch through terabytes of Bing’s logs. By building relationships between keywords, the links people click, and the type of information presented on Web pages, the software can predict what a user is trying to accomplish, even if unfamiliar search terms are used. Once Bing determines the intent of a query, it can pass the query to one of a number of specialized search engines that index the most relevant subsets of the Web and can offer task-specific tools. For example, if Li’s system decides that a user searching for “pulled pork downtown” is more likely to be trying to make a dinner reservation than to find a butcher shop, it can kick the query over to a specialized engine that deals in restaurant searches, providing quick links to reviews and reservation systems. </p></td>
    </tr>
    <tr>
      <td>Andrew Mason</td>
      <td>Electronic coupons for localized online advertising.</td>
      <td>30</td>
      <td>Groupon</td>
      <td>web-2011</td>
      <td><p>Groupon is one of the fastest-growing companies of all time. Less than three years after CEO Andrew Mason launched it, it has more than 7,000 employees, operates in 43 countries, and is on pace for more than $2 billion in revenue this year. Its model is simple—it e-mails consumers with discount offers for goods and services in their cities–but it has taken off because previously there were few other cost-effective ways for small brick-and-mortar businesses to advertise to local customers.</p>  <p>Mason created Groupon by repurposing technology he’d developed in 2007 to help groups of people pledge to perform some civic action as long as a critical mass of users agreed to take part. The twist in Groupon was that the collective action would be buying something. Starting in Chicago, Mason began offering to deliver a daily promotional discount to consumers, who get the deal only if enough people sign up to make it worthwhile for the business. If not, the deal is off.</p>  <p>Groupon isn’t close to being profitable yet, because it’s spending hundreds of millions of dollars annually on marketing, sales-force expansion, and other things required to move on from startup mode. It also has to contend with new competitors hawking local bargains. Mason plans to adapt with, for instance, a mobile service called Groupon Now that lets people see offers near where they happen to be. Groupon Now is also more flexible for businesses, which can offer bargains at targeted times, such as when sudden cancellations leave a restaurant with empty tables to fill. </p></td>
    </tr>
    <tr>
      <td>Chris Poole</td>
      <td>Designing online communities for anonymous collaboration.</td>
      <td>23</td>
      <td>Canv.as</td>
      <td>web-2011</td>
      <td><p>4Chan, founded in 2003 by Chris Poole (better known as “moot”), is one of the few corners of the Web that still celebrate faceless commentary and action. Poole’s commitment to anonymity has helped 4Chan acquire more than 12 million active users; it boasts 600 million page views a month.</p>  <p>The 4Chan discussion boards have given rise to Internet memes that have helped shape popular culture, such as the continuing vogue for abruptly inserting Rick Astley’s 1987 hit “Never Gonna Give You Up” into an online video (or live event). Less frivolously, the site was the birthplace of Anonymous, a collective of activist hackers who have targeted Scientology and companies that shunned WikiLeaks for publicizing government and corporate secrets.</p>  <p>When Poole built 4Chan, he did so with the concept of anonymity at its center, seeking to create a place where people have their mistakes forgotten rather than being haunted by everything they’ve ever posted. There is no registration system, and users can post anonymously under whatever pseudonym they choose, even one associated with another user. There is no archive: content uploaded to the site by users disappears as new images and commentary are added. </p>  <p>Poole hopes to apply the lessons he has learned from 4Chan to a recent startup called Canv.as, which will allow users to share and edit images collaboratively using a built-in editor—anonymously, of course. </p></td>
    </tr>
    <tr>
      <td>Jesse Robbins</td>
      <td>Fault-tolerant online infrastructure.</td>
      <td>33</td>
      <td>Opscode</td>
      <td>web-2011</td>
      <td><p>In 2001, Jesse Robbins applied for two jobs: one as a Seattle bus driver and another as a backup systems engineer at Amazon.com. Amazon called first, and in the decade that followed, Robbins transformed the way Web companies design and manage complex networks of servers and software. </p>  <p>A former volunteer firefighter, Robbins brought an emergency responder’s mind-set to his work. He taught Amazon that with data centers distributed around the world, a massive shopping site, and intricate fulfillment operations, some unpredictable and spectacular failures were inevitable. Rather than try to defy that inevitability, Robbins says, he made it safe for Amazon to fail, building fault tolerance into its architecture. Then he tested the Web operations teams with live drills, knocking entire data centers offline. Customers didn’t notice a thing.</p>  <p>After leaving Amazon in 2006, Robbins began blogging about his techniques. In 2007, he founded Velocity, now an annual conference, where fierce competitors such as Microsoft and Google share information about handling infrastructure problems. </p>  <p>In 2008, Robbins cofounded Opscode. Its main product, Chef, is an open-source programming language that automates management of cloud-based infrastructure. For example, one client used Chef to help scientists bring up and configure in 45 minutes a 10,000-­processor supercomputing cluster on Amazon’s pay-as-you-go cloud, solve some difficult problems related to protein binding in eight hours, and then close out the operation, for a small fraction of what it would cost to build or buy time on a supercomputer. </p></td>
    </tr>
    <tr>
      <td>Pieter Abbeel</td>
      <td>Robots that learn from people.</td>
      <td>33</td>
      <td>University of California, Berkeley</td>
      <td>computing-2011</td>
      <td><p>Instead of programming robots to handle each step of a new job, Pieter Abbeel, an assistant professor at UC Berkeley, has created robots that can observe humans demonstrating a task and then mimic them, or learn from pictures how to handle a piece of flexible material they’ve never seen before. His robots have learned to perform flying acrobatics, tie surgical sutures, and neatly sort socks.</p>  <p>Abbeel’s key innovation was to program the robots so that they can reliably infer the underlying intent of their instructors, filtering out the “noise”—irrelevant variations, or even slight mistakes, in the instructors’ demonstrations. Each robot is usually shown around 10 demonstrations before it can extract general rules of behavior. Even without an instructor, it can sometimes work out what to do. For example, Abbeel taught one robot how to fold laundry by giving it some general rules about how fabric behaves, and then showed it around 100 images of clothing so it could analyze how that particular clothing was likely to move as it was handled. After that, the robot could fold towels and sweaters without further instruction. ­</p></td>
    </tr>
    <tr>
      <td>June Andronick</td>
      <td>Software that can’t crash.</td>
      <td>32</td>
      <td>NICTA</td>
      <td>computing-2011</td>
      <td><p>PROBLEM: To test the reliability of software that controls embedded chips in medical devices and vehicles, computer scientists have relied on trial-and-error methods that can miss bugs.</p>  <p>SOLUTION: By using mathematical analysis to prove that a piece of software is reliable, June Andronick can take into account all possible inputs to the software, and all the possible ways the software could process those inputs. </p>  <p>Working at Australia’s national IT research center (NICTA), Andronick and colleagues in Gerwin Klein’s lab were able to use this analytical technique to write a small operating system that will always behave exactly as intended, never crashing (barring incorrect assumptions about the hardware). </p>  <p>Because the OS acts as the gatekeeper to the hardware, it can block instructions that would cause a crash—say, instructions coming from the application software that makes decisions about how an engine should be throttled. Some computer scientists predict that mathematically verifying the reliability of critical software components will become the norm in certain systems.</p>  <p>The technology could also help protect against cyber-attacks, Andronick says. The operating system could block unauthorized actions that are issued by software that has been hacked through some point of vulnerability, such as a Web browser. “The attack on the untrusted part can’t keep the trusted part from functioning correctly,” she says. </p></td>
    </tr>
    <tr>
      <td>Jernej Barbič</td>
      <td>Speeding up simulations of complex objects.</td>
      <td>34</td>
      <td>University of Southern California</td>
      <td>computing-2011</td>
      <td><p>Engineers and animators use computer simulations to model the ways objects bounce, bump, and change shape under external forces. Until now, these simulations were too complex to run in real time, but Jernej Barbič has developed a way to make them run tens of thousands of times faster than previously seemed possible—fast enough for engineers to be able to interact with a model and see it respond instantly, allowing them to experiment with designs as never before.</p>  <p>Barbič translates models with millions of parameters into versions that have just tens or hundreds but are still accurate. He created software that can automatically identify which parameters are the most important and determine how these can be combined to reduce their number. </p>  <p>His latest experiments connect models to haptic interfaces that allow a user to literally feel what’s happening in the virtual world. Producing a realistic physical sensation of movement takes approximately 1,000 updates per second. “That’s infeasible without Jernej’s approach,” says Adrien Treuille (<a rel="noopener noreferrer" href="http://www.technologyreview.com/TR35/Profile.aspx?TRID=818" target="_blank">a member of the 2009 TR35</a>), a professor at Carnegie Mellon University. Barbič is now in talks with the French company Haption to commercialize the technology. He says that because his techniques make it easier to quickly test and revise designs, products could “be made faster and turn out cheaper and safer.” </p></td>
    </tr>
    <tr>
      <td>Dan Berkenstock</td>
      <td>Cheaper satellite pictures.</td>
      <td>31</td>
      <td>Skybox Imaging</td>
      <td>computing-2011</td>
      <td><p>Dan Berkenstock, cofounder and chief product officer of Skybox Imaging, wants to let “anyone know what’s happening anywhere in the world at any time.” Next year the company plans to launch the first of what it hopes will be a constellation of 12 to 24 satellites taking high-­resolution pictures of Earth. Each satellite should cost about a tenth as much as the $250 million to $500 million imaging satellites operated by companies like DigitalGlobe and GeoEye.</p>  <p>Currently, so few commercial imaging satellites are in orbit that it can take days or even weeks to get pictures of a location—and there will be only one per day. By placing multiple satellites in multiple orbits for the cost of a single traditional satellite, Skybox plans to realize something closer to Berkenstock’s vision of anywhere, anytime coverage: it could photograph nearly any spot on the planet up to three or four times a day, weather permitting. (Skybox’s license from the U.S. government takes security and privacy concerns into account: the satellites will have one-meter resolution—enough detail to identify a crowd but not an individual.)</p>  <p>The secret to the low cost of Skybox’s satellites is their size: each one is about as big as a large trash can, rather than a minivan. With smaller, more modern components than those typical in the conservative aerospace industry, they’re cheaper to build, and less expensive rockets can be used to launch them. Skybox is hoping to recoup the cost of the constellation by expanding the market for fresh satellite imagery beyond the government and the military. Berkenstock is working on tools for storing and classifying pe­tabytes of data–tools that financial analysts, for example, could use to get daily counts of the cars in the parking lots at thousands of retail location. </p></td>
    </tr>
    <tr>
      <td>Brian Gerkey</td>
      <td>A common language for robots.</td>
      <td>34</td>
      <td>Willow Garage</td>
      <td>computing-2011</td>
      <td><p>PROBLEM: People who want to program robots have had to either write software from scratch or purchase proprietary software that is hard to modify. </p>  <p>SOLUTION: Brian Gerkey has developed open-source platforms, called Player and ROS, that standardize the basic software used to control a robot. Both have been adopted by thousands of companies, universities, and governments around the world. </p>  <p>Gerkey believes the software will allow entrepreneurs to create new commercial applications for robots even if they don’t have extensive robotics expertise. The goal is to help “people who have ideas for what robots can do in the marketplace,” he says. Much of the development of ROS is happening at Willow Garage, a robot technology incubator, where Gerkey is the director of open-source development. The first full version of ROS, which can handle more complex robots than Player, was released in 2010. By encouraging the adoption of ROS, Willow Garage is also increasing the market for its own robots, which it hopes will become the de facto hardware standard for would-be robot entrepreneurs.</p></td>
    </tr>
    <tr>
      <td>Jeff Hammerbacher</td>
      <td>Managing huge data sets.</td>
      <td>28</td>
      <td>Cloudera</td>
      <td>computing-2011</td>
      <td><p>In 2006, as Facebook was starting to accumulate information about its users faster than the data could be analyzed and stored, Jeff ­Hammerbacher was brought in to deal with the problem. A former Wall Street number cruncher, he soon developed techniques for handling and mining unprecedented amounts of data. </p>  <p>Realizing that the company needed entirely new technology to handle the information overload, Hammerbacher threw Facebook’s muscle behind a relatively new open-source database project called Hadoop, which allows nearly real-time processing of data in quantities that had previously been impossible. Hadoop enabled Hammerbacher to create the suite of analytics that underpins Facebook’s targeted advertising system—the key to the company’s profitability.</p>  <p>Though much of the technology he constructed is still in use at Facebook, Hammerbacher left in 2008 to found a company called Cloudera, where he is now chief scientist. Cloudera is devoted to developing Hadoop and related open-source technologies. Hammerbacher points out that industries including oil and gas, retail, and life sciences are all dealing with increasing amounts of data. They could use such technology to extract valuable insights from the deluge. </p></td>
    </tr>
    <tr>
      <td>Gert Lanckriet</td>
      <td>Teaching computers to classify music.</td>
      <td>34</td>
      <td>University of California, San Diego</td>
      <td>computing-2011</td>
      <td><p>Is Lady Gaga’s “Born This Way” a happy song? Is “Bohemian Rhapsody” sad? Gert Lanckriet wants computers to be able to tell. Then people could search for tunes that match a particular mood or instrumental style, and an online store could make better recommendations. </p>  <p>Lanckriet, an associate professor in the Department of Electrical and Computer Engineering at the University of California, San Diego, started by having his computers analyze a collection of 500 popular songs that human judges had categorized in six ways—by genre and tempo, for example. When fed a new piece of music not in the database, the computer uses that training to infer how a human would characterize it. Lanckriet continues to train the system through a Facebook game called Herd It, launched in 2009. Players listen to snippets of music and win points if they agree with the majority of their fellow users; the results are fed into Lanckriet’s software. </p>  <p>After the software gets some more fine-tuning, Lanckriet plans to let it crawl the Web like a search engine, automatically classifying the huge amount of music available online. He’s also exploring how to use the sensors in smart phones to cue up exactly the sort of music someone is in the mood for. If the phone’s accelerometer detects that the user is exercising, it could choose something energetic, while sitting in a quiet room at night might lead it to choose something mellower. </p></td>
    </tr>
    <tr>
      <td>Alina Oprea</td>
      <td>Guaranteeing cloud security.</td>
      <td>34</td>
      <td>RSA Laboratories</td>
      <td>computing-2011</td>
      <td><p>PROBLEM: Cloud computing offers numerous advantages to businesses and individuals by enabling them to store data and run websites on remote computers rather than ones they own. But many hesitate to use the technology for fear of what might happen if a cloud provider’s systems aren’t secured properly or break down. </p>  <p>SOLUTION: Software created by Alina Oprea, a researcher at RSA Laboratories in Cambridge, Massachusetts, can guarantee users that their data hasn’t been tampered with and won’t become inaccessible. For her 2007 PhD thesis, she developed a digital fingerprint capable of quickly verifying that data stored in the cloud hasn’t been maliciously altered or accidentally corrupted. Then, at RSA, Oprea helped create HAIL, a technology that lets users divide data among multiple cloud providers in such a way that if one provider goes offline, the missing information can be reconstructed from the data stored by the others.</p>  <p>Next she helped lead the development of HomeAlone, which guards against an insidious threat in cloud computing: when users buy remote computing power, they often share server space with other customers, offering an opportunity for potential hackers. Many cloud providers let customers pay extra for their own private servers to avoid this risk. HomeAlone lets customers who choose that option verify that the data is indeed isolated and no one is snooping on their space in the cloud. </p></td>
    </tr>
    <tr>
      <td>Aishwarya Ratan</td>
      <td>Converting paper records to digital in real time.</td>
      <td>30</td>
      <td>Yale University</td>
      <td>computing-2011</td>
      <td><p>Beginning in 2009, while working with Microsoft Research India, Aishwarya Ratan spent 15 months figuring out how to help local microcredit co-ops, which often struggle with handwritten entries that are illegible, incorrect, or incomplete. Her solution combines digital technology with the familiar paper notebooks that villagers prefer. Co-op members use an electronic ballpoint pen to write in ledgers placed on a slate equipped with software that recognizes handwritten numbers. The slate provides feedback on whether the records are complete and legible, stores them in a database, and gives real-time balance updates, both on a screen and verbally in the local language. The database can be shared with the nongovernmental organizations and banks that back each co-op. </p>  <p>In field tests, the hybrid slate yielded entries that were 100 percent complete and made record keeping faster while letting co-op members retain the paper records they are comfortable with. The potential of the system is tremendous: microfinance co-ops serve 86 million Indian households. High-­quality record keeping could make them more efficient, helping members save more and repay faster, and it could allow the co-ops to borrow more easily from banks. </p>  <p>In June, Ratan became the director of the Microsavings and Payments Innovation Initiative at Yale University, which as part of its mission studies how technologies can help the poor financially. Meanwhile, the NGO that Ratan was partnering with continues to test the slate in villages. </p></td>
    </tr>
    <tr>
      <td>Noah Snavely</td>
      <td>Synthesizing 3-D models from 2-D photographs.</td>
      <td>30</td>
      <td>Cornell University</td>
      <td>computing-2011</td>
      <td><p>Every snap of a shutter—be it the subtle <em>click</em> of a DSLR or the artificial <em>ka-chak</em> of a smart phone-—turns three-dimensional reality into a two-dimensional image. Noah ­Snavely is taking those images and using them to create 3-D digital models of structures ranging from individual houses to entire cities. </p>  <p>In 2006, as part of his PhD studies at the University of Washington, Snavely created a system that could assemble such models using an unstructured assortment of images from different cameras and viewpoints. “If we can find matching points between views,” he says, “we can reason about where each image was taken and what the 3-D shape of the scene is.” In 2008 his work was commercialized as Microsoft’s Photosynth service, which allows users to upload photo collections and view them in a 3-D reconstruction of the space where they were taken. Snavely has even used his technology to reconstruct the city of Rome from the wealth of amateur images available online. </p>  <p>­Snavely, now an assistant professor at Cornell, is trying to assemble a “distributed camera” composed of all the individual cameras whose pictures are shared online. He hopes to use those photos to construct a street-level digital model of much of the globe. </p></td>
    </tr>
    <tr>
      <td>Piya Sorcar</td>
      <td>Software that can be localized to teach taboo topics.</td>
      <td>33</td>
      <td>TeachAIDS</td>
      <td>computing-2011</td>
      <td><p>Despite considerable educational efforts by experts and organizations alike, public awareness in India about the growing HIV epidemic has remained low. So Piya Sorcar, founder and CEO of TeachAIDS, has developed interactive software to educate children about HIV in a way that’s sensitive to the country’s cultural mores.</p>  <p>When Sorcar traveled to India in 2005, she found that even children and young adults who received training on HIV didn’t learn much: cultural taboos prevented educators from speaking frankly about how the virus is transmitted. As she designed her software, she took pains to ensure that it didn’t run afoul of those taboos. She analyzed cultural responses to every image used. She recorded narration with correct local accents, created gender-specific versions of each program, enlisted local celebrities for voice acting, and tested to see how much information children retained, even long after the lessons were over. </p>  <p>The cultural sensitivity has paid off: Sorcar’s software has been approved and distributed by states in India where other sex education is banned. The software has been designed to be modular, so that it’s easy to swap in locally appropriate elements. The country of Botswana has approved it for every school in the nation, and Sorcar hopes to distribute it to countries around the world within five years. </p></td>
    </tr>
    <tr>
      <td>Kun Zhou</td>
      <td>Creating movie-quality graphics in real time.</td>
      <td>33</td>
      <td>Zhejiang University</td>
      <td>computing-2011</td>
      <td><p>Thanks to Kun Zhou, computer games will become more realistic and animated movies will reach cinemas faster. The Zhejiang University computer science professor has released software capable of rendering movie-quality scenes using graphics chips of the sort that most PCs use to create comparatively crude images. </p>  <p>These chips, known as GPUs, perform many relatively simple computations in parallel. While this design is adequate to synthesize images for today’s computer games, it wasn’t seen as a good fit for the complex algorithms required to create the truly photorealistic images produced by animation and special-effects studios. But in 2009 Zhou developed a programming language that could efficiently break up these algorithms in a way that suited GPUs. He used this language as the foundation of a rendering system called RenderAnts, which generates images more than 10 times as fast as traditional software. A Chinese animation studio is already using an early commercial version of the software to increase the quality of its television productions, and Zhou is collaborating with the Frankfurt-based gaming studio Crytek—maker of the popular Crysis series of games, which are often used to benchmark the graphics performance of PCs—to improve the realism of its products. </p>  <p>Making games more realistic while keeping them fast enough to respond instantaneously to a player’s actions is a personal goal for Zhou. He says he got hooked on games as a young engineering student and has been trying to overcome their limitations ever since. </p></td>
    </tr>
    <tr>
      <td>Bhaskar Krishnamachari</td>
      <td>Smarter wireless networks.</td>
      <td>33</td>
      <td>University of Southern California</td>
      <td>communications-2011</td>
      <td><p>By creating smarter wireless networks that can handle mobile devices and interference more efficiently than today’s Wi-Fi and cellular networks, Bhaskar Krishnamachari aims to ease the increasing digital congestion of the airwaves and open the door to new applications for wireless communications. </p>  <p>For example, ­Krishnamachari is working with General Motors on a vehicle-to-vehicle network that lets cars in motion swap information about traffic flow and road conditions. His design can reliably route data within a shifting network of cars and other vehicles across freeways and city streets without having to tax the congested cellular network. One key to his approach is that data is not directed to specific addresses, as is standard in many computer networks. Instead, packets of data are labeled with tags that describe things such as the packet’s contents, the geographic area the information is relevant to, and the time when the data should be considered out of date. Data is passed along the fleeting connections as needed and soon discarded. “This is opening up additional, almost free, bandwidth,” he says. </p></td>
    </tr>
    <tr>
      <td>Ajit Narayanan</td>
      <td>Affordable speech synthesizers.</td>
      <td>30</td>
      <td>Invention Labs</td>
      <td>communications-2011</td>
      <td><p>Some four million people in India suffer from cerebral palsy and other disabilities that make it difficult or impossible for them to speak. Giving them a voice is the job of Ajit Narayanan’s low-cost tablet-based system, Avaz. Even someone with only limited movement control can use Avaz to construct phrases that are spoken out loud by an artificial voice. </p>  <p>Speech synthesizers have long been used in the West (perhaps most famously by Stephen Hawking), but they are prohibitively expensive to all but the richest in India. Narayanan’s Invention Labs, based in Chennai, designed Avaz to be not only cheap but also capable of supporting multiple languages. “The average young person in India speaks and uses three different languages every day,” Narayanan points out. By working directly with Asian hardware manufacturers, he has been able to bring the cost of an Avaz down to around $800, compared with $5,000 to $10,000 for a single-­language device in the United States. </p>  <p>Just over 100 of the devices have been sold so far, mainly to specialist schools, and they are in use by around 500 children. “I’ve seen parents weep when Avaz allows them to talk with their [child] for the first time,” says Narayanan. He is currently working with the Indian Institute of Science, Bangalore, to improve the quality of the speech synthesis, and he also plans to use mobile app stores to distribute a version of his software with about 90 percent of the full Avaz system’s functionality. </p></td>
    </tr>
    <tr>
      <td>Umar Saif</td>
      <td>Improving connectivity in poor nations.</td>
      <td>32</td>
      <td>Lahore University of Management Sciences</td>
      <td>communications-2011</td>
      <td><p>In Pakistan, the bandwidth of an average landline is about 32 kilobits per second (as of 2011, the average broadband speed in the United States was 5.3 megabits per second). It can take more than 20 minutes to download a five-megabyte file—assuming the connection doesn’t drop during that time, as it frequently does. To help relieve the frustration, Umar Saif developed ­BitMate. The software lets different users in the same area pool the bandwidth of their connections to reduce download times, typically by half. Released in February, the software has already been downloaded more than 30,000 times by people in 173 countries. </p>  <p>Saif previously created a service that linked mobile phones into groups so that mass SMS messages could be sent. Since its launch in 2008, it has been used to send nearly four billion texts to about 2.4 million users in Pakistan, and the service, now called SMSall, has been used to coördinate protests, find missing persons, and organize blood drives. This summer Saif began expanding SMSall beyond Pakistan to Nigeria, Iraq, Bangladesh, and the Philippines. “SMS is the door to the world for many people,” he says. </p></td>
    </tr>
    <tr>
      <td>Danah Boyd</td>
      <td>Shaping the rules for social networks.</td>
      <td>32</td>
      <td>Microsoft Research</td>
      <td>web-2010</td>
      <td><p>As more and more people join social-networking sites, Danah Boyd is  asking and answering some uncomfortable questions about these online  communities. Among other things, she has detailed how race has been a  factor in some users’ migration from MySpace to Facebook, how social  networks are changing the way teenagers relate to one another, and how  the Internet alters the way people think about privacy. </p>  <p>Working as an advisor, Boyd has shaped the policies of companies like  Google and LiveJournal. Now employed by Microsoft Research New England,  she has been talking with government regulators and privacy advocacy  groups to determine how best to help users protect their personal  information. She believes that privacy regulation is inevitable and is  trying to guide the industry and regulators toward a set of mutually  acceptable rules. </p>  <p>Critical to any such solution, Boyd says, is making sure that people  can control what happens to their personal data after it has been  entered into a social network.</p></td>
    </tr>
    <tr>
      <td>Wesley Chan</td>
      <td>Building new technology businesses.</td>
      <td>32</td>
      <td>Google</td>
      <td>web-2010</td>
      <td><p>Wesley Chan has a knack for turning good ideas into new  businesses–and doing it with minimal resources. In 2005, Chan’s small  team at Google, which incorporated two startups he acquired for the  company, launched Google Analytics to provide a free version of the  tools the search giant previously used internally. In 2006, he dreamed  up another free service, Google Voice, which launched in 2009. This one  offers automatic transcription of voice mail, the ability to use one  number for different phones, and many other features. Given only two  company engineers to work with on the project, Chan acquired the startup  ­GrandCentral in 2007; he and his new crew spent the next two years  putting the service together in secret.</p>  <p>Google Voice now has millions of users. But Chan has moved on again  and is now a partner at Google’s venture capital investment group,  Google Ventures. He still invests in software but is free to cast his  net wider. In particular, he is developing an interest in stem-cell  medicine, even though the field has no direct connection to Google’s  business. He says, “For me it’s about going where I can learn the most,  and making the output of my learning something that is world-changing.”  </p></td>
    </tr>
    <tr>
      <td>Nick Feamster</td>
      <td>Watching the suspicious behavior of spam.</td>
      <td>31</td>
      <td>Georgia Tech</td>
      <td>web-2010</td>
      <td><p>For years, e-mail providers, IT departments, and network operators  have fought spam with the help of technology that examines what messages  say. Nick ­Feamster, an assistant professor at Georgia Tech, had a  better idea. Instead of examining content, he looks at how messages move  through networks, on the theory that the traffic flow of legitimate  messages and spam should be different. </p>  <p>For example, Feamster found that spammers often try to hide in “dark  space”–normally unconnected Internet addresses. Suddenly, a previously  unreachable block of addresses would light up, send out a bunch of  messages, and then disappear. Watching for phantom networks that appear  for 10 minutes at a time turned out to be one way to identify and stop  spam. His strategies have been adopted by companies such as Yahoo and  McAfee in their ongoing struggle to prevent spam from reaching users.</p>  <p><em><br></em></p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2010/08/Picture1-1.jpg?w=936" alt="" class="wp-image-1033238"/><figcaption>Global gunk: Nick Feamster's research team tracks the regions of the world most afflicted by spam.</figcaption><div class="image-credit">FEAMSTER</div> </figure> </div> <p></p></td>
    </tr>
    <tr>
      <td>David Karp</td>
      <td>A platform that keeps ­bloggers blogging.</td>
      <td>24</td>
      <td>Tumblr</td>
      <td>web-2010</td>
      <td><p>Maintaining a blog takes stamina: of the more than 100 million blogs  surveyed by the search engine Technorati in 2008, fewer than 10 percent  had been updated in the previous four months. David Karp thought that  simplifying posting would stop users from falling away, so he created  Tumblr, a streamlined blog platform. The result? Of the site’s six and a  half million registered users, 85 percent post more than 20 times a  month on average. </p>  <p>Within a few minutes of signing up with Tumblr, users can submit  their first post by browser, e-mail, IM, or even voice. And with large  buttons dedicated to posting music, video, and photos, it encourages  users to go beyond the blocks of text that are the mainstay of typical  blogging and social websites. Social-networking features such as  following, favoriting, reblogging, and syndication offer ways to give  users the positive feedback that keeps them contributing.</p>  <p>Karp launched Tumblr in early 2007. Two weeks later, the site had  75,000 registered users. So far, it has taken in about $10 million in  venture funding, but it doesn’t need much. “It’s the most  capital-efficient company I’m familiar with,” says Bijan Sabet of Spark  Capital.</p>  <p>Lately, Tumblr has been adding 750,000 users a month, prompting Karp  to try new ways to bring in revenue. He is charging for promotional  spots that let users advertise their blogs and for premium page layouts  to make blogs stand out. And if these strategies don’t work? “I can  always move back in with my parents,” he says. </p></td>
    </tr>
    <tr>
      <td>David Kobia</td>
      <td>Software that helps populations cope with crises.</td>
      <td>32</td>
      <td>Ushahidi</td>
      <td>web-2010</td>
      <td><p>The Ushahidi project brings crowd­sourcing to bear  on some of the most desperate situations people face around the world.  Its downloadable software allows users to submit eyewitness reports  during a conflict or disaster; the collected reports are displayed on a  map. At times when ordinary sources of news and public information are  unavailable, Ushahidi gives users a way to share information and shape  political opinion, guide rescuers, or pool resources. Ushahidi has been  used to monitor elections in Sudan, document violence in Gaza, track the  BP oil slick, and assist earthquake recovery efforts in Haiti. </p>  <p>Ushahidi was born during the riots that followed Kenya’s 2007  presidential election. President Mwai Kibaki had imposed a media  blackout throughout the East African nation, so the Internet provided  the only open channels of mass communication. David Kobia was 8,000  miles away in Birmingham, AL. A Kenyan expatriate who had dropped out of  the University of Alabama at Birmingham to work as a Web developer,  Kobia was frantically trying to moderate an online forum, Mashada, that  had started as a personal project but was becoming a very public arena  for Kenyan politics. Discussions on the site were spiraling into vitriol  and paranoia. A French news agency reporting on Mashada called it  Kenya’s answer to Radio Mille Collines, the infamous Rwandan radio  station that had fueled that country’s genocide in 1994. </p>  <p>“Being mentioned in the same sentence as Radio Mille Collines is akin  to being called a Nazi,” says Kobia, a gentle man with an open face and  an easy smile. Beset by remorse and despair, he pulled the plug on  Mashada, got into his car, and sped up Interstate 20, planning to spend a  somber winter holiday with friends in Atlanta. Somewhere near the  Georgia border, his cell phone rang. An online acquaintance, Erik  Hersman, was calling. Hersman had read a post by a prominent Kenyan  blogger, Ory Okolloh, calling for someone with the know-how to program a  Google map to track the violence and destruction. “Can you put it  together?” Hersman asked. Seeing an opportunity to atone for Mashada,  Kobia turned around and headed back to Birmingham. Two days later,  Ushahidi was up and running.</p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/legacy/dkobia_c_x600.jpg" alt=""><figcaption></figcaption></figure>\n <p><em>Ushahidi map of the disputed Kenyan election in 2007. Credit: Ushahidi</em></p>  <p>That initial version was simple: just a map and a form that let users  describe an incident, select the nearest town, and note the location,  date, and time. Nonetheless, it was enough to attract widespread  attention. “Suddenly my phone was ringing off the hook to do an  interview with BBC News or NPR,” Kobia says. </p>  <p>By now, Ushahidi–the name means “testimony” in Swahili–has played a  central role in coördinating the responses to crises around the globe.  Kobia, with the help of Hersman, Okolloh, program director ­Juliana  Rotich, and a growing number of coders, has continued to develop and  expand the original no-frills online application into a downloadable  open-source platform that includes a time line, an API to develop  applications for mobile devices, an architecture that allows  functionality to be added through software plug-ins, and support for  several mapping protocols. It has been used in more than 30 countries,  mostly by grassroots relief and watchdog organizations, to direct aid  workers to specific locations, document corruption, and track complex  events in space and time. </p>  <p>“Ushahidi is one of the most globally significant technology  projects,” says Ethan Zuckerman, cofounder of the blog network Global  Voices and a senior researcher at Harvard’s Berkman Center for Internet  and Society. “It’s built on open standards and accepts input not only  from the Web but from mobile devices–a critical feature for enabling  global participation. And it evolves with each installation, resulting  in a system that can aggregate, map, and authenticate crowdsourced data  in a very wide range of environments.”</p>  <p><strong>Redemption</strong><br>Kobia grew up in Kenya, the son of a civil engineer and a  schoolteacher. He moved to America to study computer science at the  University of Alabama in 1998. By that time, the dot-com boom was under  way, and Kobia left school to build publishing platforms for Time Inc., <em> Reader’s Digest</em>, and Cygnus Publications and also for sites that  automated processes such as hiring or booking travel. Through those  projects, he gained the deep knowledge of online infrastructure that  made it possible for him to assemble the first version of Ushahidi so  quickly.</p>  <p>Soon after Ushahidi came online, Kobia was contacted by NetSquared, a  nonprofit that promotes the Web as a vehicle for social change. The  organizers invited the Ushahidi team to enter its Mashup Challenge, and  Kobia flew to San Jose, CA. Walking among the gathered Silicon Valley  hipsters, he thought that a group of Africans had little chance. To his  great surprise, Ushahidi won the competition. It was a triumphant moment  for Kobia, who still felt lingering guilt for the Mashada forum. “I  felt drunk with redemption,” he says.</p>  <p>Returning to Birmingham, Kobia wrapped up his business and threw  himself into Ushahidi, funded by $25,000 from NetSquared and a grant  from Humanity United. Later, he secured some $700,000 from  philanthropies including the Cisco, Knight, and MacArthur foundations.  The result is a system that packs tremendous communication power into a  simple user interface. The platform collects incident reports through  e-mail, status updates, and blog posts; reports can include text,  photos, audio, and video. It uses another open-source program,  ­FrontlineSMS, to aggregate text messages, making good use of the cell  phones that are ubiquitous in the developing world even where computers  are rare. </p>  <p>Incoming incident reports queue up on a dashboard screen where  administrators–usually volunteers for organizations that have downloaded  Ushahidi and set it up on a server–can categorize and vet them by  cross-checking against news and other information online. Within minutes  of arrival, messages deemed valid are posted to a public Web page,  where they appear on a map as colored dots that grow as reports from  those locations accumulate.</p>  <p class="head"><strong>Helping Haiti</strong></p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/legacy/dkobia_d_x220.jpg" alt=""><figcaption></figcaption></figure>\n <p>After receiving the NetSquared prize, Ushahidi played a role in  crisis after crisis as tech-savvy grassroots organizations downloaded  the platform. With each implementation, it grew as users requested  features and Kobia and a growing team of developers obliged. The most  challenging test came early this year. On the evening of January 12,  2010, Kobia received an urgent phone call from Patrick Meier, director  of crisis mapping and strategic partnerships at Ushahidi and founder of  the International Network of Crisis Mappers, an Internet-based group  that brings together cartographers, imaging experts, and specialists in  crisis management. He  was looking for ways that digital mapping might  help Haiti cope with the aftermath of the earthquake that had just  struck.</p>  <p>Kobia set up a Ushahidi website for the crisis, and within hours, the  system was fielding reports of human misery on a vast scale–25,000 text  messages and 4,500,000 Twitter posts before the month was out. Working  through the U.S. State Department, he arranged with Haitian  telecommunications companies to supply a four-digit SMS code for  emergency messages. Aid workers in Haiti distributed the number on  printed flyers. </p>  <p>The bulk of incoming incident reports were written in Creole, so  Ushahidi arranged for some 10,000 Haitian expatriates in North America  to serve as translators, first through a custom system and later through  a partnership with the commercial crowdsourcing website ­CrowdFlower.  Meanwhile, Meier organized Tufts University students to log reports  around the clock. First responders, including members of the U.S.  military, used Ushahidi’s map to set priorities, organize, and reach  distressed people.</p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2010/08/WX20210825-194355@2x.png?w=1194" alt="" class="wp-image-1033233"/><figcaption>Ushahidi map of the 2010 Haitian earthquake. </figcaption><div class="image-credit">USHAHIDI</div> </figure> </div> <p>Ushahidi had a decisive impact on the Haitian crisis–and vice versa.  On the one hand, Kobia was thrilled to see the system rise to the  occasion. On the other, the effort almost drove his team into the  ground. “We put in 20-hour days for a month,” he says. “Developers were  getting burned out.” He realized that the organization was failing in  its goal of giving others the ability to use the platform independently.  </p>  <p>Since then, Kobia has focused much of his energy on making Ushahidi  more accessible and easier to operate. For instance, an initiative  called Crowdmap delivers Ushahidi’s functionality directly over the Web,  so local groups don’t have to install it on servers of their own. He’s  also working on a system that uses machine learning and natural-language  processing to evaluate the validity of incoming data.</p>  <p>Some of these efforts might ultimately generate revenue: larger  organizations might pay for Crowdmap’s services or license other parts  of the Ushahidi technology. This is necessary, Kobia says, to insulate  Ushahidi from the whims of charity, about which he is deeply ambivalent.  “In truth, I don’t like nonprofits,” he says. “They’ve never solved any  problems. Instead, they’ve destroyed free enterprise and turned  Africans into beggars. Some of the best programmers in Kenya are working  for nonprofits when they could be creating an economy. Ushahidi’s  challenge is not to get caught in that cycle.”</p>  <p>To that end, Kobia has started an innovation center meant to  galvanize ­Nairobi’s burgeoning high-tech community. “There’s a pool of  mind-blowing talent waiting to be tapped,” he says. “We remind them,  ‘It’s your duty to participate in this community and build your own  businesses.’ ”</p></td>
    </tr>
    <tr>
      <td>Christopher Kruegel</td>
      <td>Developing software that shuts down botnets.</td>
      <td>34</td>
      <td>University of California, Santa Barbara</td>
      <td>web-2010</td>
      <td><p>Botnets–armies of enslaved computers that have been infected with  carefully crafted worms or viruses–are responsible for more than 80  percent of the over 100 billion spam messages e-mailed daily. Antivirus  programs are often ineffective against them, because the software  typically works by scanning a computer for signatures of known  viruses–and the viruses that turn computers into bots are often too new  for these characteristic patterns to have been identified. Christopher  Kruegel, a security researcher in the computer science department at the  University of California, Santa Barbara, has developed technology that  can ferret out an infection even if the virus or worm has no known  signature. In 2009, he cofounded a startup called LastLine to  commercialize the technology.</p>  <p>It works by detecting when a botnet virus is communicating with its  master servers, as it must do to get its commands or to send back  data–say, your passwords and credit card numbers. To identify these  communications amid legitimate network traffic, Kruegel’s research group  analyzed tens of thousands of malware samples per day and teased out  the command-and-control messages common to botnets. </p>  <p>Catching these communications makes it possible to block the master  servers, forcing criminals to move their infrastructure or redirect  their communications. In effect, Kruegel isolates the previously  infected computers, neutralizing the infection even if it hasn’t been  wiped from your hard drive.</p></td>
    </tr>
    <tr>
      <td>Kati London</td>
      <td>Teaching real-world skills through games.</td>
      <td>34</td>
      <td>Area/Code</td>
      <td>web-2010</td>
      <td><p>Kati London is blending the virtual and physical worlds to  entertain–and to shape the real-life behavior of players. London, a  vice president and senior producer at New York-based game company  Area/Code, makes games that incorporate real-world data ranging from the  mundane (the locations of players) to the exotic (signals from tracking  devices attached to sharks in the Pacific). Many of her games are just  for fun, but others are more serious. </p>  <p>For example, the U.K.’s Department for Transport commissioned  Area/Code to make an online game for children aged 9 to 13, the group  most at risk of being killed or seriously injured while crossing the  street. When users reach a road in the fantasy-themed game, they can  cross at designated safe spots and must look both ways for monsters. The  monsters’ behavior reflects that of vehicles; at some crossings, their  speed and number is based directly on traffic data from actual  intersections in the U.K. By replicating the unpredictable variations in  the appearance, speed, and number of vehicles, London believes, the  game teaches skills that children need to handle real traffic. More than  160,000 players have been registered since the game was introduced last  year, and an independent evaluation is due out next spring. </p>  <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2010/08/Picture1.jpg?w=936" alt="" class="wp-image-1033236"/><figcaption>Fail-safe: Schoolchildren playing this game must face monsters when crossing roads; the unpredictable behavior of the monsters is derived from real traffic data.</figcaption></figure></td>
    </tr>
    <tr>
      <td>Avi Muchnick</td>
      <td>Cloud-based multimedia editing software.</td>
      <td>31</td>
      <td>Aviary</td>
      <td>web-2010</td>
      <td><p>“Everyone wants to be an artist,” says Avi Muchnick, sitting amid the  clutter of his startup’s new Manhattan headquarters. Muchnick’s  company, Aviary, makes free Web-based software for creating and editing  images and sounds. Users can do everything from tweaking photographs to  composing complex multitrack musical arrangements. </p>  <p>Aviary’s tools aren’t as powerful as commercial applications like  Adobe Photoshop, an expensive photo editing program that professionals  use. But because all user data is stored on a cloud-computing platform,  users can easily share not just finished works but all the individual  elements that went into a work; if someone creates a graphic of a teacup  for a poster about a public reading of Alice in Wonderland, someone  else can extract that graphic and use it in a logo for a café. Aviary  tracks how and where elements are used, making sure that licenses and  credits are preserved. Ultimately, the company hopes to create a  marketplace where creators can charge royalties for their work, with  Aviary taking a cut. Since the company was founded in 2007, Muchnick has  raised $11 million in venture capital and angel funding from investors  such as Amazon founder Jeff Bezos. </p>  <p><em><br></em></p></td>
    </tr>
    <tr>
      <td>Aaron Dollar</td>
      <td>Creating flexible robotic hands.</td>
      <td>32</td>
      <td>Yale University</td>
      <td>computing-2010</td>
      <td><p>Aaron Dollar, an assistant professor of mechanical engineering at  Yale, has invented a robot with a soft touch. His plastic hand is deft  enough to grasp a wide variety of objects without damaging them. What’s  more, it’s cheaper and requires less processing power than the metal  hands typically used in robots. </p>  <p>Dollar’s design uses plastic fingers that can lightly brush against  an object–whether it’s a wine glass, beach ball, or telephone–before  firming up their grip. Few researchers have used soft plastic in  robotics before, partly because it can be difficult to shape small,  precise parts out of such materials. To get around this problem, Dollar  mills wax molds for each finger. He places sensors and cables in the  molds and then pours in layers of three types of plastic with varying  degrees of softness–for fingers, joints, and finger pads. Once the  plastics harden and are removed from the molds, the fingers are ready to  be hooked up to a base. Dollar’s design has already been licensed to  one robotics manufacturer, and because it replicates the flexibility and  gentleness of a human hand, he is investigating whether it could work  as a prosthetic.</p></td>
    </tr>
    <tr>
      <td>Rikin Gandhi</td>
      <td>Educating farmers through locally produced video.</td>
      <td>29</td>
      <td>Digital Green</td>
      <td>computing-2010</td>
      <td><p>About 600 million people in India depend directly on agriculture for  their livelihood. One of the ways the country’s ministry of agriculture  tries to help them is by broadcasting videos about farming techniques.  In one, for example, officials describe how to plant a fern called  azolla in otherwise unusable wet spots; it can be used to make extra  cattle feed that enables cows to give more milk. But partly because of  cultural and ethnic differences between the ministry workers and the  villagers, the government advice is widely ignored. </p>  <p>Rikin Gandhi, founder of the nonprofit Digital Green, has developed a  pilot project that offers a solution: simple videos starring local  farmers themselves. ­Gandhi demonstrated that for every dollar spent,  the system persuaded seven times as many farmers to adopt new ideas as  an existing program of training and visits.   </p>  <p>Gandhi–who helped launch the program as a 2006 project at Microsoft  Research, India–spent six months testing various video schemes in  villages in the state of Karnataka before concluding that featuring  local farmers was the key. Villagers produce the videos using handheld  camcorders; workers from partner nongovernmental organizations then  check the quality of the videos and the accuracy of the advice before  screening them in the villages with handheld projectors. So far 500  videos have been made, but three times that number–which should reach  four times as many villages–are currently planned. </p></td>
    </tr>
    <tr>
      <td>Kim Hazelwood</td>
      <td>Reëngineering software on the fly.</td>
      <td>34</td>
      <td>University of Virginia</td>
      <td>computing-2010</td>
      <td><p>Imagine having a team of mechanics pull apart and retune your car’s  engine as you hurtle down the highway, without making the engine miss a  stroke. That’s the nature of the challenge that motivates Kim Hazelwood,  an assistant professor of computer science, who has created tools to  rewrite software as a computer is executing it. Before she started  working on the problem in grad school, “I would have said there’s no way  you can just take programs and change them and have every program  work,” says Hazelwood. But industry giants like Intel and researchers  around the world have used her subsequent achievements to do just that. </p>  <p>Hazelwood’s approach contradicts one of the most important notions in  computer programming–abstraction. Abstraction means that software is  built in layers: an application runs on top of an operating system,  which runs on top of the hardware. Each layer does its best to conceal  its inner workings. That way, someone writing, say, a Web browser  doesn’t have to know all the engineering that went into a processor. At  times, however, it would be useful for the application and hardware  layers to communicate more directly. For example, some modern processors  reduce electricity consumption by turning off portions of the chip  until they are needed, but an application that causes this to happen  excessively can shorten the life of the chip. Hazelwood’s software can  monitor the processor and detect when subsystems are being turned off  and on too often. It then analyzes the software instructions that are  triggering the problem and substitutes more hardware-friendly commands  that do the same job. </p>  <p>The ability to monitor and modify applications while they’re running  could be widely useful. For example, it could make it easier to  compensate for hardware bugs, divide tasks among multiple processors,  run software on different processor architectures, and even defend  against malicious software.<em> </em></p></td>
    </tr>
    <tr>
      <td>Indrani Medhi</td>
      <td>Building interfaces for the illiterate.</td>
      <td>32</td>
      <td>Microsoft Research India</td>
      <td>computing-2010</td>
      <td><p>Information is at the fingertips of anyone with access to a laptop or  smart phone. But what if the user is one of the 774 million adults  worldwide who cannot read? This is the problem that obsesses Indrani  Medhi. Based at Microsoft Research India’s Bangalore lab, she has  conducted field research in India, South Africa, and the Philippines to  design text-free interfaces that could help illiterate and semiliterate  people find jobs, get medical information, and use cell-phone-based  banking services.</p>  <p>Meaningful computer icons are rarely the same from one culture to  another, Medhi says, so she used symbols, audio cues, and cartoons that  are specific to particular poor communities. But then she encountered  another hurdle. Even when users became familiar with the hardware and  the interfaces, Medhi realized, they still did not fully understand how  information relevant to their lives could possibly be contained in or  delivered by a computer. </p>  <p>The key to overcoming this problem, she discovered, is to offer a  five-minute video dramatization when an application is launched,  illustrating exactly how it is supposed to work. For example, the one  that accompanies her job-search interface features an upper-middle-class  couple that needs a domestic helper. The husband posts the requirements  to a job website that is subsequently accessed by unemployed and  illiterate women at a community center. The video ends with a woman  being hired. </p></td>
    </tr>
    <tr>
      <td>Andrey Rybalchenko</td>
      <td>Stopping software from getting stuck in loops.</td>
      <td>32</td>
      <td>Technical University of Munich</td>
      <td>computing-2010</td>
      <td><p>Computer scientist Andrey Rybalchenko has developed a new method for  finding software bugs. Traditional automated testing systems detect when  programs do “bad things” that lead to crashes, forcing the program to  quit. By focusing on crashes, however, such testing often misses a  significant class of bugs–those that allow the software to keep running  but leave it unable to accept new input or do anything useful. In  essence, Rybalchenko instead tries to identify when a program is doing  “good things,” such as making progress through loops or responding to  other programs.</p>  <p>In a collaboration with Microsoft that began in 2006, Rybalchenko  incorporated his methods into Terminator, a commercial program used to  find bugs in the device drivers that mediate between an operating system  and various pieces of hardware. Countless device drivers have been  created by third-party developers, and they are often responsible for  software failures that users blame on the OS. So detecting these bugs  improves both actual and perceived OS reliability.</p>  <p>Rybalchenko is currently seeking ways to detect similar bugs that can  appear when many processors work simultaneously on the same task but  fail to coördinate properly and begin competing instead. Now that  processor speed has plateaued at a little over three gigahertz, this  kind of problem will become more and more significant as manufacturers  turn to multicore systems to continue improving performance.<em> ​</em></p></td>
    </tr>
    <tr>
      <td>T. Scott Saponas</td>
      <td>Detecting complex gestures with an armband interface.</td>
      <td>29</td>
      <td>Microsoft Research</td>
      <td>computing-2010</td>
      <td><p>Fingers flicking through the air, T. Scott Saponas is rocking a  solo in the video game Guitar Hero–without a guitar. A soft band  around his forearm monitors the muscles moving his fingers and hand. The  band hides a ring of six electrodes that pick up the weak electrical  signals produced by active muscle tissue. The signals are relayed to a  computer, which in turn controls the game.</p>  <p>Most previous work on muscle interfaces has focused on controlling  broad movements of prosthetic limbs by detecting the activity of  individual muscles. To recognize more detailed gestures, Saponas  developed software capable of processing the jumble of signals from the  mass of muscles in the arm. The system has potential for more than just  video games. A jogger using Saponas’s armband could tense his or her  hand muscles to switch tracks on an MP3 player without breaking stride,  or a mechanic whose hands were busy inside an engine could use it to  control a heads-up display.</p>  <p>Saponas created the software as a graduate student at the University  of Washington. Now working at Microsoft Research, he is interested in  combining the muscle interface with other sensors, including  accelerometers and gyroscopes, to provide additional precision. </p></td>
    </tr>
    <tr>
      <td>Jian Sun</td>
      <td>Better image searches.</td>
      <td>33</td>
      <td>Microsoft Research Asia</td>
      <td>computing-2010</td>
      <td><p>Problem: Images are hard for search engines to index because  computers find it difficult to identify their content. Algorithms called  classifiers can sort images using statistical techniques, but that  presents something of a chicken-and-egg problem: ideally, “you need  millions of [classified] images to train a classifier,” says Jian Sun, a  researcher at Microsoft Research Asia in Beijing.</p>  <p>Solution: Sun developed a way to make it easy for humans to train  computers in picture classification. With his system, which was recently  incorporated into Microsoft’s Bing Images search engine, users enter a  search term–say, “cloudy sky.” Using its existing classification  algorithm, Bing makes its best attempt to present a grid of images that  match the search term. The user can click on a nearly right image and  ask to see similar pictures, repeating the process until the perfect  image appears. As the user refines the search, each click is fed back  into the classifier. This means the next time a user searches for  “cloudy sky,” Bing will immediately present a more relevant set of  images than before. The system is also being used to help other  researchers develop image search algorithms; incorporating results from  Bing, Sun has released a training database containing 100,000  categorized images. </p>  <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2010/08/Picture1-2.jpg?w=728" alt="Jian Sun" class="wp-image-1033260"/><figcaption>Learning machine: Bing lets users refine search results (top), producing  images that better match a search term (middle). New searches will then  produce better initial results (bottom).</figcaption></figure></td>
    </tr>
    <tr>
      <td>Richard Tibbetts</td>
      <td>Reacting to large amounts of data in real time.</td>
      <td>30</td>
      <td>StreamBase Systems</td>
      <td>computing-2010</td>
      <td><p>Organizations such as businesses and governments are increasingly  obsessed with gathering data, but the results often overwhelm them when  they need to act quickly. Richard Tibbetts, CTO of StreamBase Systems in  Lexington, MA, has developed a data processing system that can accept  large amounts of rapidly changing input and distill it into the  information that organizations feel they need to make sound decisions.</p>  <p>Traditionally, organizations have turned to databases to store and  manipulate large amounts of information. Typically, however, these  databases aren’t good at processing data in real time; uers have to  wait until an entire data set has been accumulated. But Tibbetts has  invented a new set of techniques for managing data. In particular, he  invented a language called StreamSQL EventFlow, which can process a  stream of data as it arrives, analyze it, make decisions about it, and  take actions such as trading a stock or flagging a trend. </p>  <p>StreamBase counts government agencies, investment banks, and hedge  funds among its clients. The technology has been used to monitor  activity on battlefields as combat unfolds and to help businesses react  as stock market conditions change.</p></td>
    </tr>
    <tr>
      <td>Ranveer Chandra</td>
      <td>Delivering high-speed wireless Internet connections over longer distances.</td>
      <td>34</td>
      <td>Microsoft Research</td>
      <td>communications-2010</td>
      <td><p>PROBLEM: Wi-Fi uses frequencies that can’t carry a signal more than a  few tens of meters. TV stations, on the other hand, use a portion of  the radio spectrum that lets signals travel long distances, and the end  of analog television has opened up unused slices of the spectrum between  stations. They could be used for wireless Internet service, but it has  been difficult to take advantage of these so-called white spaces without  causing interference, because the exact frequencies used by TV stations  vary geographically.</p>  <p>SOLUTION: Ranveer Chandra made the Microsoft campus in Redmond, WA,  his laboratory for the first large-scale network to demonstrate the  potential of using white spaces to deliver broadband wireless. Links in  the prototype network can span up to two kilometers. To avoid treading  on the toes of TV broadcasters, his system uses GPS to determine its  location; then it checks the Web to find out what stations are active in  the area. Chandra’s devices can also listen for nearby transmissions  from wireless microphones, which use the same bands. When a conflict is  detected, they switch to a backup slice of unused spectrum on the fly. </p>  <p>If such a system gains currency, “all of us should be connected and  better connected, and not just here in the U.S.,” says Chandra. Spectrum  regulators from Singapore, India, Brazil, and China have all come to  visit his prototype network to explore the potential for white-space  signals to connect large rural areas with minimal infrastructure. </p>  <p><em><br></em></p></td>
    </tr>
    <tr>
      <td>Gabriel Charlet</td>
      <td>Record-breaking optical fibers for global communications.</td>
      <td>34</td>
      <td>Alcatel-Lucent</td>
      <td>communications-2010</td>
      <td><p>The 2,000 kilometers of fiber-optic cable stacked in Gabriel  Charlet’s lab in the Alcatel-Lucent Bell research facility in Nozay,  France, are a reminder of a record-breaking achievement: in 2009 Charlet  smashed the world high-speed long-­distance record for fiber-optic  communications, reaching a transmission rate of 7.2 terabits per second  over a single fiber 7,040 kilometers long. That’s around five times as  fast as existing commercial systems–the equivalent of transmitting more  than 6,000 movie-length DVDs in a minute. </p>  <p>Charlet reinvigorated a field. The data-carrying capacity of the  cables that form the backbone of the global telecommunications network  had improved little in recent years: as other researchers tried to boost  transmission rates, microscopic imperfections in the cables introduced  distortions that could not be compensated for. These researchers were  encoding digital data by varying the intensity of a pulse of light. For  example, high intensity would represent a <em>1</em> and low intensity would  represent a <em>0</em>. At high data rates over long distances, the imperfections  blurred the distinction between intensity levels, meaning that at  distances over 7,000 kilometers, around 1.2 terabits per second was the  limit of reliable communication.</p>  <p>To solve the problem, Charlet perfected a system that uses the  polarization and phase of a pulse of light, rather than its intensity,  to encode data. Errors induced by imperfections are far less problematic  thanks to the development of a new receiver that detects the whole  electrical field of the signal, rather than just its intensity. As a  bonus, each pulse of light can now encode four bits of data instead of  just one, because different polarizations can be used to indicate  different bit values. </p>  <p>Drawing on Charlet’s research, Alcatel-­Lucent recently launched a  new generation of commercial equipment that transmits data at 3.2  terabits per second over distances of up to 7,000 kilometers (the speeds  are slower than Charlet’s record because of the limitations of current  chip designs; the next generation will use specially made chips). The  next time you watch a video on YouTube, it may have been piped to you  with Charlet’s help. </p></td>
    </tr>
    <tr>
      <td>Amir Alexander Hasson</td>
      <td>Using cell phones to supply rural shop owners.</td>
      <td>34</td>
      <td>United Villages</td>
      <td>communications-2010</td>
      <td><p>Many shop owners in Indian villages are beyond the reach of  major distributors. Some goods are sold to them by local producers, but  owners “have to leave their shops four times a month to get 81 percent  of the stuff that they sell,” says Amir Alexander Hasson. Having to  travel to restock doesn’t just affect shop owners; villagers end up  paying higher prices for a smaller selection of goods. Since founding  United Villages in 2004, Hasson has been using wireless technologies to  help solve this and other problems facing the rural poor in developing  nations. </p>  <p>Hasson started out with a system that helped people in isolated  communities send and receive e-mail and search for jobs. Wi-Fi routers  were attached to buses; when a bus drove into a village, its router  connected with computers set up at local kiosks. Now Hasson is taking  advantage of the rapid expansion of cell-phone networks to set up a  for-profit wholesale service called E-Shop. Shop owners with phones that  run Java applications can browse an online catalogue and place orders;  data is transferred between the phones and United Villages using SMS  text messages. This method is cheap and doesn’t require powerful smart  phones. In about 36 hours, the goods are delivered directly to the shop.  </p>  <p>Hasson is planning to introduce another use of E-Shop, as a way for  people to post advertisements through a local store owner. “For [50  cents], someone can post his motorbike for sale,” says Hasson, “It will  be India’s first mobile-based classifieds.” <em><br></em></p></td>
    </tr>
    <tr>
      <td>Michael Backes</td>
      <td>Proving that Internet security protocols can really be trusted.</td>
      <td>31</td>
      <td>Saarland University</td>
      <td>web-2009</td>
      <td><p><strong>Problem: </strong>To help protect Internet users’ privacy, cryptographers have developed zero-knowledge proofs, which allow users to demonstrate that they know, say, a password or bank-account number without actually revealing what it is. IBM, Intel, and Hewlett-­Packard have used these proofs as the basis for a new Internet security protocol, similar to the Secure Sockets Layer that protects e-commerce transactions. But while the proofs themselves are secure, it’s hard to be sure that the protocols based on them are free of glitches that could allow them to be hacked.</p>  <p><strong>Solution:</strong> Software designed by Michael Backes, a professor in the information security and cryptography group at Saarlan­d University in Saarbrücken, G­ermany, can prove in less than a second whether an Internet protocol is truly secure. The program, the first one that’s been able to test protocols based on zero-­knowledge proofs, creates simplified mathematical representations of the proofs and evaluates how they work within the protocol. The result is that it can efficiently check to see whether individual instructions in a protocol might let an interloper into the system. </p></td>
    </tr>
    <tr>
      <td>Jeffrey Bigham</td>
      <td>Free service to help blind people navigate the Web.</td>
      <td>28</td>
      <td>University of Rochester</td>
      <td>web-2009</td>
      <td><p><strong>Problem: </strong>More than 38 million people worldwide have low or no vision. To use the Web, many use screen readers, which speak on-screen text aloud. But this software is expensive and is rarely installed on public computers in libraries or cybercafés; in such places, simple tasks such as confirming flight information or checking e-mail can be impossible for blind users. </p>  <p><strong>Solution:</strong> As a graduate student at the University of Washington, Jeffrey Bigham created Web­Anywhere, a free screen reader that can be used with practically any Web browser on any operating system–no special software required. Users start at webanywhere.cs.washington.edu; from there, they can use keyboard commands to navigate to any Web page. While other screen readers synthesize speech from text locally, WebAnywhere fetches speech from a central server and sends the audio to the user’s computer. “The potential is there for big lag times between when the user presses a button and gets speech back,” says Bigham, now an assistant professor in computer science at the University of Rochester. “Pretty much everyone thought that this latency problem would kill us.” To speed things up, he created a model that predict­s which parts of a page a user is most likely to interact with, such as links, and preëmptively fetches audio describing that content. The result is that WebAnywhere sends synthesized speech to users within a fraction of a second. <em>–Stephen Cass</em></p></td>
    </tr>
    <tr>
      <td>Jeffrey Heer</td>
      <td>Easy-to-use tools allow people to present data in creative and interesting ways.</td>
      <td>30</td>
      <td>Stanford University</td>
      <td>web-2009</td>
      <td><p>Lists of numbers often don’t mean as much as charts, graphs, and interactive graphics that can reveal unexpected trends. To help people make them, Jeff Heer, an assistant professor of computer science, led a project that created easy-to-use open-source visualization software called Protovis.</p>  <p>Programs like Microsoft’s Excel make it simple to turn data into charts, but they provide few options. Powerful analytical programming languages can do more but are complicated to use. Protovis lets people who have only token programming skills concentrate on the design of a visualization rather than worrying about how to structure complex computer code. The software provides chunks of code that correspond to different aspects of visual information display, such as shapes and colors; users string these chunks together to c­reate a complete graphic. People can also easil­y integrate the visualizations into Web pages to facilitate sharing and discussion. Protovis currently runs in Web browsers such as F­irefox, Chrome, and Safari. Heer is working on tools that make it easier to create inter­active and animated graphics. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1.jpg?w=936" alt="" class="wp-image-1033279"/><figcaption>Easy Imagery: Jeff Heer's tools enable people with minimal programming experience to generate intricate and informative data visualizations, like this re-creation of a chart originally published in 1951 to show the effectiveness of three antibiotics.</figcaption><div class="image-credit">JEFFREY HEER</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Vik Singh</td>
      <td>Opening up search secrets to spur innovation.</td>
      <td>24</td>
      <td>Yahoo</td>
      <td>web-2009</td>
      <td><p>Beginning in 2005, Web programmers were able to incorporate results from Yahoo’s search engine into their own services, but could do very little with those links: they were limited to 5,000 search queries per day, and they weren’t allowed to change how results were ranked or blend their own site’s content into the rankings. Then Vik Singh, only seven months out of college and five months into his first job, talked the company into giving away not just the search results but much of the data essential to its relevance formula, such as any tags that identify place names or people. His efforts led to the creation of BOSS (for “Build your Own Search Service”), an application programming interface that lets developers take Yahoo search results and manipulate them to provide services tailored to users’ needs, in some cases by considering personal data that a website has collected.</p>  <p>For instance, Singh says, typing <em>jobs</em> into Yahoo gives a user links to job-search websites such as Monster.com. But a social-networkin­g site could use BOSS to design a search that considered a user’s hometown and current job, or even where his or her friends work. </p>  <p>More than 1,000 developers (of websites, e-mail clients, and mobile-phone applications) have begun using BOSS since its launch in July 2008. The Japanese company Spysee, for example, has built a search engine that finds connections between people, such as common interests or mutual friends, using data it gleans from Yahoo. Such new, smaller search services, Singh says, will create more competition for Yahoo’s main rivals, Google and Microsoft, in a market that’s otherwise hard to break into. With new services piggybacking on its platform, Yahoo figures it can glean a bigger share of search traffic. That, in turn, will yield data that will help it improve its core search engine. New sites may also mean new revenue for Yahoo, whether from small fees charged for every query or income shared from search-related advertising. Either way, Yahoo expects to improve its own standing by letting other software developers share its wealth of knowledge. </p>  <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-1.jpg?w=936" alt="" class="wp-image-1033282"/></figure></td>
    </tr>
    <tr>
      <td>Jaime Teevan</td>
      <td>Using personal information to improve search results.</td>
      <td>32</td>
      <td>Microsoft Research</td>
      <td>web-2009</td>
      <td><p>In 1997, when search engines were relatively new, Jaime Teevan took an internship at Infoseek the summer before her senior year at Yale. William Chang, the chief technology officer, put her in a room with some research and told her to “find something fun to do.” She came up with some ideas for judging link quality and helping people navigate the company’s search engine, and she wrote the code to implement the changes. “Once, I brought the search engine down for a couple of hours,” she says with a laugh.</p>  <p>But she also discovered a career path. Today, the Microsoft researcher is a leader in using data about people’s knowledge, preferences, and habits to help them manage information. She studies the ways people navigate the flood of information available in the digital age and builds tools to help them handle it.</p>  <p>By now, personal information management has become an Internet buzzword. But Teevan pioneered the field as a graduate student working with David Karger, a professor in MIT’s Computer Science and Artificial Intelligence Laboratory. “She literally almost single-handed­ly created this whole area,” says Eric Horvitz, a principal researcher who manages teams pursuing advances in search and retrieval at Microsoft Research. </p>  <p>She began by studying how people search the Internet. They use such different strategies, she found, that a one-size-fits-all search engine can never satisfy everyone. So Teevan started building tools that sort Internet search results according to a user’s personal data, previous searches, and browsing history. </p>  <p>One of her first tools was a search engine called Re:Search. Early on, Teevan discovered that people are often looking for information they’ve already found before; more than half of all Web-page visits and a third of all search queries are repeats. But since the Web is always changing, people often have a hard time finding a site again. Re:Search relies on information from a user’s past searches to determine which items are more relevant to him or her. Teevan found that people tend to remember the first item in a list of previous search results, as well as items they clicked on; they also tend to get confused if the results they clicked on have changed position in the list. So she designed Re:Search to keep clicked links in their previous positions and insert new links in positions where they will be noticed without being confusing or distracting.  </p>  <p>One of Teevan’s key ideas is that search engines can employ information about users to help them zero in on the results they need. Since she joined Microsoft Research in 2006, she’s developed a number of experimental browser plug-ins that work with Internet Explorer and that will refine search results for each user. One, called PSearch, uses an index of documents, e-mails, and other material on the user’s hard drive to customize the results delivered by an Internet search engine. For instance, if she types her husband’s last name into a typical search engine, the top hits are for a financial-services firm that shares his name. When she turns PSearch on, the first sites listed relate to her husband. </p>  <p>Horvitz says that Psearch has been piloted internally at Microsoft for a number of years and has proven very promising. “What I like best is that all the personalization is going on on your desktop,” he says. In fact, PSearch never shares a user’s personal information with the search engine–the results are re-sorted after they’re delivered to the user’s computer. </p>  <p>Teevan’s programs have yet to be released commercially, and because search is such a competitive area for Microsoft, both she and Horvitz declined to discuss any such plans. But both eagerly talk about her contributions to Microsoft’s new search engine, Bing. Teeva­n says she met regularly with Bing’s developers to help them understand how people search and how that knowledge might be used to improve search results. Horvitz points more directly to the left-hand column of the Bing search results page, where a short list titled “Search History” appears. “You see just the tip of the iceberg right now in the current Bing search.” Teevan’s work is actually more advanced, Horvitz says. Hinting at things to come, he adds, “You might watch that corner of Bing over time.”</p></td>
    </tr>
    <tr>
      <td>Andrea Armani</td>
      <td>Sensitive optical sensors detect single molecules.</td>
      <td>31</td>
      <td>University of Southern California</td>
      <td>computing-2009</td>
      <td><p>Andrea Armani, an assistant professor of chemical engineerin­g and materials science, has developed the first optical sensor that can detect single molecules without the use of labels such as fluorescent tags. No label-free detector previously developed has been sensitive enough to distinguish a single molecule. </p>  <p>Armani’s sensor consists of a microscopic silica ring that sits on a pedestal atop a silicon wafer. “It’s this little, tiny doughnut-shaped device,” she says. The ring captures photons from a laser and holds them in orbit. Its surface is chemically treated to snag molecules of the target substance from the surrounding environment. As soon as even one molecule of the compound is ensnared, it creates a detectable change in the ring’s optical properties.</p>  <p>Because it works in liquids, including blood, the sensor could be an ideal diagnostic device. Armani envisions, for instance, incorporating one into intravenous catheters that would monitor a patient for infection, picking up telltale molecules in minuscule quantities long before symptoms appeared. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-7.jpg?w=936" alt="" class="wp-image-1033306"/><figcaption>Zeroing in: A tiny doughnut-shaped silica ring atop a silicon wafer acts as an extremely sensitive optical sensor. The ring's optical properties change when even a single molecule binds to it.</figcaption><div class="image-credit">ANDREA ARMANI</div> </figure> </div></td>
    </tr>
    <tr>
      <td>James Carey</td>
      <td>Using “black silicon” to build inexpensive, super-sensitive light detectors.</td>
      <td>32</td>
      <td>SiOnyx</td>
      <td>computing-2009</td>
      <td><p><strong>Problem:</strong> Silicon has limitations as an optical material. While devices from digital cameras to x-ray detectors take advantage of its ability to absorb electromagnetic radiation, longer wavelengths of light fly right through it. If engineers could make silicon light detectors that “see” more thoroughly into the visible and infrared spectra, relatively inexpensive silicon could replace the costlier, more exotic materials often used in optoelectronics.</p>  <p><strong>Solution: </strong>As a graduate student at Harvard, James Carey made thin, super-sensitive light detectors out of “black silicon”–a material discovered accidentally when his colleagues fired a laser at a silicon wafer in the presence of a sulfur-containing gas. Carey demonstrated that the process did more than turn silicon black: it also gave the material the ability to absorb the longer wavelengths of visible and infrared light that thin layers of traditional silicon can’t. What’s more, it absorbed every wavelength more efficiently than conventional silicon does. </p>  <p>Carey cofounded SiOnyx in Beverl­y, MA, to manufacture black-silicon chips for devices such as inexpensive night-vision equipment and infrared surveillance systems. Other potential applications include better cell-phone cameras and cheaper, more sensitive detectors that could lower the x-ray dose needed for advanced medical imaging. </p></td>
    </tr>
    <tr>
      <td>Adam Dunkels</td>
      <td>Minimal wireless-networking protocols allow almost any device to communicate over the Internet.</td>
      <td>31</td>
      <td>Swedish Institute of Computer Science</td>
      <td>computing-2009</td>
      <td><p>Adam Dunkels, a senior scientist at the Swedish Institute of Computer Science, has developed software that’s used to network devices as diverse as satellites, pipelines, electric meters, and race-car engines. Such devices often incorporate tiny computers that need to relay data to a central server. Using the Internet Protocol (IP) would allow them to communicate with any other device or computer by means of existing infrastructure. But until Dunkels proved otherwise, many computer scientists believed that these “embedded systems” had too little memory and power to use IP. </p>  <p>In 2000, Dunkels shrank the protocol so that wireless sensors could use it to report hockey players’ vital signs to fans. He continued condensing it so that ever more limited sensors could use it, eventually writing a version that uses only 100 bytes of RAM. This miniature version of IP is now used by hundreds of companies.</p>  <p>He went on to incorporate it into a complete operating system for embedded systems; called Contik­i, the freely downloadable open-source system was first released in 2003. Dunkels is still improving Contiki and finding new ways of using it to build and enhance wireless sensor networks. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-4.jpg?w=936" alt="" class="wp-image-1033293"/><figcaption>Trucks: Embedded sensors send the home station information about fuel consumption compared with distance traveled. Cameras: Networking software allows the user to send pictures directly from the camera over an Ethernet or Wi-Fi connection, and to configure the camera from the Internet. Planes: Sensors send data from various noncritical systems to the pilot's display screen. Oil Pipelines: Oil companies use Dunkels's software to receive automatic messages from remote pipelines alerting them to irregularities. Home Heating: Embedded systems enable radiators to communicate with a central controller so that a building can be heated more efficiently.</figcaption><div class="image-credit">JULIAN PACAUD</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Kevin Fu</td>
      <td>Defeating would-be hackers of radio frequency chips in objects from credit cards to pacemakers.</td>
      <td>33</td>
      <td>University of Massachusetts, Amherst</td>
      <td>computing-2009</td>
      <td><p>Could implanted medical devices that use wireless communication, such as pacemakers, be maliciously hacked to threaten patients’ lives? Kevin Fu is no stranger to such overblown scenarios based on his research, though he prefers to stick to talking about technical details. But Fu, a software engineer and assistant professor of computer science, is a security guy. And security people think differently. </p>  <p>“Anyone who works in the world of security–they always have an adversary in mind,” Fu explains, sitting behind his desk on the second floor of the UMass Amherst c­omputer science building. “That’s how you can best design your systems to defend against it.”</p>  <p>The threats Fu researches are chiefly those connected to the security of radio ­frequency identification, or RFID. RFID is an increasingly common technology, used in everything from tags for shipping containers to electronic key cards, from Exxon­Mobil’s Speedpass key-chain wands to Chase’s no-swipe “Blink” credit cards. It allows billing and personal information to be shared quickly and wirelessly. But not, Fu realized back in 2006, very securely.</p>  <p>After testing more than 20 such “smart” or no-swipe credit cards from MasterCard, Visa, and American Express, Fu and his colleagues found that they could lift account numbers and expiration dates from several of the cards–even cards inside a wallet–just by walking past them with a homemade scanner. </p>  <p>Criminals troll mailboxes, shopping malls, and airports, harvesting nearby RFID information for use in identity-theft scams. Basically, they pick your pocket without ever touching your pocket. Making these cards truly secure would require good encryption software–Fu’s specialty. But encryption requires a steady supply of energy, something that the passive, externally powered RFID chips used in these applications don’t have. “The inspiration was about the programming,” Fu explains. “But the programming won’t work without an RFID computer to program. And the RFID computer won’t work without solving the energy issues.” He breaks a weary smile. “So, thus far, it’s been something like a two-year sideline.”</p>  <p>The only way for Fu to resolve this catch-22 is to invent new technology–a project he’s working on with a team led by Wayne Burleson, a professor of electrical and computer engineering. But even as he wrestled with this problem, Fu found himself wondering, as only a security guy can: if financial information is vulnerable, what about seemingly more obscure targets with far bigger consequences?</p>  <p>This is what first brought him to the heart-attack machine.</p>  <p>At his desk, Fu clicks through a ­Power­Point slide show of bad-guy examples, from the madman who put cyanide-laced Tyleno­l on Chicago drugstore shelves in 1982 to the hacker who posted seizure-inducing animations on an Internet message board for epileptics. </p>  <p>“It might seem paranoid,” Fu admits, “but from a security standpoint, you need to start with the fact that bad people do exist.” And there seemed no better place to hunt such misanthropes than the world of medicine. </p>  <p>Fu began wondering about the security of medical devices that use RF communication, such as pacemakers and defibrillators. He discussed the problem with his longtime colleague Tadayoshi Kohno, assistant professor of computer science and engineering at the University of Washington and a veteran investigator into the vulnerabilities of computer networks and voting machines (<em>see <a href="http://www.technologyreview.com/tr35/index.aspx?year=2007" target="_blank" rel="noopener noreferrer">TR35, September/October 2007</a></em>). </p>  <p>$$PAGE$$</p>  <p>“Kevin is a fantastic researcher,” Kohno says. “His research is now covered in almost every undergraduate computer-security course that I know of. And his insights are exceptionally deep.” Together, Fu and Kohno took their questions about de­fibrillators far from the computer ­science lab–into the world of cardiologist William H. Maisel, director of the Medical Device Safety Institute at Boston’s Beth Israel Deaconess Medical Center. </p>  <p>The two explained to Maisel’s wide-eyed staff how security people think. In turn, the medical professionals introduced the security researchers to Cardiology 101–starting with pacemakers and defibrillators, devices that are implanted in some half-million people around the world every year. Basically, a pacemaker regulates aberrant heartbeats with gentle metronomic pulses of electricity, while a defibrillator provides a big shock to “reboot” a failing heart. Merged, they form an implantable cardioverter defibrillator, or ICD. The ICD is designed to stop a heart attack in a cardiac patient. But, Fu and Kohno wondered, could it create one instead?</p>  <p>In his UMass office, Fu pulls out a shoebox containing the works of an ICD. It looks the way the Tin Man’s heart might: padlock-sized and encased in hard, silvery surgical steel, now peeled away can opener-style. I instinctively reach in, drawn like a magpie to the shiny objects. Fu quickly jerks the box away. “Um, you don’t want to touch that,” he says. “The coil in these things delivers 700 volts”–enough juice to stop your heart.</p>  <p>He points out the matchbook-sized microchip and antenna coil–technolog­y that connects the latest-generation ICDs with the Internet, allowing doctors to re­program a device without surgery. From the perspective of cardiologists and patients, this wireless programming is a godsend. But from Fu’s viewpoint, it represents a new security risk. And so he wondered: Could black-hat hackers listen in on the wireless communication between an ICD and its programming computer? Could they make sense of what they heard and use it to inflict harm? </p>  <p>“Most people who make these devices don’t think like this,” Fu says. “But this is how the adversary thinks. He doesn’t play your game; he makes his own game.” To assess the security threat, the researchers needed to play the hacker’s game. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-10.jpg?w=936" alt="Kevin Fu" class="wp-image-1033319"/><figcaption>Catching bugs: By exposing ways for wireless devices to be hacked, Fu has alerted manufacturers to the potential dangers that their customers face. He found that implanted cardiac devices are particularly vulnerable.</figcaption><div class="image-credit">STEVE MOORS</div> </figure> </div> <p>Fu’s team set out to create a technique to eavesdrop on defibrillator chatter. The hardware was just off-the-shelf stuff–a platform designed to allow researchers and serious hobbyists to build their own software radios. It has been made into FM radios, GPS receivers, digital te­levision decoders–and RFID readers. All that was left was to write the software, rip the antenna coil out of an old pacemaker, solder it into the radio–and voilà, they had a transmitter. </p>  <p>“It worked pretty well–amazingly well,” Fu says. After “nine months of blood and sweat,” they could intercept digital bits from an ICD–but they had no idea what those bits meant. His students trudged back to the lab to figure out how to interpret them. Using differential analysis–basically, changing one letter of a patient’s name and then listening to how the corresponding radio transmission changed–they were able to painstakingly build up a code book. </p>  <p>Now their homemade software radio could listen in on and record ICD programming commands. The device could also rebroadcast those recordings, as fresh commands, to any nearby ICD. It had become dangerously capable of playing doctor.</p>  <p>Fu discovered one set of commands that would keep an ICD in a constant “awake” state, surreptitiously draining the battery to devastating effect. “We did a back-of-the-envelope calculation on this,” he explains. “A battery designed to last a couple years could be drained in a couple weeks. That alone was a notable risk.” </p>  <p>$$PAGE$$</p>  <p>Even more notable, Fu’s software radio was capable of completely reprogramming a patient’s ICD while it was in his or her body. The researchers were able to instruct the device not to respond to a cardiac event, such as an abnormal heart rhythm or a heart attack. They also found a way to instruct the defibrillator to initiate its test sequence–effectively delivering 700 volts to the heart–whenever they wanted. </p>  <p>Fu doesn’t like to think of himself as h­aving built a heart-attack machine, or even of discovering that such a thing could be built. Though he is an academic who doesn’t shy away from pursuing real-world applications for his theoretical technologies, that “real world” is usually at least 10 years in the future. But the ramifications of the ICD-programming radio were both immediate and chilling: the device could be easily miniaturized to the size of an iPhone and carried through a crowded mall or subway, sending its heart-attack command to random victims. </p>  <p>A heart-attack machine? Really? It would be foolish, Fu says, not to recognize that there are depraved people out there, more than capable of building and using such a machine to inflict harm on random innocents “just for kicks.” To this extent, the issue of protecting remote programming access to ICDs is directly related to the issue of protecting RFIDs. Encrypting the communication is the only way to shield millions of people from random risks. It doesn’t take a Fu to come up with practical solutions, but by exposing the security dangers he has provided a valuable, perhaps even life-saving, alert to manufacturers. </p>  <p>Fu is too smart to engage in speculation about how the technology could be abused, except to say that he’d be very surprised if there weren’t “people already working on this.” In the best case, we’ll never know how foresighted he was; medical-device maker­s will eliminate the threat before hackers ever exploit it. “Kevin is a computer scientist who also has the ability to look at problems like a medical doctor and like a patient,” says Maisel. “The work Kevin is doing now–relating to medical-device security and privacy–has the potential to impact millions of people.”</p>  <p>How about the more dramatic scenario­s? Imagine a spy agency using printed circuitry to put a heart-attack machine into a news­paper, delivered with morning coffee to a foreign leader with a pacemaker. Or a Lex Luthor-like supervillain who retrofits a radio tower to broadcast his death ray to entire populations.</p>  <p>Kevin Fu–professor, researcher, scientist–rolls his eyes. “All I can say about that one,” he says with a laugh, “is it might make a pretty good movie.” </p></td>
    </tr>
    <tr>
      <td>Andrew Houck</td>
      <td>Preserving information for practical quantum computing.</td>
      <td>30</td>
      <td>Princeton University</td>
      <td>computing-2009</td>
      <td><p>Among the most promising approaches to building a quantum computer is using superconducting circuits as quantum bits, or qubits. But controlling the qubit without destroying the information tucked inside it is a major challenge. </p>  <p>Andrew Houck, an assistant professor of electrical engineering, developed a superconducting qubit called a transmon that helps keep quantum information intact.</p>  <p>The data in a qubit–<em>0</em>, <em>1</em>, or a quantum superposition of the two–is represented using different energy and phase states in the circuit, but stray electrical fields can easily destroy these states during readout. Instead of targeting the source of interference, as other researchers have, Houck armored the qubit, adding a capacitor that makes it difficult for stray electrons to interfere. </p>  <p>Getting data from the transmon is the next hurdle. Usually the qubit is read directly, by measuring changes in charge, but that’s not possible with the transmon. So Houck coupled it to a microwave photon, which interacts differently with the qubit depending on its state. By measuring the photon, it’s possible to infer the qubit’s state and thus extract its information.</p>  <p>While the quantum data in transmons lasts a few microseconds–an order of magnitude longer than in previous qubits–there’s still a way to go before millions of qubits can be used to make a large-scale quantum computer.<em>  </em></p></td>
    </tr>
    <tr>
      <td>Shahram Izadi</td>
      <td>An intuitive 3-D interface helps people manage layers of data.</td>
      <td>33</td>
      <td>Microsoft Research U.K.</td>
      <td>computing-2009</td>
      <td><p>Shahram Izadi wants to make interacting with computers more natural. For one of his touch-based interfaces, the research scientist has improved on Microsoft’s already impressive touch table, Surface, to present information in a completely new way.</p>  <p>Surface projects infrared light and detects its reflection from fingers or other objects that are on or above a screen, enabling users to work with data displayed on the screen. Izadi’s variation, called SecondLight, uses a second projector and a switchable diffuser to add another physical layer of data. </p>  <p>The system projects one image on the table’s surface and a second, hidden image above it; passing a semiopaque object over the table reveals the second image. For instance, a user who holds a sheet of paper over an image of a human body might see the bones of the skeleton. Ultimately, Izadi envisions specialized tablets that could interact with SecondLight to facilitate collaboration; doctors working on the same patient, for example, could each add or view new data. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-12.jpg?w=936" alt="" class="wp-image-1033324"/><figcaption>Double vision: Beneath the screen are liquid crystals that rapidly switch from transparent to opaque. Two projectors underneath send out images in sync with the switching; in this case, the night sky appears on the table, with constellation names appearing above.</figcaption><div class="image-credit">MICROSOFT RESEARCH</div> </figure> </div> <p><em><br></em></p></td>
    </tr>
    <tr>
      <td>Ali Javey</td>
      <td>“Painting” nanowires into electronic circuits.</td>
      <td>29</td>
      <td>University of California, Berkeley</td>
      <td>computing-2009</td>
      <td><p>Nanowires could be the basis of tomorrow’s advanced electronics, from cheap solar cells to high-resolution displays. But it’s been difficult to arrange the tiny strands precisely. Ali Javey, an assistant professor of electrical engineering and computer science, has become a master at doing so. His latest tool for making high-quality circuits: a roller printer. He coats a glass cylinder with a catalyst and puts it in a chemical-vapor deposition chamber, where its surface sprouts nanowires. When the cylinder is pressed against a flexible piece of plastic or a silicon wafer, the tips of the nanowires cling to the flat surface; as the tube rolls, the wires are dragged and combed into straight rows before detaching from the roller. So far, Javey has used the technique to print transistors based on germanium, silicon, and indium arsenide nanowires. He has also printed arrays of light-sensing cadmium selenide nanowires, which can be used as photosensors for imaging applications.<em> </em></p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-6.jpg?w=936" alt="" class="wp-image-1033300"/><div class="image-credit">ERIK PAWASSAR</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Anat Levin</td>
      <td>New cameras and algorithms capture the potential of digital images.</td>
      <td>31</td>
      <td>Weizmann Institute of Science</td>
      <td>computing-2009</td>
      <td><p>Although a digital camera is an impressive piece of equipment, it’s the same in its basic design as the old-fashioned film camera: a lens focuses an image on a plane. The digital camera simply captures that image with a light-sensing chip instead of film. Anat Levin thinks we can do more. </p> <figure class="wp-block-image size-large"><img decoding="async" src="https://s3.amazonaws.com/files.technologyreview.com/p/pub/legacy/anat_levin_x220.jpg" alt=""><figcaption></figcaption></figure>\n <p>Levin, a senior scientist at the Weizman­n Institute in Rehovot, Israel, is at the forefront of computational photography. She develops ways to manipulate digital images, both inside the camera and on computers. And increasingly, she is exploring new camera designs. “Before digital photo­graphy, we would capture images onto a film, and the film was more or less the end of the story,” she says. “Now, with digital photography, what we have on the camera is not the end of the process.” </p>  <p>Last year, Levin invented a camera and algorithm that, together, remove motion blur from an image. Paradoxically, the camera moves its sensor horizontally at a varying speed while the image is being exposed, which of course makes the whole image blurry. However, the camera’s movement is specially designed to blur the moving and static parts of a scene equally, and by a known amount. Thus, she can use a relatively simple algorithm to remove the blur from all objects. A separate computer processes the image today, but a production model of the camera could eventually do the processing onboard.</p>  <p>Working with colleagues at MIT, Levin has also proposed a lens design that would give a camera greater depth of field, increasing the amount of a scene–near and far–that can be brought into focus at the same time. Square pieces cut from lenses with different focal lengths are superimposed over the regular lens. Each square focuses on an area a different distance from the camera. Using the information from all the lenses, Levin can recalculate the entire image to increase the depth of field, or even refocus on objects that are closer or farther away after the picture has been taken. </p>  <figure class="wp-block-image size-full"><img src="https://wp.technologyreview.com/wp-content/uploads/2021/08/Picture1.jpg" alt="" class="wp-image-1033303"/><figcaption><em><strong>No more blur: </strong>The blurry image of a moving toy car was taken with a traditional camera. The clear image was taken with Levin's modified camera. The camera's sensor moves from side to side during exposure, blurring all moving and stationary objects equally, no matter how fast each object is moving. Levin developed an algorithm that can remove this uniform blur to yield a clear image.<br>Source: "Motion-Invariant Photography" by Levin, Sand, Cho, Durand, Freeman.</em><br><br><em><strong>A new focus: </strong>Levin and colleagues designed a lattice of different lenses that can be placed over a camera's regular lens. Each lens focuses on an area a different distance from the camera. Using data from all the lenses, Levin can choose which part of the photo is in focus. In the image at left, the mouse is in the plane of focus and looks sharp. On the right, she has moved the plane of focus to the figurines in back.<br>Source: "4D Frequency Analysis of Computational Cameras for Depth of Field Extension" by Levin, Hasinoff, Green, Durand, Freeman.</em></figcaption></figure></td>
    </tr>
    <tr>
      <td>Pranav Mistry</td>
      <td>A simple, wearable device enhances the real world with digital information.</td>
      <td>28</td>
      <td>MIT</td>
      <td>computing-2009</td>
      <td><p>Retrieving information from the Web when you’re on the go can be a challenge. To make it easier, graduate student Pranav Mistry has developed SixthSense, a device that is worn like a pendant and super­imposes digital information on the physical world. Unlike previous “augmented reality” systems, Mistry’s consists of in­expensive, off-the-shelf hardware. Two cables connect an LED projector and webcam to a Web-enabled mobile phone, but the system can easily be made wireless, says Mistry. </p>  <p>Users control SixthSense with simple hand gestures; putting your fingers and thumbs together to create a picture frame tells the camera to snap a photo, while drawing an @ symbol in the air allows you to check your e-mail. It is also designed to automatically recognize objects and retrieve relevant information: hold up a book, for instance, and the device projects reader ratings from sites like Amazon.com onto its cover. With text-to-speech software and a Bluetooth headset, it can “whisper” the information to you instead.  </p>  <p>Remarkably, Mistry developed SixthSense in less than five months, and it costs under $350 to build (not including the phone). Users must currently wear colored “marker­s” on their fingers so that the system can track their hand gestures, but he is designing algorithms that will enable the phone to recognize them directly.</p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-11.jpg?w=936" alt="" class="wp-image-1033322"/><figcaption>1. Camera: A webcam captures an object in view and tracks the user's hand gestures. It sends the data to the smart phone.  2. Colored Markers: Marking the user's fingers with red, yellow, green, and blue tape helps the webcam recognize gestures. Mistry is working on gesture-recognition algorithms that could eliminate the need for the markers.  3. Projector: A tiny LED projector displays data sent from the smart phone on any surface in view--object, wall, or person. Mistry hopes to start using laser projectors to increase the brightness.  4. Smart Phone: A Web-enabled smart phone in the user's pocket processes the video data, using vision algorithms to identify the object. Other software searches the Web and interprets the hand gestures.</figcaption><div class="image-credit">SAM OGDEN</div> </figure> </div> <p><em><br></em></p></td>
    </tr>
    <tr>
      <td>Aydogan Ozcan</td>
      <td>Inexpensive chips and sophisticated software could make microscope lenses obsolete.</td>
      <td>30</td>
      <td>UCLA</td>
      <td>computing-2009</td>
      <td><p>Expensive, bulky lenses have been the basis of imaging technology for centuries. Now, says Aydogan Ozcan, an assistant professor of electrical engineering, “it’s time to change our thinking.” By writing sophisticated image-processing software and taking advantage of the inexpensive light sensors now ubiquitous in cell phones, he may have made lenses obsolete. The lensless imaging devices that Ozcan has built achieve roughly the same resolution as standard bench-top microscopes (about a micrometer), so they can be used to count, identify, and even image living cells. </p>  <p>He’s made prototypes mounted in cell phones to demonstrate the technology and has started a company called Microskia to develop it. The first products are likely to be simple microscopes that plug into a cell phone or laptop through a USB cord and display the magnified images on their screens; the first uses will probably be in remote medical centers, to diagnose anemia, cancer, and infectious diseases such as malaria. According to Ozcan, though, his prototypes are actually good enough to replace the large, expensive cell counters used in U.S. hospitals. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-8.jpg?w=936" alt="" class="wp-image-1033311"/><figcaption>1. Light Detector: A microscope slide holding a sample such as blood can be mounted here, over the phone's camera, which contains a light-detecting chip. The phone's processor runs the imaging software.  2. Light Source: The black plastic tube contains light filters and a light-emitting diode powered by the phone's batteries, but no lenses. Light shines from the tube through a sample and onto the camera's imaging chip.  3. Add-on Imaging: The imaging system can be removed for a more convenient cell-phone conversation or replaced with a light source better suited to a particular imaging application.</figcaption><div class="image-credit">CHRISTOPHER HARTING</div> </figure> </div> <p><em><strong><br></strong><br></em></p></td>
    </tr>
    <tr>
      <td>Vera Sazonova</td>
      <td>World’s smallest resonator could lead to tiny mechanical devices.</td>
      <td>30</td>
      <td>Nat’l Research Council Canada</td>
      <td>computing-2009</td>
      <td><p>Microelectromechanical systems, or MEMS, play a key role in gyroscopes, tiny chemical sensors, optical switches used in the telecom industry, and more. An even smaller version of the technology–nanoelectromechanica­l systems, or NEMS–could likewise have broad technological importance. Vera Sazonov­a has made the world’s smallest NEMS device: a tiny resonator that consists of a single carbon nanotube suspended over a silicon gate. A voltage at the gate makes the nanotube vibrate, creating a high-frequency current. Since the current is hard to detect, Sazonova applied another voltage at a slightly different frequency; the two signals mix to create a third, low-­frequency current that is easier to pick up. Potential applications include ultrasensitive motion detectors, sensors that can detect the mass of molecules, and even devices for detecting gravitational waves. </p></td>
    </tr>
    <tr>
      <td>Elena Shevchenko</td>
      <td>Assembling nanocrystals to create made-to-order materials.</td>
      <td>32</td>
      <td>Argonne National Laboratory</td>
      <td>computing-2009</td>
      <td><p>Elena Shevchenko is a master at making nanoparticles and assembling them into precise structures with useful properties. Materials made from the nanocrystals created with her methods could lead to ultra-efficient solar cells, tiny but powerful magnets, super-dense hard disks, and faster computers.</p>  <p>Trained as a chemist in Belarus, the University of Hamburg in Germany, and Columbia University in New York, Shevchenko has found better ways to make nanoparticles out of metallic compounds; she’s produced lead telluride, cadmium selenide, and cobalt-platinum particles, among others. She has also developed a technique for assembling these nanoparticles into “superlattices,” orderly crystal structures. Paul ­Alivisatos, a nanotech pioneer and interim director of the Lawrence Berkeley National Laboratory, calls Shevchenko “the best grower of nanocrystals in the world today.”</p>  <p>Mixing and matching these nanoscale building blocks offers endless possibilities for engineering structures with desired optical, electrical, and magnetic properties. A nanoparticle array of lead telluride and silver telluride, for example, is 100 times as conductive as arrays made of either particle alone. So far, Shevchenko has created dozens of new materials. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-9.jpg?w=936" alt="" class="wp-image-1033315"/><figcaption>Creating order: Top left: a crystal made from cobalt-platinum nanoparticles. Clockwise from top right: "superlattices" combining nanoparticles of lead selenide and gold, cadmium selenide and gold, and lead selenide and palladium.</figcaption><div class="image-credit">ELENA SHEVCHENKO</div> </figure> </div> <p><em><br></em></p></td>
    </tr>
    <tr>
      <td>Dawn Song</td>
      <td>Defeating malware through automated software analysis.</td>
      <td>34</td>
      <td>University of California, Berkeley</td>
      <td>computing-2009</td>
      <td><p>For years, says Dawn Song, computer defenders have been reacting to each new virus, worm, or other piece of malware after it appears, developing and deploying filters that detect known patterns in malicious code in order to stop its spread. Instead of stopping malicious programs one by one, Song, an associate professor of computer science, aims to protect computers at a deeper level. </p>  <p>Source code for both malware and commercial software is often not available, which slows the hunt for vulnerabilities. Song figured out how to find security flaws by examining only the <em>1</em>s and <em>0</em>s that the computer runs. Her platform, BitBlaze, analyzes malware and automatically generates a filter to protect against it until a security patch is released. It can also analyze those patches and produce new malware that exploits any vulnerabilities; this allows programmers to make security patches as sound as possible. </p>  <p>Such tasks “were previously relegated to highly specialized manual labor,” says Avi Rubin, technical director of the Johns Hopki­ns University Information Security Institute; he calls BitBlaze “a giant step forward in the battle against those who wish harm against computer systems.” For examp­le, if a worm tried to infiltrate a computer, BitBlaze’s response could fend off a variety of future attacks targeting the same vulnerability. Technology spun out of Song’s research has already been incorporated into Google’s Chrome browser, and she has collaborated with security software companies such as Symantec. </p></td>
    </tr>
    <tr>
      <td>Andrea Thomaz</td>
      <td>Robots that learn new skills the way people do.</td>
      <td>33</td>
      <td>Georgia Institute of Technology</td>
      <td>computing-2009</td>
      <td><p>Before robots can be truly useful in homes, schools, and hospitals, they must become capable of learning new skills. Andrea Thomaz, an assistant professor of interactive computing, wants them to learn from their users, so that experts don’t have to program every task. She aims to make robots that not only understand a human teacher’s verbal instructions and social signals but give social feedback of their own, using gestures, expressions, and other cues to let the person know whether they have correctly understood the directions. </p>  <p>Thomaz has designed machine learning algorithms based on human learning mechanisms and built them into her robots Junior and Simon, which have faces that make basic expressions and hands that can grasp simple objects. In experiments with people untrained in formal teaching, Junior has quickly learned enough about things in its environment to catch on to tasks such as opening and closing a box. </p></td>
    </tr>
    <tr>
      <td>Adrien Treuille</td>
      <td>Complex physics simulations that can run on everyday PCs.</td>
      <td>30</td>
      <td>Carnegie Mellon University</td>
      <td>computing-2009</td>
      <td><p>Adrien Treuille creates simulations of physical processes ranging from the flow of people in a crowd to the motion of proteins in a cell. And while his models are stunningly realistic, what’s truly amazing is that they run not on supercomputers but on ordinary PCs. “I want to place curling smoke in the palm of your hand,” he says.</p>  <p>To make this possible, Treuille, an assistant professor of computer science, streamlines the mathematical representation of a scenario, removing unlikely outcomes. For example, he says, a full simulation of how a shirt might be folded would include fantastic origami-style shapes. In most cases, a simulation would need to cover only ordinary creases. </p>  <p>Treuille’s simulations have attracted commercial interest. For example, ESPN used his techniques to simulate the airflow around NASCAR vehicles on live TV. And Electronic Arts has licensed his crowd-simulation techniques for its games, where they’re replacing more processing-intensive artificial-intelligence methods. </p>  <p>But Treuille’s work has applications beyond entertainment. He and colleague Seth Cooper designed a downloadable game called Foldit that allows players to fold and tug on simulations of known proteins to design new molecules. More than 90,000 users have registered and played since the game’s launch in May 2008. Treuille wonders if someone–perhaps even an amateur–might someday use Foldit to discover a protein that cures cancer.</p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-5.jpg?w=936" alt="" class="wp-image-1033296"/><figcaption>Mini model: Adrien Treuille creates realistic simulations that can run in close to real time on ordinary PCs. His simulations of airflow (above) have been adapted for use on live TV.</figcaption><div class="image-credit">ADRIEN TREUILLE</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Nathan Eagle</td>
      <td>Mining mobile-phone data for the public good.</td>
      <td>32</td>
      <td>Sante Fe Institute</td>
      <td>communications-2009</td>
      <td><p>Nathan Eagle, a research fellow at the Santa Fe Institute in New Mexico, believes that mobile phones offer more than a way to communicate. In his hands, they can provide windows on the social structure of communities, information that can lead to better public-policy decisions, and unexpected sources of income for people in poor countries. </p>  <p>For years, Eagle has been mining cell-phone data captured by service providers around the world. Using algorithms he developed as a graduate student at MIT, he strips all identifying information from call logs and looks for patterns in where people go and how they use their phones–patterns that can reveal how social networks are affected by outside forces. For instance, he is working with city planners in Kenya and Rwanda to understand how slums grow and change in response to events such as natural disasters and declines in crop prices. And earlier this year, Eagle began using phone-derived data to build a more accurate model of the spread of malaria in Africa. Previous models had relied on spotty information about people’s movements, collected in sporadic surveys. With a better picture of how the disease spreads, governments can improve the policies designed to fight it.</p>  <p>In February, he launched Txteagle, a service that lets any company send cell-phone users simple tasks such as text translation. Participants are paid with credits that can be used for phone service or redeemed for cash at special kiosks. A pilot program in Kenya paid a few cents per task and was too successful for its own good. Within hours of its launch, the ranks of users swelled into the thousands; within days, all the tasks were exhausted. </p>  <p>Eagle plans to relaunch the service later this year in Kenya and other countries, including Rwanda, Indonesia, and the Dominican Republic, with two changes that he hopes will make it sustainable: capping the amount of money a person can make in a day, so that completing tasks becomes more like a hobby than a job, and offering more tasks, such as identifying objects and people in digital pictures or deciphering distorted words from scanned books. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-13.jpg?w=936" alt="" class="wp-image-1033330"/><div class="image-credit">TXTEAGLE</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Shwetak Patel</td>
      <td>Simple sensors to detect residents’ activities.</td>
      <td>27</td>
      <td>University of Washington</td>
      <td>communications-2009</td>
      <td><p>Walls <em>can</em> talk, and Shwetak Patel, an assistant professor of computer science and electrical engineering, captures their stories: tales of how people move through their homes and how they use electricity, gas, and water. Patel has shown that each electrical appliance in a house produces a signature in the building’s wiring; plugged into any outlet, a single sensor that picks up electrical variations in the power lines can detect the signal made by every device as it’s turned on or off. This monitoring ability could be particularly useful for elder care, but there was previously no practical way to achieve it, because it would have required numerous expensive sensors.</p>  <p>Last year, Patel did something similar with ventilation systems, designing a sensor that detects subtle changes in air pressure when a person leaves or enters a room. More recently, he’s shown that slight pressure changes in gas lines and water pipes betray the use of specific appliances or fixtures, such as a stove or faucet. Patel believes that providing people with information about their patterns of resource consumption can help them reduce it. He has cofounded a startup that will provide consumers with utility bills itemized by appliance.</p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2009/08/Picture1-14.jpg?w=936" alt="" class="wp-image-1033332"/><figcaption>1. Anything plugged into an electrical outlet--DVD players, TVs, lamps--displays a unique signature when turned on or off. Even identical light bulbs in different rooms produce impulses with distinct shapes.  2 and 3. Ventilation systems can be used to detect a person's location. Opening or closing a door, or even stepping into a doorway, c­reates slight variations in air pressure that can be detected by a sensor installed in an HVAC control unit.  4. Gas lines that connect to water heaters and stoves can be outfitted with sensors that record changes in pressure when each appliance is used.  5. People's locations and activities can be inferred from the lights they turn on and the appliances and fixtures they use. This information could be used to monitor elderly or infirm people without employing a complicated collection of expensive motion sensors.  6. Even identical toilets in different parts of the house produce distinct pressure signatures in the plumbing.  7. Just as a single sensor in an electrical outlet can distinguish various electronic devices, one pressure sensor connected to a cutoff valve or an exterior water bib can distinguish different water fixtures, such as showers, sinks, and toilets.</figcaption><div class="image-credit">BRYAN CHRISTIE DESIGN</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Ashoke Ravi</td>
      <td>Using software to send diverse radio signals.</td>
      <td>32</td>
      <td>Intel</td>
      <td>communications-2009</td>
      <td><p>With Ashoke Ravi’s help, future cell phones and netbooks won’t need separate circuits to transmit multiple radio signals (over a cellular network, Wi-Fi, and WiMax, for example); a single transmitter will handle them all. </p>  <p>Radios that use software to receive signals over different wireless protocols exist already, but progress has lagged on the transmission side. Much of the difficulty has involved building amplifiers that can cope with the different power levels needed to transmit over the varied distances typical of different wireless networks.</p>  <p>Ravi, a researcher at Intel, built a software-controlled transmitter that solves the problem. Instead of changing the power level to transmit different signals, its amplifier can attenuate or boost the outgoing signal by combining the output of two oscillators that operate at a constant power level. His design allows the amplifier to be optimized for a single power level, increasing battery life. </p>  <p>Ravi expects devices incorporating the technology, such as laptops capable of switching seamlessly between 3G and Wi-Fi networks, to be on the shelves within five years. </p></td>
    </tr>
    <tr>
      <td>Blaise Agüera y Arcas</td>
      <td>Building immersive 3-D environments.</td>
      <td>33</td>
      <td>Microsoft Live Labs</td>
      <td>computing-2008</td>
      <td><p>Imagine taking hundreds of photos in the Rockies and being able to piece the images into a virtual re-creation of the peaks. With Microsoft’s Photosynth, you can. Created by Blaise Agüera y Arcas, the software uses digital photos to construct 3-D environments called “synths.” Agüera y Arcas created the first version in 2006, drawing on Seadragon–a data navigation technology he’d developed previously–and computer-vision research from Microsoft and the University of Washington.</p>  <p>In August, Agüera y Arcas and his team released a version of Photosynth that allows users to construct their own synths for the first time. The software runs on users’ computers and includes algorithms that let them more easily pivot in 3-D space. It also allows them to post their synths online and discover other synths of the same or similar places. As users add synths of cities, stores, and homes, Agüera y Arcas says, the Photosynth site will be able to “enrich online 3-D mapping, shopping, real estate, and other immersive Web applications that involve real objects and places.” </p></td>
    </tr>
    <tr>
      <td>Dries Buytaert</td>
      <td>Simple, flexible Web publishing.</td>
      <td>29</td>
      <td>Drupal</td>
      <td>computing-2008</td>
      <td><p>The Internet has made publishing on a global scale almost effortless. That’s the rhetoric, anyway. The truth is more complicated, because the Internet provides only a means of distribution; a would-be publisher still needs a publishing tool. A decade ago, people who wanted such a tool had three choices, all bad: a cheap but inflexible system, a versatile but expensive one, or one written from scratch. What was needed was something in the ­middle, requiring neither enormous expense nor months of development–not a single application, but a platform for creating custom publishing environments. For tens of thousands of sites and millions of users, that something is Drupal.</p>  <p>Created as an open-source project by Dries Buytaert, Drupal is a free content management framework–a tool for building customized websites quickly and easily, without sacrificing features or stability. Site owners can choose from a list of possible features: they might, say, want to publish ­articles, offer each user a profile and a blog, or allow users to vote or comment on content. All these features are optional, and most are independent of the others. </p>  <p>With Drupal’s high degree of individualization, users can escape cookie-cutt­er tools without investing in completely ­custom-­made creations, which can be time-­consuming, costly, and hard to maintain. The Howard Dean presidential campaign used Drupal in 2004, and today it’s used by Greenpeace U.K., the humor magazine the <em>Onion</em>, Nike’s Beijing Olympics site, and MTV U.K., among many others.</p>  <p>The diversity of its users has led to many improvements, Buytaert says: “The size, passion, and velocity of the Drupal community makes incredible things happen.” There are tens of thousands of active Drupal installations worldwide. Thousands of developers have contributed to the system’s core, and more than 2,000 plug-ins have been added by outside contributors.</p>  <p>Buytaert began the work that became Drupal in 2000, when he was an undergraduate at the University of Antwerp. He had a news site called Drop.org, and he needed an internal message board to host discussions. After reviewing the existing options for flexible message boards, Buytaert decided he could write a better version from scratch.</p>  <p>The original version of Drupal (its name derives from the Dutch for <em>droplet</em>) worked well enough to attract additional users, who proposed new features. Within a year, Buytaert decided to make the project open source. He released the code in January 2001 as version 1.0.</p>  <p>Since open-source projects tend to attract expert users, they often lack clear user interfaces and readable documentation, making them unfriendly to mere mortals. But Buytaert understood from the beginning how important usability is to the cycle of improvement, adoption, and more improvement that drives the development of open-source software. The core Drupal installation comes with voluminous help files. The central team regularly polls users as well as developers (which is unusual in an open-source project) to decide what to improve next. The process reveals not just features to add, but ones to remove, and ways to make existing features easier to understand. For example, the project’s website has been redesigned to help people new to Drupal figure out how to get up and running.</p>  <p>Buytaert has also founded a company, Acquia, to offer support, service, and custom development for Drupal users, especially businesses. He calls Acquia “my other full-time job” and likens it to Linux distributor Red Hat, which provides custom packaging and support for its version of the open-source operating system. </p>  <p>With Drupal version 7, due later this year, Buytaert hopes to include technologies that will make sites running Drupal part of the Semantic Web, Tim ­Berners-­Lee’s vision for making online data understandable to machines as well as people. If Drupal hosts a website containing a company’s Securities and Exchange Commission profile, for example, other sites could access just the third-quarter revenues, without having to retrieve the whole profile. The goal of sharing data in smaller, better-defined chunks is to make Drupal a key part of the growing eco­system of websites that share structured data. If this effort succeeds, it will ensure Drupal’s continued relevance to the still-developing Web. </p></td>
    </tr>
    <tr>
      <td>Jenova Chen</td>
      <td>Gaming with the flow.</td>
      <td>26</td>
      <td>Thatgamecompany</td>
      <td>computing-2008</td>
      <td><p>Jenova Chen has been playing video games for 20 years, and he’s desperate to see something new: right now, he says, most games focus on stimulating players by inciting aggression. “I want to expand what a video game can be,” he says. So as a graduate student in interactive media at the University of Southern California, Chen looked to psychologis­t Mihály C­sikszentmihályi’s theory of “flow,” which identifies a state of focus that people find enjoyable and fulfilling. Chen uses the theory’s principles to design games that offer just enough challenge–not so little that players become bored, not so much that they become anxious. </p>  <p>Chen’s first effort was FlOw, a Web-based “Zen game” in which players control a sea creature that swims, eats, and evolves. After graduating in 2006, Chen cofounded Thatgamecompany to continue his work. The company released a PlayStation 3 version of FlOw in 2007; it has become one of the most downloaded games on the PlayStation Network. The next game, Flower, will be released later this year. By going with the flow, Chen may help video games reach a whole new audience. </p></td>
    </tr>
    <tr>
      <td>Tanzeem Choudhury</td>
      <td>Inferring social networks automatically.</td>
      <td>33</td>
      <td>Dartmouth College</td>
      <td>computing-2008</td>
      <td><p>Social-networking sites such as Facebook require users to find and confirm connections with other people. But what if your cell phone could automatically identify the people you know, and even sort them into categories?</p>  <p>If that capability arrives, it will be thanks to reality mining, a field that Tanzee­m Choudhury pioneered as a PhD student at the MIT Media Lab. Working at Intel after graduation, she created a pager-size sensor pack–loaded with software plus microphones, accelerometers, and other data-gatherin­g devices–to collect and analyze data about human interactions and activity. For instance, by processing verbal utterances, she can identify the most influential people in a social network. </p>  <p>Now an assistant professor of computer science at Dartmouth, Choudhury is conducting experiments with the sensor-laden iPhone. Within a few years, she says, simple versions of her software could be available for cell phones. </p></td>
    </tr>
    <tr>
      <td>Jack Dorsey</td>
      <td>Personal updates made simple.</td>
      <td>31</td>
      <td>Twitter</td>
      <td>computing-2008</td>
      <td><p>In 2006, Jack Dorsey created Twitter so that he could let friends and family know what he was doing, wherever he–or they–might be. Today more than two million people use it to send out 140-character-or-fewer updates, called “tweets,” through Twitter’s website or by text message over mobile devices. Dorsey’s ethos of simplicity shapes everything about Twitter, from the application itself to the company’s San Francisco offices <em>(see “<a href="http://www.technologyreview.com/Biztech/20942/?a=f" target="_blank" rel="noopener noreferrer">Home Tweet Home</a>,” July/August 2008)</em>. Twitter’s popularity has given rise to an entire eco­system of applications. Yet Dorsey, cofounder and now CEO of the bemusing micro­blogging service, is secretive about how Twitter will ever make money; critics say that’s because its executives have no idea. What’s not a secret is that Twitter has had difficulties supporting its growing band of obsessives: in recent months, twitterers have been frequently confronted by error screens bearing messages such as “Twitte­r is stressing out a bit right now.” </p>  <p>Jason Pontin, <em>TR</em>’s editor in chief, recently chatted with Dorsey about these and other issues using Twitter’s @reply function, which directs a public message to a particular user.</p>  <p><strong>jason_pontin</strong> @jack Explain Twitter.</p>  <p><strong>jack</strong> @jason_pontin Twitter is a real-time repository of state for people, events, &amp; things. A personal news wire of sorts.</p>  <p><strong>jason_pontin</strong> @jack I twitter every day. But whenever I explain it to people who’ve not, they are uncomprehending or angry. Why?</p>  <p><strong>jack</strong> @jason_pontin People have to discover value for themselves. Especially w/ something as simple &amp; subtle as Twitter. It’s what you make of it.</p>  <p><strong>jason_pont</strong><strong>in</strong> @jack Critics say that tweets are trivial. Is that missing the point?</p>  <p><strong>jack</strong> @jason_pontin It depends on the context the recipient brings. There’s a universe in the smallest, most “trivial” details of one’s life.</p>  <p><strong>jason_pontin</strong> @jack Even people who love Twitter are frustrated by the service. It’s broken far too often to feel reliable.</p>  <p><strong>jack </strong>@jason_pontin We love what we’re building &amp; we hate to see it suffer. Our goal is to make it reliable enough to be trusted as a public good.</p>  <p><strong>jason_pontin</strong> @jack Twitter also seems to lack basic stuff. I can’t organize my followers intelligently. Or search very well. When will Twitter grow up? </p>  <p><strong>jack</strong> @jason_pontin Unfortunately, we’ve neglected the user experience to focus on stability of the foundation. We have designs to put this right.</p>  <p><strong>jason_pontin</strong> @jack You recently got $15 million from Spark Capital and Bezos Expeditions. Will you buy some servers and infrastructure with that?</p>  <p><strong>jack</strong> @jason_pontin I can’t confirm the number, but I can confirm we’ll make the money work for our users (20 of whom happen to be our investors)!</p>  <p><strong>jason_pontin</strong> @jack What’s Twitter’s business model?</p>  <p><strong>jack</strong> @jason_pontin We’re building what we love. While we have many ideas for sustainable revenue, Twitter’s will emerge naturally from our work.</p>  <p><strong>jason_pontin</strong> @jack Sometimes it sounds like your monetization plan is: let’s get acquired by a communications company.</p>  <p><strong>jack </strong>@jason_pontin We’re not focused on answering that question. We’re determined to build a solid platform and service we can take all the way.</p></td>
    </tr>
    <tr>
      <td>Stefanus Du Toit</td>
      <td>Programming for parallel processors.</td>
      <td>25</td>
      <td>RapidMind</td>
      <td>computing-2008</td>
      <td><p><strong>PROBLEM:</strong> As the ever-shrinking computer chip begins to run into fundamental physical limits, designers have begun building multiple processor “cores” onto each chip to improve performance. But writing software that can run in parallel on multiple cores is complicated and time consuming, and few programmers have the expertise to do it. As a result, most of the capacity on a multicore chip goes to waste. </p>  <p><strong>Solution:</strong> Stefanus Du Toit has created software that makes it easier to translate traditional serial programs into parallel programs. He began its development as a graduate student at the University of Waterloo, in Ontario; in 2004 he cofounded RapidMind, in Waterloo, to commercialize it. The company has raised $10 million and partners with Advanced Micro Devices, Hewlett-Packard, IBM, and others. </p>  <p>With RapidMind’s technology, programmers write software in C++ as usual; then they use a special interface to specify which parts of the program should be parallelized. The platform automatically parcels out those tasks among the cores. It builds code into the final program that manages workload, ensuring that each core is fully utilized and preventing errors such as one task’s stalling while it waits for another to finish. Finally, the platform optimizes the program to run on a particular chip–say, an eight-core chip from Intel. The finished program runs more efficiently; in one example, an image-­processing application rewritten with the RapidMind platform ran 10 times as quickly on eight cores as on a single processor. </p></td>
    </tr>
    <tr>
      <td>Seth Hallem</td>
      <td>Deconstructing software to find bugs.</td>
      <td>28</td>
      <td>Coverity</td>
      <td>computing-2008</td>
      <td><p><strong>PROBLEM:</strong> Programmers, despite their best efforts, make errors, any one of which could cause a system to crash or admit an attacker. Although automated test programs have improved software, major bugs still slip through, costing businesses and governments billions of dollars each year. </p>  <p><strong>SOLUTION:</strong> As a graduate student at Stanford, Seth Hallem perfected an improved approach to finding bugs, called static analysis. Where ordinary test software runs a program and hopes to stumble on errors, static analysis breaks it into pieces that perform discrete functions, such as “add the results of lines 42 to 47.” The computer determines what each piece does and then simulates how various functions might interact, looking for problematic combinations. </p>  <p>Previous attempts at static analysis were either too simplistic to find important bugs or too comprehensive to ever finish the job. Hallem developed algorithms to weed out redundant analysis and examine only the most important combinations, allowing millions of lines of code to be examined quickly and effectively. He cofounded Coverity in San Francisco to apply the technology commercially. More than 450 customers, including Raytheon and Yahoo, use Coverity’s tools to vet their software. </p></td>
    </tr>
    <tr>
      <td>Xian-Sheng Hua</td>
      <td>Enhancing video search.</td>
      <td>34</td>
      <td>Microsoft Research Asia</td>
      <td>computing-2008</td>
      <td><p>The amount of video on the Web is growing at an ­incredible rate. Effectively searching online video, however, remains difficult. Microsoft researcher ­Xian-Sheng Hua hopes to crack the problem by teaching computers to recognize objects, scenes, events, and other elements of digital images. </p>  <p>Hua uses machine-learning techniques and annotated videos to train computers to automatically categorize new videos. While this general approach isn’t new, Hua’s system permits multiple labels for each video segment–and relies not only on specified tags applied by experts but also on descriptions written by large numbers of grassroots Internet users. These user-­generated tags are gathered by means of online games, “pay for labeling” schemes, analysis of how people search for video, or other methods. Hua applies some automated filters to the labels to ensure their quality.</p>  <p>The system, which runs online, is first trained on videos tagged by experts; it’s then periodically updated and retrained using the grassroots labels. This “online active learning” makes the algorithm more accurate and several times faster than previous systems; applying multiple labels to each video increases the speed further. The technology should aid searches for still images, too. Some of the techniques involved are already being incorporated into Microsoft’s Live Search Video. Ultimately, Hua says, the technology should improve not only online video and image searches but also video surveillance and digital media management. </p></td>
    </tr>
    <tr>
      <td>Sundar Iyer</td>
      <td>Making memory at Internet speed.</td>
      <td>31</td>
      <td>Cisco Systems</td>
      <td>computing-2008</td>
      <td><p><strong>PROBLEM:</strong> At the heart of the Internet are the routers that direct packets of data to their destinations. But by briefly holding each packet in memory while figuring out where to send it, these specialized computers create a bottleneck. The speed of today’s 10-­gigabit-per-secon­d links forces router makers to use fast but expensive static random-access memory (SRAM) instead of slower, cheaper digital random-access memory (DRAM). As connection speeds increase, the amount of SRAM needed will become prohibitively expensive, leading to data loss and limiting applications such as voice calls and videoconferencing.</p>  <p><strong>SOLUTION:</strong> As a graduate student at Stanford, Sundar Iyer created a technique that lets equipment makers combine SRAM with DRAM to make routers at once faster, more reliable, less expensive, and more energy efficient. In Iyer’s “perfect caching” scheme, each arriving data packet is stored in an SRAM chip. Once every hundred nanoseconds, the cache sends all the packets to the main memory, made from DRAM. Fifty nanoseconds later, another SRAM cache takes only the packets it needs and sends them to their destinations. Iyer founded Nemo Systems to develop the technology in 2003; Cisco bought Nemo in 2005 and is building the system into its next generation of enterprise routers. </p></td>
    </tr>
    <tr>
      <td>Farinaz Koushanfar</td>
      <td>Locking microchips to prevent piracy.</td>
      <td>32</td>
      <td>Rice University</td>
      <td>computing-2008</td>
      <td><p><strong>PROBLEM:</strong> High-tech piracy isn’t limited to illegal downloads and knockoff DVDs: there are growing, multibillion-dollar gray and black markets for the microchips that run everything from video players to high-end weapons. Unscrupulous employees in overseas foundries that produce chips for other companies can divert extra chips, made for pennies, and resell them. </p>  <p><strong>SOLUTION: </strong>Farinaz Koushanfa­r, an assistant professor of electrical and computer engineering, has developed a way to foil hardware pirates using tiny physical variations between circuit elements on a chip–variations produced normally in the chip-manufacturing process. As small as a stray atom or two, the variations cause identical signals traveling to two such elements to arrive a few trillionths of a second apart; each chip contains hundreds of these pairs. For each pair, Koushanfar designates the first signal to arrive as a <em>0</em> and the second as a <em>1</em>, creating an ID code unique to each chip. When a buyer first uses the chip, it transmits its ID to its designer over the Internet. The designer sends back a corresponding “unlock” code that makes the chip usable. Koushanfa­r has created prototypes of the coded chips, and several chip makers have expressed interest in the technology. </p></td>
    </tr>
    <tr>
      <td>Johnny Lee</td>
      <td>Streamlining human-computer interactions.</td>
      <td>28</td>
      <td>Microsoft</td>
      <td>computing-2008</td>
      <td><p>When the Nintendo Wii came out, most people saw a fun new way to play video games. Johnny Lee saw a surprisingly good infrared camera that could make innovative computer interfaces affordable. At the 2008 Technology, Entertainment, Design (TED) conference, he drew spontaneous applause when he demonstrated two devices he’d hacked together, which used the $40 Wii remote and some inexpensive hardware to simulate systems that can cost thousands. The audience may not have realized that Lee had spent no more than “a few days” on each. “I have some knack,” he says, “for being able to identify easy projects that have a relatively big impact”–like those at right. Having completed his PhD at Carnegie Mellon, Lee is honing that knack as a researcher in Microsoft’s hardware division. <a rel="noopener noreferrer" href="http://www.technologyreview.com/Infotech/21239/?a=f" target="_blank">Read</a> why Lee thinks researchers should focus on bringing technologies to all. </p></td>
    </tr>
    <tr>
      <td>Meredith Ringel Morris</td>
      <td>Searching websites jointly.</td>
      <td>29</td>
      <td>Microsoft Research</td>
      <td>computing-2008</td>
      <td><p>“I’m not really interested in technology for the sake of ­technology. I’m interested in how it helps ­people connect and work with other people,” says Meredit­h Ringe­l Morris, a computer scientist in the Adaptive Systems and Interaction Group at ­Microsoft Research. Her tool Search­Together, shown below, is a plug-in for Internet Explorer that makes it easy for groups to share the work of searching without duplicating each other’s labor. Bookmarked websites appear in a frame beside the main browser window, along with users’ comments and ratings. A chat window at the bottom of the screen lets users discuss results in real time if they’re online simultaneously. ­Morris says that collaborative search combines the two activities she thinks people are most interested in doing online: communicating and gathering information. She’s also working on a tool that will help groups search collaboratively when sharing one computer, which could be particularly useful in classrooms.</p></td>
    </tr>
    <tr>
      <td>Andrew Ng</td>
      <td>Building household robots.</td>
      <td>32</td>
      <td>Stanford University</td>
      <td>computing-2008</td>
      <td><p>Housekeeping robots are still the stuff of science fiction, but not for want of hardware: there’s almost no task too precise or delicate for a robot that knows in advance what it’s supposed to do. The problem lies in teaching robots to deal with the unknown. That’s precisely what Andrew Ng, an assistant professor of computer science, set out to do when he founded the Stanford Artificial Intelligence Robot (STAIR) project a few years ago.</p>  <p>Previous robots have had some ability to improvise–many could locate familiar objects in unfamiliar environments, for example. But Ng has gone a step further: STAIR can deduce how to pick up an object it’s never seen before. Using traditional machine-learnin­g techniques, Ng trained STAIR on a database of pictures of objects such as wine glasses, coffee mugs, and pencils, as seen from different perspectives. Each object was correlated with information about the best place to grasp it: the stem of the wine glass, the middle of the pencil. After its training, STAIR could generalize those associations to adapt to new situations–liftin­g, among other things, a lunch box by its handle and a piece of intricate lab equipment by its metal stem. It was even able to remove dishes from a dishwasher and place them on a drying rack.</p>  <p>The STAIR team has made other advances–its innovative system for robotic depth perception even spawned a side project, software that converts static 2-D photo­graphs into 3-D images. But despite this progress, Ng knows that building a general­-­purpose household robot is beyond the means of any one lab. So he’s developing an open-source robotics operating system that will let researchers integrate a robot’s sensor systems and functional components in new ways, without having to write code from scratch. </p></td>
    </tr>
    <tr>
      <td>Adam Smith</td>
      <td>Making sense of e-mail madness.</td>
      <td>23</td>
      <td>Xobni</td>
      <td>computing-2008</td>
      <td><p>Not all e-mail is created equal. Some messages may be relevant for years, while others lose meaning within minutes. Yet e-mail in-boxes treat all messages alike, regardless of who wrote them, what they’re about, or when they were sent. Adam Smith has set out to change that with Xobni, software that pulls useful information out of e-mails and contextualizes it according to sender.</p>  <p>Smith’s goal is to help people unlock and harness the social relationships embodied in their in-boxes. The first version of Xobni (<em>inbox</em> spelled backwards) is a plug-in for Microsoft Outlook and works only on Windows computers–but the results are remarkable. </p>  <p>Once it’s installed, Xobni scans every e-mail and extracts information such as a sender’s phone numbers, what time she is most likely to e-mail you, who else she has corresponded with, and what files the two of you have exchanged. It labels all the data with descriptive tags, which it then indexes and analyzes. When you click on a specific e-mail, it displays all the information relevant to that sender in a sidebar that runs down the right side of the Outlook window. The tags also allow Xobni to search all indexed e-mails very rapidly. </p>  <p>Smith and his friend Matt Brezina founded Xobni in San Francisco two years ago and have raised $4.25 million from companies including First Round Capital and Khosla Ventures. The plug-in has received one startling endorsement: Bill Gates used it in a public demo at a Microsoft conference, even though the free download remains in beta. There have been rumors of Microsoft’s offering around $20 million for Xobni, but the young cofounders didn’t bite. Instead, they intend to offer a “Pro” version and à la carte features for sale. Xobni also plans to extend its reach to other e-mail programs, including Web-based services such as Yahoo Mail and Gmail. And the team has already begun building in access to social networks such as LinkedIn. </p>  <p>Other companies have tried to streamline e-mail before. But if Xobni can reach a significant fraction of the world’s 400 million Outlook users, Smith may save people time and annoyance by making e-mail more useful. </p></td>
    </tr>
    <tr>
      <td>JB Straubel</td>
      <td>Engineering electric sports cars.</td>
      <td>32</td>
      <td>Tesla Motors</td>
      <td>computing-2008</td>
      <td><p>As he pulls away from the headquarters of Tesla Motors in San Carlos, CA, JB Straubel apologizes for the condition of the car. The outside looks fine, a gleaming orange. But inside, instruments dangle from the dashboard. A message scrawled on blue masking tape warns that the passenger’s-side air bag is disabled. A bell chimes mysteriously. The car had been shipped to England and subjected to vibration tests designed to “shake it apart and kill it,” Straubel says. Now it’s an engineering car–one Straubel, the company’s chief technology officer, feels comfortable drilling holes in and bolting prototype hardware to. “It’s pretty much already written off,” he says. “But it’s also the fastest car in our fleet at the moment.” </p>  <p>He punctuates the sentence by hitting the accelerator. Straubel looks remarkably calm as the car surges forward, pressing him into the seat. From a dead stop at the on-ramp, it takes just a few seconds to overtake the vehicles on California’s Highway 101. In sports cars, this kind of acceleration is ordinarily accompanied by rapid-fire shifting, but Straubel never takes his hands off the steering wheel. Powered by batteries and an electric motor, the Tesla Roadster isn’t bound by the limits of old-fashioned gas-burning engines. At its top speed of over 120 miles per hour, it remains in its first and only gear. </p>  <p>Straubel doesn’t come close to 120 miles per hour today. Since the car can accelerate to 60 miles per hour from a stop in just under four seconds, “you get caught up to traffic pretty fast,” he says, easing off the accelerator. “It kind of spoils you.” It’s easy to see why this powerful alternative to gas-guzzling internal-combustion engines <em>(see Hack, “<a href="http://www.technologyreview.com/Energy/21199/" target="_blank" rel="noopener noreferrer">Tesla Roadster</a>”, September/October 2008)</em> has generated such remarkable excitement.</p>  <p>Straubel, more than anyone else, is responsible for the car’s impressive acceleration. The Roadster is the first production model from Tesla, which was founded to mass-produce high-performan­ce electric cars. The car’s carbon-fiber exterior and aluminum frame, which make it visually appealing but keep it light, are based on designs from British automaker Lotus. Straubel and his hand-picked team, however, engineered the car’s brains, muscles, and guts–the electronic controls, electric motor, and battery pack that enable the Roadster to beat many of even the quickest gas-powered cars off the starting line. </p>  <p>Electric cars are best known for their environmental benefits: they produce no harmful emissions, and they’re so efficient that they reduce total carbon emissions even if the electricity used to recharge them comes from power plants that burn fossil fuels. But Straubel’s achievements capitalize on another, less appreciated advantage. Gas engines deliver their peak torque–the key to acceleration–only within a limited range of engine speeds. Keeping the engine in its optimal range requires a convoluted system of gears and clutches, and acceleration is still compromised. Electric motors, however, deliver maximum torque from a standstill up through thousands of revolutions per minute. That makes it possible to use a transmission with just one or two speeds–and it makes electric cars more responsive than gas-powered ones. Yet most electric vehicles haven’t reaped the full benefit of their torque advantage, says Marc Tarpennin­g, one of Tesla’s founders. That’s because they have typically been underpowered, partly in an effort to make them as inexpensive as possible. Straubel set out to change that.</p>  <p>During his early days at Tesla, the company licensed a number of technologies from AC Propulsion, a small company that had pieced together a prototype electric car with acceleration similar to the Roadster’s. Tesla’s founders decided to use AC Propulsion’s parts to produce their own prototype. But those parts were “ruinously expensive,” Tarpenning says, “and no two were alike.” Straubel has since reëngineered almost every one of them.</p>  <p></p>  <p>It was soon clear that the extreme torque provided by electric motors can be a problem, especially in a high-powered car. Without a well-tuned motor controller, the torque can jerk the driver around, says Andrew Baglino, one of the engineers Straubel hired. What’s more, the complex interplay between the driver’s application of the accelerator, the conditions of the road, and the electronic characteristics of the battery and motor can have unexpected consequences. AC Propulsion’s controller was “a hokey analog syste­m–messy circuitry that was 20 years old,” Straubel says. As he and his team worked to develop a production-ready car, they found that one controller would work well while another would inexplicably fail. “We’d debug it for weeks trying to figure out what the hell was different, and we never could,” Straubel says. The unreliable controllers would sometimes cause the motor to jitter. Worse, at times all power would cut out–once, as the car was hurtling down the highway. </p>  <p>Straubel reasoned that a digital control system would solve these problems. Switching to digital would require starting from scratch, but he was sure the new system would both improve performance and speed development. Yet the decision was made to stick with the analog system, in the hope that its kinks could be worked out.</p>  <p>Undeterred, Straubel put Baglino to work on what appeared to be a side project: designing test equipment that put the company’s motors and batteries through the paces of simulated driving cycles. This equipment was to have digital controls, which Straubel intended to translate into a digital controller for the car.</p>  <p>Meanwhile, the engineers continued to painstakingly debug the analog system. “It felt silly to be solving problems that we knew we were trying to make obsolete,” Straubel says. </p>  <p>After months of working on the digital test equipment, the engineers had learned enough to design a prototype digital controller. It worked, and soon the messy analog system was gone. The jittering and jerking gave way to a digitally controlled, reliably smooth ride–and a car that was, incidentally, far more responsive. </p>  <p>The Roadster’s exceptional motor, too, is a tribute to Straubel’s persistence. Tesla initially used a third-party transmission that included two gears–one to accelerate from a stop and the other to reach high speeds. The system gave the Roadster a top speed of more than 120 miles an hour. However, the shifting system routinely wore out after just a couple of thousand miles. So Straubel found a way to replace it with a single-speed gearbox. Early on, Straubel and his team had redesigned the patterned metal plates and wire coils at the heart of electric motors to improve both efficiency and torque. But the electronics feeding power from the battery to the motor still limited its output. To exploit the added torque, Straubel added higher-performance transistors and retooled the electrical connections between the motor and the gearbox. These changes increased the torque that the motor could deliver at low speeds and allowed the engineers to use a single-speed transmission without sacrificing either acceleration or maximum speed. </p>  <p>But Straubel’s most notable contribution may have been to keep the car from bursting into flames. Tesla’s founders decided from the start to power the car with lightweight lithium-ion batteries of the type used in laptops, and they knew they had their work cut out for them. If lithium-ion cells are pierced, crushed, overcharged, or overheated, they can combust. The challenge was even greater because the individual cells were small: it would take 6,831 of them to give the car a decent range. All those cells would have to be wired together into an ensemble that was durable but allowed the charging and temperature of each cell to be carefully controlled.</p>  <p></p>  <p>This was fine with Straubel, who had been building electric ­vehicles since before he was old enough to drive and had long wanted to make a laptop-battery-powered car. Under his direction, all those goals were reached. But along the way, the team discovered that in some (extremely rare) cases, manufacturing defects within a cell could cause it to heat up and catch fire without any outside cause. (This problem led to the recall of millions of laptop batteries in 2006.) Using computer models, Straubel found that if any one of the 6,831 cells caught fire, it could set off its neighbors, starting a chain reaction that could destroy the battery pack and turn the car into a smoldering wreck. Tarpenning asked at the time, “So, JB, what’s going to happen to our energy storage system?”</p>  <p>As it turned out, the solution was already at hand, largely because of an argument Straubel had won early in the development of the battery pack. The car’s initial design called for air cooling to control the temperature of the batteries and extend their lifetime. But Straubel quickly realized that that approach wouldn’t provide the necessary control. </p>  <p>“We had a lot of heated discussions about what direction we should go,” Straubel says. But his cool-headed logic, along with some hard figures, won the day. The resulting liquid cooling syste­m–a network of tubes running past almost every cell in the pack–also offered a solution to the problem of the spontaneously combusting cell. With slight improvements, the system was able to evacuate the heat from a flaming cell so quickly that it couldn’t set off its neighbors. As with the digital controller, Straubel had been able to find a solution, even if it meant going against the grain. </p>  <p>Tesla began shipping Roadsters this year; the first four were delivered by June. Richard Chen, a former Google product manager who hopes to have his car by Christmas, mailed in a $100,000 check long before the production car existed, and before the company had even announced a price. His excitement is not unique: the car, which has a base price of $109,000, is back-ordered for at least a year. </p>  <p>Its success may have an impact well beyond Tesla’s bottom line. Bob Lutz, GM’s vice chairman, was quoted in Newsweek as saying that the Roadster was a deciding factor in GM’s decision to return to electric cars after abandoning them several years ago. If a Silicon Valley startup can do it, he reasoned, why can’t GM? What’s more, the Roadster may be changing the image of electric cars and increasing their chances for success. People such as Chen, who got to test-drive the car before finalizing his purchase, are buying it not to save the planet (though the green credentials are a nice side benefit, Chen says) but simply because it’s so much fun to drive. </p>  <p>These days, Straubel is focusing on improving the Roadster and engineering a sedan to open up a new, wider market for the company. And tentative plans are in the works for a small car, such as an electric version of Daimler’s tiny, inexpensive Smart car. </p>  <p>All that means long days for Straubel, and part of what keeps him going is the belief that he’s doing something important: finding a way to deal with the world’s energy woes. But he seems most driven by pure enjoyment. That’s clear enough when he’s behind the wheel of the latest version of the Roadster, whose new electronics can deliver far more power than the first version had. “It’s amazing what a few hundred more amps can do,” he says, laughing, after a burst of acceleration. “It’s fun, huh?” </p></td>
    </tr>
    <tr>
      <td>Eric Wilhelm</td>
      <td>Putting DIY projects online.</td>
      <td>31</td>
      <td>Instructables</td>
      <td>computing-2008</td>
      <td><p>When Eric Wilhelm finished his PhD in mechanical engineering at MIT, he and three friends started Squid Labs, a consultancy based in Emeryville, CA, that finds fixes for clients’ technical problems (how to make solar-collecting concrete, for example). But Squid Labs was also founded as a place where the colleagues could explore their own projects and ideas–funding them through their consulting jobs. In 2005, Wilhelm had an idea for a how-to website where people could share step-by-step visual instructions for original projects. The team spun the site out into its own company, and Instructables was born. </p>  <p>Wilhelm had hit upon the idea at the right time, just as the spirit behind open-source software began permeating other technological fields. Instructables offers its growing community of more than 300,000 registered users an easy way to document do-it-yourself technology projects and share ideas with others. </p></td>
    </tr>
    <tr>
      <td>Robert Wood</td>
      <td>Building robotic flies.</td>
      <td>31</td>
      <td>Harvard University</td>
      <td>computing-2008</td>
      <td><p>Robotic flies equipped with cameras, microphones, and other sensors would be a spy’s dream. But researchers have had trouble creating the materials needed to make robots that look and behave like real insects. Robert Wood, an assistant professor of engineering and applied sciences, took on the challenge: he developed a revolutionary fabrication technique that allows engineers to make a range of very tiny parts for any kind of robot. </p>  <p>Wood’s technique bears similarities to origami. To create three-dimensional structures that bend and rotate precisely as needed–not only for flying robots, but also for crawlers and swimmers–Wood builds “fold lines” into layered composites of materials such as polymers or carbon fiber. Last year he used the method to build the world’s smallest robotic insect capable of taking off. It is powered and controlled externally, but he plans to develop an onboard power source and sensors, and to refine the robot’s control systems. Wood’s ultimate goal is a fully autonomous robotic insect. </p></td>
    </tr>
    <tr>
      <td>Sanjit Biswas</td>
      <td>Cheap, easy Internet access.</td>
      <td>25</td>
      <td>Meraki Networks</td>
      <td>computing-2007</td>
      <td><p>Sanjit Biswas worked on a system for connecting local residents to the Internet wirelessly. In 2006, a nonprofit group asked if the technology could help provide Internet service to the poor. Intrigued, Biswas took a leave of absence to cofound Meraki Networks in Mountain View, CA, and create wireless mesh networks that would link people to the Internet cheaply. <br></p>  <p>In most mesh networks, all the nodes that receive a particular data packet forward it on; but in Biswas’s version, the nodes “talk” to each other and decide, on the basis of the packet’s destination and their own signal strengths, which one of them should forward it. The protocol also takes into account changing network conditions, as users sign on or off, or, say, a passing truck blocks a node’s radio signal. Biswas’s protocol, combined with commonly available hardware components, allows Meraki to produce Wi-Fi routers that cost as little as $50. (The routers Biswas used at MIT initially cost $1,500.) <br></p>  <p>Here’s how a Meraki network works: a user plugs a router into a broadband Internet connection; that person’s neighbors stick routers to their windows, and a mesh network of up to hundreds of people forms automatically. Users can give away or sell Internet access to their neighbors. There are already Meraki-based networks in 25 countries, from Slovakia to Venezuela, serving more than 15,000 users.  <br></p>  <p></p></td>
    </tr>
    <tr>
      <td>Josh Bongard</td>
      <td>Adaptive robots</td>
      <td>33</td>
      <td>University of Vermont</td>
      <td>computing-2007</td>
      <td><p>Josh Bongard’s robot walks with a limp. But it’s impressive that it walks at all.</p>  <p>As a postdoc at Cornell, Bongard collaborated with roboticist Hod Lipson and PhD student Victor Zykov to develop a robot that can adapt to changes in its body or in the environment–a key advance for robots designed to work outside a controlled laboratory setting. ­Bongard, now an assistant professor of computer science, begins by programming his robot with basic information about its design, such as the mass and shape of each of its parts. In his standard demonstration, he then disconnects one of its four legs. To get a sense of its handicap, the robot rocks back and forth, activating two tilt sensors. It then builds a virtual model of itself, using simulation software, and uses that model to test new ways of walking despite its handicap. Once the robot has developed a successful simulation, it attempts to walk using the same technique.</p>  <p>Rodney Brooks, professor of robotics at MIT, says that Bongard’s work is interesting because it’s inspired by the way biological systems adapt. To meet roboticists’ future goals of creating self-configuring robots, Brooks says, “these sorts of ideas are going to be essential.”</p>  <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2007/08/Picture1-6.jpg?w=936" alt="" class="wp-image-1033419"/></figure></td>
    </tr>
    <tr>
      <td>Garrett Camp</td>
      <td>Discovering more of the Web.</td>
      <td>28</td>
      <td>StumbleUpon</td>
      <td>computing-2007</td>
      <td><p>In 2001, Garrett Camp and two friends began working–“out of our bedrooms,” he says–on a tool to help people serendipitously discover interesting Web content. Camp, who was then a grad student in software engineering, has guided the research behind the site and the design of its architecture ever since. In May, eBay acquired the Web 2.0 “discovery engine” for approximately $75 million. As of July, more than three million users had downloaded the ­StumbleUpon toolbar; the simple interface consists of a row of about 15 buttons at the top of a Web browser. Clicking “I like it” when viewing a site amounts to a recommendation; clicking the thumbs-down button submits a negative review. Clicking “Stumble­” takes a user to one of more than 10 million sites recommended by friends or other users with similar interests. The system refines individual recommendations on the basis of the user’s previous reviews and the preferences of users whom the site judges to have similar tastes. So what kinds of sites has Camp stumbled upon? Take a sneak peek here. </p>  <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2007/08/Picture1-5.jpg?w=936" alt="" class="wp-image-1033413"/><figcaption>1. cabspotting.org Where cabs go in San Francisco. I discovered this through a journalist whom I had friended on StumbleUpon, and it was developed by Stamen Design (which did Digg Swarm) right here in SF. <br>2. jessekriss.com/projects/samplinghistory/ A visual history of audio sampling. A great depiction of how hip-hop and electronic music have sampled from earlier musical forms since the mid-1980s. <br>3. gethuman.com How to get to a human operator when calling for support. Definitely an example of a site you probably wouldn't search for, but a great find once you stumble upon it. <br>4. twittervision.com Twittervision is a mashup between the text-message blogging service Twitter and Google Maps. It shows you what people across the globe are blogging from their phones at this moment. <br>5. levitated.net/exhibit/index.html A visual exploration of computation using Flash. StumbleUpon is great for discovering graphical content such as art, photos, and videos, and this is a perfect example of a graphics-rich site that doesn't contain a lot of keywords you might search for yet is an interesting discovery when you're stumbling through graphics or design sites.</figcaption></figure></td>
    </tr>
    <tr>
      <td>Mung Chiang</td>
      <td>Optimizing networks.</td>
      <td>30</td>
      <td>Princeton University</td>
      <td>computing-2007</td>
      <td><p>Mung Chiang likes to say that there’s nothing more practical than a good theory. An assistant professor of electrical engineering, he improves the design of telecommunications networks by applying the mathematics of optimization theory. Through industry collaborations, his algorithms are revolutionizing the backbone of the Internet, the broadband connections that bring data and video to homes and offices, and wireless networks of every stripe.</p>  <p>In one project, Chiang and coworkers found a way around the limits of the current Internet routing protocol, which sends packets along the shortest available paths on the network. It’s a seemingly straightforward strategy that ends up causing complex n­etwork-management problems. The researchers realized there were advantages to sending the occasional packet along a longer path; the new algorithm achieves the lowest computational cost possible for a routing protocol and increases network capacity by 15 percent–without adding equipment to the network. </p>  <p>Though the real-world impact of his work matters to Chiang, he says another important motivation is the beauty of an airtight mathematical proof. “I’m an engineer at heart,” he says, “and a mathematician in my brain.” </p>  <p></p></td>
    </tr>
    <tr>
      <td>Tadayoshi Kohno</td>
      <td>Securing systems cryptographically.</td>
      <td>29</td>
      <td>University of Washington</td>
      <td>computing-2007</td>
      <td><p>Our reliance on the Internet is increasing all the time. Tadayosh­i Kohno, an assistant professor of computer science and engineering, worries that even if our data is encrypted, hackers can still glean information about us by working around the codes. For instance, someone tapping into your system might not be able to view the movie you’re watching but could guess its title from properties such as the file size and the compression algorithm used.</p>  <p>So Kohno invented the concept of systems-oriented provable security. Traditionally, cryptologists have assumed that a security protocol is unbreakable if no one they show it to can crack it. But with provable security, they use sophisticated math to show that cracking a given code would require someone to decipher a cryptographic “building block” that’s known to be secure. </p>  <p>Kohno extended this technique to the system level, examining everything from the software that compresses a file to the Internet protocols used to send it. He searches for weak points that might leak identifying information and writes provably secure algorithms to protect them. One of his schemes can handle data transmitted at 10 gigabits per second, the new Internet standard–a rate that overwhelmed previous security protocols. The U.S. government is incorporating a derivative of the scheme into an official encryption standard; Kohno anticipates that banks and corporate networks will use it as well. </p></td>
    </tr>
    <tr>
      <td>Tariq Krim</td>
      <td>Building a personal, dynamic Web page.</td>
      <td>34</td>
      <td>Netvibes</td>
      <td>computing-2007</td>
      <td><p>“When I open my Web browser, I want to get the latest stuff that’s really important to <i>me</i>,” says software engineer, Web entrepreneur, and former journalist Tariq Krim. That’s the idea behind Netvibes, a free and “agnostic” Web service Krim created to let netizens build customized pages from disparate modules such as RSS feeds from blogs, competing news sites such as Google and Yahoo, and even user-translated international sites. On the “Tariq” tab of his own ­Netvibes page, Krim uses search modules to track what bloggers are saying about him and his company. A portion of his page is shown below. </p>  <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2007/08/Picture1-8.jpg?w=812" alt="" class="wp-image-1033439"/></figure></td>
    </tr>
    <tr>
      <td>Ivan Krstic´</td>
      <td>Making antivirus software obsolete</td>
      <td>21</td>
      <td>One Laptop per Child</td>
      <td>computing-2007</td>
      <td><p>Ivan Krstic takes extracurricular activities to the extreme. Born in Croatia, he received a scholarship to attend a Michigan high school when he was 13. While there, he wrote software to interpret data for a neuroscientist at the University of Michigan. He also spent two summers in Croatia, building a patient-management computer system for Zagreb Children’s Hospital. He enrolled at Harvard in 2004 but then took a year’s leave to return to Croatia and reëngineer the Zagreb hospital’s IT system–after a month-long detour to Silicon Valley to help scale up Facebook’s software architecture.</p>  <p>Krstic returned to Harvard in 2005 to work on a degree in computer science and theoretical math, but he took another leave last spring to become director of security architecture for the One Laptop per Child (OLPC) program, which is building inexpensive laptops for Third World children. His mandate was to create a secure system that children could use, and that wouldn’t need the tech support and continual updates that current anti­virus programs require. </p>  <p>So he set about making such software obsolete, building into OLPC’s Linux-based operating system a ­security platform called Bitfrost, named after Bifröst, a bridge in Norse ­mythology that reaches from Earth to heaven and that intruders can’t cross. Instead of blocking specific viruses, the system sequesters every program on the computer in a separate virtual operating system, preventing any program from damaging the computer, stealing files, or spying on the user. Viruses are left isolated and impotent, unable to execute their code. “This defeats the entire purpose of writing a virus,” says Krstic.</p>  <p>Some in the Linux community are so impressed with this novel approach to fighting malicious code that they have proposed making it part of the Linux standard. But since Bitfrost will allow only programs that are aware of it to run, it would make Linux incompatible with existing applications. The solution is for programmers to create “wrappers,” small programs tacked onto existing applications to enable them to communicate with Bitfrost. After OLPC’s computer ships late this year, Krstic plans to return to Harvard–and to help write those wrappers. It’s just one more ­extracurricular activity to take on. </p></td>
    </tr>
    <tr>
      <td>Jeff LaPorte</td>
      <td>Internet-based calling from mobile phones.</td>
      <td>30</td>
      <td>Eqo Communications</td>
      <td>computing-2007</td>
      <td><p><b>Problem:</b> If you’re at your computer, you can use Skype and similar programs to make zero-cost domestic and international phone calls. But if you’re forced to use your mobile phone for an international call, you pay exorbitant rates. Sending mobile calls over the Internet, as Skype does with PC calls, would be cheaper–but the big carriers don’t offer such a service, and their clout with handset manufacturers makes it hard for third-party developers to create easy-to-use Internet calling software. </p>  <p><b>Solution:</b> Jeff LaPorte conceived a clever end run around the wireless carriers and cofounded Eqo Communications of Vancouver, British Columbia, to market the idea. When an Eqo (pronounced “echo”) user dials an international number, software downloaded to the phone actually connects the call to a local Eqo number. From there, an Eqo server converts the user’s voice into data packets and sends them over the Internet to an Eqo server in the destination country, which puts the call back onto the wireless voice network. There are no complicated settings to configure or 800 numbers to dial, and calls sound as good as they do with standard wireless technology. Calls from one Eqo member to another are free, and other international calls can cost as little as 5 percent of what the major carriers charge. Eqo members must still have domestic wireless calling plans–but in LaPorte’s words, Eqo effectively “turns your local minutes into inter­national ­minutes.” </p>  <p></p></td>
    </tr>
    <tr>
      <td>Karen Liu</td>
      <td>Bringing body language to computer-animated characters.</td>
      <td>30</td>
      <td>Georgia Tech</td>
      <td>computing-2007</td>
      <td><p>A crowded sidewalk is a ca­cophony of unspoken yet unmistakable messages. A young woman’s “I feel sexy” walk, for instance, is instantly distinguishable from a biker dude’s “Don’t mess with me” stride. But getting computer-generated (CG) characters to reproduce physical attitudes like these is still an arcane craft. Animators must either eyeball characters’ movements in hundreds of hand-drawn “key frames,” with software interpolating the in-between moments, or cheat by using expensive motion-capture systems to digitize the behavior of real actors.</p>  <p>As a computer science graduate student at the University of Washington in the early 2000s, Karen Liu set out to find an easier method. Her article of faith: “There [had] to be some way, from our knowledge of physics and biomechanics, to distill the properties that create motion styles.”</p>  <p>Biomechanics researchers had long been analyzing the mechanical factors that affect the way people move. Simulating those factors, Liu thought, would yield CG characters that move more naturally. But the human body contains hundreds of interacting parts, and it was impractical to measure or even stipulate the values of parameters such as tension and elasticity for every muscle, tendon, and ligament. Working with advisor Zoran Popovic, Liu eventually showed that feeding just a handful of these values into animation software is enough to reproduce a distinctive motion such as a “happy walk” in a range of CG models, from people to penguins.</p>  <p>To establish her style parameters, Liu developed algorithms based on a singl­e, simplifying assumption: that people naturally try to waste as little energy as possible when they move. Into these algorithms she feeds short segments of motion-capture data from subjects instructed to move in a certain way–to walk happily, for example. The software then reasons backward to guess the values of certain parameters, choosing those values that would have made the movements energy efficient. </p>  <p>Liu, who just joined the computer science faculty at Georgia Tech, is talking with major game makers and film studios about applying her algorithms to video games and animated films. She hopes the algorithms will help animators create CG humans that move more naturally than the robotically stiff characters in films like <i>The Polar Express</i>. “I think we’re really close,” she says. </p>  <p></p></td>
    </tr>
    <tr>
      <td>Anna Lysyanskaya</td>
      <td>Securing online privacy.</td>
      <td>31</td>
      <td>Brown University</td>
      <td>computing-2007</td>
      <td><p><strong>Problem:</strong> People want to use the Internet without having their habits documented or their personal data stolen. But they need to prove they’re authorized to access bank accounts or subscription sites, processes that usually involve revealing their identities.</p>  <p><strong>Solution:</strong> Anna Lysyanskaya, an assistant professor of computer science, has developed a practical way for people to securely log in to websites without providing any identifying information. Her approach relies on “zero-knowledge proofs.” Say you want to browse a newspaper’s archives in total privacy. With zero-­knowledge proofs, you subscribe using a pseudo­nym and receive digitally signed credentials. When you access the paper’s site, your computer sends encrypted versions of the pseudonym and credentials. The archive can’t decrypt this information; instead, it tests it for characteristics that valid data must have. (A certain field has to contain a specific number of digits, for example.) If the credentials are fake, some attribute will be wrong, and the site will be able to tell.</p>  <p>Zero-knowledge proofs have been around for a while, but they’ve required too much computing power to be practical. Collaborating with Jan ­Camenisch of the IBM Zürich Research Laboratory, Lysyanskaya developed algorithms that make both generating and testing credentials much more efficient. IBM is incorporating these algorithms into its Idemix anonymous-credential systems. </p></td>
    </tr>
    <tr>
      <td>Tapan Parikh</td>
      <td>Simple, powerful mobile tools for developing economies.</td>
      <td>33</td>
      <td>University of Washington</td>
      <td>computing-2007</td>
      <td><p>When fishermen from the Indian state of Kerala are done fishing each day, they have to decide which of an array of ports they should sail for in order to sell their catch. Traditionally, the fishermen have made the decision at random–or, to put it more charitably, by instinct. Then they got mobile phones. That allowed them to call each port and discover where different fishes were poorly stocked, and therefore where they would be likely to get the best price for their goods. That helped the fishermen reap a profit, but it also meant that instead of one port’s being stuck with more fish than could be sold while other ports ran short, there was a better chance that supply would be closer to demand at all the ports. The fishermen became more productive, markets became more efficient, and the Keralan economy as a whole got stronger. </p>  <p>This story demonstrates an easily forgotten idea: relatively simple improvements in information and communication technologies can have a dramatic effect on the way businesses and markets work. That idea is central to the work of Tapan Parikh, a doctoral student in computer s­cience and the founder of a company called Ekgaon ­Technologies. Parikh has created information systems tailored for small-business people in the developing world–systems with the mobile phone, rather than the PC, at their core. His goal is to make it easier for these business owners to manage their own operations in an efficient and transparent way, and to build connections both with established financial institutions and with consumers in the developed world. This will help them–they’ll be able to get money to expand their operations and, ideally, find better prices for what they sell–and it should be a boon to development as well.</p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2007/08/Picture1-10.jpg?w=936" alt="" class="wp-image-1033445"/><figcaption>Tapan Parikh demonstrates his mobile-phone-based software to members of a microfinance group in India.</figcaption><div class="image-credit">TAPAN PARIKH</div> </figure> </div> <p>In the developing world, working with mobile phones has obvious advantages: they’re ubiquitous even in poorer countries (there are 185 million cell-phone subscribers in India and more than 200 million in Africa); they’re relatively affordable; and with the right software, they’re easy to use. So Parikh developed Cam (so called because the phone’s camera plays a key role in the user interface), a toolkit that makes it simple to use phones to capture images and scan documents, enter and process data, and run interactive audio and video. The Keralan fishermen had been able to improve their business simply by making phone calls. Cam would carry the process a step further, by taking advantage of modern phones’ computing capabilities.</p>  <p>Parikh’s most important project with Cam has focused on perhaps the trendiest field in economic development: microfinance, in which lending groups grant tiny loans–on the order of $25–to people in the developing world, usually to fund small-business ventures. (Muhammad Yunus, the founder of the best-known microfinance institution, the Grameen Bank, won the Nobel Peace Prize last year for his work in establishing the field.) The best-publicized version of microfinance involves a solo entrepreneur getting a small loan from a well-financed bank. But Parikh is collaborating with organizations that are more representative of the way it usually works. A big chunk of the microfinance business in India, for example, is conducted by self-help groups, in which 15 to 20 people (usually women) pool their capital and then meet weekly or monthly to make collective decisions about loans to members of the group. They also use their collective borrowing power to obtain loans from nongovernmental aid organizations or from financial institutions, and then lend that money to their members.</p>  <p>Parikh built a software system on top of Cam to assist self-help groups in managing their information and their operations. Unglamorously called SHG MIS (for “self-help group management and information system”), it includes a Cam-based application for entering and processing data, a text-messaging tool for uploading data to online databases, and a package of Web-based software for managing data and reporting it to any institution that has lent money to the self-help group. Such groups have traditionally relied on paper documentation, however, and because their members still trust paper, the software also includes a bar-code-based system. Loan applications, grants, receipts, and other documents are printed with identifying bar codes; the software enables the phone to scan the code, identify the document, photograph it, process the data it contains, and associate that data with the code. The result is a system that facilitates a quick and accurate flow of data from small villages to bigger cities, and vice versa.</p>  <p></p>  <p>In addition to providing a more efficient way for self-help groups to manage their finances, SHG MIS allows such groups to overcome two major challenges. First, it enables them to run their internal operations in a fair and transparent way, while ensuring that their loans make economic sense. “In these groups, things are often done in a somewhat ad hoc manner, using informal documentation,” Parikh says, “which can lead to instability and impermanence and contribute to the kinds of tensions that lead small groups to fall apart.” His software gives groups a more systematic method of documenting decisions, tracking financial performance over time, and collecting information on which kinds of loans work and which don’t. These advantages should help groups make better decisions and reduce internal political tensions.</p>  <p>The software could also improve the flow of information ­between self-help groups and the formal financial sector, which should enable them to get capital at better rates. As things stand right now, Parikh says, bankers’ interest in micro­finance is so high that the supply of capital more than meets demand. But because it’s difficult to track so many small, scattered loans, banks tend to offer the same deal to every business, regardless of performance, ability to repay, and so on. If self-help groups could document their performance in a formal, auditable system that banks could access quickly and reliably, the groups would be more likely to get fair prices. They would have access to more capital, too.</p>  <p>Two things are striking about Parikh’s invention. The first is how unremarkable it seems, and yet how consequential it is in practice. Parikh did not radically reimagine computing, nor did he make a major break with the way financial data is managed in the developed world. Instead, he focused on something whose benefits we take for granted–reliable, instant access to financial data–and figured out an easy, affordable way to bring it to people who need it. The second thing is that instead of forcing small-business people to discard all their old ways and embrace an entirely new paradigm, Parikh’s work attempts to meet them, as it were, where they live, in order to enhance their existing abilities and resources. Other engineers might insist that the self-help groups need to do away with paper, since it’s less efficient than simply using digital entry devices, or develop PC-­centered systems, since mobile phones (whatever their virtues) are limited in their power and capacity. Cam, though, relies on a different strategy, one that emerges from the bottom rather than being imposed from the top.</p>  <p>This strategy runs counter to the way computer science has traditionally been done. Many computer scientists tend to think more about making machines faster and more powerful than they do about making sure they meet people’s needs. What’s distinctive about Parikh’s approach is that he’s spent so much of the past seven years working not in front of a computer but in the field, talking with the people he hopes will eventually be his customers. It’s a way of life that seems more characteristic of an anthro­pologist than a coder, but it’s responsible for much of what Cam has become. In fact, Parikh says, “all of my ideas are really just rehashes of ideas that local people have come up with.”</p>  <p>Parikh has adopted the same approach in his work with fair-trade coffee farmers in Guatemala. In recent years, the “fair trade” and “organic” designations have come to have real economic value: fair-trade farmers are guaranteed a minimum price for their crop, and organic farmers can often charge higher prices. But these labels also cause problems. Because they’re one-size-fits-all, they reduce the incentive for farmers to improve their growing methods or the quality of their crops above the general minimum. And they create incentives for cheating, which in turn reduces the value of the label to consumers: are you really sure how that organic coffee you bought at Starbucks or Peet’s was grown? So Parikh devised a Cam system called Randi, for “representation and inspection tool.” It allows farm inspectors to use mobile phones to systematically photograph and document farms in order to ensure their compliance with quality and production standards, and to put that data online so that it’s easily found by certifying agencies, wholesalers, and consumers.</p>  <p></p>  <p>In other words, if you wanted to know how that organic coffee was grown and whether a fair price was paid for it, Randi would let you find out. In the long run, the system would allow today’s simple labels to become more nuanced, and in the process it would allow prices to more accurately reflect what consumers really value. “At the moment, prices are good at transmitting the value of goods in strict economic terms,” Parikh says. “But they’re not so good at transmitting other kinds of information, like what the production of a good has taken away from the environment, or the experience of the workers producing that good. One of the things technologies allow us to do is actually convey more of that information.” </p>  <p>It would be a mistake to see Cam and technologies like it as a panacea for the problem of underdevelopment. While it’s easy to become infatuated with the promise of microfinance and small-scale entrepreneurship, it’s also easy to overestimate how much influence these things can exert on developing economies, which often face structural problems that won’t be solved by making local markets more efficient. And it’s also the case that, in the short run at least, the arrival of new technologies can widen the gap between the prosperous and the struggling: if you’re buying more from the Cam-equipped farmers, you’ll probably buy less from the non-Cam-equipped ones. In other words, not everyone will win.</p>  <p>Parikh seems well aware of the limits of technology in general and Cam in particular. But he is also convinced that mobile phones have the capability to become far more powerful tools, which is why he has other applications in mind for Cam–such as tracking disease outbreaks and improving the coördination of relief after disasters. In each case, one can observe Parikh’s respect for the virtues of decentralized organization and the conviction that bringing more information and more transparency to social systems is better. Parikh is focused more on solving real problems than on developing complex technologies. “I think oftentimes with formal and well-established disciplines like computer s­cience, you run into the problem of inertia, a kind of hesitancy to accept new ideas about what should count as important,” he says. “But I’m cautiously optimistic that within academia as a whole, there’s a broad sense that the real-world impact of someone’s work is an important criterion by which to judge it. Ultimately, I think that’s what counts: how can the work we do have a practical impact? How can it make a difference in the way people live?”</p>  <p></p></td>
    </tr>
    <tr>
      <td>Babak Parviz</td>
      <td>Self-assembling micromachines.</td>
      <td>34</td>
      <td>University of Washington</td>
      <td>computing-2007</td>
      <td><p><strong>Problem:</strong> Relatively simple microelectromechanical systems are already used in air bags and other devices, but MEMS of greater complexity hold promise in applications ranging from medical implants to advanced navigation devices. Such machines might include components like tiny sensors, motors, and power sources. The methods for manufacturing these diverse parts, however, are largely incompatible, which makes assembling complex MEMS on a large scale and at a reasonable cost impossible.</p>  <p><strong>Solution:</strong> Babak Parviz, an assistant professor of electrical engineering, has developed a method of coaxing individual components to assemble themselves into MEMS devices. Recently, he used it to build a working single-crystal silicon circuit on a flexible plastic substrate; the two materials are difficult to combine using conventional manufacturing methods. </p>  <p>Parviz began by manufacturing micrometer­-size silicon parts in bulk. He also designed a plastic substrate with binding sites whose shapes complemented those of the silicon components. Parvi­z immersed the substrate in a fluid containing the silicon parts, which quickly attached to their binding sites. Metal interconnects embedded in the plastic completed the circuitry.</p>  <p>Such silicon-on-plastic devices could form the basis for flexible displays, biosensors, and low-cost solar panels. Parviz says that self-assemb­ly offers the ability to efficiently and cheaply manufacture multifunctional devices of all sizes from nanoscale components. </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2007/08/Picture1-4.jpg?w=936" alt="" class="wp-image-1033409"/><figcaption>Left: To create self-assembling devices, Babak Parviz began by manufacturing micrometer-size silicon components in bulk, yielding a loose collection of parts that resembled a fine powder. Right: A finished silicon-on-plastic device made via self-assembly. Parviz designed a plastic substrate with binding sites whose shapes complemented those of the silicon components. When the plastic was immersed in a fluid containing the silicon parts, the components found their binding sites and locked into place.</figcaption><div class="image-credit">BABAK PARVIZ</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Partha Ranganathan</td>
      <td>Power-aware computing systems.</td>
      <td>34</td>
      <td>Hewlett-Packard Labs</td>
      <td>computing-2007</td>
      <td><p>Every year, computing devices–from cell phones to servers–consume at least 125 terawatt-hours of electricity, roughly the amount produced by burning 350 million tons of coal. Partha Ranganathan, principal research scientist at Hewlett-Packard Labs, is developing strategies to bring that figure down (see below). “All the ideas are very intuitive,” he says. “But we needed to solve some hard problems to get there.” Technologies he helped develop, which could save money and lower greenhouse-gas emissions, are already starting to appear in consumer and business products. </p></td>
    </tr>
    <tr>
      <td>Kevin Rose</td>
      <td>Online social bookmarking.</td>
      <td>30</td>
      <td>Digg</td>
      <td>computing-2007</td>
      <td><p>In 2004, Kevin Rose set out to transform the way people read news. The result, Digg, mixes blogging, online syndication, social networking, and “crowdsourcing”–which combines the knowledge and opinions of many individuals–to create an online newspaper of stories selected by the masses. The principles behind Digg are simple. Users can submit stories; if other users like a story, they can “digg,” or praise, it; if not, they can “bury,” or condemn, it. A new visitor sees a ceaseless scroll of stories accompanied by a flurry of comments. Digg’s straightforward rules have made it hugely popular: less than three years after its launch, more than 17 million users visit the site each month. But with success, Digg has also attracted controversy. Some observers decry the inanity of the site’s top stories, and even habitual users admit that the comments are mostly puerile. Rose, who acts as the site’s chief architect, must increasingly weigh the anarchic free speech that characterized Digg’s early days against a more responsible approach to publishing that protects intellectual property and other institutional interests. </p>  <p><i><strong>TR:</strong></i> Digg is a testament to collective wisdom–but I wonder if at any point you’ve felt embarrassed, either by the top stories or by the comments about the stories.</p>  <p><strong>Kevin Rose:</strong> Not really. Every single day I find something that’s really interesting that I wouldn’t have found on a traditional news outlet, an interesting nugget of information that happens to surface on an unknown blog <br>or a website that I haven’t heard of before. I think if you go on <br>CNN.com or MSNBC.com, you’re going to find the news that you’re used to reading. When you come to Digg, you never know what you’re going to get.</p>  <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2007/08/Picture1-7.jpg?w=936" alt="" class="wp-image-1033423"/></figure>  <p><strong><em>TR: </em></strong>What about the common criticism of Digg, that what tends to be “dugg” is often superficial? Are the most popular stories on Digg really the best stories?</p>  <p><strong>KR:</strong> As we speak, right now, the top three stories on Digg are do-it-yourself lucid dreaming, an update about the Apple iPhone, and why a former official of the Reagan administration thinks that President Bush should be tried as a war criminal. We get a mixture of all types of news on our front page. </p>  <p><strong><em>TR: </em></strong>Stories appear and disappear on Digg’s main pages with tremendous speed. Does Digg move too quickly for most people to usefully understand what’s there? </p>  <p><strong>KR:</strong> We try to make sure there isn’t too much information flowing through the system. We are constantly tweaking our promotion algorithm to make sure that it doesn’t become overwhelming. As we grow, we also have to continue to raise the bar required for stories to get promoted to the front page. One of the things that I’m really focused on is improving the experience that’s off the front page. Already you can get recommendations from friends; soon the system will start recommending stories that you might have missed or that you might find interesting, based on what you’ve dugg in the past. </p>  <p><strong><em>TR: </em></strong>You had a small scandal recently, when you published the encryption key that protects high-definition video discs (HD-DVD). First, under industry pressure, you took down the post; then, under pressure from your users, you put it back. What is your policy on censorship?</p>  <p><strong>KR:</strong> We sort of take everything on a case-by-case basis. Things that are very clear violations of our terms of service come off the site; we don’t allow pornography or pirated software, for instance. But when it’s in one of the gray areas, it gets tricky.</p>  <p><strong><em>TR: </em></strong>I’m curious about your feelings about the power of the Digg community. Do you think it can be controlled or directed?</p>  <p><strong>KR:</strong> It resists being directed, that’s for sure. It was very clear when the HD-DVD story broke, and then again, during the aftermath. I was watching the Digg community saying, “You can’t censor us; this is free speech.” The home page reflected those comments, and there was really nothing that we could do. We just built the platform. It’s really up to the users to determine what they want to see on the front page.</p>  <p><strong><em>TR: </em></strong>You’re saying that even if you wanted to, you couldn’t control what appears on Digg–except by removing a story ex post facto.</p>  <p><strong>KR:</strong> Yeah. Behind the scenes, what you don’t see is that we have these servers that are just going crazy. I mean, you have thousands and thousands of people digging stories and submitting stories and commenting and posting–and we can’t write code that would keep up with that. The HD-DVD business was absolutely fascinating. I sat there, and I was kind of in shock and spellbound at the same time. It was quite the evening. </p>  <p><strong><em>TR: </em></strong>Digg watchers say that 100 users are respon­sible for more than half the stories on the site’s home page, a phenomenon that creates the potential for abuse. How do you know when someone is gaming Digg? And what can the company do to stop them?</p>  <p><strong>KR:</strong> The system knows. Our main job is to evolve the platform so that it promotes to the front page news and videos that have a diverse crowd of people digging them. We have to make sure that when a story does make the front page, it was actually chosen by individuals who wanted to see it on the front page–and not spammers trying to promote their own stories.</p>  <p>Have you heard that media companies are ambivalent about the traffic Digg sends them? It’s hard to sell it to advertisers, because it’s unpredictable, and the quality of the audience isn’t measurable.</p>  <p>I think that’s probably true. But I find it a little hard to think of Digg as a source of traffic; it was designed as just a way for people to share things with their friends. Also, this trend is much bigger than us. If a story is ­popu­lar, it’s going to spread. We often see a chain reaction occur: a story will hit Del.icio.us, and then it’s on Digg, and then it’s on Boing Boing. </p>  <p><strong><em>TR: </em></strong>To date, Digg has been a haven for science and technology geeks. Can you imagine a day when Digg will truly be a ­general-­interest site?</p>  <p><strong>KR:</strong> Definitely. Politics is one of our most popular sections and will soon overtake technology. We started off with a large tech base; we were 100 percent technology for the first year, so that’s our roots. But we’re quickly expanding beyond that.</p>  <p></p></td>
    </tr>
    <tr>
      <td>Marc Sciamanna</td>
      <td>Controlling chaos in telecom lasers.</td>
      <td>29</td>
      <td>École Supérieure d’Électricité and Centre National de la Recherche Scientifique (France)</td>
      <td>computing-2007</td>
      <td><p>Problem: Vertical-cavity surface-­emitting lasers, or VCSELs, are commonly used in telecommunications networks, but they behave in ways scientists don’t completely understand. Specifically, the polarization of the light they emit–the orientation of its magnetic field–fluctuates unpredictably. Moreover, a little optical feedback, such as light reflected from network equipment, may result in chaotic changes in the power or wavelength of the light emitted by the lasers. Engineers would like to harness all of these fluctuations to increase the data-carrying capacity of light. </p>  <p>Solution: Marc Sciamanna, a professor at the École Supérieure d’Électricité in Paris, has developed a theoretical explanation of the lasers’ chaotic behavior. He has also suggested different techniques for controlling VCSEL polarization and chaotic laser dynamics in general; in particular, he demonstrated that optical feedback can be used to regularize polarization. More recently, he showed that increasing the amount of noise, or random fluctuation, in the electrical current that powers the lasers would make the variations in polarization more predictable and also stabilize the chaotic output. If light polarization and chaotic dynamics were subject to engineers’ control, they could be used to encode digital information–significantly expanding Internet bandwidth.</p>  <p></p></td>
    </tr>
    <tr>
      <td>Desney Tan</td>
      <td>Teaching computers to read minds.</td>
      <td>31</td>
      <td>Microsoft Research</td>
      <td>computing-2007</td>
      <td><p>It’s not unusual to walk into Desney Tan’s Microsoft Research office and find him wearing a red and blue electroencephalography (EEG) cap, white wires cascading past his shoulders. Tan spends his days looking at a monitor, inspecting and modifying the mess of squiggles that approximate his brain’s electrical activity. He is using algorithms to sort through and make sense of EEG data in hopes of turning electrodes into meaningful input devices for computers, as common as the mouse and keyboard.</p>  <p>The payoff, he says, will be technology that improves productivity in the workplace, enhances video-game play, and simplifies interactions with computers. Ultimately, Tan hopes to develop a mass-market EEG system consisting of a small number of electrodes that, affixed to a person’s head, communicate wirelessly with software on a PC. The software could keep e-mail at bay if the user is concentrating, or select background music to suit different moods.</p>  <p>As early as 1929, researchers observed slight changes in EEG output that corresponded to mental exertion. But these results haven’t led to a mass-­market computer-input device, for a number of reasons. Most EEG experiments are conducted in labs where electrical “noise” has been minimized, but outside the lab, EEG is susceptible to electrical interference. EEG equipment also tends to be expensive. And previous research has averaged data from many users over long periods of time; some studies have shown that individual results vary widely.</p>  <p>Tan believes he can solve these problems by training machine-­learning algorithms–often used to understand speech and recognize photos–to account for variations between individuals’ EEG patterns and to distinguish interesting electrical signals from junk. Contrary to popular practice, Tan keeps his lab as electrically noisy as the average home or office. He is even using the least expensiv­e EEG equipment he could find–a kit he bought for a couple of hundred dollars at a New Age store. (Some people use EEG for meditation.)</p>  <p>Tan’s EEG cap has 32 electrodes that are affixed to the scalp with a conductive gel or paste. When neurons fire, they produce an electrical signal of a few millivolts. Electronics within the device record the voltage at each electrode, relative to the others, and send that data to a computer. </p>  <p>A subject using Tan’s system spends 10 to 20 minutes performing a series of tasks that require either high or low concentration–such as remembering letters or images for various amounts of time. EEG readings taken during the activity are fed to a computer, which manipulates them mathematically to generate thousands of derivations called “features.” The machine-­learning algorithm then sifts through the features, identifying patterns that reliably indicate the subject’s concentration level when the data was collected. Tan and his collaborators at the University of Washington, Seattle, and Carnegie Mellon University have shown that a winnowed set of about 30 features can predict a subject’s concentration level with 99 percent accuracy.</p>  <p>Tan expects the technology to be used initially as a controller for video games, since gamers are accustomed to “strapping on new devices,” he says. In fact, next year a company called Emotiv Systems, based in San Francisco, plans to offer an EEG product that controls certain aspects of video games. However, the company will not discuss the specifics of its technology, and there isn’t widespread consensus on the feasibility and accuracy of the approach.</p>  <p>The true challenge, Tan says, will be to make EEG interfaces simple enough for the masses. He and his team are working on minimizing the number of electrodes, finding a semisolid material as an alternative to the conductive gel, and developing wireless electrodes. A mass-market product could be many years away. But if Tan succeeds, getting a computer to read your thoughts could be as easy as putting on a Bluetooth headset. </p>  <p></p></td>
    </tr>
    <tr>
      <td>Luis von Ahn</td>
      <td>Using “captchas” to digitize books.</td>
      <td>29</td>
      <td>Carnegie Mellon University</td>
      <td>computing-2007</td>
      <td><p>Luis von Ahn is a pioneer of “captchas”–those strings of distorted characters that websites force you to recognize and type in order to establish that you are a person and not a malevolent computer. But he finds the technology’s success a mixed blessing. “At first I was feeling quite proud of myself,” says von Ahn, a 2006 MacArthur “genius grant” recipient who created captchas (an acronym for “completely automated public Turing test to tell computers and humans apart”) for Yahoo in 2000 to thwart automated e-mail account registration, a tool of spammers. “But then I was feeling bad, because every time you solve a captcha, you waste 10 seconds.” People around the world solve an estimated 60 million captchas every day, adding up to more than 150,000 wasted hours. </p>  <p>Von Ahn, an assistant professor of computer science, is a leader in using human skills to make computers work better. For example, he created an online game in which players identify elements in photographs; their answers help improve image-search algorithms. He’s now trying to put captchas to work in one of the epic efforts of the information age: digitizing millions of old books and making them searchable online. </p>  <p>An estimated 8 percent of words in these old books can’t be read by the optical character recognition (OCR) software used to scan them. Von Ahn has teamed with the nonprofit Internet Archive to use captchas to help interpret those words. After all, he says, “while you are solving a captcha, you are solving a task that computers can’t perform.” So he created a tool, called ­”recaptcha,” that pairs an unknown word with a known one. He distorts them both and puts a line through them–standard techniques for creating captchas. A user must decipher both captchas to access a site. The accurate typing of the known word serves the security purpose of captchas and adds a measure of confidence that the unknown word was identified correctly and can be used in place of the OCR’s gibberish. Volunteers have begun deploying recaptchas, and the technique has been used to decipher two million words for the Internet Archive’s book digitization effort. Recaptchas tap the joint power of people, networks, and computers in a way that should have a big impact, says Brewster Kahle, an Internet entre­preneur and cofounder of the archive: “It is like an army of ants building the Taj Mahal.” </p> <div class="wp-block-image"> <figure class="wp-block-image size-large"><img src="https://wp.technologyreview.com/wp-content/uploads/2007/08/Picture1.gif?w=544" alt="" class="wp-image-1033425"/><figcaption>This image illustrates the difficulty that optical-character-recognition software can have in interpreting the content of older books. Luis von Ahn's recaptcha project is designed to help replace the OCR gibberish with the actual words.</figcaption><div class="image-credit">RECAPTCHA</div> </figure> </div></td>
    </tr>
    <tr>
      <td>Mark Zuckerberg</td>
      <td>Circle of friends.</td>
      <td>23</td>
      <td>Facebook</td>
      <td>computing-2007</td>
      <td><p>Three and a half years ago, Mark Zuckerberg (then a ­Harvard sophomore) and a couple of friends built a ­website to let them share photos and personal profiles with other Harvardians. ­Zuckerberg became CEO of the new enterprise, called Facebook. The social-networking site gradually opened its doors to students at other colleges and then high schools. Now that anyone with an e-mail address can register, the site has more than 30 million members, who use it to blog, share pictures, connect with old friends, and expand their networks.</p>  <p>In May, the company announced the Facebook ­Platform, which lets users build and share tools for personalizing their profile pages and adding, say, videos or music from other websites. The idea, says Zuckerberg, is that the personal connections people have made within Facebook will lead them to content that’s interesting to them.</p>  <p>The company is embroiled in a long-standing legal dispute with ConnectU, another networking site that originated at Harvard, over ownership of the initial source code and even the basic business idea. Still, Bloomberg reported in December that the privately held company’s value may be more than $1 billion, thanks largely to the site’s appeal to advertisers. As Facebook grows, so does its potential to become a major content distributor. Not a bad prospect for a programming project hatched in a dorm room. </p>  <p></p></td>
    </tr>
    <tr>
      <td>Roger Dingledine</td>
      <td>When your Internet communications absolutely, positively need to be anonymous.</td>
      <td></td>
      <td>The Tor Project</td>
      <td>computing-2006</td>
      <td><p>A dissident in China uses Web-based e-mail to contact a journalist in Canada. An intelligence agency wants to surveil a foreign website. Like every operation on the Internet, these activities leave tracks. Online anonymity measures provide a way around this problem; one of the most advanced is Tor, or the Onion Router. <br></p>  <p>Computer scientist Roger Dingledine developed Tor under a contract with the U.S. Naval Research Lab; today, the software is distributed by the Tor Project, under the fiscal sponsorship of the Electronic Frontier Foundation.  <br></p>  <p>To disguise Internet traffic’s origins, Tor plots a route through any three of more than 700 volunteer-run Onion routers around the world. It sets up a two-way link between the sender’s computer and the final router in the chain; data passed between them is encrypted in three layers, and each router in the chain peels off one layer along the way. Each data packet “remembers” only the address of the last router it visited. That way, even if the data is intercepted before the final router hands it off to the recipient, it’s difficult to trace back to the sender. <br></p>  <p>Editors’ note: This text is corrected version of the story that ran in the September/October 2006 print issue of Technology Review.</p></td>
    </tr>
    <tr>
      <td>Jason Fried</td>
      <td>Keeping online collaboration simple.</td>
      <td>32</td>
      <td>37signals</td>
      <td>computing-2006</td>
      <td><p>37signals builds aggressively simple Web-based collaboration tools that help people manage everything from family to-do lists to big corporate projects. Hundreds of companies are using Ruby on Rails, the open-source software toolkit that the firm created, to quickly develop their own online applications. Jason Fried, the founder and president of the seven-person firm, is fond of saying, “It’s better to tell a short story well than a long one poorly.” In that spirit: <br></p>  <p>“Jason is immune to dogma and has much to teach. In 37signals, he has built an elegant company with elegant products based on the idea that less is more.” <i>–Jeff Bezos, CEO, Amazon.com, and the first outside investor in 37signals</i></p></td>
    </tr>
    <tr>
      <td>Matthew Herren</td>
      <td>Beaming textbooks across Africa.</td>
      <td>23</td>
      <td>EduVision</td>
      <td>computing-2006</td>
      <td><p>Growing up in Africa, Matthew Herren saw that many children in cash-strapped rural schools have to make do with textbooks that are decades out of date. Inspired to find a low-cost solution to the problem, he hit on the idea of using satellites to transmit up-to-date educational materials. He aims to establish the technology not through programs run by traditional aid organizations but through a series of self-sustaining businesses. <br></p>  <p>“We figured there had to be a way for technology to lower the cost” of providing books and other materials to children, Herren says (see “<a href="http://www.technologyreview.com/read_article.aspx?id=17421"><i>Development Powered by Education</i></a>”). Herren, who is Swiss, turned to one-way satellite radio transmission because Internet access is unlikely to reach much of the African interior anytime soon. In a test last year, a Swiss foundation called BioVision installed a satellite receiver in a grade school in Mbita Point, Kenya, on the shores of Lake Victoria. The receiver downloaded textbooks onto its hard drive. The information was then transferred to handheld computers rigged with simple Linux-based software for book viewing. Sixty students received current classroom materials.  <br></p>  <p>Herren is now trying to implement his scheme on a grander scale. Working with Bridgeworks, a venture capital firm in Zürich, he has already raised most of the $650,000 needed for seed money. With that capital, Herren hopes to launch a network of businesses across Africa that will sell and service the satellite receivers and handheld PCs. A country’s education ministry would hire one of these companies to provide and maintain its educational-download system–and slash the per-pupil cost of providing classroom materials by more than 20 percent.  <br></p>  <p>If delivering educational materials by satellite works as hoped, the basic system could be used to provide remote villages with health and agricultural information. Herren notes that in many villages that lack even roads, all paths literally lead to schools. <br></p>  <p></p></td>
    </tr>
    <tr>
      <td>Eddie Kohler</td>
      <td>A better operating system.</td>
      <td>33</td>
      <td>University of California, Los Angeles</td>
      <td>computing-2006</td>
      <td><p>Operating systems are the software foundation for all computers, from laptops to servers–but most were designed decades ago, without Internet security in mind. Small flaws in the operating system or software on, say, a bank’s server could compromise millions of dollars’ worth of sensitive data.  <br></p>  <p>To make such information more secure, computer scientist Eddie Kohler and his team designed Asbestos, an operating system that keeps private data from falling into the wrong hands even when other software on a computer has failed. Asbestos keeps personal data secure by “tagging” it with information about which programs or users can access it.  <br></p>  <p>Usually, this sort of tagging requires a large amount of memory, but Kohler has structured the tag data to use minimal system resources. Initial tests have been promising, and Kohler hopes that within a few years, Asbestos will be an alternative to server operating systems such as Linux and Windows. <br></p></td>
    </tr>
    <tr>
      <td>Joshua Napoli</td>
      <td>Super-high-resolution 3-D displays could change the way people look at everything from tumors to drug targets and natural gas deposits.</td>
      <td>28</td>
      <td>Actuality Systems</td>
      <td>computing-2006</td>
      <td><p>Before treating a tumor with radiation, an oncologist must decide how to direct the radiation beams so as to minimize damage to surrounding tissues without compromising efficacy. That kind of planning may soon become more accurate, thanks to true 3-D displays whose software Joshua Napoli helped pioneer. <br></p>  <p>The image on the left shows different perspectives on the same plan for treating a brain tumor with radiation: red marks the tumor site, blue marks critical structures such as the brain stem (which must receive as little radiation as possible), and green marks the proposed path of radiation beams. The images, 25 centimeters in diameter, are projected inside a somewhat larger dome; this “volumetric display” is made by Actuality Systems of Bedford, MA, where Napoli is head of software development.  <br></p>  <p>Napoli’s software breaks up 3-D models generated by a computer into hundreds of frames that are projected onto spinning panels inside the dome, making a smooth, interactive image. The software has produced the highest-resolution volumetric 3-D displays in the world, Napoli says. Along with doctors at three hospitals, Actuality is studying whether radiation plans made using its displays are superior to those made using traditional monitors. Eventually, doctors could use the 3-D displays to view most types of medical scans.  <br></p>  <p>Already, petroleum companies are using them to help visualize oil and gas deposits, and pharmaceutical researchers are using them to help picture how potential drugs interact with their targets. One of the biggest challenges, Napoli says, has been engineering the underlying graphics-processing software to work with real 3-D displays; displaying 3-D images this way requires a computer to process about 50 times as many picture elements as it would if the images were displayed on flat screens.  <br></p>  <p></p></td>
    </tr>
    <tr>
      <td>Nikos Paragios</td>
      <td>Clearer computer vision.</td>
      <td>34</td>
      <td>École Centrale Paris</td>
      <td>computing-2006</td>
      <td><p>Vision is one of biology’s most complex processes. But that doesn’t stop Nikos Paragios from trying to bring this marvel of flesh and blood to the world of bits and bytes. He develops software that allows computers to interpret images more accurately, which could improve everything from medical diagnosis to driving. <br></p>  <p>As a professor at the École Centrale Paris, Paragios is a long way from the world of his childhood on the tiny Aegean island of Kárpathos, where he worked summers in a family-owned coffee shop, and there wasn’t a computer in sight. “But everyone said computer science is the future,” he recalls, so he headed to the University of Crete to study it. <br></p>  <p>Today Paragios is a leader in computer vision. Among his many projects is the mathematical modeling of hand gestures. The idea is to develop software to translate sign language into text, easing communication between the hearing and the deaf. The models could also allow drivers to simply point at icons printed on a dashboard–gestures that would be interpreted by onboard cameras and computers–rather than twisting knobs or pressing buttons. <br></p>  <p>Paragios is best known for his contributions to medical imaging. As a research scientist at Siemens in Princeton, NJ, he created software to automatically detect and define the boundaries of anatomical structures. Applied to magnetic resonance images of the heart, for example, the software highlights complex structures such as the coronary arteries, allowing doctors to pinpoint changes that can lead to heart attacks. Siemens is now integrating Paragios’s system into its MRI scanners. <br></p>  <p>Paragios continues to work on medical imaging technologies. With physicians at Henri Mondor University Hospital outside Paris, he’s developing software to diagnose muscle diseases called myopathies without painful biopsies. Paragios and his team are turning to a variation of MRI called diffusion tensor imaging, which measures the random motion of water in biological tissues (<i>see “<a href="http://www.technologyreview.com/read_article.aspx?id=16473">10 Emerging Technologies: Diffusion Tensor Imaging</a>”</i>). The goal is to create algorithms that can use this motion to determine the structure and orientation of muscle fibers, thus revealing developing myopathies. <br></p>  <p>But no matter its application, Paragios’s research is driven by his desire to “do something that brings great innovation and serves society.” <br></p>  <p><br></p></td>
    </tr>
    <tr>
      <td>Paul Rademacher</td>
      <td>The man who opened up the map.</td>
      <td>32</td>
      <td>Google</td>
      <td>computing-2006</td>
      <td><p>There’s a magical moment when an unfamiliar piece of information–say, an address or an image–produces a flash of recognition, when we suddenly know where to place it. That happened to Paul Rademacher in April 2005, when he fired up his hacked version of the brand-new Google Maps site. To ease his housing hunt, Rademacher had deciphered, then modified, the JavaScript behind Google’s application, creating a version that retrieved data from two different sources: Google and craigslist, the popular classified site. The result was a hybrid page that displayed Google’s familiar map and scattered across it icons indicating houses for rent around San Francisco. <br></p>  <p>Rademacher’s new picture of the world–or at least of selected cities–took the Web by storm. Even Google employees wrote on a company Web page that his site, housingmaps.com, “blew our minds right off our shoulders.” Thousands of people realized that Google’s maps were a giant canvas on which they could doodle, taking the locations of crime scenes, favorite restaurants, or cheap gas stations and creating online tableaux for all to see. But more than that, Rademacher had shown a way to combine data and tools from completely different websites to create something new. One blogger called it a “mashup,” a word DJs use to describe the mixture of vocal and instrumental tracks from different songs, and the term stuck. <br></p>  <p>For Rademacher, there’s a moral to the story. Innovation is possible only when companies let you tinker with their creations. Too many good ideas are squandered, he says, because the tools needed to realize them are locked away: “To this day, there are very few technologies that are open.” Creating open technologies is Rademacher’s new passion. In September 2005, he left his job developing animation tools at PDI/Dreamworks Animation to pursue that passion at Google. His projects there, he says, are still “under wraps.”  <br></p></td>
    </tr>
    <tr>
      <td>Joshua Schachter</td>
      <td>How tags exploit the self-interest of individuals to organize the Web for everyone.</td>
      <td>32</td>
      <td>Del.icio.us (Yahoo)</td>
      <td>computing-2006</td>
      <td><p>In 2001, a wonky Wall Street quantitative analyst named Joshua Schachter had a problem. In the late 1990s, he’d started a website called Memepool, which was a simple collection of Web links that he had found interesting, useful, or both. Over time, as Memepool’s users began sending in links they thought the site should feature, Schachter’s personal list of bookmarked Web pages grew to more than 20,000 entries, far more than any folder system could handle. To bring some order to the chaos, Schachter wrote an application called Muxway, which allowed him to manage his links by giving each a short label, or tag–enabling him to call up all the pages that were tagged, say, “Wi-Fi” or “math.” <br></p>  <p>People continued to view Schachter’s list of interesting links; but now, because of Muxway, those links were organized around tags. Pretty soon, about ten thousand people every day were stopping by. Schachter realized that even with (or perhaps because of) the deluge of information available on the Web, people were still hungry for good links, and they were interested in finding out what others thought was interesting. He also figured that if tagging was helpful to him, it could make storing and finding bookmarks easier for everyone else. So with that in mind, he rewrote Muxway, and in 2003 he launched it as a website called del.icio.us. Within a couple of years, hundreds of thousands of people were using del.icio.us, and it had metamorphosed into a system for organizing not just individuals information but the whole Web. Today it exemplifies the promise of what’s often called Web 2.0–websites and online applications that rely on user participation to achieve their greatest value. <br></p>  <p>At its core, del.icio.us is a bookmarking system: a place to store all those links that don’t fit in a “Favorites” folder. But it took off because it offers everyone what Muxway had offered Schachter: a way not just to collect links in one place but also to organize them. As people trawled the Web, they could tag interesting pages using whatever words they wanted, and del.icio.us would keep track of them all.  <br></p>  <p>“You bookmark for one of two reasons: either you think you’re going to need that page again somewhere down the road, or you don’t have time to read it now, but you want to read it later,” Schachter says. “The challenge is, once you’ve got all these bookmarks, how do you manage them? The problem we’re really dealing with is memory and recall, and using technology to make your memory more scalable.”  <br></p>  <p>Schachter deliberately avoided imposing any rules about how people could use tags. He knew it wouldn’t work: “If I went in there and said, Hey, you’re using that tag wrong, people would just tell me to fuck off,” he says. He also knew that letting people use their own tags–instead of choosing them from a menu he provided–would make del.icio.us more likely to be genuinely useful. Each person who uses del.icio.us is effectively coming up with an idiosyncratic system for classifying the Web: an article about, say, Dallas Mavericks owner Mark Cuban might be tagged “Mavericks” by one person, “crazy” by another, and “Mavericks” <i>and</i> “crazy” by a third. (Del.icio.us allows users to pin as many tags on a page as they want.) “If you’re trying to tag a page in a way that’ll get you back there someday, you want to use your vocabulary, not someone else’s,” he says. <br></p>  <p>Though del.icio.us has become a way for users to collectively organize information across the Web, it did not begin as anything so grand. Rather, it emerged as a way to help individuals manage their own information. “For a system to be successful, the users of the system have to perceive that it’s directly valuable to them,” Schachter says. “If you need scale in order to create value, it’s hard to get scale, because there’s little incentive for the first people to use the product. Ideally, the system should be useful for user number one.” This makes del.icio.us different from systems that rely on what economists call “network externalities”–meaning they’re valuable only if lots of people use them. It was hard to get the first person to buy a fax machine, because a fax machine is useless if you’re the only one who has one. But even for the first person to use del.icio.us–Schachter–it worked. <br></p>  <p>As it happens, lots of people found del.icio.us valuable right from the start, making it a proverbial grassroots hit. Schachter did no advertising, no marketing. But the site was so successful that in 2005 he quit his day job at Morgan Stanley, raised some money from outside investors, and launched del.icio.us as a regular business. Less than a year later, Schachter sold del.icio.us to Yahoo, where he now works in the Groups business, running the site full time. <br></p>  <p>Schachter’s original focus on the individual user has never wavered, and it remains essential to the way del.icio.us works. But as more and more people started to use the site, something interesting happened: when aggregated, all those individual tags created a useful system for categorizing Web pages. On the surface, del.icio.us doesn’t seem designed to do this, since each person makes his or her own tags, and there’s no overarching authority to maintain order. But even with no one in charge, the product of all the individual decisions of del.icio.us’s users is surprisingly well organized–and surprisingly intelligent. That is, if you do a search on del.icio.us for all the pages that are tagged with a particular word, you’re likely to come up with a remarkably good–and well-rounded–selection of related Web sources. In other words, although del.icio.us didn’t need lots of users to be useful, once it had lots of users, it became valuable in an entirely new way. Almost accidentally, it became an excellent tool for making sense of the Web. <br></p>  <p>What del.icio.us’s users were creating–without necessarily knowing they were doing so–was what technology blogger Thomas Vander Wal has dubbed a “folksonomy,” a flexible system of organization that emerges organically from the choices users make. We’re all familiar with the alternative, the kind of rule-bound, top-down classification scheme that Internet theorist Clay Shirky calls “ontological” in nature. The Dewey decimal system is an example: every object is assigned its place in a hierarchical system of organization, and every object is defined as, ultimately, one thing: a book goes in one place in the library and nowhere else. In a folksonomy, by contrast, definitions are fuzzier. With del.icio.us, the same Web page has many different tags, which often aren’t even related to one another, and no explicit rules are being followed. Web pages are therefore listed not in one place but in many places, and sometimes pages aren’t quite where you might expect them to be. So folksonomies are messier than “ontologies” are. <br></p>  <p>What del.icio.us has shown, though, is that folksonomies’ imperfections are outweighed by their benefits. In the first place, folksonomies are dynamic rather than static. A Web folksonomy thus allows us to reclassify content according to our changing interests. An academic paper that’s interesting today might be equally interesting a decade from now–but why it’s interesting, why people care about it, might be very different. A traditional categorization system has a hard time dealing with this: once the essence of an object is defined, it’s supposed to be defined for good. In a folksonomy, the reclassification happens almost automatically–as people start tagging the paper with new, more relevant tags, for example. Web folksonomies are also better at capturing the multiple meanings and uses that a given site has, rather than constraining the possible range of meanings. It’s useful, after all, to learn that many people have tagged stories about Mark Cuban “crazy,” in addition to indicating everything else that’s important about him. Finally, folksonomies are cheap. Imagine the labor and the time it would take to construct a traditional organizing system for all the pages on the Web, and then to maintain and update it. Then recognize that del.icio.us is producing a ceaselessly revised organizing system–at almost no cost. <br></p>  <p>The real magic of folksonomies–and the reason sites like del.icio.us can create so much value with so little hired labor–is that they require no effort from users beyond their local work of tagging pages for themselves. It just happens that the by-product of that work is a very useful system for organizing information. This distinguishes del.icio.us from other high-profile Web 2.0 sites like Wikipedia and Digg, which people contribute to without reaping any obvious personal benefit. <br></p>  <p>Schachter thinks the fact that del.icio.us does not rely on the selflessness of its users makes it more robust than it might otherwise be. “Im not a big believer in expecting a large number of people to act in an altruistic fashion,” he says. “You want to rely on people to do what they do.” The echoes of Adam Smith are unmistakable: del.icio.us is a system that, like a healthy market, turns individual self-interest into collective good.  <br></p>  <p>Del.icio.us now has more than 300,000 registered users, and it generates as much traffic in a single day as it did in its entire first year. But even as tagging has become an industry buzzword that businesses are straining to associate themselves with, Schachter is confronting the fact that the vast majority of people on the Web don’t tag at all–and probably have never even heard of tagging. So how does he expand his sites audience? “You have to solve a problem that people actually have,” Schachter says. “But it’s not always a problem that they know they have, so that’s tricky.” He remains more focused on the site’s value to the individual than on its folksonomic aspects, because to him, helping individuals store and recall information is far more important than classifying the Web. And it may well be individual value that’s most likely to keep del.icio.us growing. <br></p>  <p>Regardless of what happens, Schachter has already shown that out of the seeming chaos of hundreds of thousands of independent and eccentric judgments, order and wisdom can emerge. And if you think about del.icio.us in terms of his idea of making memory scalable, he’s also helped create a rather remarkable social memory system, in which all of us are able to find more and better information than we would on our own. As Schachter puts it, “The one who stashes a page doesn’t have to be the one who ends up recalling it. Del.icio.us is a storer of one’s own attention. But it also means you can share it with others.” And that ability will only become more valuable over time. “The better you understand the world, the better you’ll do,” Schachter says. “I really think that in the end, more understanding wins.” <br></p>  <p><i>–James Surowiecki</i></p></td>
    </tr>
    <tr>
      <td>Ben Zhao</td>
      <td>Perfecting peer-to-peer networks.</td>
      <td>30</td>
      <td>University of California, Santa Barbara</td>
      <td>computing-2006</td>
      <td><p>Ben Zhao wants to improve the Internet by letting new networks piggyback on top of it.  <br></p>  <p>Zhao creates structured overlay networks. These peer-to-peer networks are like the ones file-sharing services use, routing data directly between individual users over the Internet. But instead of allowing any computer in the network to talk to any other, structured overlays have strict rules about which machines may talk to which. This allows them to route data more efficiently and to detect and sidestep failures more quickly. “Everything is about resiliency and recovery and robustness,” Zhao says. <br></p>  <p>As a graduate student at the University of California, Berkeley, Zhao wrote Tapestry, a series of networking protocols that was one of the first structured overlay networks. Some of his Berkeley colleagues built an application called OceanStore that uses Tapestry to provide cheap, reliable, global-scale data storage. Since then, Zhao and others have developed a host of programs that take advantage of Tapestry.  <br></p>  <p>Now an assistant professor at UC Santa Barbara, Zhao is working to make structured overlay networks more secure. With companies such as Microsoft interested in the technology, his success could mean practical networks that manage and heal themselves.  <br></p></td>
    </tr>
    <tr>
      <td>Parham Aarabi</td>
      <td>Sharpening a computers listening skills.</td>
      <td>29</td>
      <td>University of Toronto</td>
      <td>computing-2005</td>
      <td><p>Computers have difficulty doing what the brain does easily: concentrating on one voice while ignoring other sounds. University of Toronto electrical-engineering professor Parham Aarabi created an algorithm that calculates the difference between the times at which a sound reaches two closely spaced microphones. Based on the delay, the software can determine the direction of speakers and amplify the speech of any one of them; all other conversation is reprocessed into a slight hum. Aarabis invention, which is 30 percent more accurate than other multimicrophone systems, could filter out extraneous voices in cell-phone conversations or enhance voice control in cars.</p></td>
    </tr>
    <tr>
      <td>Regina Barzilay</td>
      <td>Teaching computers to read and write.</td>
      <td>34</td>
      <td>MIT</td>
      <td>computing-2005</td>
      <td><p>For her doctoral dissertation at Columbia University, computer scientist Regina Barzilay led the development of Newsblaster, which does what no computer program could do before: recognize stories from different news services as being about the same basic subject, and then paraphrase elements from all of the stories to create a summary.  Though humans can easily divine the meaning of a word from its context, computers cannot. Barzilay uses statistical machine-learning software to teach computers to make educated guesses. A computer is fed pairs of text samples that it is told are equivalent – two translations of the same sentence from Madame Bovary, say. The computer then derives its own set of rules for recognizing matches. Once trained, it can tackle new sentences, computing “syntactic trees” that parse out their structural elements in different ways and determining the probability that each interpretation is correct. Then it statistically compares the most likely trees from two sentences to see if they match. The Newsblaster software recognizes matches about 80 percent of the time.  The software works best with news stories, because they exhibit some regularity; “the problem is more constrained,” says Barzilay, now an MIT assistant professor of electrical engineering and computer science. Shes working on a variation of Newsblaster for spoken language, which could yield applications that range from summarizing recorded lectures to handling airline reservation calls.</p></td>
    </tr>
    <tr>
      <td>Stewart Butterfield</td>
      <td>Building communities through photos.</td>
      <td>32</td>
      <td>Flickr (Yahoo)</td>
      <td>computing-2005</td>
      <td><p>In February 2004, Stewart Butterfield and his coworkers at Ludicorp, then engaged in developing an online game, launched a side product called Flickr – “kind of on a lark.” By summer, the project had taken over the company; today its the Webs fastest-growing photo-sharing site. Employing “tags” that allow people to make their photos searchable by content, Flickr encourages users to engage in discussions about their pictures. Acquired by Yahoo in March, Flickr now has more than one million users, who post hundreds of thousands of new photos a day.</p></td>
    </tr>
    <tr>
      <td>George Candea</td>
      <td>Protecting software from crashes</td>
      <td>30</td>
      <td>Aster Data Systems</td>
      <td>computing-2005</td>
      <td><p>As counterintuitive as it might seem, George Candeas “crash-only software” concept may actually help keep software crash free. According to Candea, software crashes and subsequent reboots neednt be catastrophic, systemwide events. He has described software that can be trained to monitor itself and, if it detects something amiss, to launch a surgical, or “micro,” reboot of just the problematic application element, while the system as a whole functions uninterrupted. “Microrebooting allows software to react to failure in machine time as opposed to human time,” says Candea, who recently got his doctorate in computer science at Stanford University.</p></td>
    </tr>
    <tr>
      <td>Bryan Cantrill</td>
      <td>Tracing software in real time.</td>
      <td>31</td>
      <td>Sun Microsystems</td>
      <td>computing-2005</td>
      <td><p>Even with all the recent advances in information technology, systems administrators are still running blind: if a piece of software doesnt quite do what it should, administrators may spend days hunting down the problem and figuring out how to fix it. Bryan Cantrill, senior staff engineer at Sun Microsystems, has created an application called DTrace that offers real-time software diagnostics – giving IT folks a way to see whats going on and start improving performance in minutes. This kind of power elates many programmers. “With DTrace,” says Cantrill, “I can walk into a room of hardened technologists and get them giggling.”</p></td>
    </tr>
    <tr>
      <td>Andy Carvin</td>
      <td>Bringing Internet power to the have-nots.</td>
      <td>34</td>
      <td>Digital Divide Network</td>
      <td>computing-2005</td>
      <td><p>As founding editor in 1999 and current director of the Digital Divide Network, Andy Carvin has helped build an online community of more than 7,500 technology activists, educators, small-business owners, and policy makers. Their mission is to devise remedies for the fundamental information-age inequity: most people in the world lack the ability to access the Internet or the skills to use it. Carvin is also promoting a way for technology to give voice to the disenfranchised: mobcasting.  Carvins idea is to combine the ubiquity of cell phones with the ease of posting information to Web logs (blogs). Say protesting human-rights activists get roughed up by police, with no traditional media on hand to record their plight. Over their phones, the human-rights activists could send multiple reports on whats happening – either audio or video – to the same website. Carvin is pushing programmers to create mobcasting software that works outside the U.S. phone system. With the use of mobcasting, suggests Carvin, “suddenly, the very people who are victims are empowered to bear witness to the world almost instantaneously.”</p></td>
    </tr>
    <tr>
      <td>Narashima Chari</td>
      <td>Setting the mesh networking standard.</td>
      <td>31</td>
      <td>Tropos Networks</td>
      <td>computing-2005</td>
      <td><p>In the late 1990s, when Wi-Fi-equipped laptops were still a novelty, Narasimha Chari saw the possibility of creating large communications infrastructures using wireless mesh networks – which at the time were the exclusive province of the military. In 18 months of moonlighting while a physics grad student at Harvard University, he created elegant algorithms that tailored mesh networking for routine civilian communications.  Tropos Networks, the company Chari founded in 2000 with coinventor Devabhaktuni Srikrishna, helped launch commercial wireless mesh networking. With their straightforward installation – routers attach to lampposts – and attendant low cost, mesh networks have eased into plentiful use both outdoors (on campuses, in public safety networks, and at gatherings such as festivals) and in (in hospitals and factories). But Tropos is focusing on the rapidly growing market for networks that serve entire municipalities. Thats the application of choice for one-third of the companys 200 customers.  Troposs services, which are built around Charis routing protocols, dominate the nascent mesh-networking industry. Telecommunications companies fear the proliferation of the technology, seeing it as a threat to their Internet access businesses. In fact, the telecommunications industry is lobbying for legislation granting them – not local governments – first dibs on municipal Wi-Fi installations. Meanwhile, Tropos is gaining customers at a rapid clip; 75 signed on in the first half of 2005.  Troposs expansion is bringing Chari full circle. In 1992, after receiving the third-highest score out of 80,000 on the Indian Institutes of Technology entrance exam, Chari left India for Caltech. Later, while at Harvard, he had late-night talks with Caltech pal Srikrishna about providing anytime, anywhere communications in developing countries. Now, as Tropos ships its first systems to India, Chari is seeing his innovation connect back to his homeland.</p></td>
    </tr>
    <tr>
      <td>Bram Cohen</td>
      <td>Upending the file-sharing world, bit by bit.</td>
      <td>29</td>
      <td>BitTorrent</td>
      <td>computing-2005</td>
      <td><p>Bram Cohens creation, BitTorrent, answers a deceptively simple question: if someone requests a file over a network, and multiple people on the network possess the file, why should only one person send the file in its entirety to the requester? Cohens revolutionary solution: send tiny chunks of the file from multiple users, eliminating the bandwidth crunch that results when a single user sends a large file in its entirety. A 400-megabyte video file that could take hours for a single user to distribute can be broken up into thousands of pieces, each of which takes only a few seconds to send. The impact of the technology that Cohen developed goes far beyond the world of illicit file-swapping: game companies and Linux developers are now experimenting with BitTorrent distribution as well.  Cohen is humble about his creation and its potential impact. It is, he says, “just a way to move bits around.”</p></td>
    </tr>
    <tr>
      <td>Dennis Crowley</td>
      <td>Moving online socializing into the streets</td>
      <td>29</td>
      <td>Dodgeball</td>
      <td>computing-2005</td>
      <td><p>When Dennis Crowley goes out clubbing in New York, hell text a message with his location to Dodgeball, the company that he founded. Crowleys message – “@ Luna Lounge,” for example – goes out to all the friends he has listed at the Dodgeball website. The companys computer checks the clubs address against its list of geographical locations in 22 cities. If someone who is not on Crowleys friend list but is on the list of one of his friends has checked in within the last three hours and a 10-block radius, the computer notifies both parties. If Crowley has listed a girl he doesnt know as a “crush,” shell get a message with his picture saying hes interested. Shell have the option to find him or dodge him, without his ever knowing where she is. Google liked the idea so much it bought Dodgeball in May. Crowley says its “a very powerful thing to know where your friends are all the time.”</p></td>
    </tr>
    <tr>
      <td>Tracey Ho</td>
      <td>Scrambling bits for a more efficient Internet.</td>
      <td>29</td>
      <td>Caltech</td>
      <td>computing-2005</td>
      <td><p>Todays Internet transmissions chop files into packets, each of which is passed from router to router until it reaches its final destination. But when files get big or are sent to many users, transmitting them without clogging the network becomes complicated. With “network coding,” an idea first proposed in 2000, routers would jumble together the bits from different packets, forming new packets. Recombining the data in this way gives the end user additional information, theoretically speeding downloads and increasing network capacity. But early network coding schemes required a godlike central authority that knew how the packets were to be combined – a practical impossibility.  As a PhD student at MIT, Tracey Ho had a novel alternative: let network nodes mix packets together at random, tagging them with just enough information to help end users computers recover the original data. This decentralized method automatically optimizes bandwidth use. “It sounds kind of insane,” says Muriel Medard, Hos PhD advisor. “But its not just that it works; you cant make it work better.” As an assistant professor of electrical engineering and computer science, Ho still studies network coding. But only months after she first presented her “distributed random network coding” scheme, Microsoft researchers showed that it can clearly outperform todays multicast systems. The company has embarked on a project called Avalanche to commercialize the scheme.</p></td>
    </tr>
    <tr>
      <td>Samuel Madden</td>
      <td>Simplifying wireless sensor nets.</td>
      <td>29</td>
      <td>MIT</td>
      <td>computing-2005</td>
      <td><p>Wireless sensor networks enable the remote monitoring of everything from the habitat of an endangered bird species to a buildings response to an earthquake. The problem, says computer scientist Samuel Madden, is that proper programming of the nets data-gathering “motes” can require months of expert attention. In 2003, while a graduate student at the University of California, Berkeley, Madden created software called TinyDB that translates high-level queries like “Whats the average temperature in the forest?” into precise instructions. Madden, an assistant professor of computer science, is now installing sensors in cars to monitor operating conditions and figure out faster routes.</p></td>
    </tr>
    <tr>
      <td>David Pennock</td>
      <td>Predicting the future of markets</td>
      <td>34</td>
      <td>Yahoo Research</td>
      <td>computing-2005</td>
      <td><p>How could markets possibly be able to predict things like where a hurricane will strike? In part because they aggregate information well, says David Pennock, who studies how economic theory can be expressed via computation. Pennocks research underlies not only predictive markets but also the enormously successful sponsored search functions featured on Yahoo, Google, and elsewhere. Recommendation engines like those on Amazon.com also draw from Pennocks work. Most recently, Pennock designed a new type of market, the “dynamic pari-mutuel market,” now being offered at Yahoo Tech Buzz. Part horse racing, part futures market, it lets people bet on whether a product is a fad or for real.</p></td>
    </tr>
    <tr>
      <td>Matthew Rabinowitz</td>
      <td>Giving GPS a sharper image.</td>
      <td>32</td>
      <td>Rosum</td>
      <td>computing-2005</td>
      <td><p>Inside buildings and the urban valleys of large cities, Global Positioning System technology is often inaccurate or unusable. Matthew Rabinowitz has sharpened GPS precision by exploiting the synchronization codes embedded in broadcast television signals. These codes allow a TV receiver to compile numerous signals into a single harmonious output. Rabinowitz, who cofounded Rosum and now serves as chief technology officer, has developed a handheld device that uses sync codes to calculate how far the user is from the source of the signals and thus determine his or her location. The Rosum technology refines GPS position readings to within a meter or two, even indoors and in cities.</p></td>
    </tr>
    <tr>
      <td>Jonathan Abrams</td>
      <td>Created the Nets top social-networking site, where eight million people communicate with friends and friends of friends.</td>
      <td>34</td>
      <td>Founder and chairman, Friendster</td>
      <td>computing-2004</td>
      <td><p>The Mountain View, CA, firm has raised $14 million in venture capital.</p></td>
    </tr>
    <tr>
      <td>Guido Appenzeller</td>
      <td>Started a Palo Alto, CA, firm to commercialize an encryption technology that uses a simple ID, such as an e-mail address, to ensure secure communications.</td>
      <td>33</td>
      <td>Founder and chief technology officer, Voltage Security</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Alyssa Apsel</td>
      <td>Adapts optical-communications technology to build receivers, transmitters, and interconnects that speed chip-to-chip communications within computers.</td>
      <td>31</td>
      <td>Assistant professor, Cornell University</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Anuj Batra</td>
      <td>Leads one of the industrys top teams advancing ultrawideband wireless technology, which provides the high transmission speeds needed for streaming-media applications while consuming little power.</td>
      <td>34</td>
      <td>Systems engineer, Texas Instruments</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Serge Belongie</td>
      <td>Created video software to analyze lab mice for adverse reactions to trial drugs.</td>
      <td>30</td>
      <td>Assistant professor,University of California, San Diego</td>
      <td>computing-2004</td>
      <td><p>The system is related to fingerprint-matching technology he and Vance Bjorn (see below) founded DigitalPersona to commercialize.</p></td>
    </tr>
    <tr>
      <td>Vance Bjorn</td>
      <td>Partnered with fellow TR100 honoree Serge Belongie (see above) to found a Redwood City, CA, biometrics company that specializes in fingerprint recog-nition for computer access.</td>
      <td>31</td>
      <td>Chief technology officer and cofounder, DigitalPersona</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>David Brussin</td>
      <td>Built a router that examines the content and source of messages passing through it.</td>
      <td>29</td>
      <td>Cofounder, TurnTide</td>
      <td>computing-2004</td>
      <td><p>All e-mail is handled by a set of rules that determines how messages get from one point to another. David Brussin, cofounder and chief technology officer of TurnTide (recently acquired by Symantec), turned those rules against spammers by building a router that examines the content and source of messages passing through it. When Brussins router identifies a computer thats sending spam, it reduces the number of messages that computer can send out. According to Brussin, companies using the TurnTide router see spam drop by about 90 percent.</p></td>
    </tr>
    <tr>
      <td>J. J. Cadiz</td>
      <td>Invented a better approach to alleviating information overload.</td>
      <td>29</td>
      <td>Program manager, Microsoft</td>
      <td>computing-2004</td>
      <td><p>Invented a better approach to alleviating information overload, using a sidebar window on computer displays to track e-mail alerts, weather reports, and other data. Look for Sideshow in future versions of Windows.</p></td>
    </tr>
    <tr>
      <td>Tianqiao Chen</td>
      <td>Specializes in multiplayer fantasy and role-playing games.</td>
      <td>31</td>
      <td>CEO and cofounder, Shanda Interactive Entertainment</td>
      <td>computing-2004</td>
      <td><p>Built his Shanghai startup into Chinas largest online game company by specializing in multiplayer fantasy and role-playing games that now attract millions of users. Shandas IPO last May raised $152 million.</p></td>
    </tr>
    <tr>
      <td>Aref Chowdhury</td>
      <td>Invented techniques at Bell Labs that enable higher-speed transmission of data over very long distances (up to 6,400 kilometers) within fiber-optic networks.</td>
      <td>32</td>
      <td>Member of technical staff, Lucent Technologies</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Raffaele Colombelli</td>
      <td>Develops new types of quantum cascade microlasers with a variety of sensing and imaging applications.</td>
      <td>33</td>
      <td>Research staff member, University of Paris-Sud</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Adrian Colyer</td>
      <td>Leads the effort to improve software quality and cut development costs.</td>
      <td>33</td>
      <td>Senior technical-staff member, IBM</td>
      <td>computing-2004</td>
      <td><p>Leads IBMs Winchester, England-based effort to improve software quality and cut development costs through “aspect-oriented programming,” an approach that promises to simplify coding for a wide range of applications.</p></td>
    </tr>
    <tr>
      <td>Robert Drost</td>
      <td>Pioneered a wireless technology to eliminate the wired connections between closely spaced chips in computer systems.</td>
      <td>34</td>
      <td>Principal investigator, Sun Microsystems</td>
      <td>computing-2004</td>
      <td><p>The advance, enabling a 100-fold speed gain over wired connectors, will be crucial to future Sun supercomputers.</p></td>
    </tr>
    <tr>
      <td>Robert Frederick</td>
      <td>Helping to lead Amazons transformation, with its own virtual vending machines.</td>
      <td>31</td>
      <td>Senior technical manager, Amazon.com</td>
      <td>computing-2004</td>
      <td><p>You probably think of Amazon.com as a place to buy everything from books to kitchenware. But thats only a part of what the company aspires to be. Programmer Robert Frederick is leading Amazons transformation into something more like the Coca-Cola of e-commerce, with its own virtual vending machines – each a gateway to Amazons entire inventory – scattered across thousands of third-party websites. Its all part of a grand vision starring Amazon as the Webs central platform for almost any kind of online purchase. Frederick got his start at the company five years ago by building Amazon Anywhere, software that prepares data from Amazons vast product database for display on cell phones and other mobile devices. From there, it was a short conceptual step to opening up Amazons database to any independent Web merchant or programmer with a need for product information. And the resulting tools – a set of standardized commands for interacting with Amazons database, built around XML and other new Web standards for describing content – have allowed outsiders to soup up their businesses with a range of Amazon services.  More than 60,000 Web developers have signed up to use Amazons new services, with many hoping to bring new customers to their sites – and earn a commission of up to 10 percent on every sale.</p></td>
    </tr>
    <tr>
      <td>Dan Gruhl</td>
      <td>Serves as chief architect for IBMs WebFountain system.</td>
      <td>32</td>
      <td>Research staff member, IBM</td>
      <td>computing-2004</td>
      <td><p>Serves as chief architect for IBMs WebFountain system, which identifies patterns in and extracts meaning from billions of Web pages to aid business decisions and fraud detection.</p></td>
    </tr>
    <tr>
      <td>Ali Hajimiri</td>
      <td>Developed an entire radar system, squeezed into a single chip.</td>
      <td>32</td>
      <td>Cofounder, Axiom Microdevices</td>
      <td>computing-2004</td>
      <td><p>By squeezing an entire radar system onto a single chip, Ali Hajimiri may have brought us closer to the day when even a low-end car can “see” through fog. Earlier, the Caltech electrical-engineering professor found a way to fabricate a multiwatt amplifier on inexpensive silicon with no external components – a development that could result in smaller, cheaper, less power-hungry single-chip cell phones and led him to start Axiom Microdevices of Orange, CA.</p></td>
    </tr>
    <tr>
      <td>Scott Heiferman</td>
      <td>Built a database and developed software that would help people organize themselves.</td>
      <td>32</td>
      <td>Cofounder and CEO, Meetup.com</td>
      <td>computing-2004</td>
      <td><p>In the wake of September 11, Scott Heiferman felt the need to find new ways to build community. He knew that Americans no longer belonged to bowling leagues and Elks Clubs in the numbers that they once had, but he didnt feel that electronic chat rooms and Internet personal ads filled the void. “People still live in the real world, the real non-cyber world, where they want to be face to face,” he says. “The idea was, How do you use the Internet to get people off the Internet?” <br></p>  <p>So in early 2002, he assembled a five-person team to build a database and develop software that would help people organize themselves. People sign up at the Meetup.com site, indicating where they live and what topics theyre interested in, and when a certain number of like-minded people in the same area have registered, the site announces a meeting. About 190,000 supporters of Howard Deans presidential campaign used Meetup.com to organize in the months before the Iowa caucuses, giving his campaign early momentum. About 170,000 people are now registered for meetings of Democracy for America, an organization that grew out of Deans campaign. Today, Meetup.com has more than 1.4 million registered users, and revenues at the privately funded company are seven times what they were a year ago. <br></p>  <p>Heiferman can get passionate about his theme of bringing people together, invoking de Tocqueville on the importance to Americans of forming associations and even citing an evolutionary imperative. “Were a species who was optimized for face-to-face interaction,” he says. Meetups innovations, he adds, are “as much in social engineering as software engineering.” <br></p>  <p>Heiferman has been an entrepreneur since about age nine, when he founded Scotts Slave Service to market menial tasks to his siblings. And his sense of community engagement began to blossom the next year, when he wrote what he calls a “pointless letter to every U.S. governor, major-city mayor, and Fortune 100 CEO.” <br></p></td>
    </tr>
    <tr>
      <td>Michael Helmbrecht</td>
      <td>Fabricates microscopic, deformable mirrors on computer chips that perform image correction for medical imaging, surveillance, and other applications.</td>
      <td>34</td>
      <td>Founder and CEO, Iris AO</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Aaron Hertzmann</td>
      <td>Combines machine learning and graphics to capture the motion of actors, dancers, and athletes -- and to generate realistic animations for films and video games.</td>
      <td>30</td>
      <td>Assistant professor, University of Toronto</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Kurt Huang</td>
      <td>Launched a startup developing micropayments technology that allows artists, small businesses, and others to charge fees of as little as one cent for access to online content.</td>
      <td>34</td>
      <td>Cofounder and president, BitPass</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Ari Juels</td>
      <td>Improved the security and privacy of radio frequency identification tags, as well as cryptographic tools for authentication systems.</td>
      <td>34</td>
      <td>Principal research scientist, RSA Security</td>
      <td>computing-2004</td>
      <td><p>Devised techniques at Bedford, MA, firm to improve the security and privacy of radio frequency identification tags, as well as cryptographic tools for authentication systems based on personal information and biometrics.</p></td>
    </tr>
    <tr>
      <td>Richard Kent</td>
      <td>Produces biomechanical data vital to the design of air bags and auto safety systems.</td>
      <td>34</td>
      <td>Assistant professor, University of Virginia</td>
      <td>computing-2004</td>
      <td><p>Produces biomechanical data vital to the design of air bags and auto safety systems that adjust during a crash, customizing protection to such factors as the passengers size, weight, and physical condition.</p></td>
    </tr>
    <tr>
      <td>Andre Kulzer</td>
      <td>Created a thermodynamic simulation that showed the feasibility of gasoline direct injection, which lowers auto fuel consumption and emissions and eliminates the electric starter.</td>
      <td>29</td>
      <td>Research engineer, Bosch</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Golan Levin</td>
      <td>Explores the artistic implications of information technology.</td>
      <td>32</td>
      <td>Assistant professor, Carnegie Mellon University</td>
      <td>computing-2004</td>
      <td><p>For Dialtones: A Telesymphony, the artist and engineer choreographed the ringing of audience cell phones.</p></td>
    </tr>
    <tr>
      <td>Massimo Marchiori</td>
      <td>Develops more efficient ways of identifying, finding, and retrieving information on the Web.</td>
      <td>34</td>
      <td>Professor, University of Venice</td>
      <td>computing-2004</td>
      <td><p>The computer scientist also developed the World Wide Web Consortiums Internet privacy standards.</p></td>
    </tr>
    <tr>
      <td>Wojciech Matusik</td>
      <td>Creates 3-D television and related 3-D photo and video systems that weave together images from multiple cameras.</td>
      <td>31</td>
      <td>Visiting research scientist, Mitsubishi Electric</td>
      <td>computing-2004</td>
      <td><p>Uses sophisticated computer graphics and image-rendering techniques at Mitsubishi Electrics Cambridge, MA, lab to create 3-D television and related 3-D photo and video systems that weave together images from multiple cameras.</p></td>
    </tr>
    <tr>
      <td>James OBrien</td>
      <td>Invented algorithms for simulating natural phenomena such as splashing water and explosions, for use in movies, video games, and advanced training simulations.</td>
      <td>34</td>
      <td>Assistant professor, University of California, Berkeley</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Nuria Oliver</td>
      <td>Constructs more-intuitive human-computer interfaces.</td>
      <td>33</td>
      <td>Researcher, Microsoft</td>
      <td>computing-2004</td>
      <td><p>The Spanish natives projects include a smart office that can recognize what its occupants are doing and a system that lets users interact with computers via hand gestures.</p></td>
    </tr>
    <tr>
      <td>Maria Petrucci-Samija</td>
      <td>Created materials that might soon make such integrated photonic circuits possible.</td>
      <td>33</td>
      <td>Photonics R&D program leader, DuPont</td>
      <td>computing-2004</td>
      <td><p>The Internet would be even faster and cheaper if more components of the fiber-optic network could be combined on individual chips – in much the way that computers evolved from room-sized monstrosities to desktop machines when transistors were condensed onto integrated circuits. Chemist Maria Petrucci-Samija has created materials that might soon make such integrated photonic circuits possible.  The problem with putting multiple optical components on a single chip is that different components work best when built from different, often incompatible materials. Silica glass is great for shunting a beam of light from one place to another,  but its not so good at modulating a signal so that it carries information. Petrucci-Samija has shown that plastics can be molecularly tailored to combine the best of all worlds. “Its really trying to figure out at the atomic level what is necessary to do that,” she says.  Petrucci-Samija figured it out well enough to produce a polymer as transparent as the best optical glass; this helped the company she worked for, Lumenon Innovative Lightwave Technology, create the first polymer versions of several optical-communications components. Petrucci-Samijas work continues at DuPont, where she heads a team striving to develop new plastics and to combine plastic and silica glass devices on individual chips. She hopes to have marketable components ready for use in optical networks in about three years.  Petrucci-Samija says the first use of integrated photonic circuits will most likely be to make network communications more reliable and bring down the cost of equipment. Eventually, though, the same approach could help realize the dream of superfast optical computers.</p></td>
    </tr>
    <tr>
      <td>Ramesh Raskar</td>
      <td>Built large computer display systems that seamlessly combine images from multiple projectors.</td>
      <td>34</td>
      <td>Visiting research scientist, Mitsubishi Electric</td>
      <td>computing-2004</td>
      <td><p>The computer scientists image-processing and graphics research may lead to new applications in entertain-ment, image-guided surgery, and user interfaces.</p></td>
    </tr>
    <tr>
      <td>Jennifer Rexford</td>
      <td>Created tools for monitoring and automatically managing Internet traffic on large networks.</td>
      <td>34</td>
      <td>Senior technical consultant, AT&T</td>
      <td>computing-2004</td>
      <td><p>The computer scientists innovations are used in several systems, including AT&amp;Ts commercial backbone network.</p></td>
    </tr>
    <tr>
      <td>Sokwoo Rhee</td>
      <td>Designed extremely-low-power wireless-sensor networks.</td>
      <td>34</td>
      <td>Founder and chief technology officer, Millennial Net</td>
      <td>computing-2004</td>
      <td><p>Designed extremely-low-power wireless-sensor networks at Burlington, MA, startup. The companys dime-sized sensor nodes can be used for environmental monitoring, surveillance, and health-care applications where inexpensive, long-term data collection and control are key.</p></td>
    </tr>
    <tr>
      <td>Shad Roundy</td>
      <td>Built tiny generators for wireless sensor networks that convert low-level background vibrations into electricity, eliminating the need for batteries.</td>
      <td>33</td>
      <td>Lecturer, Australian National University</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Jesse Schell</td>
      <td>Invents new forms of digital visualization.</td>
      <td>34</td>
      <td>Professor, Carnegie Mellon University</td>
      <td>computing-2004</td>
      <td><p>The professor of entertainment technology teaches game design and heads simulation projects, including one that helps firefighters deal with terrorism.</p></td>
    </tr>
    <tr>
      <td>Kees Schep</td>
      <td>Helped develop blue-laser optical-disc storage systems with much greater capacity than todays DVDs. The discs are now being introduced commercially.</td>
      <td>34</td>
      <td>Department head, Philips Electronics</td>
      <td>computing-2004</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>John Apostolopoulos</td>
      <td>Develops ways to improve the security of streaming video on the Net.</td>
      <td>35</td>
      <td>Hewlett-Packard</td>
      <td>computing-2003</td>
      <td><p>The only TR100 innovator who can also say he’s an Emmy Ward winner is John Apostolopoulos. An MIT graduate student, he helped develop the video compression system that was integrated into the U.S. Digital TV standard for high-definition television, for which he received a Technical Emmy in 1997. That year Apostolopoulos joined Hewlett-Packard Laboratories, aiming to improve the fidelity and security of streaming video- video sent through the Internet in continuous flows of data packets. The internet is vulnerable to errors, or even attacks, that can keep those packets from their destinations, so Apostolopoulos designed a technique for sending video information across multiple paths simultaneously rather than relying on a single path. Interruption of one path doesn’t kill the transmission because the missing video can be recovered using the stream from another path. Meanwhile, a security-conscious U.S. government agency, which Apostolopoulos prefers not to identify, is evaluating a method he codeveloped for encrypting media streams so they can be carried by diverse networks and then adapted for viewing on diverse devices. Now a senior research scientist, Apostolopoulos has begun to tackle streaming-media schemes for wireless networks.</p></td>
    </tr>
    <tr>
      <td>Brian Behlendorf</td>
      <td>Sparked the widespread development of Web servers, mainstreaming the nascent Web.</td>
      <td>30</td>
      <td>CollabNet</td>
      <td>computing-2003</td>
      <td><p>Few people have had as broad an impact on the Web’s development as Brian Behlendorf. In 1993, while an undergraduate at the University of California, Berkeley, Behlendorf set up wired.com, one of the earliest non-academic Web sites. In 1994 he led the team that built hotwired.com, the first ad-supported site. That same year, Behlendorf contributed to the development of the Virtual Reality Modeling Language, which added animation, music, and video to what had been a text-laden Web. But Behlendorf’s most important contribution came in 1995 when he founded the Apache Web Server Project, which sparked the proliferation of university and commercial server computers. Apache is a freely available, Unix-based Web server program that is now used to host more than 65 percent of the world’s Web sites; it is unquestionably one of the most important open-source projects in the history of computing. The Apache Software Foundation, which Behlendorf let for three years, now has 700 developers working on 120 projects to improve the Web. In 1999, Behlendorf founded CollabNet, a software firm in Brisbane, CA, that offers Web collaboration toolsl to help companies write software more efficiently.</p></td>
    </tr>
    <tr>
      <td>Jud Bowman</td>
      <td>Wrote software that is accelerating the expansion of wireless networking.</td>
      <td>22</td>
      <td>Pinpoint Networks</td>
      <td>computing-2003</td>
      <td><p>Steve Nelson, a venture capitalist and chairman of Durham, NC,-based Pinpoint Networks, says Jud Bowman “gains knowledge in the morning that becomes great business judgment in the afternoon.” Bowman exercises that judgment as Pinpoint’s founder and CEO. In 1999 Bowman deferred undergraduate admission to Stanford University to launch Pinpoint with a high-school friend. The company’s initial offering was a search engine that helped cell-phone users find wireless-data applications such as internet-messaging software. But Bowman quickly recognized that incompatibilities among handsets and service providers were stymieing wireless networking. So Pinpoint created Fuel- a software platform that acts as a mediator, feeding wireless applications from just about any network to just about any headset. Bowman believes Fuel could accelerate the wireless market; he raised $20 million in capital and has licensed Fuel to cellular giants Verizon Wireless and U.K.- based mm02. Fuel faces fierce competition from rival startups, telecommunications companies, and hand-set makers, but Bowman shows little strain, finding time to play viola in the Raleigh (NC) Symphony Orchestra. He never did find time for college.</p></td>
    </tr>
    <tr>
      <td>Lorrie Cranor</td>
      <td>Leads the global effort to improve privacy practices and tools on the Web.</td>
      <td>32</td>
      <td>AT&T</td>
      <td>computing-2003</td>
      <td><p>In high school, the artistic Lorrie Cranor has no interest in a computer career, but today she is chair of the World Wide Web Consortium’s Platform for Privacy Preferences Project (P3P). P3P, a high-profile collection of Internet protocols released in 2002, has been adopted by more than 500 companies and will soon be added to more than 400 U.S. government sites. It allows Web sites to produce machine-readable privacy statements free of legal jargon, and enables browsers to interrogate these privacy policies automatically whenever they access the Web pages. Both the Netscape and Internet Explorer browsers have adopted P3P and take it a step further by blocking third-party cookies- those files Web sites plant on visitors’ hard drives to send back data. Discussion of P3P’s specifications began within the consortium in 1997, and Cranor, a leader in privacy research at AT&amp;T who holds a doctorate of science in engineering and policy, steered representatives from industry, government, and academia toward consensus.</p></td>
    </tr>
    <tr>
      <td>Jason Hill</td>
      <td>Wrote software that allows hundreds of minute wireless sensors to communicate better.</td>
      <td>26</td>
      <td>JLH Labs</td>
      <td>computing-2003</td>
      <td><p>When sandstorms raged during the 2003 Iraq war, coalition forces stalled because they could not track enemy movement. Small wireless sensors scattered across terrain could in principle do the tracking instead- and Jason Hill, a PhD in electrical engineering and computer science, has created free software called TinyOS that greatly reduces the cost of setting up and running such a sensor network. Sensors in previous networks relayed information about acoustic vibrations or magnetic fields along predetermined paths to base stations. TinyOS allows the sensors to pass messages to any nearby peer as needed. The system can survive if some sensors are destroyed and reduces reliance on costly base stations, making for quicker deployment and greater flexibility. Today, 80 companies, including Intel and Bosch, use TinyOS in everything from military surveillance to energy monitoring. Last year Hill cofounded Dust in Berkeley, CA, to build custom network applications, some already sold to Honeywell to help grocery stores monitor power usage, and he has now started his own firm, JLH Labs in Capistrano Beach, CA.</p></td>
    </tr>
    <tr>
      <td>Meg Hourihan</td>
      <td>Sparked the rise of the popular Web-based journals known as blogs.</td>
      <td>31</td>
      <td>The Lafayette Project</td>
      <td>computing-2003</td>
      <td><p>Meg Hourihan didn’t intend to start a revolution when she cofounded the San Francisco Web application company Pyra Labs with fellow TR100 honoree Evan Williams in 1999. The duo, along with programmer Paul Bausch, created the pioneering application Blogger. Web logs, or “blogs,” are frequently updated, Web-based journals kept by individuals or groups; they have become wildly popular, with people around the globe now posting Web links, political commentary, or even diaries on them. Before Blogger, one had to be fluent in HTML code- and rent server space- in order to put up a Web log. Blogger removed this barrier with a simple interface that allows anyone to create a Web log, hosted free on Pyra’s servers. Today, Blogger has more than one million registered users. After leaving Pyra Labs in 2001, Hourihan cofounded the Lafayette Project in New York City, where she directs development of a Web-based search tool to help manage the growing glut of blogs. Last February, Pyra Labs was bought by search engine giant Google, where Blogger and its servers live on.</p></td>
    </tr>
    <tr>
      <td>Paul Q. Judge</td>
      <td>Wrote software that stops spam and viruses before they enter a network.</td>
      <td>26</td>
      <td>CipherTrust</td>
      <td>computing-2003</td>
      <td><p>Where most of us see a nuisance, Paul Judge sees a security threat. While working on his master’s thesis on secure content distribution, Judge became employee number four at CipherTrust, an Atlanta data security startup. Judge, now chief technology officer, envisioned a clack box installed at the gateway between the Internet and a corporate or campus network that would block unwanted e-mail and viruses before they slowed productivity or destroyed data. Leading a team of 10 developers (all older than he was), Judge produced IronMail, a computer that runs a series of spam filters and virus detectors, some based on algorithms the team created. Now deployed at 700 corporations and universities, IronMail stops 95 to 98 percent of incoming spam without blocking legitimate mail, Judge says. He also founded the Spam Archive, a research storehouse of junk e-mail, and his efforts let to his appointment as the first head of the Anti-Spam Research Group within the Internet Research Task Force, a professional society. “Over the years, the anti-spam community has focused on symptom relief,” Judge remarks. “The Anti-Spam Research Group was formed to focus on a cure.”</p></td>
    </tr>
    <tr>
      <td>Rasmus Lerdorf</td>
      <td>Invented a server language that brought live data to the Web.</td>
      <td>34</td>
      <td>Yahoo!</td>
      <td>computing-2003</td>
      <td><p>Born near the North Pole on Greenland’s Disco Island, Rasmus Lerdorf has learned five languages while living around the world. But it’s the language he invented that has had global impact. In 1995, without any formal programming training, Lerdorf developed a server language to help him set up Web sites he was designing for companies. He named the language PHP, for PHP hypertext preprocessor- an acronym that contains itself. Once embedded in the Web’s basic addressing protocol, PHP solved a fundamental problem. Before PHP, Web pages were dominated by static text and pictures; creating sites that could readily incorporate up-to-date information or interact with databases was difficult. PHP made all that possible. Lerdorf offered his code free, and today companies worldwide, including Ericsson, CBS, and Yahoo!, use it as the backbone for more than 12 million sites, where it enables live financial data, news feeds, and stock tickers. Along the way, Lerdorf worked stints at IBM and Linuxcare. In September 2002, he joined Yahoo! To assist it in migrating to PHP-based tools, a move expected to speed development and reduce training costs.</p></td>
    </tr>
    <tr>
      <td>Lih Y. Lin</td>
      <td>Built micromirror switches for faster, all-optical telecommunications networks.</td>
      <td>34</td>
      <td>University of Washington</td>
      <td>computing-2003</td>
      <td><p>At about three times the diameter of a human hair, the micromechanical optical switches that Lih Lin designed for AT&amp;T in 1997 and 1998 were scarcely visible. And that miniscule machines she subsequently built solved a fundamental problem in telecommunications. Information travels at high speed over the optical fibers that form the backbones of telecom networks, but converting the optical signals to electronic bits for processing by traditional circuitry limits the network’s overall transmission rate and increases its cost. Lin introduced pivoting micromirrors that can switch light-wave signals directly, circumventing the pitfalls of electronic manipulation. Her technique has since been widely developed and is enhancing the capacity and reducing the cost of the optical-fiber network, as well as enabling faster and broader-band data and video transmission over the Internet. Lin’s work has yielded 16 patents and 120 published papers. As a newly appointed associate professor of electrical engineering at the University of Washington in Seattle, she plans to apply her knowledge of photonics and micromechanics to biotechnology to devise new kinds of imaging tools that can analyze individual cells.</p></td>
    </tr>
    <tr>
      <td>Paul Meyer</td>
      <td>Brings database and Web-like services to remote areas through touch-tone phones.</td>
      <td>33</td>
      <td>Voxiva</td>
      <td>computing-2003</td>
      <td><p>There are about 2.5 billion phones worldwide but only 600 million computers. Knowing this, Paul Meyer, a Yale Law School grad and former speechwriter for President Clinton, founded Washington, DC-based Voxiva in 2001 to help isolated communities access computing power through touch-tone telephones. Because phone use requires neither literacy not much electricity, the system benefits regions that are short on both. Launched with funding from the Markle Foundation and the World Bank, Voxiva enables users to input and retrieve information by tapping phone buttons, listening to messages, and speaking responses. In Peru, health-care workers can call a Voxiva server to submit reports about patient symptoms or disease outbreaks. Peru’s Ministry of Health has already collected 50,000 reports on threatening diseases. Meyer’s ingenuity has benefited other countries as well. Working with the international Rescue Committee in 1999, he built a wireless network that became Kosovo’s first Internet service provider. He also set up a Lotus Notes system to help reunite refugees in Guinea. Impressed with Voxiva’s performance, the U.S. government hired the company to track the effect of smallpox vaccinations on U.S. soldiers.</p></td>
    </tr>
    <tr>
      <td>Sanjay Parekh</td>
      <td>Develops software that lets companies tailor services to their customers locations.</td>
      <td>29</td>
      <td>Digital Envoy</td>
      <td>computing-2003</td>
      <td><p>Stuck behind a dial-up connection in 1999, Sanjay Parekh grew frustrated having to enter information like his city and state before he cold find store locations on, say, the Federal Express and Ikea Web sites. “These sites should already know where I am,” he thought. Rather than curse at his monitor, he formed Digital Envoy in Norcross, GA, to make his idea real. Four years later his product, NetAculty, is used by eBay, AOL Time Warner, Microsoft, and others to determine a visitor’s locality. It traces connections back thorough Internet switching stations to the network nodes where log-ons originate- almost always in a visitor’s city or town. This is close enough to give users local weather forecasts, or the addresses of nearby electronics stores, without their having to enter any data. NetAcuity also enables Web sites to automatically tailor advertisements. A billboard ad for Home Depot, for example, could announce a sale at a store near the visitor’s home. Indeed, Google uses NetAcuity to target area-specific ads. “A lot of people don’t know about us,” Parekh says, “but everyone is touched by us,”</p></td>
    </tr>
    <tr>
      <td>Vipul Ved Prakash</td>
      <td>Developed free and commercial software filters that fight spam.</td>
      <td>25</td>
      <td>Cloudmark</td>
      <td>computing-2003</td>
      <td><p>In 1997, Vipul Ved Prakash dropped out of Delhi University “for want of undisturbed coding time,” as he puts it. He then cofounded Sense/Net, one of India’s first privately owned Internet service providers, but soon encountered the scourge of spam. Customers paying by the minute for their connections complained they were wasting time deleting inwanted e-mail. So Prakash developed Vipul’s Razoe, a spam-fighting, opensource software tool available online for free. Thousands of users downloaded the “collaborative filter” program, which allowed them to keep messages or move them into spam folders. Vipul’s Razor transmitted those decisions to a central server, and if a majority of users discarded a given message, it would therefore be blocked for the entire group. After moving from New Delhi to California in 2000, Prakash worked for a time at Napster and then cofounded Cloudmark with Jordan Ritter, Napster’s former software chief. The San Francisco startup adapted Vipul’s Razor into a tool called SpamNet that today boasts 500,000 users. Initially free, it now costs $3.99 per month. “When a new person joins,” Prakash says, “they get the benefit of the entire community.” Cloudmark also markets Authority, a corporate version of SpamNet.</p></td>
    </tr>
    <tr>
      <td>Rueben Singh</td>
      <td>Provides support services and startup money for entrepreneurs.</td>
      <td>27</td>
      <td>alldayPA</td>
      <td>computing-2003</td>
      <td><p>Rueben Singh combines technology and capital to help other entrepreneurs. He started his first business- a fashion accessories shop- at age 18, and four years later, as CEO of a retail chain, he was worth millions. Relying heavily on eight assistants, he realized that most other time-strapped entrepreneurs could use the same kind of support. So in 1999, he used $6 million of his own money to found alldayPA in Manchester, England. The company uses custom  software that enables a team of live personal assistants to handle calls, manage calendars, type letters, and perform other tasks for business owners, whose customers need never know that the assistants are at a 650-seat around-the-clock call center. AlldayPA now has a database of 94,000 registered customers, who save money by not having to hire employees. Meantime, Singh’s Golden Fund, a $24 million war chest for acquiring and turning around ailing information technology companies, has aided more than a dozen businesses. The Bentley-driving CEO is helping other entrepreneurs through Dream On Attitude, a venture capital fund that invests his and other people’s cash in startups founded by innovators younger than 25.</p></td>
    </tr>
    <tr>
      <td>Martin Wattenberg</td>
      <td>Simplifies peoples electronic lives with graphical data management.</td>
      <td>32</td>
      <td>IBM</td>
      <td>computing-2003</td>
      <td><p>By the time he completed his first high-school calculus class, Martin Wattenberg had already coauthored a software package for teaching calculus using a more visual method. Since then he has employed his rare combination of mathematical and artistic talent (New York’s Whitney Museum of American Art has exhibited his computer-based art) to introduce new ways of visualizing data. At SmartMoney.com, his popular, Java-based , interactive “Map of the Market” offers investors color-coded graphical representations of market capitalization and stock activity for more than 500 companies. Rather than sifting through reams of data investors can monitor the map for real-time color changes indicating whether a stock is up or down. His current research for the Collaborative User Experience group at IBM focuses on creating a visual paradigm for electronic collaboration. One tool under development will present users with maps of their in-boxes that highlight the names of people they own mail to and can graphically trace the history of each message. Wattenberg’s innovations at IBM are still in the lab (he only joined the company last year), but his skills should help people better organize and make sense of their increasingly electronic existence.</p></td>
    </tr>
    <tr>
      <td>Andrew Wheeler</td>
      <td>Builds wireless sensor networks that improve industrial efficiency.</td>
      <td>24</td>
      <td>Ember</td>
      <td>computing-2003</td>
      <td><p>From Hawaii to Norway to Japan, Andrew Wheeler’s wireless sensor networks are providing real-time control over factory conditions, energy usage, and inventory. As a graduate student at MIT, Wheeler built small processors with built-in sensors and radios that could be spread around a factory or power plant, where they organized themselves into smart communications networks that could manage sensor information, such as temperature. Wheeler’s hardware and data-routing algorithm proved reliable in field tests, so in 2001, he cofounded Ember in Boston, one of the first companies to commercialize self-organizing nodes for wireless sensing and control. An intensely curious engineer who can “focus like a battering ram,” in the words of Michael Hawley, his advisor at MIT, Wheeler helped raise $28 million for Ember in a difficult investment climate-which has enabled the company to aggressively sell its communications nodes to customers in industry, to utility companies, and to defense contractors.</p></td>
    </tr>
    <tr>
      <td>Evan Williams</td>
      <td>Fueled the expansion of blogs across the Web.</td>
      <td>31</td>
      <td>Google</td>
      <td>computing-2003</td>
      <td><p>Evan Williams is a survivor. In early 2001 he was the sole remaining employee of Pyra labs, the San Francisco company he had cofounded with fellow TR100 honoree Meg Hourihan and programmer Paul Bausch. They had designed Blogger, a Web application that allows people to create Web logs (or “blogs”)- Web pages where users can maintain Internet journals. Blogger helped realize the promise of the Internet; that ordinary folks with no programming experience could use it to air their views. Blogger’s friendly interface- and free server space- are widely popular. After the dot-com crash, when Williams had trouble raising money to buy badly needed servers, Pyra Labs asked users for help, and they donated more than $10,000. That modest infusion was enough for the company to rally, and Blogger’s popularity skyrocketed. It currently has more than one million registered users. Williams continues to develop Blogger at search engine heavyweight Google, which bought Pyra Labs last February. He believes blogs will become “an accepted part of the media ecosystem.” Indeed, blogs have turned public attention to overlooked news, including the controversial remarks of Trent Lott (R-Mississippi) that led to his ouster as U.S. Senate majority leader.</p></td>
    </tr>
    <tr>
      <td>Jennifer Yates</td>
      <td>Wrote software widely adopted by the telecom industry that speeds up optical networks.</td>
      <td>31</td>
      <td>AT&T</td>
      <td>computing-2003</td>
      <td><p>As a graduate student, Jennifer Yates was the only optical-network researcher in her native Australia. In 1999 she took a job in the United States at AT&amp;T, where she went about rethinking the conventional method for managing optical networks, which required expensive hardware; Yates created an architecture, based on the common Internet Protocol, that uses software employed at each network node to do the same job. Previously, manual processes and centralized management computers set up each network connection and switch individually, slowing communications and introducing bottlenecks. Instead, Yates’s software is deployed across the network. Because the software can establish new connections and restore broken ones quickly, it lowers capacity demands and eliminates congestion. This network management methods is now being adopted by the telecommunications industry as the General Multi-Protocol Label Switching standard, embraced today by behemoths such as Lucent Technologies and Tellium.</p></td>
    </tr>
    <tr>
      <td>Richard Barton</td>
      <td>Internet and Web</td>
      <td>34</td>
      <td>Expedia</td>
      <td>computing-2002</td>
      <td><p>In 1994, Richard Barton devised a plan to revolutionize the travel industry. He convinced Bill Gates, his boss, that online travel planning had a future and in 1996 launched Expedia. In 1999,Barton spun the company off from Microsoft and has since grown it into a thriving dot com. Today the site receives queries from 15 million people a  month. In February, USA Networks—which owns Ticketmaster and Citysearch—acquired majority interest in Expedia for more than $1.3 billion. Barton, who helped develop the MS- DOS 5.0 and Windows 95 operating systems, says, “Our competitive differential is all about  technology. ”Under his leadership as chief executive officer, Expedia developed an award-winning algorithm that compares prices on billions of flight combinations and allows customers to find and buy the lowest fares. Barton now wants to make the customers’ transactions even easier and more secure while customizing services to each person’s buying habits. “Helping people take a trip is fundamental to our long-term dream, ”he says.</p></td>
    </tr>
    <tr>
      <td>Sergey Brin</td>
      <td>Internet and Web</td>
      <td>28</td>
      <td>Google</td>
      <td>computing-2002</td>
      <td><p>Today’s World Wide Web is a jungle. How to speedily and smartly sort through it? More than 150 million times a day, users turn to Google, the four-year-old search engine developed by a pair of Stanford University graduate students. Sergey Brin and Larry Page (p.84), PhD candidates in computer science, often found themselves stymied when hunting for data. “Innovation in search had halted,” recalls the Russian-born Brin, who had been researching data mining. Brin and Page dropped their doctoral work and came up with PageRank. The software measures the importance of a given Web page by how many other pages link to it— and by how important those linked pages are. As soon as Mountain View, CA-based Google went live in 1998,it attracted Web surfers who wanted rational search results. Today nobody lists as many Web pages (over two billion) or sorts them as fast (a typical search takes under a second).Now that Google is a success, Brin, once known as a jokester, says he has turned  serious. “Jokes are no longer allowed—that’s what our PR people tell me,” the copresident says.</p></td>
    </tr>
    <tr>
      <td>John Carmack</td>
      <td>Entertainment</td>
      <td>31</td>
      <td>ID Software</td>
      <td>computing-2002</td>
      <td><p>For a decade, John Carmack, cofounder of id Software, has revolutionized the computer game industry with immersive first-person shoot-’em-up games where players maneuver through 3-D worlds as characters on the screen. Since 1992 the self-taught programmer has attracted a devoted following of millions and has broken sales records with  Wolfenstein 3-D, Doom I and II and the three- part Quake series. His work raised the standard from simple games to complex, role-playing scenarios, which are so compelling that the U.S. Marines have used the games to train fighters. To make possible more realistic environments, Carmack has used leading-edge graphics hardware to create game engines, and he freely allows developers to improve them. “A great many people in the industry got their start modifying our games,” he says proudly. Carmack—who also builds small rocket-powered vehicles—and his crew in Mesquite, TX, are working on a new engine that improves the depth and texture of 3-D environments. His ultimate goal: achieve a level of rendering equal to those “of film and television graphics.”</p></td>
    </tr>
    <tr>
      <td>Josh Coates</td>
      <td>Software</td>
      <td>28</td>
      <td>Scale Eight</td>
      <td>computing-2002</td>
      <td><p>Ignore the bare feet. Josh Coates may look like an exuberant techie grad student, but he is a serious business player who has convinced investors to pony up $55 million for his 1999 San Francisco startup, Scale Eight. The chief technology officer has a paradigm-shattering idea that says the right software deployed over the Internet or local networks will let large corporations dramatically cut their data storage bills. Right now, data storage involves expensive, proprietary hard drives that are usually deployed at a few central sites; it’s a $20 billion market set to grow inexorably as more computers produce ever more information. But Scale Eight challenges that inevitability. Coates says his software will let customers use networks to route data to scores of cheap, off-the-shelf hard drives, where they can be stored inexpensively and securely. “I’m trying to sweep hardware out of the way and thereby commoditize storage, really lowering the costs, ”says Coates, who counts Microsoft among his two-dozen customers. “Software has no bounds, ”he adds. “If you can think of it, you can do it in software.”</p></td>
    </tr>
    <tr>
      <td>Paul Debevec</td>
      <td>Entertainment</td>
      <td>30</td>
      <td>University of Southern California</td>
      <td>computing-2002</td>
      <td><p>Paul Debevec’s rise to computer graphics stardom sounds like a fairy tale. In 1996 Debevec presented a paper on Façade, a system he developed as a student that digitally generates 3-D scenes from 2-D photographs. Soon after, he was flown to Hollywood to present his technology to John Dykstra, the visual-effects supervisor on Batman and Robin. Effects companies have since used Debevec’s techniques in several films, including The Matrix. Debevec now directs the graphics laboratory at the University of Southern California, where he is perfecting the Light Stage. Inside this three-meter-wide spherical structure, actors and objects are illuminated by 156 light-emitting diodes that duplicate light from any environment. For example, an actress can be illuminated with light recorded inside the Sistine Chapel, and her image can be simultaneously superimposed on a scene set there. The technique yields far more realistic results in less time than the standard method of adjusting concocted lighting frame by frame. “The idea is to use the light from the actual scene, rather than manually try to approximate it,” says Debevec, who admits to being under Hollywood’s spell.</p></td>
    </tr>
    <tr>
      <td>Shawn Fanning</td>
      <td>Internet and Web</td>
      <td>21</td>
      <td>Napster</td>
      <td>computing-2002</td>
      <td><p>Not many undergrads write world-changing code, appear on the covers of Time, Fortune and BusinessWeek, or testify in front of U.S.Senate committees before they can legally buy beer. Shawn Fanning has done all three since founding the cultural juggernaut Napster in a Northeastern University dorm in 1999. Fanning transformed a software script he wrote to help a roommate retrieve digital music files from the Internet into a full-featured online swap service millions of users strong. The free program enabled users to post MP3 digital music files they had on their computers to an online index supported by Napster, and to access files from any other person’s computer. That way, users could swap music files directly. The application became so popular that the Recording Industry Association of America effectively shut it down in 2001 through lawsuits alleging copyright infringement. Fanning is busy relaunching his company as a paid subscription service. His concept, though, continues to challenge the status quo. Music industry giants are scrambling to mimic Napster’s success on a pay-per-use basis— but to no avail, as free copycat sites constantly spring up.</p></td>
    </tr>
    <tr>
      <td>Justin Frankel</td>
      <td>Internet and Web</td>
      <td>22</td>
      <td>AOL Time Warner</td>
      <td>computing-2002</td>
      <td><p>Justin Frankel has brought music to desktops in numerous ways. After dropping out of college in 1997 and returning home to Arizona, he wrote Winamp, a program that let people play downloaded MP3 music files on their PCs. It was much easier to use than existing MP3 players. He and partner Tom Pepper also devised Shoutcast, which enables computers to broadcast like radio stations over the Internet. To vastly expand music’s availability online, Frankel then created Gnutella, a system that lets Internet users swap MP3s and other files. Unlike Napster, Gnutella does not pass files through a central distribution point—and recording companies can’t track them. By the time Frankel released Gnutella in 2000, he had sold Nullsoft, the company under which he developed Winamp and Gnutella, to America Online.AOL paid $400 million for Winamp and online-radio pioneer Spinner Networks and merged them under AOL Music in San Francisco. But AOL became wary of Gnutella because it let people acquire music they hadn’t paid for and pulled the program. What’s next from Frankel? “Just stuff that hopefully will make a difference,” the rebel says. That’s a tune he’s played before.</p></td>
    </tr>
    <tr>
      <td>Vinay Gidwaney</td>
      <td>Software</td>
      <td>20</td>
      <td>Control-F1</td>
      <td>computing-2002</td>
      <td><p>Vinay Gidwaney wrote the software that his Calgary, Alberta, high school used to teach his classmates word processing. Resellers expressed interest, and Gidwaney, only 16, started a small company to supply it. But he found himself spending a lot of time meeting customer requests. Youthfully impatient and eager to reserve his time for writing code, he created software tools to automatically handle certain customer support tasks .Gidwaney soon realized he could develop versions of the software tools to sell to other companies, to enable them to provide live support to their customers over the Internet. So the Canadian started Control-F1 in Calgary. Gidwaney, chief technology officer of the 40-person company, calls his tools “better than being there.” That’s because a remote customer can continue to work on her computer while Control-F1 software is solving her support problem in the background: no need for her to step away from the computer for a human technician. Several organizations now use Control-F1 to provide customer support, including Novell, Unisys and IBM.</p></td>
    </tr>
    <tr>
      <td>Robert Guttman</td>
      <td>Software</td>
      <td>32</td>
      <td>Frictionless Commerce</td>
      <td>computing-2002</td>
      <td><p>Choosing a car color is hard enough. Imagine trying to make strategic purchasing decisions for a huge corporation. Robert Guttman’s knack for softwareagents—autonomous, personalized programs that facilitate better-informed decisions—has made such buying chores easier. With an artificial-intelligence degree and four years at Motorola, Guttman arrived at the MIT Media Lab in 1996 to plan the world’s first agent-mediated marketplace  experiment. His idea was to create software agents that could find certain goods for their masters at preferred prices, then negotiate and close sales on the buyer’s behalf. The successful experiment left Guttman wondering whether similar agents could function in real-world marketplaces. In June 1998,along with two MIT colleagues, Guttman founded Frictionless Commerce in Cambridge, MA, to commercialize his technology. The software is now used by operations like the U.S. Army for large purchase orders of laptops, truck brakes, even lumber. With Frictionless’s success secure, Guttman has left his post as chief technology officer— though he remains a board member— and is shopping his talents around.</p></td>
    </tr>
    <tr>
      <td>Ramesh Hariharan</td>
      <td>Software</td>
      <td>32</td>
      <td>Strand Genomics</td>
      <td>computing-2002</td>
      <td><p>In school, Ramesh Hariharan found biology boring. But once he became a computer science professor at the Indian Institute of Science, he got excited about the race to map the human genome. So he cofounded Strand  Genomics in Bangalore, where he designs software tools to efficiently analyze the ever increasing volume of data about the makeup of genes. One U.S. customer is applying Hariharan’s data-crunching innovations to proteomics—the analysis of protein structures to aid in the discovery of new drugs. Strand Genomics expects to grow from 35 to 100 employees this year. Wearing another hat, Hariharan also works to bridge the digital divide. With colleagues from the university and from a local software firm, he started the nonprofit Simputer Trust to develop a simple, cheap (under $200), portable, battery-operated computer to bring the Internet to the developing world. The trust’s first targets are rural Indian village schools, hospitals or community centers that have phone lines. Villagers get smart cards that give them access to a shared Simputer, while touch-screen icons and the Dhvani text-to-speech system Hariharan developed empower illiterate users.</p></td>
    </tr>
    <tr>
      <td>Maria Hershenson</td>
      <td>Software</td>
      <td>30</td>
      <td>Barcelona Design</td>
      <td>computing-2002</td>
      <td><p>Mar Hershenson came to Silicon Valley from Barcelona, Spain, for a summer job, met her future husband and stayed, bringing a bit of her native city to California in the form of Barcelona Design, which she cofounded in  1999.The Sunnyvale, CA, company produces software and intellectual property, developed by Hershenson, for quickly optimizing the design of analog circuits for cell phones, TVs and DVD players. Previously, engineers could spend a year designing a single analog chip. With Barcelona’s solution, custom analog circuits can be finished in hours. Hershenson’s breakthrough was to represent circuits with equations that can be solved mathematically. She learned the technique in a course taught by Stephen Boyd, the Stanford University professor with whom she launched the company. The 45- employee firm has raised $44 million and lined up several large clients, including chip-making giant STMicroelectronics. Bursting with ideas, Hershenson plans to apply Barcelona’s technology to a wider range of circuitry.</p></td>
    </tr>
    <tr>
      <td>Travis Kalanick</td>
      <td>Internet and Web</td>
      <td>25</td>
      <td>Red Swoosh</td>
      <td>computing-2002</td>
      <td><p>Travis Kalanick is good at escaping sticky situations. In 1998,he launched Scour.com with six buddies at the University of California, Los Angeles. What began as a Web search engine morphed into a popular peer- to-peer file exchange system with 250,000 simultaneous users trading movies and music. Everything was looking up until more than 30 media companies sued Scour for $250 billion for copyright infringement. Scour settled and eventually sold its assets. Then, in 2001, Kalanick founded Los Angeles-based Red Swoosh with Scour’s engineering team. They’ve developed software that streamlines the way content—documents, music, videos—is moved around on the Internet. Typically, when you request a file from a Web site, it is delivered from a centralized server. Red Swoosh’s software continually updates a directory that lists which files are on which servers and end-user desktops and transfers the file to you from the closest source, speeding delivery. The scheme also saves big bucks in server infrastructure for the company that posted the file. Several media moguls with busy Web sites are now testing his software.</p></td>
    </tr>
    <tr>
      <td>Lydia Kavraki</td>
      <td>Software</td>
      <td>34</td>
      <td>Rice University</td>
      <td>computing-2002</td>
      <td><p>Lydia Kavraki made her first move between worlds when she left Greece to do a PhD in computer science at Stanford University. Drawn to the human potential of robotics, Kavraki studied how robots—from assembly line “arms” to autonomous machines—assess the obstacle-laden world and move around in it. She then created an algorithm that rapidly generates a path for a robot to follow through a given environment, using descriptions of how the robot moves, the space it’s in, obstacles it must navigate and its beginning and end points. Today, most papers on robot-path planning cite her algorithm, and engineers in the automotive industry are using variations of it to build better robotic assembly lines. Kavraki, meanwhile, has moved to a new research world, applying the rules of her algorithm to predict how two molecules will move through space and interact with each other—crucial to designing drugs. Intense and determined, Kavraki finds the two problems closely linked: “There is a potential here for solving problems that could affect our lives, whether it’s a robot that helps disabled people get out of bed or a tool that helps find a compound to treat disease.”</p></td>
    </tr>
    <tr>
      <td>Reiner Kraft</td>
      <td>Internet and Web</td>
      <td>33</td>
      <td>IBM</td>
      <td>computing-2002</td>
      <td><p>The Internet is a great set of parts. Reiner Kraft wants to make them a more valuable whole. One way is to exploit the many computers linked to the Internet to solve massive computing tasks that no single computer could handle well. Kraft coinvented a program that parcels out such tasks over the Internet to thousands of PCs; each solves its morsel, and the program integrates the solutions. In 1998,IBM applied for a patent based on Kraft’s distributed- computing scheme, which is used increasingly to crack computing problems. Kraft then created jCentral and xCentral—custom search engines for IBM’s programmers. They search and return Java and XML programs, respectively—the software behind many Web applications— and nothing else. This allows the company’s programmers (and non-IBMers, too) to much more efficiently build libraries of code for creating advanced applications that leverage the Internet’s capabilities. Kraft has cranked out numerous other programs that integrate Internet functions and has filed 80 patent applications. Despite his prolific youth, however, Kraft frets about what’s been left undone. “I worry,” he says, “that I am missing some good opportunities.”</p></td>
    </tr>
    <tr>
      <td>Raymond Lau</td>
      <td>Software</td>
      <td>30</td>
      <td>IPhrase Technologies</td>
      <td>computing-2002</td>
      <td><p>At 16,Raymond Lau wrote StuffIt, which soon became the prevailing software for compressing files on Macintosh computers so they take up less space. But Lau really heard his calling when he realized “the mathematical models for data compression are pretty similar to those for language processing.” He joined MIT’s Spoken Language Systems Group in 1994 and was central to its Galaxy project, producing software to recognize speech and interpret language, then deliver database information. He followed with Galaxy II—software that lets U.S. marines access information hands-free. Lau then used Galaxy II as the backbone of the MIT lab’s most ambitious project: Mercury. The system allows anyone to call the lab, speak to a computer and book flights on 23 airlines, as if talking to a travel agent. In 1999 Lau became chief technology officer of startup iPhrase Technologies in Cambridge, MA, to apply his expertise to written words. IPhrase programs have advanced search capabilities for Web sites such as Yahoo!  Finance and Schwab.</p></td>
    </tr>
    <tr>
      <td>Max Levchin</td>
      <td>Innovator of the Year</td>
      <td>26</td>
      <td>PayPal</td>
      <td>computing-2002</td>
      <td><p>After emigrating from Ukraine to Chicago as a teenager, Max Levchin enrolled as a computer science student at the University of Illinois so he could create and break codes. He moved to Silicon Valley after graduation to start a company based on his cryptography passion. In 1999, he cofounded PayPal in Palo Alto, CA, which quickly became the Internets leading person-to-person payments processor. One in four transactions on eBay is settled using PayPals system for debiting and crediting checking accounts and charge cards. In February, the company went public, raising $70 million.As chief technology officer, Levchin not only manages servers that store encrypted data about the companys 15 million members but has led the development of an antifraud program called Igor, named after a Russian fraudster it helped apprehend in 2000. Igor monitors PayPals transactions for unusual behavior, alerting personnel to freeze suspicious accounts or head off cash en route to dubious destinations. The FBI has also enlisted Igor to combat wire fraud. Citibank and Bank One, and even eBay itself,have launched rival online payment services, but none has matched PayPals market share.</p></td>
    </tr>
    <tr>
      <td>Pamela Lipson</td>
      <td>Software</td>
      <td>34</td>
      <td>Imagen</td>
      <td>computing-2002</td>
      <td><p>In 1997, after finishing her PhD and starting up Imagen in Cambridge, MA, Pamela Lipson would get phone calls from her mentor Alex d’Arbeloff, chairman of the MIT Corporation. “Focus,” he’d always tell her. Lipson had devised algorithms that could rapidly identify and classify digital images. Venture capitalists wanted them, but for far-flung applications: to improve Web searches for images, or for face recognition, video-database indexing or pharmaceutical R&amp;D. But it was not clear any of these emerging markets would embrace Lipson’s technology. In a quest for real customers, Lipson bet on inspection of printed circuit boards. She adapted Imagen’s software so it could identify production errors from a digital snapshot without misidentifying normal variations in parts. She designed a straightforward interface so users could easily modify the software. Inspections using Imagen software enhanced productivity without introducing lag. “What used to take five minutes now takes 20 seconds,” says Paul Keating at Teradyne, which has rights to use Lipson’s technology. Now that’s focus.</p></td>
    </tr>
    <tr>
      <td>Rob Malda</td>
      <td>Internet and Web</td>
      <td>25</td>
      <td>Slashdot</td>
      <td>computing-2002</td>
      <td><p>While Rob—don’t call him Robert—Malda may fit the irreverent hacker stereotype, his finest hack does not. Malda is founder of Holland, MI-based Slashdot, a Web site cum online community cum Internet Zeitgeistmeter visited by more than 250,000 surfers daily. What started in 1997 as an online hang-out for Malda’s cronies to trade banter on geek subjects is now “the number one site for tech news and geek ranting, ”according to the  Washington Post.Contributors recommend news items to Slashdot, where Malda and his small staff create links to the stories and write introductory paragraphs. Readers post comments, which are then graded by other readers. Many times, Web sites whose addresses are cited experience the “Slashdot effect”—an increase in traffic so sharp that their operations sometimes halt. The open-source program that runs Slashdot, which Malda created and regularly works on, is intuitive enough to have attracted 500,000 registered users. Countless others have downloaded it to run their own online discussion groups. As Malda continues to refine the Slashdot experience, he will refine the way the world experiences the Internet.</p></td>
    </tr>
    <tr>
      <td>Steve McCanne</td>
      <td>Internet and Web</td>
      <td>33</td>
      <td>Inktomi</td>
      <td>computing-2002</td>
      <td><p>Steve McCanne’s career as a rock star fizzled in high school. But noodling on a synthesizer did spark his interest in digital signal processing, which blossomed into graduate work at Berkeey National Laboratory. There he helped his mentor, Van Jacobson, invent the “Internet multicast backbone” (Mbone), which led to Internet standards for streaming media and enables people at scattered locations to collaborate using video, audio and a whiteboard. Among Mbone’s first users: NASA engineers. In1998,McCanne cofounded FastForward Networks and pioneered the first scalable techniques for live Internet broadcasting. In 2000 Internet giant Inktomi bought FastForward for $1.3 billion to get its multimedia tools—and McCanne, now chief technology officer. Inktomi, in Foster City, CA, performs cataloguing and searching for huge portals like America Online and MSN. McCanne is now devising systems to let big businesses, including Ford Motor, McDonald’s and Merrill Lynch use video webcasting throughout their own networks. Someday he’d like to write a book about “how the Internet really works.”</p></td>
    </tr>
    <tr>
      <td>Lou Montulli</td>
      <td>Internet and Web</td>
      <td>32</td>
      <td>Freelancer</td>
      <td>computing-2002</td>
      <td><p>It’s one thing to devise a key innovation for the Internet. Lou Montulli has designed half a dozen. While a computer science major at the University of Kansas in 1991,he wrote Lynx, a program that enabled a computer user to automatically link text documents. It became one of the earliest and most popular World Wide Web browsers. At the same time, Montulli was a leading figure in the grass-roots effort to improve several fundamental computer languages and protocols, including the hypertext transfer protocol—the addressing scheme that links Web pages—and HTML, the language for creating text and images on Web pages. In 1994 he moved to California to work as a founding engineer at what became Netscape, developing the first commercial Web application. Not all of his innovations have been universally embraced: he is responsible for cookies—data files that enable Web sites to recognize returning users—as well as blink tags—those endlessly flashing words on Web pages. Shrugging off the burden of being named People magazine’s sexiest Internet mogul of 1999,the freelancing Montulli continues to experiment with new ways to exploit the Internet.</p></td>
    </tr>
    <tr>
      <td>Kazuho Oku</td>
      <td>Internet and Web</td>
      <td>24</td>
      <td>Ilinx</td>
      <td>computing-2002</td>
      <td><p>Commuters in Japan are staring into their hands—and Kazuho Oku is to blame. Oku used personal digital assistants in high school but only experienced the Internet when he enrolled at the University of Tokyo as a geology major. He was struck by how much more useful the Internet could be—especially to idle commuters on subways and trains—if it were easily accessible over handheld devices. He was soon spending his time in the university’s computer department, devising a way to compress Web pages and developing software to convert them into a format for handhelds. The result was Palmscape, one of the world’s first Web browsers for handhelds. Oku distributed Palmscape—intended for the Palm Pilot’s Palm operating system—free over the Internet. Before finishing his studies, Oku was lured to Ilinx, a software company in Tokyo, where he developed his successor product, Xiino. It comes installed in a wide range of handhelds and is a leading browser for Palm products in North America, Europe and Japan. Oku is now adding capabilities that allow corporate clients and individuals to write their own custom applications.</p></td>
    </tr>
    <tr>
      <td>Larry Page</td>
      <td>Internet and Web</td>
      <td>29</td>
      <td>Google</td>
      <td>computing-2002</td>
      <td><p>Google combs more Web pages, faster, than any other search engine. But perhaps just as impressive is that despite the dot-com meltdown, the company has never veered from its mission. Competitors have tried to reposition themselves as all-purpose “portals,” only to slip from the radar screen. That thrills Google cofounder Larry Page, a feisty roller hockey player. Google has continued to expand the kinds of data it searches, recently adding Usenet news groups and retail catalogues.  And it keeps expanding its tool set: for instance, Google now serves its results to cell phones. Copresidents Page and Sergey Brin (p.69) have worked as equal teammates since they first devised their unique search software and went live in 1998.They are both competitive but know how productive they are working together. Their responsibilities often overlap, and they still share an office. For them, Google is about solving intellectual problems. Indeed, they recently recruited Novell and Sun veteran Eric Schmidt as CEO tomanage their 300-plus employees, so they can continue to focus on technology. “Our goal is to keep innovating,” Page says.</p></td>
    </tr>
    <tr>
      <td>Joseph Reagle</td>
      <td>Internet and Web</td>
      <td>29</td>
      <td>World Wide Web Consortium</td>
      <td>computing-2002</td>
      <td><p>Joseph Reagle bikes rather than use polluting transportation. He eats vegetarian so animals are not killed, and brings a quiet but strong sense of social conscience to bear on issues like trust, privacy and intellectual-property rights on the World Wide Web. After earning his graduate degree from MIT’s Technology and Policy Program in 1996,Reagle established himself as a creative thinker at the World Wide Web Consortium, based at MIT. He has driven several initiatives that will dramatically affect online interactions. He led the group that developed a standard way for Web sites to disclose their privacy policies, telling people what might be done with personal information. He coordinated input from far-flung institutions to create rules recognizable by all Web browsers for signing online documents, so people can leave unique stamps verifying that documents have been made or approved by them. Sound like fun? It was for Reagle, who says innovation is not just for technology but for culture. Web inventor Tim Berners-Lee, who oversees the consortium, says Reagle is “continually” looking to better the relationship of the Web tosociety.</p></td>
    </tr>
    <tr>
      <td>Tim Tuttle</td>
      <td>Internet and Web</td>
      <td>33</td>
      <td>Bang Networks</td>
      <td>computing-2002</td>
      <td><p>When Tim Tuttle was 30,he quit his job at Lucent Technologies’ Bell Labs, moved into a dilapidated apartment in Cambridge, MA, and began to reinvent the Web. It had a freshness problem. If the information on a Web page changes while you’re reading it, you don’t know—unless you hit the “refresh” button. Tuttle saw a different possibility: a virtual network, overlaying the Web, that lets sites send you live updates on information that  changes, the moment it changes. And he was sure he could get it to function on ordinary Web browsers using ordinary Internet protocols—no extra software needed. Working with no funding or source of income, he built the first node of such a network: the prototype of the “Bang object router.” After securing $10 million in July 2000,Tuttle,an active ultimate Frisbee player, moved to San Francisco to become an Internet entrepreneur. Six months later, his network was up and running, used chiefly by financial-services companies that need continually updated information from dozens of sources. Tuttle’s company, Bang Networks, has thrived through the dot-com collapse: it raised almost half of its $32 million in November 2001.</p></td>
    </tr>
    <tr>
      <td>Susie Wee</td>
      <td>Internet and Web</td>
      <td>32</td>
      <td>Hewlett-Packard Laboratories</td>
      <td>computing-2002</td>
      <td><p>Handheld wireless devices are great for voice and simple data but are frustratingly limited when it comes to handling video—mostly because today’s networks were designed for wired computers with robust processors and full-sized screens. Susie Wee, R&amp;D manager for Hewlett-Packard Laboratories’ streaming media systems group—and an avid hockey player—is skating around those constraints. Her first move was to devise algorithms that adapt data-heavy video streams to the capabilities of different online computers. The result:a handheld device can receive video at a lower resolution than a workstation, allowing it to display the video much faster. Wee is now developing protocols for moving streamed content away from central Internet servers to cache servers geographically closer to end users. Doing so would reduce network congestion and interruptions, making video and audio flow more easily to wireless devices. Wee’s goal is to turn your cell phone into a full-blown multimedia player—a goal she is speeding toward.</p></td>
    </tr>
    <tr>
      <td>Ethan Zuckerman</td>
      <td>Internet and Web</td>
      <td>28</td>
      <td>Geekcorps</td>
      <td>computing-2002</td>
      <td><p>When Ethan Zuckerman went to Ghana in 1993 as a Fulbright scholar in percussion, he immediately tried to get online; he was a Usenet junkie and eager to e-mail his girlfriend (now his wife). But in bustling Accra, he found only one temperamental Net connection. Zuckerman later became vice president of R&amp;D at Web-hosting company Tripod, which made him a dot-com millionaire, but he never forgot Ghanas inadequate communications. In July 1999 he left Tripod and in February 2000 cofounded Geekcorps in North Adams, MA. Geekcorps sends volunteers with information technology expertise to underdeveloped countries for four-month stints, where they help businesses-from furniture factories to radio stations-get online, expand sales and thus create jobs.One volunteer even helped launch the Ghanaian parliaments Web sites. Funded by foundations, aid agencies and private donors, Geekcorps has sent 35 tutors to Ghana and several other countries.A recent merger with the International Executive Service Corps gives Zuckerman the support to expand much further. Theres no shortage of volunteers; more than 1,100 people are on Geekcorpss waiting list.</p></td>
    </tr>
    <tr>
      <td>Marc Andreessen</td>
      <td></td>
      <td>28</td>
      <td>America Online/Netscape</td>
      <td>computing-1999</td>
      <td><p>First he helped make the Internet accessible to nonprofessionals by co-creating the browsers that launched the public’s stampede to get connected–Mosaic and Netscape Navigator. Then at 23,he became one of the first overnight Internet multimillionaires when Netscape, which he co-founded, made its Wall Street debut. When America Online bought Netscape in 1998, Marc Andreessen became CTO. In September, after 7 months guiding a company with as many subscribers as the combined population of Denmark and Sweden, he stepped aside. The move leaves him connected to AOL as a part-time consultant. Fittingly, this super-entrepreneur will advise the company on its investments in high-tech startups. <br>At 6 feet 4 inches, Andreessen exudes gawky charm, and displays a polymath’s knowledge of the most exotic subjects. An Internet analyst told Fortune: “When Marc doesn’t know about something he thinks he needs to understand, he gets a book and talks to people and learns. The guy has a knowledge base that is just incredible.” Ultimately, his greatest influence on the future of technology could be the outcome of the Justice Department’s antitrust suit against Microsoft, in large part the result of Bill Gates’ business practices vis-à-vis Andreessen’s Netscape.</p></td>
    </tr>
    <tr>
      <td>Sabeer Bhatia</td>
      <td></td>
      <td>30</td>
      <td>Arzoo</td>
      <td>computing-1999</td>
      <td><p>Sabeer Bhatia arrived in the United States from Bangalore at 19; now he’s a Web gazillionaire. With friend and co-worker Jack Smith, Bhatia founded Hotmail, the first free Web-based e-mail service. This concept was a radical departure from the dial-up services that required a paid account. Hotmail, in contrast, could be accessed via a Web browser from any computer connected to the Net. The idea found a market niche. Make that a cavern: After two and a half years, Hotmail had 25 million active e-mail accounts; now there are more than 50 million. <br></p>  <p>After emigrating from India, Bhatia studied at Caltech as an undergrad. While attending graduate school at Stanford, he was inspired by high-tech successes like Steve Jobs and Scott McNealy. In August 1995,Bhatia and Smith began seeking capital for “JavaSoft,” a Net-based personal database. The reception was lukewarm, but at the same time they were shopping Hotmail, which proved to be a more dynamic prospect. Venture capital firm Draper Fisher Jurvetson invested $300,000, and Hotmail launched on July 4, 1996. Just 18 months later, Microsoft bought the company for $400 million worth of Microsoft stock. <br></p>  <p>For the passionate innovator, a success like that is just a prelude. Bhatia is now president and CEO of Arzoo, an e-commerce startup that intends to offer a set of integrated e-commerce tools, such as a “shopping cart” that users will be able to push down the digital aisles from site to site.</p></td>
    </tr>
    <tr>
      <td>Amy Bruckman</td>
      <td></td>
      <td>33</td>
      <td>Georgia Institute of Technology</td>
      <td>computing-1999</td>
      <td><p>One of the greatest potentials of the World Wide Web is the creation of online communities–electronic congregations of people with shared interests from all over the globe. But which environments best foster these interactions? Answering that question is the business of a new field–online community design. Amy Bruckman is a pioneer in this endeavor. <br></p>  <p>She develops virtual spaces called MUDs–multi-user domains–that allow many people to interact in real time. Bruckman specializes in a subset of MUDs called MOOs (MUD, object oriented), which allow users to interact not only with each other but also with “objects.” As a graduate student, Bruckman founded an online community for new-media researchers called MediaMOO,as well as a MOO for children called MOOSE Crossing. Bruckman has undertaken “the most notable MOO research in education,” says Aaron Tornberg, an educational technology researcher at the University of Cincinnati. <br></p>  <p>To make this possible, Bruckman had to design a new interface, as well as a new programming language. Once she creates virtual communities, Bruckman doffs her engineer’s cap, puts on her anthropologist hat, and studies how the online environment influences the interactions of its participants.</p></td>
    </tr>
    <tr>
      <td>Sky Dayton</td>
      <td></td>
      <td>32</td>
      <td>Earthlink Network</td>
      <td>computing-1999</td>
      <td><p>In 1994, Sky Dayton wanted to connect to the Internet, just then emerging as a nugget of ground truth from the fog of hype about an “information superhighway.” Dayton toiled nearly 80 hours configuring his computer for Net access–a numbingly complicated chore. <br></p>  <p>Intent on simplifying this task, he founded Earthlink Network–now one of the nation’s top five Internet service providers (ISPs), with more than 1.3 million subscribers. Attribute that success to Dayton’s near-religious commitment to the user’s experience: from spending heavily on customer service to innovations such as introducing the $19.95 monthly flat rate for unlimited surfing. That change came in November 1995, when most ISPs were still clinging to the notion of hourly fees. <br></p>  <p>Dayton–a high-school graduate who started up a West Hollywood, Calif., coffeehouse before getting into the Internet business–believes the Internet is the next great mass medium, replacing television. While that’s no mental stretch, getting the masses connected is: Only one in five Americans now has Internet access. Earthlink is working to connect the rest, and Dayton remains chairman of the Pasadena, Calif.-based company. Meanwhile, he is looking to play a new role in the Internet’s growth through eCompanies, a Santa Monica, Calif., incubator for Web startups that he launched over the summer with executives from Disney.</p></td>
    </tr>
    <tr>
      <td>Roy Thomas Fielding</td>
      <td></td>
      <td>34</td>
      <td>University of California, Irvine</td>
      <td>computing-1999</td>
      <td><p>Without public streets, common laws and mutually held beliefs, life would be nasty, brutish and short. So would a trip on the Web if it weren’t for Roy Fielding. Fielding is a primary force behind open-source software, a movement that has brought transparent standards to the most widely used Internet programs. Fielding’s first big contribution came in 1994, when he invented a way for browsers to efficiently update stored Web pages, by transmitting information only if something has changed. Without this traffic-saving advance, the Web might have collapsed under its own explosive growth. Thanks to that success, Fielding was tapped byWWW inventor Tim Berners-Lee to author the latest version of the Hypertext Transfer Protocol (HTTP),the standard that governs how computers exchange text, image, video and sound over the Internet. Fielding’s dedication to open standards means that no single company can control the Web.  <br></p>  <p>Indeed, Fielding, who is due to receive his PhD this year from the University of California, Irvine, is also co-founder and chairman of the Apache Group,a collective of programmers whose free software now powers more than half of all Web servers–trouncing competition from Microsoft and Netscape.</p></td>
    </tr>
    <tr>
      <td>Peter Girardi</td>
      <td></td>
      <td>33</td>
      <td>Funny Garbage</td>
      <td>computing-1999</td>
      <td><p>Peter Girardi calls what he does “translation.” What he means is that he’s moving words written in traditional media–cartoons, theater and music, for example–into the digital realm. Girardi is well placed to do this work, because the transition from conventional media to bits is one he has made himself. At 16,Girardi was spray-painting New York subway cars. In 1987 he moved from graffiti artist to student at the School of Visual Arts, where he began exploring what computers can do. At Funny Garbage, the company he founded in 1995, he is helping bring interactive technology to many established art forms. <br></p>  <p>For instance, in his earlier work as creative director of CD-ROM developer Voyager, Girardi produced an interactive CD version of Art Spiegelman’s dark “Maus”–the Pulitzer Prize-winning cartoon epic Spiegelman based on his father’s experience of the Holocaust. In addition to participating in digital artistic collaborations, his company also does Web site design. Clients range from the popular search engine Alta Vista, for which Funny Garbage created a new interface, to David Byrne’s world music label, Luaka Bop. According to Spiegelman, “Peter is the best of the new gardeners landscaping our new virtual jungle.”</p></td>
    </tr>
    <tr>
      <td>Helen Greiner</td>
      <td></td>
      <td>31</td>
      <td>IS Robotics</td>
      <td>computing-1999</td>
      <td><p>These days, robots are typically used in limited, specialized roles. But if Helen Greiner and Colin Angle have anything to say about that, robots may soon be a more versatile and ubiquitous part of our lives. Greiner and Angle are two of the founders of IS Robotics. Working for the Defense Advanced Research Projects Agency and the Office of Naval Research, IS Robotics has built a number of innovative robots designed to detect mines, retrieve unexploded bombs, swim like fish–even walk up walls. The company’s focus isn’t solely on the military, though: IS Robotics recently signed a contract with Hasbro to develop interactive robots as future toys, and is working with the oil exploration industry and other industries. As president of the company and head of research, Greiner has been able to balance the company’s business and research needs. “Helen is an innovator in technology, government research and business,” says Rodney Brooks, director of MIT’s Artificial Intelligence Laboratory and a co-founder of the company. In her position at IS, she is one of the leaders of an effort to develop networked robots that Brooks says will become “the eyes, ears and arms of the Internet.”</p></td>
    </tr>
    <tr>
      <td>Jonathan Heiliger</td>
      <td></td>
      <td>23</td>
      <td>Frontier Global Center</td>
      <td>computing-1999</td>
      <td><p>Even among the TR100, venture capitalist Jonathan Heiliger is a youngster. He got a head start in high technology, working at the Stanford Linear Accelerator when he was 15. From there, he made warp-speed transitions from basic science to network engineering to deal making. Highlights include designing the network architecture used by megaprovider UUNet and brokering the acquisition of Internet Systems by Frontier Global Center. As Frontier’s CTO, he laid out the firm’s Internet strategy, formulating a system of data centers connected by high-speed links; Frontier’s network hosts 40 percent of the top 100 Web sites. <br></p>  <p>Being CTO wasn’t enough; Heiliger wanted to try being a venture capitalist. For most people that would entail getting an MBA. But Heiliger, who doesn’t have a college degree, choose a different track. He drafted a proposal, asking Frontier to start a $30 million venture capital fund and to appoint him to manage it. <br></p>  <p>The company agreed, “rounding” the fund up to $100 million. As Interactive Week said, “Heiliger’s contribution to the Web’s emergence as a medium for reaching the masses is staggering.” Heiliger now says he’d like to be a CEO– if he can find the right small company.</p></td>
    </tr>
    <tr>
      <td>Katherine Isbister</td>
      <td></td>
      <td>30</td>
      <td>NTT Open Laboratory</td>
      <td>computing-1999</td>
      <td><p>Two hot areas of software design today are intelligent agents to find information and conduct transactions, and realistic depiction of characters (as in movies and video games).What happens when these two pursuits intersect? We get intelligent agents that we can interact with just as we do with people. Having such animated agents may change the way we access the Web and carry on dialogues with people in other cultures. One of the folks hatching such virtual conversationalists is Katherine Isbister. <br></p>  <p>Animated agents are a natural for communication across cultural barriers, since the agents could store large amounts of information to help the participants understand each other–literally, in <br></p>  <p>language, and also more subtly in culture. Isbister is in the midst of such a collaboration, working at NTT Open Laboratory in Japan. Using a high-speed link between Kyoto and Stanford, she has two students converse across the Pacific, aided by computer characters. Isbister does not just create innovative new interfaces. She also uses social-science methods to study them and draw conclusions about how to improve them. As the world of Web interface design “moves from seat-of-the-pants theorizing to demanding rigorous guidance, Katherine will be a leader,” says Clifford Nass of Stanford, who supervised her dissertation there.</p></td>
    </tr>
    <tr>
      <td>Natalie Jeremijenko</td>
      <td></td>
      <td>32</td>
      <td>"Bureau of Inverse Technology"</td>
      <td>computing-1999</td>
      <td><p>Are you a knowledge worker? If so, Natalie Jeremijenko would like you to install Stump on your computer. Every time you print out a tree’s worth of paper, Stumpprints a picture of a tree ring. With enough rings, you can reconstruct the stump of a tree. For Australian-born Jeremijenko, who is director of the Yale University Engineering Design Lab and an acclaimed technoartist, Stump is a way to make “a tangible version of the Internet world.” <br></p>  <p>Jeremijenko says her aim is to pierce the shared “hallucination” that cyberspace is somehow clean and immaterial. In reality, she points out, the digital domain is a world of hardware and some hard truths. Jeremijenko makes the latter difficult to ignore with projects like OneTree, in which 2,000 walnut trees will be placed in sensor-equipped planters around the San Francisco Bay area next year. As the trees grow, their condition will record the region’s climatic, socioeconomic and environmental extremes. Silicon Valley is home to a large concentration of Superfund toxic waste sites, and one of the nation’s largest gaps between rich and poor.  <br></p>  <p>Jeremijenko, who produces much of her art under the auspices of a fictional institution she calls the Bureau of Inverse Technology, makes novel use of technologies to record social phenomena. She shot a documentary of Silicon Valley from a remote-controlled spy plane, concealed cameras in teddy bears to record children’s expressions, and installed a motion detector near the Golden Gate Bridge to count suicides (17 in 100 days).</p></td>
    </tr>
    <tr>
      <td>Shivkumar Kalyanaraman</td>
      <td></td>
      <td>28</td>
      <td>Rensselaer Polytechnic Institute</td>
      <td>computing-1999</td>
      <td><p>At the dawn of the Internet, back when it was ARPAnet, the task of managing network traffic was pure engineering. But as the Net has exploded in size and economic importance, traffic control has come to depend on other disciplines, such as economics, graphic design, network theory and sociology. The innovators who can bring together people from these and other fields will play a big part in ensuring that the Web grows smoothly. There aren’t many people with a high degree of technical expertise and also such a wide-ranging perspective; one of them is Shivkumar Kalyanaraman, professor of electrical, computer and systems engineering at RPI. Kalyanaraman has made important contributions to research on asynchronous transfer mode, a protocol that permits high-speed network communications. But he joins the TR100 because of the breadth of his vision: In addition to traffic management and congestion control, he also studies Internet pricing, the development of online simulations for network management, and networking for multimedia. He works with network theorists, economists and programmers to study how the Net functions in real time. DARPA, the National Science Foundation and Internet companies are funding his productive collaborations to the tune of more than $2 million–an investment that will pay off handsomely if Kalyanaraman’s efforts help stave off a major Internet meltdown in the next few years.</p></td>
    </tr>
    <tr>
      <td>Maja Kuzmanovic</td>
      <td></td>
      <td>26</td>
      <td>National Research Institute for Mathematics and Computer Science</td>
      <td>computing-1999</td>
      <td><p>Digital artist Maja Kuzmanovic has created striking interactive works that bridge differentartistic traditions and present the viewer with stunningly different visual worlds. She is now working on the Chameleon Project as artist in residence at the National Research Institute for Mathematics and Computer Science in the Netherlands. One part of the project involves an interaction with what looks like a film clip, using little bandwidth with the recently developed Web tool called synchronized multimedia integration language (SMIL, pronounced “smile”). <br></p>  <p>In 1997 she developed an interactive piece called Once Upon a Moment, about a worker in a dystopian office who is plagued by ever more sinister nightmares. To tell this story, she drew on film, photography and existing new media work to create an interactive movie and Web site. The Croatian-born Kuzmanovic studied art and design in Italy before starting her undergraduate studies at Utrecht University in the Netherlands. There she designed Creation of Change, a CD-ROM that is a collaboration between the disciplines of fashion design, interactive design and graphic design. Interactive art has thus far been a field of enormous promise and uncertain execution. Kuzmanovic might be one of the people who can clarify this murky picture.</p></td>
    </tr>
    <tr>
      <td>Come Lague</td>
      <td></td>
      <td>33</td>
      <td>Adesemi Communications</td>
      <td>computing-1999</td>
      <td><p>Many experts fear the Internet will exacerbate, rather than alleviate, the already ominous gap between rich and poor countries. One techno-Samaritan who is giving developing countries a chance to participate in the information revolution is Côme Laguë, co-founder and chief operating officer of Adesemi Communications. Laguë’s company has begun expanding telecom services in Tanzania and Ghana and is coordinating the launch of wireless telecommunications services in Sri Lanka, Zambia and the Ivory Coast. <br></p>  <p>To bring telecommunications to poor countries in Africa, Laguë often must integrate several generations of technology, work around gaps in infrastructure and reduce budgets. Take the Tanzania project, which operated in areas where as few as one in 2,000 people have a telephone. First, Laguë developed a system in which each subscriber has a pager and a voice- mail account–when they get a message, they go to a pay phone. Only problem? No pay phones. So Laguë put in a system of wireless pay phones. Now, even though there may be only one phone in a remote village, any villager has access to phone service. That kind of ingenuity on behalf of poor countries makes Côme Laguë a champion whose work deserves emulation.</p></td>
    </tr>
    <tr>
      <td>Magdamena Mik</td>
      <td></td>
      <td>25</td>
      <td>Walker Digital</td>
      <td>computing-1999</td>
      <td><p>Among the auction sites burgeoning on the Web, Priceline.com is an early trendsetter. Its business of liquidating unsold airline seats and hotel rooms by letting travelers make low-ball bids online has pushed the company to a market valuation of $10 billion. To ensure a robust patent portfolio for his site, Priceline.com founder and vice chairman Jay Walker set up a think tank, Walker Digital, staffed with inventors and patent attorneys. Two years after joining the company, Magdalena Mik has her name on 44 pending U.S. patents for Priceline and other e-businesses. Her innovations include the Adaptive Marketing Program, in which Priceline adds a dollar amount to a customer’s offer as a reward for an agreement to sign up for a credit card or some other service. Mik’s latest e-brainstorm: a system enabling online shoppers to name the price they are willing to pay for merchandise, which they would pick up from a participating retailer. Mik came to Walker Digital after receiving a BS in chemistry and completing one semester of law school (she’s officially on a leave of absence). Though Polish is her native tongue ,this immigrant to the United States at age 8 is fluent in commerce. She recently told Forbes that her inspiration was “the thought of being obscenely wealthy by the time I’m 30.”</p></td>
    </tr>
    <tr>
      <td>Jonathan Nelson</td>
      <td></td>
      <td>32</td>
      <td>Organic Online</td>
      <td>computing-1999</td>
      <td><p>Not too long ago, marketing was pretty straight forward. The major channels were obvious. The techniques for working in television, radio and print were well established. And there wasn’t much overlap among them. Proliferating cable networks and the Internet have obliterated this tidy world. Jonathan Nelson’s job is to bring companies bewildered by the media meltdown into the 21st century. <br></p>  <p>Nelson began his career as a recording engineer. Today he is CEO of Organic Online, which manages advertising, public relations, marketing and research for such big-time clients as Gateway, Sun Microsystems and Starbucks. Since its 1993 founding, Organic has grown into a 350-person organization with offices in San Francisco, New York, Chicago and Brazil. Organic is known for innovative Web site design. But clients are beginning to demand data on the impact of their digital offerings–and Nelson is there to help. He is co-founder and chairman of Accrue Software, a San Francisco-based Web measurement and analysis software company. If Nelson can come up with ways to measure accurately the impact of Web marketing and devise effective strategies that tap the advantages of the medium, he will be heard from well into the next century.</p></td>
    </tr>
    <tr>
      <td>Michael Robertson</td>
      <td></td>
      <td>32</td>
      <td>MP3.com</td>
      <td>computing-1999</td>
      <td><p>The business of selling recorded music could be on the cusp of a complete makeover–and Michael Robertson is one of the main drivers of this change. Robertson is the force behind MP3.com,a Web site where recording artists bypass the marketing labyrinth of the recording companies and give their music away, via MP3 music-compression software. <br></p>  <p>MP3.com began in 1996 as the Z Company, which provided an online search engine. But when Robertson saw the MP3 software then being developed, he was dazzled by its potential. He promptly renamed his company and secured the rights to the MP3.com domain name. Over the next two years, the company grew from four employees to 35. In January it received a $10 million venture investment from Sequoia Capital. Soon after that, Tom Petty posted a song on Robertson’s site to publicize the release of his new album–and the ball was rolling. <br></p>  <p>Music lovers’ free ride can’t last forever; legal battles over copyright and other issues are sure to erupt.&nbsp;&nbsp;But Robertson, named “one of the 100 most influential figures in the music industry” by the industry publication BAM, professes little worry about the feelings of recording company executives: “I don’t have any friends in the music industry, so I don’t have to worry about upsetting anybody.”</p></td>
    </tr>
    <tr>
      <td>John Romero</td>
      <td></td>
      <td>30</td>
      <td>Ion Storm</td>
      <td>computing-1999</td>
      <td><p>Almost all of the TR100 showed an early affinity for innovation. Perhaps none, however, blossomed earlier than John Romero, one of the creators of the popular video games Doom and Quake. Romero began writing games at 12 on an Apple IIe. His first paid games programming was at Origin Systems, creators of the Ultima series. He later took a job at Softdisk Publishing, where he met John Carmack, Adrian Carmack and Tom Hall. In the annals of popular culture, it was a fateful meeting. Together the four founded id software, where Romero was responsible for the design of the Doom series and Quake–games that set industry standards for their ability to simulate reality. These products have become so popular that Rolling Stone and Entertainment Weekly have hailed Romero as “the Steven Spielberg of gaming.” <br></p>  <p>Although id had planned to begin on Quake II, Romero left to found Ion Storm and begin work on Daikatana, a first-person game that takes the player on a time-traveling quest for a mystical Japanese sword. The violent content of Doom, Quake and other computer games gives many observers qualms. But there is no question that they have been enormously influential in shaping the way teenagers spend their time–and perhaps how they think and feel. Like it or not, Romero’s creations will shape the cultural landscape of the years to come.</p></td>
    </tr>
    <tr>
      <td>Andrew Shapiro</td>
      <td></td>
      <td>31</td>
      <td>Aspen Institute Internet Policy Project</td>
      <td>computing-1999</td>
      <td><p>Many intellectuals writing about the Webolution tend toward either cheerleading or nay-saying. Carving out a third way is attorney/advocate Andrew Shapiro, director of the Aspen Institute Internet Policy Project, First Amendment Fellow at the Brennan Center for Justice at New York University Law School, and a senior advisor to the Markle Foundation. Shapiro first came to prominence writing about the Internet for The Nation as a student at Yale Law School. Since his admission to the New York State bar in 1996,he has been a fellow of Harvard Law School’s Berkman Center for Internet &amp; Society and at The Century Foundation. The latter supported the research and writing of The Control Revolution–his recent tome on the politics of new media. Shapiro may best be known as co-founder of Technorealism, which seeks to define a middle ground between pro and anti-technology thinking. Some critics find Technorealism banal; Newsweek’s Steven Levy described the movement’s founding statement as “vapid” and “muddled.” Not everyone agrees. Mitch Kapor, founder of Lotus Development and the Electronic Frontier Foundation, says Shapiro has “enormous potential to make lasting contributions to society in the form of better integration and usefulness of computer and communications technology by the citizenry.”</p></td>
    </tr>
    <tr>
      <td>Eric Silberstein</td>
      <td></td>
      <td>23</td>
      <td>Idiom Technologies</td>
      <td>computing-1999</td>
      <td><p>Wouldn’t it be nice if everybody could comprende everybody else? C’est impossible on the Internet, which is growing most rapidly in the non-English-speaking world. Right now, Web businesses cope with the multiplicity of tongues by maintaining separate sites for each language group–a costly proposition. But leaving sites in English leaves some international surfers wondering “Was ist das?” That’s a problem: Forrester Research reports that business Web users are three times as likely to buy when addressed in their own language. If Eric Silberstein has his way, the Internet will look muy differente in a few years: A single site will satisfy speakers of many languages. His company, Idiom Technologies, designs and markets “WorldServer” software, which tracks text that needs to be translated and then inserts translations into the multilingual site. Silberstein’s high-tech career began as CTO of ChipshotGolf.com, which sells golf merchandise online. In 1998 he founded Idiom, which recently received a total of $5.25 million from three different venture capital outfits. An early customer was Lycos, whose search engines attract global audiences. Angelo Santinelli, a principal at North Bridge Venture Partners, says Silberstein is certain to be “an impact player.” Domo arigato, Mr.Silberstein.</p></td>
    </tr>
    <tr>
      <td>Jagdeep Singh</td>
      <td></td>
      <td>32</td>
      <td>Stanford University</td>
      <td>computing-1999</td>
      <td><p>Today’s telecommunications network is woven largely from fiber optics–glass threads that carry thousands of times more information than copper wires. The key to expanding this capacity even further lies in a technology called wavelength division multiplexing (WDM), which sends multiple signals down the same fiber, using different colors of light (see “Wavelength Division Multiplexing,” TR March/April 1999). WDM requires a sophisticated switch to direct multi-spectral traffic–and that’s just what Jagdeep Singh created at his 1998 startup, Lightera Networks. Their invention, called the Core Director, was deemed so critical to WDM that last spring optical networking company Ciena bought Singh’s year-and-a-half-old startup for a whopping $500 million. Born in New Delhi to the family of a globetrotting diplomat, Singh landed in the United States and enrolled at the University of Maryland at 15. By 20 he was working for Hewlett-Packard and getting an introduction to telecommunications networking–a field primed for an explosion of demand. In 1993, he started AirSoft, which made software to improve the performance of wireless networks. He formed Lightera after selling AirSoft for $65 million. Now studying for a management degree at Stanford, Singh says he intends to switch from entrepreneur to captain of industry–building a company that will be a “lasting piece of the economy.”</p></td>
    </tr>
    <tr>
      <td>Alex Thompson</td>
      <td></td>
      <td>31</td>
      <td>Mixed Signals Technologies</td>
      <td>computing-1999</td>
      <td><p>Interactive television has been an elusive goal almost as long as Alex Thompson has been alive. Although various schemes for real-time viewer feedback to TV programs have been demonstrated, none has secured a market foothold. A new system promoted by Thompson’s company, Mixed Signals Technologies, could turn this dismal history around. This system combines WebTV and Echostar set-top boxes and relies on program encoding equipment from Mixed Signals, which Thompson started in 1997. Mixed Signals inserts data for interactivity into the interval between broadcast video frames. Having developed the software, marketed as TV Link Creator, Thompson merged her firm with Ultech, which makes video-encoding hardware. The resulting ITV Dataflo System is becoming a standard tool for program developers, adding interactivity to TV game shows. Sony/Columbia TriStar Television, producer of&nbsp;&nbsp;“Wheel of Fortune” and&nbsp;&nbsp;“Jeopardy,” liked the technology so much that parent company Sony Pictures is investing upwards of $13 million in Thompson’s venture. Says Andy Kaplan, executive vice president of Columbia TriStar: “Alex has proven herself to be a leader in developing a cutting-edge technology which, we believe, will have a significant effect on our future business.”</p></td>
    </tr>
    <tr>
      <td>Mike Volpi</td>
      <td></td>
      <td>32</td>
      <td>Cisco Systems</td>
      <td>computing-1999</td>
      <td><p>In his job as senior vice president for business development and global alliances at Cisco Systems, Mike Volpi has developed a habit of collecting things–things like high-tech startups. In five years at Cisco, the leading maker of network routers, Volpi has been instrumental in that company’s acquisition of 34 companies. In his vigorous appetite for bringing smaller outfits into the Cisco fold, Volpi has developed a new model for corporate R&amp;D: If you see a budding technology you like, don’t copy it–buy its origination. This way, Cisco gets the technology ahead of its competition, and the founders of the startup get Cisco stock (which has performed phenomenally in recent years) as well as Cisco’s powerful marketing muscle. Volpi’s acquisitions make him one of “the most influential dealmakers in technology, giving him,in many ways, more power than the myriad investment bankers and venture capitalists plying their trade in Silicon Valley,” wrote The New York Timeslast year. Born in Milan, raised in Tokyo and educated at U.S. universities (including an MBA from Stanford), Volpi demonstrates that innovations in ways of doing business can shape the technology landscape just as surely as dramatic new findings from the lab bench.</p></td>
    </tr>
    <tr>
      <td>Hakon Wium Lie</td>
      <td></td>
      <td>34</td>
      <td>Opera Software</td>
      <td>computing-1999</td>
      <td><p>Scandinavia is one of the most wired regions in the world. And within that realm, Håkon Wium Lie is a key player. As an early colleague of World Wide Web inventor Tim Berners-Lee, Lie has had a central role in the Web’s evolution–particularly in relation to browsers. Working with Berners-Lee in Switzerland in 1994, Lie proposed the concept of cascading style sheets (CSS). CSS is a mechanism for adding typographical style (different fonts, color, spacing) to Web documents. Today, almost every major maker of Web browsers has adopted CSS–a big reason why Web sites look so much better than they did five years ago. Asthe Web matured, Lie’s career grew with it. When the World Wide Web Consortium (W3C) was organized to govern Web standards, Lie set up the W3C technical team in France. His chief concern was to maintain open (rather than proprietary) systems so the Web remained accessible to people using the widest array of access software. Lie has taken that passion for choice into the private sector as CTO of Oslo Web browser company Opera Software. <br></p>  <p>Opera claims to be one of the most standards-compliant browser companies in the industry, and Lie’s experience at W3C clearly helped them get that way.</p></td>
    </tr>
    <tr>
      <td>Jerry Yang</td>
      <td></td>
      <td>29</td>
      <td>Yahoo!</td>
      <td>computing-1999</td>
      <td><p>In book publishing, indexing is almost an afterthought. In electronic publishing, indexers are kings of the jungle. What started in 1993 on a Stanford grad student’s home page as “Jerry’s Guide to the World Wide Web”–a categorized list of sites, managed by a search engine–became “Yet Another Hierarchical Officious Oracle.” Today, millions know it as Yahoo!, and it has become the second-most-visited site on the Web. Thanks to Jerry Yang’s irreverent tone, and to top-notch programming by a fellow Stanford grad student, David Filo, Yahoo! had a huge part in making the Web accessible to people who didn’t consider themselves computer-wise. After dropping out of grad school to take Yahoo! public, Yang has seen his worth in stock and options top $1 billion. <br></p>  <p>Born Chih-Yuan Yang in Taiwan, he was 10 when his family immigrated to Silicon Valley. Speaking recently on “The Motley Fool Radio Hour” about his astounding success, Yang said, “It’s a dream come true, and in many ways it’s what America is all about: Nowhere else in the world could people like me do something like this.” Having described himself as “lazy” in grad school, now he is known at Yahoo! as Grumpy (his official title: ChiefYahoo) due to his fixation on staying ahead of the competition. <br></p>  <p>Is Happy in his future?</p></td>
    </tr>
  </tbody>
</table>